{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"xhRVpY12qvzD"},"outputs":[],"source":["#from google.colab import drive\n","#drive.mount('/content/gdrive')\n","#path = '/content/gdrive/My Drive/Colab Notebooks/707/Labs/'\n","#import sys\n","#sys.path.append(path)"]},{"cell_type":"code","source":["!pip install Box2D\n","!pip install box2d-py\n","!pip install gym[all]\n","!pip install gym[Box_2D]\n","!pip install torc\n","!pip install -U \"ray[rllib]\" torch\n","import gym \n","env = gym.make(\"LunarLander-v2\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FrHcoNvJFxl8","executionInfo":{"status":"ok","timestamp":1649850969257,"user_tz":-60,"elapsed":121333,"user":{"displayName":"k Yuichi","userId":"17236341909464291729"}},"outputId":"2981436e-8e04-4237-c6ec-455cef0d2a51"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: Box2D in /usr/local/lib/python3.7/dist-packages (2.3.10)\n","Requirement already satisfied: box2d-py in /usr/local/lib/python3.7/dist-packages (2.3.8)\n","Requirement already satisfied: gym[all] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[all]) (1.5.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[all]) (1.4.1)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[all]) (1.3.0)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[all]) (1.21.5)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym[all]) (7.1.2)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from gym[all]) (2.4.1)\n","Requirement already satisfied: box2d-py~=2.3.5 in /usr/local/lib/python3.7/dist-packages (from gym[all]) (2.3.8)\n","Collecting mujoco-py<2.0,>=1.50\n","  Using cached mujoco-py-1.50.1.68.tar.gz (120 kB)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gym[all]) (4.1.2.30)\n","Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[all]) (0.2.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py~=0.2.0->gym[all]) (1.15.0)\n","Requirement already satisfied: glfw>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from mujoco-py<2.0,>=1.50->gym[all]) (2.5.3)\n","Requirement already satisfied: Cython>=0.27.2 in /usr/local/lib/python3.7/dist-packages (from mujoco-py<2.0,>=1.50->gym[all]) (0.29.28)\n","Requirement already satisfied: cffi>=1.10 in /usr/local/lib/python3.7/dist-packages (from mujoco-py<2.0,>=1.50->gym[all]) (1.15.0)\n","Requirement already satisfied: lockfile>=0.12.2 in /usr/local/lib/python3.7/dist-packages (from mujoco-py<2.0,>=1.50->gym[all]) (0.12.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.10->mujoco-py<2.0,>=1.50->gym[all]) (2.21)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[all]) (0.16.0)\n","Building wheels for collected packages: mujoco-py\n","  Building wheel for mujoco-py (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for mujoco-py\u001b[0m\n","\u001b[?25h  Running setup.py clean for mujoco-py\n","Failed to build mujoco-py\n","Installing collected packages: mujoco-py\n","    Running setup.py install for mujoco-py ... \u001b[?25l\u001b[?25herror\n","\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-nbj3qvf7/mujoco-py_8397aa03472a45909340414fb455142b/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-nbj3qvf7/mujoco-py_8397aa03472a45909340414fb455142b/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-_v5a1a3m/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/mujoco-py Check the logs for full command output.\u001b[0m\n","Requirement already satisfied: gym[Box_2D] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n","\u001b[33mWARNING: gym 0.17.3 does not provide the extra 'box_2d'\u001b[0m\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.4.1)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.21.5)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.5.0)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.3.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[Box_2D]) (0.16.0)\n","Requirement already satisfied: torc in /usr/local/lib/python3.7/dist-packages (0.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torc) (1.21.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torc) (1.4.1)\n","Collecting ray[rllib]\n","  Downloading ray-1.11.0-cp37-cp37m-manylinux2014_x86_64.whl (52.7 MB)\n","\u001b[K     |████████████████████████████████| 52.7 MB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n","Collecting torch\n","  Downloading torch-1.11.0-cp37-cp37m-manylinux1_x86_64.whl (750.6 MB)\n","\u001b[K     |████████████████████████████████| 750.6 MB 10 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n","Collecting redis>=3.5.0\n","  Downloading redis-4.2.2-py3-none-any.whl (226 kB)\n","\u001b[K     |████████████████████████████████| 226 kB 79.2 MB/s \n","\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (7.1.2)\n","Collecting grpcio<=1.43.0,>=1.28.1\n","  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n","\u001b[K     |████████████████████████████████| 4.1 MB 71.7 MB/s \n","\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (4.3.3)\n","Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (3.17.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (3.13)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (21.4.0)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (1.0.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (3.6.0)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (1.21.5)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (0.8.9)\n","Requirement already satisfied: gym<0.22 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (0.17.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (1.3.5)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (0.18.3)\n","Requirement already satisfied: matplotlib!=3.4.3 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (3.2.2)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (0.1.6)\n","Collecting tensorboardX>=1.9\n","  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 87.1 MB/s \n","\u001b[?25hCollecting lz4\n","  Downloading lz4-4.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 79.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (2.23.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (1.4.1)\n","Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.28.1->ray[rllib]) (1.15.0)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym<0.22->ray[rllib]) (1.5.0)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym<0.22->ray[rllib]) (1.3.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.4.3->ray[rllib]) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.4.3->ray[rllib]) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.4.3->ray[rllib]) (1.4.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.4.3->ray[rllib]) (3.0.7)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym<0.22->ray[rllib]) (0.16.0)\n","Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[rllib]) (21.3)\n","Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[rllib]) (4.11.3)\n","Collecting deprecated>=1.2.3\n","  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n","Collecting async-timeout>=4.0.2\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[rllib]) (1.14.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[rllib]) (3.7.0)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[rllib]) (5.4.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[rllib]) (0.18.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[rllib]) (2018.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[rllib]) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[rllib]) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[rllib]) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray[rllib]) (2.10)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->ray[rllib]) (2.6.3)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->ray[rllib]) (2021.11.2)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->ray[rllib]) (2.4.1)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->ray[rllib]) (1.3.0)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->ray[rllib]) (7.1.2)\n","Installing collected packages: deprecated, async-timeout, redis, grpcio, tensorboardX, ray, lz4, torch\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.44.0\n","    Uninstalling grpcio-1.44.0:\n","      Successfully uninstalled grpcio-1.44.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n","torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.11.0 which is incompatible.\n","torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.11.0 which is incompatible.\n","torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.11.0 which is incompatible.\u001b[0m\n","Successfully installed async-timeout-4.0.2 deprecated-1.2.13 grpcio-1.43.0 lz4-4.0.0 ray-1.11.0 redis-4.2.2 tensorboardX-2.5 torch-1.11.0\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"id":"XRSA3yCcxoCJ","executionInfo":{"status":"ok","timestamp":1649851150742,"user_tz":-60,"elapsed":3,"user":{"displayName":"k Yuichi","userId":"17236341909464291729"}}},"outputs":[],"source":["import ray\n","import ray.rllib.agents.dqn as dqn\n","\n","def evaluation_fn(result):\n","    return result['episode_reward_mean']\n","\n","\n","def objective_fn(config):\n","\n","    \n","    trainer = dqn.DQNTrainer(config=config)\n","\n","    for i in range(40):\n","      # Perform one iteration of training the policy with DQN\n","      result = trainer.train()\n","      intermediate_score = evaluation_fn(result)\n","      \n","      # Feed the score back back to Tune.\n","      tune.report(iterations=i, mean_reward=intermediate_score)\n","      "]},{"cell_type":"markdown","metadata":{"id":"QauOX-mbyqp_"},"source":["## Use DQN and train your algorithm on the Dungeon environment.\n","\n","You can take inspiration from:\n","https://docs.ray.io/en/latest/rllib/rllib-training.html#basic-python-api\n","\n","Experiment with the different parameters of the configuration:\n","https://docs.ray.io/en/latest/rllib/rllib-algorithms.html#deep-q-networks-dqn-rainbow-parametric-dqn\n","\n","\n","\n"]},{"cell_type":"code","source":["\n","import ray\n","import ray.rllib.agents.dqn as dqn\n","from ray.tune.logger import pretty_print\n","from ray import tune \n","\n","config = dqn.DEFAULT_CONFIG.copy()\n","config[\"dueling\"] = tune.grid_search([True, False])\n","config[\"double_q\"] = tune.grid_search([True, False])\n","config[\"model\"] = { \"fcnet_hiddens\": [128, 128, 128],\n","                    \"fcnet_activation\": 'relu',\n","    }\n","config[\"env\"] = \"LunarLander-v2\"\n","#config['lr'] = tune.loguniform(1e-4, 1e-1),\n","config[\"gamma\"] = tune.uniform(0, 1)\n","\n","analysis = tune.run(\n","        objective_fn,\n","        metric=\"mean_reward\",\n","        mode=\"max\",\n","        num_samples=3,\n","        config=config)\n","\n","\n","print(\"Best hyperparameters found were: \", analysis.best_config)\n"],"metadata":{"id":"CvzsysIZfjTc","executionInfo":{"status":"ok","timestamp":1649851527388,"user_tz":-60,"elapsed":221945,"user":{"displayName":"k Yuichi","userId":"17236341909464291729"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"704719cf-4197-4e0c-ad36-3ac940f0390d"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:01:53 (running for 00:00:00.17)<br>Memory usage on this node: 2.4/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 PENDING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc  </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>PENDING </td><td>     </td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>PENDING </td><td>     </td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>PENDING </td><td>     </td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>PENDING </td><td>     </td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>PENDING </td><td>     </td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>PENDING </td><td>     </td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>PENDING </td><td>     </td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>PENDING </td><td>     </td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>PENDING </td><td>     </td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>PENDING </td><td>     </td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>PENDING </td><td>     </td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>PENDING </td><td>     </td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[2m\u001b[36m(ImplicitFunc pid=2775)\u001b[0m 2022-04-13 12:01:58,874\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=2775)\u001b[0m 2022-04-13 12:01:58,895\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(objective_fn pid=2775)\u001b[0m 2022-04-13 12:01:58,895\tINFO simple_q.py:155 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n","\u001b[2m\u001b[36m(objective_fn pid=2775)\u001b[0m 2022-04-13 12:01:58,895\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n","\u001b[2m\u001b[36m(ImplicitFunc pid=2769)\u001b[0m 2022-04-13 12:01:58,872\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=2769)\u001b[0m 2022-04-13 12:01:58,893\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(objective_fn pid=2769)\u001b[0m 2022-04-13 12:01:58,894\tINFO simple_q.py:155 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n","\u001b[2m\u001b[36m(objective_fn pid=2769)\u001b[0m 2022-04-13 12:01:58,894\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n","\u001b[2m\u001b[36m(ImplicitFunc pid=2776)\u001b[0m 2022-04-13 12:01:58,897\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=2776)\u001b[0m 2022-04-13 12:01:58,919\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(objective_fn pid=2776)\u001b[0m 2022-04-13 12:01:58,919\tINFO simple_q.py:155 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n","\u001b[2m\u001b[36m(objective_fn pid=2776)\u001b[0m 2022-04-13 12:01:58,919\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n","\u001b[2m\u001b[36m(ImplicitFunc pid=2768)\u001b[0m 2022-04-13 12:01:58,909\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=2768)\u001b[0m 2022-04-13 12:01:58,930\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(objective_fn pid=2768)\u001b[0m 2022-04-13 12:01:58,930\tINFO simple_q.py:155 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n","\u001b[2m\u001b[36m(objective_fn pid=2768)\u001b[0m 2022-04-13 12:01:58,931\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n","\u001b[2m\u001b[36m(ImplicitFunc pid=2778)\u001b[0m 2022-04-13 12:01:58,875\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=2778)\u001b[0m 2022-04-13 12:01:58,895\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(objective_fn pid=2778)\u001b[0m 2022-04-13 12:01:58,896\tINFO simple_q.py:155 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n","\u001b[2m\u001b[36m(objective_fn pid=2778)\u001b[0m 2022-04-13 12:01:58,896\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n","\u001b[2m\u001b[36m(ImplicitFunc pid=2773)\u001b[0m 2022-04-13 12:01:58,912\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=2773)\u001b[0m 2022-04-13 12:01:58,933\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(objective_fn pid=2773)\u001b[0m 2022-04-13 12:01:58,933\tINFO simple_q.py:155 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n","\u001b[2m\u001b[36m(objective_fn pid=2773)\u001b[0m 2022-04-13 12:01:58,933\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n","\u001b[2m\u001b[36m(ImplicitFunc pid=2772)\u001b[0m 2022-04-13 12:01:58,913\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=2772)\u001b[0m 2022-04-13 12:01:58,934\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(objective_fn pid=2772)\u001b[0m 2022-04-13 12:01:58,934\tINFO simple_q.py:155 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n","\u001b[2m\u001b[36m(objective_fn pid=2772)\u001b[0m 2022-04-13 12:01:58,935\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n","\u001b[2m\u001b[36m(ImplicitFunc pid=2767)\u001b[0m 2022-04-13 12:01:58,923\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=2767)\u001b[0m 2022-04-13 12:01:58,943\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(objective_fn pid=2767)\u001b[0m 2022-04-13 12:01:58,944\tINFO simple_q.py:155 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n","\u001b[2m\u001b[36m(objective_fn pid=2767)\u001b[0m 2022-04-13 12:01:58,944\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n","\u001b[2m\u001b[36m(ImplicitFunc pid=2771)\u001b[0m 2022-04-13 12:01:58,872\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=2771)\u001b[0m 2022-04-13 12:01:58,894\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(objective_fn pid=2771)\u001b[0m 2022-04-13 12:01:58,894\tINFO simple_q.py:155 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n","\u001b[2m\u001b[36m(objective_fn pid=2771)\u001b[0m 2022-04-13 12:01:58,894\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n","\u001b[2m\u001b[36m(ImplicitFunc pid=2774)\u001b[0m 2022-04-13 12:01:58,919\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=2774)\u001b[0m 2022-04-13 12:01:58,940\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(objective_fn pid=2774)\u001b[0m 2022-04-13 12:01:58,941\tINFO simple_q.py:155 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n","\u001b[2m\u001b[36m(objective_fn pid=2774)\u001b[0m 2022-04-13 12:01:58,941\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n","\u001b[2m\u001b[36m(ImplicitFunc pid=2777)\u001b[0m 2022-04-13 12:01:58,925\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=2777)\u001b[0m 2022-04-13 12:01:58,945\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(objective_fn pid=2777)\u001b[0m 2022-04-13 12:01:58,945\tINFO simple_q.py:155 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n","\u001b[2m\u001b[36m(objective_fn pid=2777)\u001b[0m 2022-04-13 12:01:58,946\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n","\u001b[2m\u001b[36m(ImplicitFunc pid=2770)\u001b[0m 2022-04-13 12:01:58,885\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=2770)\u001b[0m 2022-04-13 12:01:58,906\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(objective_fn pid=2770)\u001b[0m 2022-04-13 12:01:58,907\tINFO simple_q.py:155 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n","\u001b[2m\u001b[36m(objective_fn pid=2770)\u001b[0m 2022-04-13 12:01:58,907\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:01:59 (running for 00:00:06.13)<br>Memory usage on this node: 6.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[2m\u001b[36m(objective_fn pid=2775)\u001b[0m 2022-04-13 12:02:00,493\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=2768)\u001b[0m 2022-04-13 12:02:00,484\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=2772)\u001b[0m 2022-04-13 12:02:00,495\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=2774)\u001b[0m 2022-04-13 12:02:00,490\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=2777)\u001b[0m 2022-04-13 12:02:00,500\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=2771)\u001b[0m 2022-04-13 12:02:00,524\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=2769)\u001b[0m 2022-04-13 12:02:00,793\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=2773)\u001b[0m 2022-04-13 12:02:00,793\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=2776)\u001b[0m 2022-04-13 12:02:00,866\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=2778)\u001b[0m 2022-04-13 12:02:00,839\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=2767)\u001b[0m 2022-04-13 12:02:00,850\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=2770)\u001b[0m 2022-04-13 12:02:00,832\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n"]},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00011:\n","  date: 2022-04-13_12-02-02\n","  done: false\n","  experiment_id: f576928441b043f48c9de3d6907ccbdd\n","  hostname: aa9ef03c8f27\n","  iterations: 0\n","  iterations_since_restore: 1\n","  mean_reward: -166.21299480738392\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 32.06666666666667\n","    ram_util_percent: 18.53333333333333\n","  pid: 2768\n","  time_since_restore: 3.8993098735809326\n","  time_this_iter_s: 3.8993098735809326\n","  time_total_s: 3.8993098735809326\n","  timestamp: 1649851322\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: 825a7_00011\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-02-02\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 0\n","  iterations_since_restore: 1\n","  mean_reward: -245.5896682354995\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 31.933333333333337\n","    ram_util_percent: 18.516666666666666\n","  pid: 2771\n","  time_since_restore: 3.938135862350464\n","  time_this_iter_s: 3.938135862350464\n","  time_total_s: 3.938135862350464\n","  timestamp: 1649851322\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-02-02\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 0\n","  iterations_since_restore: 1\n","  mean_reward: -160.46369531733646\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 31.933333333333334\n","    ram_util_percent: 18.516666666666666\n","  pid: 2775\n","  time_since_restore: 3.936117649078369\n","  time_this_iter_s: 3.936117649078369\n","  time_total_s: 3.936117649078369\n","  timestamp: 1649851322\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00002:\n","  date: 2022-04-13_12-02-02\n","  done: false\n","  experiment_id: 315539c1caa744e78ed8486a6a2213a0\n","  hostname: aa9ef03c8f27\n","  iterations: 0\n","  iterations_since_restore: 1\n","  mean_reward: -210.09260237271388\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 32.1\n","    ram_util_percent: 18.55\n","  pid: 2774\n","  time_since_restore: 3.8971478939056396\n","  time_this_iter_s: 3.8971478939056396\n","  time_total_s: 3.8971478939056396\n","  timestamp: 1649851322\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: 825a7_00002\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-02-02\n","  done: false\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  hostname: aa9ef03c8f27\n","  iterations: 0\n","  iterations_since_restore: 1\n","  mean_reward: -217.5596390699512\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 32.083333333333336\n","    ram_util_percent: 18.55\n","  pid: 2777\n","  time_since_restore: 3.887202262878418\n","  time_this_iter_s: 3.887202262878418\n","  time_total_s: 3.887202262878418\n","  timestamp: 1649851322\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: 825a7_00010\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00006:\n","  date: 2022-04-13_12-02-02\n","  done: false\n","  experiment_id: 1452367bf557484fb196e21a6489d80a\n","  hostname: aa9ef03c8f27\n","  iterations: 0\n","  iterations_since_restore: 1\n","  mean_reward: -194.79528965226504\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 32.03333333333334\n","    ram_util_percent: 18.53333333333333\n","  pid: 2772\n","  time_since_restore: 3.93534255027771\n","  time_this_iter_s: 3.93534255027771\n","  time_total_s: 3.93534255027771\n","  timestamp: 1649851322\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: 825a7_00006\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00009:\n","  date: 2022-04-13_12-02-03\n","  done: false\n","  experiment_id: 95c2bb28a0b642edb97e6a45503efe15\n","  hostname: aa9ef03c8f27\n","  iterations: 0\n","  iterations_since_restore: 1\n","  mean_reward: -194.0498163052829\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 33.457142857142856\n","    ram_util_percent: 18.585714285714285\n","  pid: 2769\n","  time_since_restore: 4.243354797363281\n","  time_this_iter_s: 4.243354797363281\n","  time_total_s: 4.243354797363281\n","  timestamp: 1649851323\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: 825a7_00009\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00005:\n","  date: 2022-04-13_12-02-03\n","  done: false\n","  experiment_id: d42ae5be5b334ba6981aa7673828d6d2\n","  hostname: aa9ef03c8f27\n","  iterations: 0\n","  iterations_since_restore: 1\n","  mean_reward: -194.74053926764927\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 32.949999999999996\n","    ram_util_percent: 18.53333333333333\n","  pid: 2773\n","  time_since_restore: 4.2072179317474365\n","  time_this_iter_s: 4.2072179317474365\n","  time_total_s: 4.2072179317474365\n","  timestamp: 1649851323\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: 825a7_00005\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00000:\n","  date: 2022-04-13_12-02-03\n","  done: false\n","  experiment_id: 696b6ae5d0474799847a48a1fd9db44c\n","  hostname: aa9ef03c8f27\n","  iterations: 0\n","  iterations_since_restore: 1\n","  mean_reward: -153.32779155094704\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 33.58571428571428\n","    ram_util_percent: 18.585714285714285\n","  pid: 2770\n","  time_since_restore: 4.2484190464019775\n","  time_this_iter_s: 4.2484190464019775\n","  time_total_s: 4.2484190464019775\n","  timestamp: 1649851323\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: 825a7_00000\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00001:\n","  date: 2022-04-13_12-02-03\n","  done: false\n","  experiment_id: bee5f156b4e14866b4e9e4f5ab3fad72\n","  hostname: aa9ef03c8f27\n","  iterations: 0\n","  iterations_since_restore: 1\n","  mean_reward: -150.80493764396653\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 33.542857142857144\n","    ram_util_percent: 18.585714285714285\n","  pid: 2778\n","  time_since_restore: 4.268730640411377\n","  time_this_iter_s: 4.268730640411377\n","  time_total_s: 4.268730640411377\n","  timestamp: 1649851323\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: 825a7_00001\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00008:\n","  date: 2022-04-13_12-02-03\n","  done: false\n","  experiment_id: cd76c37ed72a4c299a0583e20567f167\n","  hostname: aa9ef03c8f27\n","  iterations: 0\n","  iterations_since_restore: 1\n","  mean_reward: -178.87109854233105\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 33.84285714285714\n","    ram_util_percent: 18.614285714285717\n","  pid: 2767\n","  time_since_restore: 4.234183073043823\n","  time_this_iter_s: 4.234183073043823\n","  time_total_s: 4.234183073043823\n","  timestamp: 1649851323\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: 825a7_00008\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-02-03\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 0\n","  iterations_since_restore: 1\n","  mean_reward: -203.88119423046302\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 33.800000000000004\n","    ram_util_percent: 18.585714285714285\n","  pid: 2776\n","  time_since_restore: 4.292703628540039\n","  time_this_iter_s: 4.292703628540039\n","  time_total_s: 4.292703628540039\n","  timestamp: 1649851323\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: 825a7_00004\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:02:05 (running for 00:00:11.56)<br>Memory usage on this node: 6.7/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00001 with mean_reward=-150.80493764396653 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.09457191336813742, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': False, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.24842</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">     -153.328</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.26873</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">     -150.805</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.89715</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">     -210.093</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.93612</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">     -160.464</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.2927 </td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">     -203.881</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.20722</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">     -194.741</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.93534</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">     -194.795</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.93814</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">     -245.59 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.23418</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">     -178.871</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.24335</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">     -194.05 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.8872 </td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">     -217.56 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.89931</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">     -166.213</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:02:10 (running for 00:00:16.72)<br>Memory usage on this node: 6.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00000 with mean_reward=-149.42659924630223 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.3029924584127983, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         8.47816</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     -149.427</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         8.51384</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     -162.976</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         8.0379 </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     -171.982</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         8.02946</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     -169.131</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         8.46556</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     -206.07 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         8.4575 </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     -205.912</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         8.00655</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     -176.612</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         8.09409</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     -216.377</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         8.48376</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     -175.02 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         8.49295</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     -174.422</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         8.00579</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     -193.176</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         8.03927</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     -204    </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00006:\n","  date: 2022-04-13_12-02-10\n","  done: false\n","  experiment_id: 1452367bf557484fb196e21a6489d80a\n","  hostname: aa9ef03c8f27\n","  iterations: 2\n","  iterations_since_restore: 3\n","  mean_reward: -166.50167447507954\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.78333333333333\n","    ram_util_percent: 19.266666666666666\n","  pid: 2772\n","  time_since_restore: 12.060600757598877\n","  time_this_iter_s: 4.054053544998169\n","  time_total_s: 12.060600757598877\n","  timestamp: 1649851330\n","  timesteps_since_restore: 0\n","  training_iteration: 3\n","  trial_id: 825a7_00006\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-02-11\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 2\n","  iterations_since_restore: 3\n","  mean_reward: -156.3395874813405\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.78333333333334\n","    ram_util_percent: 19.266666666666666\n","  pid: 2775\n","  time_since_restore: 12.12886381149292\n","  time_this_iter_s: 4.099408149719238\n","  time_total_s: 12.12886381149292\n","  timestamp: 1649851331\n","  timesteps_since_restore: 0\n","  training_iteration: 3\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-02-11\n","  done: false\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  hostname: aa9ef03c8f27\n","  iterations: 2\n","  iterations_since_restore: 3\n","  mean_reward: -171.4611920553176\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.75\n","    ram_util_percent: 19.266666666666666\n","  pid: 2777\n","  time_since_restore: 12.123893976211548\n","  time_this_iter_s: 4.118108510971069\n","  time_total_s: 12.123893976211548\n","  timestamp: 1649851331\n","  timesteps_since_restore: 0\n","  training_iteration: 3\n","  trial_id: 825a7_00010\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00002:\n","  date: 2022-04-13_12-02-11\n","  done: false\n","  experiment_id: 315539c1caa744e78ed8486a6a2213a0\n","  hostname: aa9ef03c8f27\n","  iterations: 2\n","  iterations_since_restore: 3\n","  mean_reward: -155.5342985890209\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.73333333333334\n","    ram_util_percent: 19.266666666666666\n","  pid: 2774\n","  time_since_restore: 12.148907661437988\n","  time_this_iter_s: 4.111004590988159\n","  time_total_s: 12.148907661437988\n","  timestamp: 1649851331\n","  timesteps_since_restore: 0\n","  training_iteration: 3\n","  trial_id: 825a7_00002\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-02-11\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 2\n","  iterations_since_restore: 3\n","  mean_reward: -179.87931249231494\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.76666666666667\n","    ram_util_percent: 19.266666666666666\n","  pid: 2771\n","  time_since_restore: 12.203634977340698\n","  time_this_iter_s: 4.109545946121216\n","  time_total_s: 12.203634977340698\n","  timestamp: 1649851331\n","  timesteps_since_restore: 0\n","  training_iteration: 3\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00011:\n","  date: 2022-04-13_12-02-11\n","  done: false\n","  experiment_id: f576928441b043f48c9de3d6907ccbdd\n","  hostname: aa9ef03c8f27\n","  iterations: 2\n","  iterations_since_restore: 3\n","  mean_reward: -181.43550460662289\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.81666666666666\n","    ram_util_percent: 19.266666666666666\n","  pid: 2768\n","  time_since_restore: 12.205919742584229\n","  time_this_iter_s: 4.166652202606201\n","  time_total_s: 12.205919742584229\n","  timestamp: 1649851331\n","  timesteps_since_restore: 0\n","  training_iteration: 3\n","  trial_id: 825a7_00011\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-02-11\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 2\n","  iterations_since_restore: 3\n","  mean_reward: -179.26791224755632\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.85\n","    ram_util_percent: 19.299999999999997\n","  pid: 2776\n","  time_since_restore: 12.676152467727661\n","  time_this_iter_s: 4.210593938827515\n","  time_total_s: 12.676152467727661\n","  timestamp: 1649851331\n","  timesteps_since_restore: 0\n","  training_iteration: 3\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00005:\n","  date: 2022-04-13_12-02-11\n","  done: false\n","  experiment_id: d42ae5be5b334ba6981aa7673828d6d2\n","  hostname: aa9ef03c8f27\n","  iterations: 2\n","  iterations_since_restore: 3\n","  mean_reward: -175.52709324903367\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.650000000000006\n","    ram_util_percent: 19.299999999999997\n","  pid: 2773\n","  time_since_restore: 12.674591302871704\n","  time_this_iter_s: 4.217090368270874\n","  time_total_s: 12.674591302871704\n","  timestamp: 1649851331\n","  timesteps_since_restore: 0\n","  training_iteration: 3\n","  trial_id: 825a7_00005\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00009:\n","  date: 2022-04-13_12-02-11\n","  done: false\n","  experiment_id: 95c2bb28a0b642edb97e6a45503efe15\n","  hostname: aa9ef03c8f27\n","  iterations: 2\n","  iterations_since_restore: 3\n","  mean_reward: -160.8934379664499\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.81666666666666\n","    ram_util_percent: 19.299999999999997\n","  pid: 2769\n","  time_since_restore: 12.720274925231934\n","  time_this_iter_s: 4.227322816848755\n","  time_total_s: 12.720274925231934\n","  timestamp: 1649851331\n","  timesteps_since_restore: 0\n","  training_iteration: 3\n","  trial_id: 825a7_00009\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00000:\n","  date: 2022-04-13_12-02-11\n","  done: false\n","  experiment_id: 696b6ae5d0474799847a48a1fd9db44c\n","  hostname: aa9ef03c8f27\n","  iterations: 2\n","  iterations_since_restore: 3\n","  mean_reward: -146.0483959361754\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.76666666666666\n","    ram_util_percent: 19.299999999999997\n","  pid: 2770\n","  time_since_restore: 12.704098463058472\n","  time_this_iter_s: 4.225935935974121\n","  time_total_s: 12.704098463058472\n","  timestamp: 1649851331\n","  timesteps_since_restore: 0\n","  training_iteration: 3\n","  trial_id: 825a7_00000\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00008:\n","  date: 2022-04-13_12-02-11\n","  done: false\n","  experiment_id: cd76c37ed72a4c299a0583e20567f167\n","  hostname: aa9ef03c8f27\n","  iterations: 2\n","  iterations_since_restore: 3\n","  mean_reward: -157.2359494946309\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.699999999999996\n","    ram_util_percent: 19.299999999999997\n","  pid: 2767\n","  time_since_restore: 12.727806329727173\n","  time_this_iter_s: 4.244049787521362\n","  time_total_s: 12.727806329727173\n","  timestamp: 1649851331\n","  timesteps_since_restore: 0\n","  training_iteration: 3\n","  trial_id: 825a7_00008\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00001:\n","  date: 2022-04-13_12-02-11\n","  done: false\n","  experiment_id: bee5f156b4e14866b4e9e4f5ab3fad72\n","  hostname: aa9ef03c8f27\n","  iterations: 2\n","  iterations_since_restore: 3\n","  mean_reward: -155.82986089745214\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.98333333333333\n","    ram_util_percent: 19.299999999999997\n","  pid: 2778\n","  time_since_restore: 12.784992933273315\n","  time_this_iter_s: 4.271147966384888\n","  time_total_s: 12.784992933273315\n","  timestamp: 1649851331\n","  timesteps_since_restore: 0\n","  training_iteration: 3\n","  trial_id: 825a7_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:02:15 (running for 00:00:22.14)<br>Memory usage on this node: 6.9/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00000 with mean_reward=-146.0483959361754 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.3029924584127983, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         12.7041</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     -146.048</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         12.785 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     -155.83 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         16.2781</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">     -146.713</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         16.2761</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">     -162.477</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         16.9318</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">     -157.852</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         12.6746</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     -175.527</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         16.2445</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">     -155.657</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         16.3054</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">     -156.218</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         12.7278</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     -157.236</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         12.7203</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     -160.893</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         16.3227</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">     -157.772</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         16.3523</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">     -165.98 </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-02-19\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 4\n","  iterations_since_restore: 5\n","  mean_reward: -147.26406241410123\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.650000000000006\n","    ram_util_percent: 19.53333333333333\n","  pid: 2775\n","  time_since_restore: 20.41099262237549\n","  time_this_iter_s: 4.134925365447998\n","  time_total_s: 20.41099262237549\n","  timestamp: 1649851339\n","  timesteps_since_restore: 0\n","  training_iteration: 5\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00006:\n","  date: 2022-04-13_12-02-19\n","  done: false\n","  experiment_id: 1452367bf557484fb196e21a6489d80a\n","  hostname: aa9ef03c8f27\n","  iterations: 4\n","  iterations_since_restore: 5\n","  mean_reward: -154.1946251047158\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.666666666666664\n","    ram_util_percent: 19.53333333333333\n","  pid: 2772\n","  time_since_restore: 20.372437477111816\n","  time_this_iter_s: 4.127934217453003\n","  time_total_s: 20.372437477111816\n","  timestamp: 1649851339\n","  timesteps_since_restore: 0\n","  training_iteration: 5\n","  trial_id: 825a7_00006\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00002:\n","  date: 2022-04-13_12-02-19\n","  done: false\n","  experiment_id: 315539c1caa744e78ed8486a6a2213a0\n","  hostname: aa9ef03c8f27\n","  iterations: 4\n","  iterations_since_restore: 5\n","  mean_reward: -140.31541865159696\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.61666666666667\n","    ram_util_percent: 19.53333333333333\n","  pid: 2774\n","  time_since_restore: 20.470163345336914\n","  time_this_iter_s: 4.192021131515503\n","  time_total_s: 20.470163345336914\n","  timestamp: 1649851339\n","  timesteps_since_restore: 0\n","  training_iteration: 5\n","  trial_id: 825a7_00002\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-02-19\n","  done: false\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  hostname: aa9ef03c8f27\n","  iterations: 4\n","  iterations_since_restore: 5\n","  mean_reward: -149.41678289745067\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.6\n","    ram_util_percent: 19.53333333333333\n","  pid: 2777\n","  time_since_restore: 20.472172498703003\n","  time_this_iter_s: 4.149442195892334\n","  time_total_s: 20.472172498703003\n","  timestamp: 1649851339\n","  timesteps_since_restore: 0\n","  training_iteration: 5\n","  trial_id: 825a7_00010\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00011:\n","  date: 2022-04-13_12-02-19\n","  done: false\n","  experiment_id: f576928441b043f48c9de3d6907ccbdd\n","  hostname: aa9ef03c8f27\n","  iterations: 4\n","  iterations_since_restore: 5\n","  mean_reward: -155.98873529394618\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.65\n","    ram_util_percent: 19.53333333333333\n","  pid: 2768\n","  time_since_restore: 20.518957376480103\n","  time_this_iter_s: 4.166662693023682\n","  time_total_s: 20.518957376480103\n","  timestamp: 1649851339\n","  timesteps_since_restore: 0\n","  training_iteration: 5\n","  trial_id: 825a7_00011\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-02-19\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 4\n","  iterations_since_restore: 5\n","  mean_reward: -141.86456714464455\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.61666666666667\n","    ram_util_percent: 19.53333333333333\n","  pid: 2771\n","  time_since_restore: 20.563244104385376\n","  time_this_iter_s: 4.2578284740448\n","  time_total_s: 20.563244104385376\n","  timestamp: 1649851339\n","  timesteps_since_restore: 0\n","  training_iteration: 5\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00005:\n","  date: 2022-04-13_12-02-20\n","  done: false\n","  experiment_id: d42ae5be5b334ba6981aa7673828d6d2\n","  hostname: aa9ef03c8f27\n","  iterations: 4\n","  iterations_since_restore: 5\n","  mean_reward: -154.27132546294527\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.29999999999999\n","    ram_util_percent: 19.549999999999997\n","  pid: 2773\n","  time_since_restore: 21.211119890213013\n","  time_this_iter_s: 4.264029502868652\n","  time_total_s: 21.211119890213013\n","  timestamp: 1649851340\n","  timesteps_since_restore: 0\n","  training_iteration: 5\n","  trial_id: 825a7_00005\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00009:\n","  date: 2022-04-13_12-02-20\n","  done: false\n","  experiment_id: 95c2bb28a0b642edb97e6a45503efe15\n","  hostname: aa9ef03c8f27\n","  iterations: 4\n","  iterations_since_restore: 5\n","  mean_reward: -140.53259265506918\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.333333333333336\n","    ram_util_percent: 19.549999999999997\n","  pid: 2769\n","  time_since_restore: 21.27227020263672\n","  time_this_iter_s: 4.266440391540527\n","  time_total_s: 21.27227020263672\n","  timestamp: 1649851340\n","  timesteps_since_restore: 0\n","  training_iteration: 5\n","  trial_id: 825a7_00009\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00000:\n","  date: 2022-04-13_12-02-20\n","  done: false\n","  experiment_id: 696b6ae5d0474799847a48a1fd9db44c\n","  hostname: aa9ef03c8f27\n","  iterations: 4\n","  iterations_since_restore: 5\n","  mean_reward: -130.3533003045916\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.4\n","    ram_util_percent: 19.549999999999997\n","  pid: 2770\n","  time_since_restore: 21.269187450408936\n","  time_this_iter_s: 4.24960732460022\n","  time_total_s: 21.269187450408936\n","  timestamp: 1649851340\n","  timesteps_since_restore: 0\n","  training_iteration: 5\n","  trial_id: 825a7_00000\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-02-20\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 4\n","  iterations_since_restore: 5\n","  mean_reward: -144.33116502856635\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.449999999999996\n","    ram_util_percent: 19.549999999999997\n","  pid: 2776\n","  time_since_restore: 21.26264500617981\n","  time_this_iter_s: 4.330827474594116\n","  time_total_s: 21.26264500617981\n","  timestamp: 1649851340\n","  timesteps_since_restore: 0\n","  training_iteration: 5\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00001:\n","  date: 2022-04-13_12-02-20\n","  done: false\n","  experiment_id: bee5f156b4e14866b4e9e4f5ab3fad72\n","  hostname: aa9ef03c8f27\n","  iterations: 4\n","  iterations_since_restore: 5\n","  mean_reward: -158.1108254950882\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.300000000000004\n","    ram_util_percent: 19.549999999999997\n","  pid: 2778\n","  time_since_restore: 21.365102291107178\n","  time_this_iter_s: 4.294870615005493\n","  time_total_s: 21.365102291107178\n","  timestamp: 1649851340\n","  timesteps_since_restore: 0\n","  training_iteration: 5\n","  trial_id: 825a7_00001\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00008:\n","  date: 2022-04-13_12-02-20\n","  done: false\n","  experiment_id: cd76c37ed72a4c299a0583e20567f167\n","  hostname: aa9ef03c8f27\n","  iterations: 4\n","  iterations_since_restore: 5\n","  mean_reward: -141.98456684481425\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.349999999999994\n","    ram_util_percent: 19.549999999999997\n","  pid: 2767\n","  time_since_restore: 21.32063603401184\n","  time_this_iter_s: 4.3171021938323975\n","  time_total_s: 21.32063603401184\n","  timestamp: 1649851340\n","  timesteps_since_restore: 0\n","  training_iteration: 5\n","  trial_id: 825a7_00008\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:02:21 (running for 00:00:27.57)<br>Memory usage on this node: 6.9/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00000 with mean_reward=-130.3533003045916 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.3029924584127983, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         21.2692</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">     -130.353</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         21.3651</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">     -158.111</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         20.4702</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">     -140.315</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         20.411 </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">     -147.264</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         21.2626</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">     -144.331</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         21.2111</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">     -154.271</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         20.3724</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">     -154.195</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         20.5632</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">     -141.865</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         21.3206</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">     -141.985</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         21.2723</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">     -140.533</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         20.4722</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">     -149.417</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         20.519 </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">     -155.989</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-02-24\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 5\n","  iterations_since_restore: 6\n","  mean_reward: -144.14984392333702\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.24285714285714\n","    ram_util_percent: 19.657142857142855\n","  pid: 2775\n","  time_since_restore: 25.711780071258545\n","  time_this_iter_s: 5.300787448883057\n","  time_total_s: 25.711780071258545\n","  timestamp: 1649851344\n","  timesteps_since_restore: 0\n","  training_iteration: 6\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-02-25\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 5\n","  iterations_since_restore: 6\n","  mean_reward: -138.20889952538994\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.042857142857144\n","    ram_util_percent: 19.671428571428574\n","  pid: 2776\n","  time_since_restore: 26.46008276939392\n","  time_this_iter_s: 5.197437763214111\n","  time_total_s: 26.46008276939392\n","  timestamp: 1649851345\n","  timesteps_since_restore: 0\n","  training_iteration: 6\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00000:\n","  date: 2022-04-13_12-02-25\n","  done: false\n","  experiment_id: 696b6ae5d0474799847a48a1fd9db44c\n","  hostname: aa9ef03c8f27\n","  iterations: 5\n","  iterations_since_restore: 6\n","  mean_reward: -133.94904995245588\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.042857142857144\n","    ram_util_percent: 19.671428571428574\n","  pid: 2770\n","  time_since_restore: 26.538673400878906\n","  time_this_iter_s: 5.269485950469971\n","  time_total_s: 26.538673400878906\n","  timestamp: 1649851345\n","  timesteps_since_restore: 0\n","  training_iteration: 6\n","  trial_id: 825a7_00000\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00008:\n","  date: 2022-04-13_12-02-26\n","  done: false\n","  experiment_id: cd76c37ed72a4c299a0583e20567f167\n","  hostname: aa9ef03c8f27\n","  iterations: 5\n","  iterations_since_restore: 6\n","  mean_reward: -136.94697349277158\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.925\n","    ram_util_percent: 19.674999999999997\n","  pid: 2767\n","  time_since_restore: 27.18071985244751\n","  time_this_iter_s: 5.860083818435669\n","  time_total_s: 27.18071985244751\n","  timestamp: 1649851346\n","  timesteps_since_restore: 0\n","  training_iteration: 6\n","  trial_id: 825a7_00008\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:02:27 (running for 00:00:33.42)<br>Memory usage on this node: 7.0/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00000 with mean_reward=-133.94904995245588 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.3029924584127983, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         26.5387</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">     -133.949</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         25.9638</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">     -156.398</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         24.6718</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">     -136.566</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         25.7118</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">     -144.15 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         26.4601</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">     -138.209</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         25.6827</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">     -146.674</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         24.622 </td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">     -152.342</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         24.846 </td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">     -135.543</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         27.1807</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">     -136.947</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         25.7254</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">     -140.871</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         24.6707</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">     -142.012</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         25.2153</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">     -156.836</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00002:\n","  date: 2022-04-13_12-02-28\n","  done: false\n","  experiment_id: 315539c1caa744e78ed8486a6a2213a0\n","  hostname: aa9ef03c8f27\n","  iterations: 6\n","  iterations_since_restore: 7\n","  mean_reward: -139.22278837326002\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.66666666666667\n","    ram_util_percent: 19.749999999999996\n","  pid: 2774\n","  time_since_restore: 29.101385354995728\n","  time_this_iter_s: 4.429619312286377\n","  time_total_s: 29.101385354995728\n","  timestamp: 1649851348\n","  timesteps_since_restore: 0\n","  training_iteration: 7\n","  trial_id: 825a7_00002\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00006:\n","  date: 2022-04-13_12-02-28\n","  done: false\n","  experiment_id: 1452367bf557484fb196e21a6489d80a\n","  hostname: aa9ef03c8f27\n","  iterations: 6\n","  iterations_since_restore: 7\n","  mean_reward: -153.8137040796629\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.63333333333333\n","    ram_util_percent: 19.749999999999996\n","  pid: 2772\n","  time_since_restore: 29.300413370132446\n","  time_this_iter_s: 4.67841100692749\n","  time_total_s: 29.300413370132446\n","  timestamp: 1649851348\n","  timesteps_since_restore: 0\n","  training_iteration: 7\n","  trial_id: 825a7_00006\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-02-28\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 6\n","  iterations_since_restore: 7\n","  mean_reward: -136.59517278591383\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.642857142857146\n","    ram_util_percent: 19.757142857142856\n","  pid: 2771\n","  time_since_restore: 29.689208984375\n","  time_this_iter_s: 4.843159437179565\n","  time_total_s: 29.689208984375\n","  timestamp: 1649851348\n","  timesteps_since_restore: 0\n","  training_iteration: 7\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00009:\n","  date: 2022-04-13_12-02-29\n","  done: false\n","  experiment_id: 95c2bb28a0b642edb97e6a45503efe15\n","  hostname: aa9ef03c8f27\n","  iterations: 6\n","  iterations_since_restore: 7\n","  mean_reward: -134.04968747695705\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.34285714285714\n","    ram_util_percent: 19.771428571428572\n","  pid: 2769\n","  time_since_restore: 30.27952527999878\n","  time_this_iter_s: 4.554155349731445\n","  time_total_s: 30.27952527999878\n","  timestamp: 1649851349\n","  timesteps_since_restore: 0\n","  training_iteration: 7\n","  trial_id: 825a7_00009\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00011:\n","  date: 2022-04-13_12-02-29\n","  done: false\n","  experiment_id: f576928441b043f48c9de3d6907ccbdd\n","  hostname: aa9ef03c8f27\n","  iterations: 6\n","  iterations_since_restore: 7\n","  mean_reward: -158.45056346960428\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.75\n","    ram_util_percent: 19.762500000000003\n","  pid: 2768\n","  time_since_restore: 30.247448682785034\n","  time_this_iter_s: 5.032193660736084\n","  time_total_s: 30.247448682785034\n","  timestamp: 1649851349\n","  timesteps_since_restore: 0\n","  training_iteration: 7\n","  trial_id: 825a7_00011\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00005:\n","  date: 2022-04-13_12-02-29\n","  done: false\n","  experiment_id: d42ae5be5b334ba6981aa7673828d6d2\n","  hostname: aa9ef03c8f27\n","  iterations: 6\n","  iterations_since_restore: 7\n","  mean_reward: -146.03909579082426\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.86666666666667\n","    ram_util_percent: 19.766666666666666\n","  pid: 2773\n","  time_since_restore: 30.249660968780518\n","  time_this_iter_s: 4.566953897476196\n","  time_total_s: 30.249660968780518\n","  timestamp: 1649851349\n","  timesteps_since_restore: 0\n","  training_iteration: 7\n","  trial_id: 825a7_00005\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00001:\n","  date: 2022-04-13_12-02-29\n","  done: false\n","  experiment_id: bee5f156b4e14866b4e9e4f5ab3fad72\n","  hostname: aa9ef03c8f27\n","  iterations: 6\n","  iterations_since_restore: 7\n","  mean_reward: -164.0821124059291\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.15714285714286\n","    ram_util_percent: 19.771428571428572\n","  pid: 2778\n","  time_since_restore: 30.530730485916138\n","  time_this_iter_s: 4.566930532455444\n","  time_total_s: 30.530730485916138\n","  timestamp: 1649851349\n","  timesteps_since_restore: 0\n","  training_iteration: 7\n","  trial_id: 825a7_00001\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-02-29\n","  done: false\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  hostname: aa9ef03c8f27\n","  iterations: 6\n","  iterations_since_restore: 7\n","  mean_reward: -137.95619267794658\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.7\n","    ram_util_percent: 19.762500000000003\n","  pid: 2777\n","  time_since_restore: 30.602635383605957\n","  time_this_iter_s: 5.931981801986694\n","  time_total_s: 30.602635383605957\n","  timestamp: 1649851349\n","  timesteps_since_restore: 0\n","  training_iteration: 7\n","  trial_id: 825a7_00010\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-02-30\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 6\n","  iterations_since_restore: 7\n","  mean_reward: -135.60382165420185\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.11428571428571\n","    ram_util_percent: 19.785714285714285\n","  pid: 2776\n","  time_since_restore: 31.548377990722656\n","  time_this_iter_s: 5.088295221328735\n","  time_total_s: 31.548377990722656\n","  timestamp: 1649851350\n","  timesteps_since_restore: 0\n","  training_iteration: 7\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-02-30\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 6\n","  iterations_since_restore: 7\n","  mean_reward: -139.84413714457705\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.8125\n","    ram_util_percent: 19.775\n","  pid: 2775\n","  time_since_restore: 31.61641836166382\n","  time_this_iter_s: 5.904638290405273\n","  time_total_s: 31.61641836166382\n","  timestamp: 1649851350\n","  timesteps_since_restore: 0\n","  training_iteration: 7\n","  trial_id: 825a7_00003\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:02:32 (running for 00:00:38.74)<br>Memory usage on this node: 7.0/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00000 with mean_reward=-127.48777613320522 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.3029924584127983, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         31.3805</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">     -127.488</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         30.5307</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">     -164.082</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         33.5072</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">     -148.037</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         31.6164</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">     -139.844</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         31.5484</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">     -135.604</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         30.2497</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">     -146.039</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         29.3004</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">     -153.814</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         29.6892</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">     -136.595</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         31.7648</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">     -135.543</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         30.2795</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">     -134.05 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         30.6026</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">     -137.956</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         30.2474</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">     -158.451</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-02-33\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 7\n","  iterations_since_restore: 8\n","  mean_reward: -143.78197369735676\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.285714285714285\n","    ram_util_percent: 19.842857142857145\n","  pid: 2771\n","  time_since_restore: 34.761775732040405\n","  time_this_iter_s: 5.072566747665405\n","  time_total_s: 34.761775732040405\n","  timestamp: 1649851353\n","  timesteps_since_restore: 0\n","  training_iteration: 8\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00000:\n","  date: 2022-04-13_12-02-34\n","  done: false\n","  experiment_id: 696b6ae5d0474799847a48a1fd9db44c\n","  hostname: aa9ef03c8f27\n","  iterations: 7\n","  iterations_since_restore: 8\n","  mean_reward: -117.68687466279364\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.75\n","    ram_util_percent: 19.86666666666667\n","  pid: 2770\n","  time_since_restore: 35.80561327934265\n","  time_this_iter_s: 4.425094127655029\n","  time_total_s: 35.80561327934265\n","  timestamp: 1649851354\n","  timesteps_since_restore: 0\n","  training_iteration: 8\n","  trial_id: 825a7_00000\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00008:\n","  date: 2022-04-13_12-02-35\n","  done: false\n","  experiment_id: cd76c37ed72a4c299a0583e20567f167\n","  hostname: aa9ef03c8f27\n","  iterations: 7\n","  iterations_since_restore: 8\n","  mean_reward: -133.4616072385505\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.042857142857144\n","    ram_util_percent: 19.88571428571429\n","  pid: 2767\n","  time_since_restore: 36.87636852264404\n","  time_this_iter_s: 5.111524343490601\n","  time_total_s: 36.87636852264404\n","  timestamp: 1649851355\n","  timesteps_since_restore: 0\n","  training_iteration: 8\n","  trial_id: 825a7_00008\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-02-36\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 7\n","  iterations_since_restore: 8\n","  mean_reward: -132.19163141368932\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.8\n","    ram_util_percent: 19.88888888888889\n","  pid: 2776\n","  time_since_restore: 37.44069719314575\n","  time_this_iter_s: 5.892319202423096\n","  time_total_s: 37.44069719314575\n","  timestamp: 1649851356\n","  timesteps_since_restore: 0\n","  training_iteration: 8\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00002:\n","  date: 2022-04-13_12-02-36\n","  done: false\n","  experiment_id: 315539c1caa744e78ed8486a6a2213a0\n","  hostname: aa9ef03c8f27\n","  iterations: 8\n","  iterations_since_restore: 9\n","  mean_reward: -145.21628555887236\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.166666666666664\n","    ram_util_percent: 19.916666666666668\n","  pid: 2774\n","  time_since_restore: 37.90869998931885\n","  time_this_iter_s: 4.401527166366577\n","  time_total_s: 37.90869998931885\n","  timestamp: 1649851356\n","  timesteps_since_restore: 0\n","  training_iteration: 9\n","  trial_id: 825a7_00002\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00006:\n","  date: 2022-04-13_12-02-37\n","  done: false\n","  experiment_id: 1452367bf557484fb196e21a6489d80a\n","  hostname: aa9ef03c8f27\n","  iterations: 8\n","  iterations_since_restore: 9\n","  mean_reward: -149.36322674215208\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.957142857142856\n","    ram_util_percent: 19.928571428571427\n","  pid: 2772\n","  time_since_restore: 38.119041442871094\n","  time_this_iter_s: 4.419754505157471\n","  time_total_s: 38.119041442871094\n","  timestamp: 1649851357\n","  timesteps_since_restore: 0\n","  training_iteration: 9\n","  trial_id: 825a7_00006\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:02:38 (running for 00:00:44.35)<br>Memory usage on this node: 7.1/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00000 with mean_reward=-117.68687466279364 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.3029924584127983, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         35.8056</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">     -117.687</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         34.9046</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">     -159.256</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         37.9087</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     -145.216</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         36.081 </td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">     -138.131</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         37.4407</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">     -132.192</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         34.9156</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">     -154.315</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         38.119 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     -149.363</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         34.7618</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">     -143.782</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         36.8764</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">     -133.462</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         34.6672</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">     -143.001</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         35.2028</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">     -138.903</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         34.9267</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">     -157.068</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00009:\n","  date: 2022-04-13_12-02-38\n","  done: false\n","  experiment_id: 95c2bb28a0b642edb97e6a45503efe15\n","  hostname: aa9ef03c8f27\n","  iterations: 8\n","  iterations_since_restore: 9\n","  mean_reward: -150.41559464635355\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.03333333333334\n","    ram_util_percent: 19.95\n","  pid: 2769\n","  time_since_restore: 39.21811509132385\n","  time_this_iter_s: 4.550882339477539\n","  time_total_s: 39.21811509132385\n","  timestamp: 1649851358\n","  timesteps_since_restore: 0\n","  training_iteration: 9\n","  trial_id: 825a7_00009\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00001:\n","  date: 2022-04-13_12-02-38\n","  done: false\n","  experiment_id: bee5f156b4e14866b4e9e4f5ab3fad72\n","  hostname: aa9ef03c8f27\n","  iterations: 8\n","  iterations_since_restore: 9\n","  mean_reward: -162.2775078439042\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.8\n","    ram_util_percent: 19.957142857142856\n","  pid: 2778\n","  time_since_restore: 39.52948832511902\n","  time_this_iter_s: 4.624878883361816\n","  time_total_s: 39.52948832511902\n","  timestamp: 1649851358\n","  timesteps_since_restore: 0\n","  training_iteration: 9\n","  trial_id: 825a7_00001\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00005:\n","  date: 2022-04-13_12-02-38\n","  done: false\n","  experiment_id: d42ae5be5b334ba6981aa7673828d6d2\n","  hostname: aa9ef03c8f27\n","  iterations: 8\n","  iterations_since_restore: 9\n","  mean_reward: -156.4068657364408\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.9\n","    ram_util_percent: 19.957142857142856\n","  pid: 2773\n","  time_since_restore: 39.51776051521301\n","  time_this_iter_s: 4.602111339569092\n","  time_total_s: 39.51776051521301\n","  timestamp: 1649851358\n","  timesteps_since_restore: 0\n","  training_iteration: 9\n","  trial_id: 825a7_00005\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00011:\n","  date: 2022-04-13_12-02-38\n","  done: false\n","  experiment_id: f576928441b043f48c9de3d6907ccbdd\n","  hostname: aa9ef03c8f27\n","  iterations: 8\n","  iterations_since_restore: 9\n","  mean_reward: -159.02433949370686\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.84285714285714\n","    ram_util_percent: 19.957142857142856\n","  pid: 2768\n","  time_since_restore: 39.63219332695007\n","  time_this_iter_s: 4.705510377883911\n","  time_total_s: 39.63219332695007\n","  timestamp: 1649851358\n","  timesteps_since_restore: 0\n","  training_iteration: 9\n","  trial_id: 825a7_00011\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-02-39\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 8\n","  iterations_since_restore: 9\n","  mean_reward: -142.3967872749331\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.6\n","    ram_util_percent: 19.9625\n","  pid: 2771\n","  time_since_restore: 40.16437125205994\n","  time_this_iter_s: 5.402595520019531\n","  time_total_s: 40.16437125205994\n","  timestamp: 1649851359\n","  timesteps_since_restore: 0\n","  training_iteration: 9\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-02-39\n","  done: false\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  hostname: aa9ef03c8f27\n","  iterations: 8\n","  iterations_since_restore: 9\n","  mean_reward: -137.78098216985435\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.67142857142857\n","    ram_util_percent: 19.97142857142857\n","  pid: 2777\n","  time_since_restore: 40.206767320632935\n","  time_this_iter_s: 5.004016399383545\n","  time_total_s: 40.206767320632935\n","  timestamp: 1649851359\n","  timesteps_since_restore: 0\n","  training_iteration: 9\n","  trial_id: 825a7_00010\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-02-39\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 8\n","  iterations_since_restore: 9\n","  mean_reward: -141.68900170860346\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.642857142857146\n","    ram_util_percent: 19.985714285714288\n","  pid: 2775\n","  time_since_restore: 40.87732648849487\n","  time_this_iter_s: 4.796308755874634\n","  time_total_s: 40.87732648849487\n","  timestamp: 1649851359\n","  timesteps_since_restore: 0\n","  training_iteration: 9\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00008:\n","  date: 2022-04-13_12-02-40\n","  done: false\n","  experiment_id: cd76c37ed72a4c299a0583e20567f167\n","  hostname: aa9ef03c8f27\n","  iterations: 8\n","  iterations_since_restore: 9\n","  mean_reward: -134.71046820924573\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.614285714285714\n","    ram_util_percent: 20.014285714285712\n","  pid: 2767\n","  time_since_restore: 41.977479457855225\n","  time_this_iter_s: 5.101110935211182\n","  time_total_s: 41.977479457855225\n","  timestamp: 1649851360\n","  timesteps_since_restore: 0\n","  training_iteration: 9\n","  trial_id: 825a7_00008\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00002:\n","  date: 2022-04-13_12-02-41\n","  done: false\n","  experiment_id: 315539c1caa744e78ed8486a6a2213a0\n","  hostname: aa9ef03c8f27\n","  iterations: 9\n","  iterations_since_restore: 10\n","  mean_reward: -150.26053962024545\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.612500000000004\n","    ram_util_percent: 20.0375\n","  pid: 2774\n","  time_since_restore: 42.9908390045166\n","  time_this_iter_s: 5.082139015197754\n","  time_total_s: 42.9908390045166\n","  timestamp: 1649851361\n","  timesteps_since_restore: 0\n","  training_iteration: 10\n","  trial_id: 825a7_00002\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-02-42\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 8\n","  iterations_since_restore: 9\n","  mean_reward: -131.10856120121244\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.544444444444444\n","    ram_util_percent: 20.044444444444444\n","  pid: 2776\n","  time_since_restore: 43.86857557296753\n","  time_this_iter_s: 6.427878379821777\n","  time_total_s: 43.86857557296753\n","  timestamp: 1649851362\n","  timesteps_since_restore: 0\n","  training_iteration: 9\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00000:\n","  date: 2022-04-13_12-02-43\n","  done: false\n","  experiment_id: 696b6ae5d0474799847a48a1fd9db44c\n","  hostname: aa9ef03c8f27\n","  iterations: 9\n","  iterations_since_restore: 10\n","  mean_reward: -126.62731852896873\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.71666666666666\n","    ram_util_percent: 20.083333333333332\n","  pid: 2770\n","  time_since_restore: 44.88061499595642\n","  time_this_iter_s: 4.5748772621154785\n","  time_total_s: 44.88061499595642\n","  timestamp: 1649851363\n","  timesteps_since_restore: 0\n","  training_iteration: 10\n","  trial_id: 825a7_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:02:43 (running for 00:00:50.09)<br>Memory usage on this node: 7.1/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00000 with mean_reward=-126.62731852896873 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.3029924584127983, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         44.8806</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -126.627</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         43.9873</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -164.675</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         42.9908</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -150.261</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         40.8773</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     -141.689</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         43.8686</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     -131.109</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         43.973 </td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -164.256</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         42.595 </td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -150.96 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         40.1644</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     -142.397</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         41.9775</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     -134.71 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         43.8496</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -154.233</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         40.2068</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     -137.781</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         39.6322</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     -159.024</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00011:\n","  date: 2022-04-13_12-02-44\n","  done: false\n","  experiment_id: f576928441b043f48c9de3d6907ccbdd\n","  hostname: aa9ef03c8f27\n","  iterations: 9\n","  iterations_since_restore: 10\n","  mean_reward: -162.00350157341322\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.6125\n","    ram_util_percent: 20.075000000000003\n","  pid: 2768\n","  time_since_restore: 45.09681153297424\n","  time_this_iter_s: 5.46461820602417\n","  time_total_s: 45.09681153297424\n","  timestamp: 1649851364\n","  timesteps_since_restore: 0\n","  training_iteration: 10\n","  trial_id: 825a7_00011\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-02-44\n","  done: false\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  hostname: aa9ef03c8f27\n","  iterations: 9\n","  iterations_since_restore: 10\n","  mean_reward: -139.64230215330696\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.75714285714286\n","    ram_util_percent: 20.085714285714285\n","  pid: 2777\n","  time_since_restore: 45.339295387268066\n","  time_this_iter_s: 5.132528066635132\n","  time_total_s: 45.339295387268066\n","  timestamp: 1649851364\n","  timesteps_since_restore: 0\n","  training_iteration: 10\n","  trial_id: 825a7_00010\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-02-44\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 9\n","  iterations_since_restore: 10\n","  mean_reward: -140.46533204144382\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.775000000000006\n","    ram_util_percent: 20.087500000000002\n","  pid: 2771\n","  time_since_restore: 45.735312700271606\n","  time_this_iter_s: 5.57094144821167\n","  time_total_s: 45.735312700271606\n","  timestamp: 1649851364\n","  timesteps_since_restore: 0\n","  training_iteration: 10\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00006:\n","  date: 2022-04-13_12-02-45\n","  done: false\n","  experiment_id: 1452367bf557484fb196e21a6489d80a\n","  hostname: aa9ef03c8f27\n","  iterations: 10\n","  iterations_since_restore: 11\n","  mean_reward: -156.9310264656045\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.65\n","    ram_util_percent: 20.116666666666667\n","  pid: 2772\n","  time_since_restore: 46.93578362464905\n","  time_this_iter_s: 4.340805768966675\n","  time_total_s: 46.93578362464905\n","  timestamp: 1649851365\n","  timesteps_since_restore: 0\n","  training_iteration: 11\n","  trial_id: 825a7_00006\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00008:\n","  date: 2022-04-13_12-02-46\n","  done: false\n","  experiment_id: cd76c37ed72a4c299a0583e20567f167\n","  hostname: aa9ef03c8f27\n","  iterations: 9\n","  iterations_since_restore: 10\n","  mean_reward: -139.80519924766867\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.7\n","    ram_util_percent: 20.125\n","  pid: 2767\n","  time_since_restore: 47.80158042907715\n","  time_this_iter_s: 5.824100971221924\n","  time_total_s: 47.80158042907715\n","  timestamp: 1649851366\n","  timesteps_since_restore: 0\n","  training_iteration: 10\n","  trial_id: 825a7_00008\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00001:\n","  date: 2022-04-13_12-02-47\n","  done: false\n","  experiment_id: bee5f156b4e14866b4e9e4f5ab3fad72\n","  hostname: aa9ef03c8f27\n","  iterations: 10\n","  iterations_since_restore: 11\n","  mean_reward: -177.2188864146389\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.166666666666664\n","    ram_util_percent: 20.150000000000002\n","  pid: 2778\n","  time_since_restore: 48.29523491859436\n","  time_this_iter_s: 4.3079633712768555\n","  time_total_s: 48.29523491859436\n","  timestamp: 1649851367\n","  timesteps_since_restore: 0\n","  training_iteration: 11\n","  trial_id: 825a7_00001\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00009:\n","  date: 2022-04-13_12-02-47\n","  done: false\n","  experiment_id: 95c2bb28a0b642edb97e6a45503efe15\n","  hostname: aa9ef03c8f27\n","  iterations: 10\n","  iterations_since_restore: 11\n","  mean_reward: -155.39031469009106\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.583333333333336\n","    ram_util_percent: 20.150000000000002\n","  pid: 2769\n","  time_since_restore: 48.32671093940735\n","  time_this_iter_s: 4.477102518081665\n","  time_total_s: 48.32671093940735\n","  timestamp: 1649851367\n","  timesteps_since_restore: 0\n","  training_iteration: 11\n","  trial_id: 825a7_00009\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-02-48\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 9\n","  iterations_since_restore: 10\n","  mean_reward: -129.5798389500091\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.14444444444444\n","    ram_util_percent: 20.166666666666668\n","  pid: 2776\n","  time_since_restore: 50.004271030426025\n","  time_this_iter_s: 6.135695457458496\n","  time_total_s: 50.004271030426025\n","  timestamp: 1649851368\n","  timesteps_since_restore: 0\n","  training_iteration: 10\n","  trial_id: 825a7_00004\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:02:48 (running for 00:00:55.22)<br>Memory usage on this node: 7.1/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00004 with mean_reward=-129.5798389500091 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.9143838356374548, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         49.6683</td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">     -131.364</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         48.2952</td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">     -177.219</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         47.378 </td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">     -164.524</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         45.2913</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -148.731</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         50.0043</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -129.58 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         43.973 </td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -164.256</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         46.9358</td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">     -156.931</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         45.7353</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -140.465</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         47.8016</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -139.805</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         48.3267</td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">     -155.39 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         45.3393</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -139.642</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         49.7677</td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">     -159.946</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00005:\n","  date: 2022-04-13_12-02-49\n","  done: false\n","  experiment_id: d42ae5be5b334ba6981aa7673828d6d2\n","  hostname: aa9ef03c8f27\n","  iterations: 10\n","  iterations_since_restore: 11\n","  mean_reward: -164.87514787516508\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.75555555555556\n","    ram_util_percent: 20.166666666666668\n","  pid: 2773\n","  time_since_restore: 50.57698464393616\n","  time_this_iter_s: 6.604003429412842\n","  time_total_s: 50.57698464393616\n","  timestamp: 1649851369\n","  timesteps_since_restore: 0\n","  training_iteration: 11\n","  trial_id: 825a7_00005\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-02-49\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 10\n","  iterations_since_restore: 11\n","  mean_reward: -141.00535488141048\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.75714285714285\n","    ram_util_percent: 20.2\n","  pid: 2771\n","  time_since_restore: 50.88443374633789\n","  time_this_iter_s: 5.149121046066284\n","  time_total_s: 50.88443374633789\n","  timestamp: 1649851369\n","  timesteps_since_restore: 0\n","  training_iteration: 11\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-02-49\n","  done: false\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  hostname: aa9ef03c8f27\n","  iterations: 10\n","  iterations_since_restore: 11\n","  mean_reward: -133.73794085894284\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.7\n","    ram_util_percent: 20.1875\n","  pid: 2777\n","  time_since_restore: 50.9633264541626\n","  time_this_iter_s: 5.624031066894531\n","  time_total_s: 50.9633264541626\n","  timestamp: 1649851369\n","  timesteps_since_restore: 0\n","  training_iteration: 11\n","  trial_id: 825a7_00010\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00002:\n","  date: 2022-04-13_12-02-50\n","  done: false\n","  experiment_id: 315539c1caa744e78ed8486a6a2213a0\n","  hostname: aa9ef03c8f27\n","  iterations: 11\n","  iterations_since_restore: 12\n","  mean_reward: -167.0652631669449\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.800000000000004\n","    ram_util_percent: 20.2\n","  pid: 2774\n","  time_since_restore: 51.75982475280762\n","  time_this_iter_s: 4.381861209869385\n","  time_total_s: 51.75982475280762\n","  timestamp: 1649851370\n","  timesteps_since_restore: 0\n","  training_iteration: 12\n","  trial_id: 825a7_00002\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-02-51\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 10\n","  iterations_since_restore: 11\n","  mean_reward: -148.6570816851891\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.82\n","    ram_util_percent: 20.2\n","  pid: 2775\n","  time_since_restore: 52.25626492500305\n","  time_this_iter_s: 6.964988708496094\n","  time_total_s: 52.25626492500305\n","  timestamp: 1649851371\n","  timesteps_since_restore: 0\n","  training_iteration: 11\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00000:\n","  date: 2022-04-13_12-02-52\n","  done: false\n","  experiment_id: 696b6ae5d0474799847a48a1fd9db44c\n","  hostname: aa9ef03c8f27\n","  iterations: 11\n","  iterations_since_restore: 12\n","  mean_reward: -130.1831380590173\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.35\n","    ram_util_percent: 20.249999999999996\n","  pid: 2770\n","  time_since_restore: 54.00575375556946\n","  time_this_iter_s: 4.337468147277832\n","  time_total_s: 54.00575375556946\n","  timestamp: 1649851372\n","  timesteps_since_restore: 0\n","  training_iteration: 12\n","  trial_id: 825a7_00000\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00011:\n","  date: 2022-04-13_12-02-53\n","  done: false\n","  experiment_id: f576928441b043f48c9de3d6907ccbdd\n","  hostname: aa9ef03c8f27\n","  iterations: 11\n","  iterations_since_restore: 12\n","  mean_reward: -159.14858666519922\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.385714285714286\n","    ram_util_percent: 20.257142857142856\n","  pid: 2768\n","  time_since_restore: 54.32738733291626\n","  time_this_iter_s: 4.55969500541687\n","  time_total_s: 54.32738733291626\n","  timestamp: 1649851373\n","  timesteps_since_restore: 0\n","  training_iteration: 12\n","  trial_id: 825a7_00011\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:02:54 (running for 00:01:00.56)<br>Memory usage on this node: 7.2/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00004 with mean_reward=-129.5798389500091 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.9143838356374548, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         54.0058</td><td style=\"text-align: right;\">          11</td><td style=\"text-align: right;\">     -130.183</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         52.7872</td><td style=\"text-align: right;\">          11</td><td style=\"text-align: right;\">     -175.018</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         51.7598</td><td style=\"text-align: right;\">          11</td><td style=\"text-align: right;\">     -167.065</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         52.2563</td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">     -148.657</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         50.0043</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -129.58 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         50.577 </td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">     -164.875</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         51.2511</td><td style=\"text-align: right;\">          11</td><td style=\"text-align: right;\">     -158.044</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         50.8844</td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">     -141.005</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         52.297 </td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">     -143.961</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         52.7213</td><td style=\"text-align: right;\">          11</td><td style=\"text-align: right;\">     -156.647</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         50.9633</td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">     -133.738</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         54.3274</td><td style=\"text-align: right;\">          11</td><td style=\"text-align: right;\">     -159.149</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00006:\n","  date: 2022-04-13_12-02-54\n","  done: false\n","  experiment_id: 1452367bf557484fb196e21a6489d80a\n","  hostname: aa9ef03c8f27\n","  iterations: 12\n","  iterations_since_restore: 13\n","  mean_reward: -167.0679251636271\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.4\n","    ram_util_percent: 20.28333333333333\n","  pid: 2772\n","  time_since_restore: 55.45385789871216\n","  time_this_iter_s: 4.202764511108398\n","  time_total_s: 55.45385789871216\n","  timestamp: 1649851374\n","  timesteps_since_restore: 0\n","  training_iteration: 13\n","  trial_id: 825a7_00006\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00005:\n","  date: 2022-04-13_12-02-54\n","  done: false\n","  experiment_id: d42ae5be5b334ba6981aa7673828d6d2\n","  hostname: aa9ef03c8f27\n","  iterations: 11\n","  iterations_since_restore: 12\n","  mean_reward: -167.09333731721512\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.4875\n","    ram_util_percent: 20.275\n","  pid: 2773\n","  time_since_restore: 55.70813703536987\n","  time_this_iter_s: 5.131152391433716\n","  time_total_s: 55.70813703536987\n","  timestamp: 1649851374\n","  timesteps_since_restore: 0\n","  training_iteration: 12\n","  trial_id: 825a7_00005\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-02-54\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 10\n","  iterations_since_restore: 11\n","  mean_reward: -128.10383130130023\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.5375\n","    ram_util_percent: 20.275\n","  pid: 2776\n","  time_since_restore: 55.80675792694092\n","  time_this_iter_s: 5.802486896514893\n","  time_total_s: 55.80675792694092\n","  timestamp: 1649851374\n","  timesteps_since_restore: 0\n","  training_iteration: 11\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-02-55\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 11\n","  iterations_since_restore: 12\n","  mean_reward: -140.77416269131174\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.287499999999994\n","    ram_util_percent: 20.3\n","  pid: 2771\n","  time_since_restore: 56.708929777145386\n","  time_this_iter_s: 5.824496030807495\n","  time_total_s: 56.708929777145386\n","  timestamp: 1649851375\n","  timesteps_since_restore: 0\n","  training_iteration: 12\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00008:\n","  date: 2022-04-13_12-02-55\n","  done: false\n","  experiment_id: cd76c37ed72a4c299a0583e20567f167\n","  hostname: aa9ef03c8f27\n","  iterations: 11\n","  iterations_since_restore: 12\n","  mean_reward: -136.1524421831815\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.583333333333336\n","    ram_util_percent: 20.316666666666666\n","  pid: 2767\n","  time_since_restore: 56.904563426971436\n","  time_this_iter_s: 4.6075356006622314\n","  time_total_s: 56.904563426971436\n","  timestamp: 1649851375\n","  timesteps_since_restore: 0\n","  training_iteration: 12\n","  trial_id: 825a7_00008\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00001:\n","  date: 2022-04-13_12-02-56\n","  done: false\n","  experiment_id: bee5f156b4e14866b4e9e4f5ab3fad72\n","  hostname: aa9ef03c8f27\n","  iterations: 12\n","  iterations_since_restore: 13\n","  mean_reward: -183.93234460840108\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.06666666666667\n","    ram_util_percent: 20.333333333333332\n","  pid: 2778\n","  time_since_restore: 57.16969895362854\n","  time_this_iter_s: 4.382496356964111\n","  time_total_s: 57.16969895362854\n","  timestamp: 1649851376\n","  timesteps_since_restore: 0\n","  training_iteration: 13\n","  trial_id: 825a7_00001\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00009:\n","  date: 2022-04-13_12-02-56\n","  done: false\n","  experiment_id: 95c2bb28a0b642edb97e6a45503efe15\n","  hostname: aa9ef03c8f27\n","  iterations: 12\n","  iterations_since_restore: 13\n","  mean_reward: -160.0204618426601\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.21666666666667\n","    ram_util_percent: 20.333333333333332\n","  pid: 2769\n","  time_since_restore: 57.375970125198364\n","  time_this_iter_s: 4.654635190963745\n","  time_total_s: 57.375970125198364\n","  timestamp: 1649851376\n","  timesteps_since_restore: 0\n","  training_iteration: 13\n","  trial_id: 825a7_00009\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-02-57\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 11\n","  iterations_since_restore: 12\n","  mean_reward: -148.01986467630445\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.07777777777778\n","    ram_util_percent: 20.344444444444445\n","  pid: 2775\n","  time_since_restore: 58.93013000488281\n","  time_this_iter_s: 6.673865079879761\n","  time_total_s: 58.93013000488281\n","  timestamp: 1649851377\n","  timesteps_since_restore: 0\n","  training_iteration: 12\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00011:\n","  date: 2022-04-13_12-02-58\n","  done: false\n","  experiment_id: f576928441b043f48c9de3d6907ccbdd\n","  hostname: aa9ef03c8f27\n","  iterations: 12\n","  iterations_since_restore: 13\n","  mean_reward: -159.4175957419592\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.625\n","    ram_util_percent: 20.375\n","  pid: 2768\n","  time_since_restore: 59.80306315422058\n","  time_this_iter_s: 5.475675821304321\n","  time_total_s: 59.80306315422058\n","  timestamp: 1649851378\n","  timesteps_since_restore: 0\n","  training_iteration: 13\n","  trial_id: 825a7_00011\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00002:\n","  date: 2022-04-13_12-02-59\n","  done: false\n","  experiment_id: 315539c1caa744e78ed8486a6a2213a0\n","  hostname: aa9ef03c8f27\n","  iterations: 13\n","  iterations_since_restore: 14\n","  mean_reward: -176.97169085971518\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.53333333333334\n","    ram_util_percent: 20.400000000000002\n","  pid: 2774\n","  time_since_restore: 60.27056074142456\n","  time_this_iter_s: 4.300765037536621\n","  time_total_s: 60.27056074142456\n","  timestamp: 1649851379\n","  timesteps_since_restore: 0\n","  training_iteration: 14\n","  trial_id: 825a7_00002\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00005:\n","  date: 2022-04-13_12-02-59\n","  done: false\n","  experiment_id: d42ae5be5b334ba6981aa7673828d6d2\n","  hostname: aa9ef03c8f27\n","  iterations: 12\n","  iterations_since_restore: 13\n","  mean_reward: -165.9907122772153\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.32857142857143\n","    ram_util_percent: 20.400000000000002\n","  pid: 2773\n","  time_since_restore: 61.0647611618042\n","  time_this_iter_s: 5.356624126434326\n","  time_total_s: 61.0647611618042\n","  timestamp: 1649851379\n","  timesteps_since_restore: 0\n","  training_iteration: 13\n","  trial_id: 825a7_00005\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:02:59 (running for 00:01:06.30)<br>Memory usage on this node: 7.2/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00004 with mean_reward=-128.10383130130023 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.9143838356374548, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         58.693 </td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">     -131.782</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         57.1697</td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">     -183.932</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         60.2706</td><td style=\"text-align: right;\">          13</td><td style=\"text-align: right;\">     -176.972</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         58.9301</td><td style=\"text-align: right;\">          11</td><td style=\"text-align: right;\">     -148.02 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         55.8068</td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">     -128.104</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         61.0648</td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">     -165.991</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         59.6516</td><td style=\"text-align: right;\">          13</td><td style=\"text-align: right;\">     -168.235</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         56.7089</td><td style=\"text-align: right;\">          11</td><td style=\"text-align: right;\">     -140.774</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         56.9046</td><td style=\"text-align: right;\">          11</td><td style=\"text-align: right;\">     -136.152</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         57.376 </td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">     -160.02 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         55.9306</td><td style=\"text-align: right;\">          11</td><td style=\"text-align: right;\">     -134.819</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         59.8031</td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">     -159.418</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-03-00\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 11\n","  iterations_since_restore: 12\n","  mean_reward: -128.01672040093334\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.887499999999996\n","    ram_util_percent: 20.412499999999998\n","  pid: 2776\n","  time_since_restore: 61.2106237411499\n","  time_this_iter_s: 5.403865814208984\n","  time_total_s: 61.2106237411499\n","  timestamp: 1649851380\n","  timesteps_since_restore: 0\n","  training_iteration: 12\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-03-00\n","  done: false\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  hostname: aa9ef03c8f27\n","  iterations: 12\n","  iterations_since_restore: 13\n","  mean_reward: -136.47973317065288\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.43333333333334\n","    ram_util_percent: 20.42222222222222\n","  pid: 2777\n","  time_since_restore: 62.03482460975647\n","  time_this_iter_s: 6.104231595993042\n","  time_total_s: 62.03482460975647\n","  timestamp: 1649851380\n","  timesteps_since_restore: 0\n","  training_iteration: 13\n","  trial_id: 825a7_00010\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00009:\n","  date: 2022-04-13_12-03-01\n","  done: false\n","  experiment_id: 95c2bb28a0b642edb97e6a45503efe15\n","  hostname: aa9ef03c8f27\n","  iterations: 13\n","  iterations_since_restore: 14\n","  mean_reward: -162.6569966753908\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.3125\n","    ram_util_percent: 20.4375\n","  pid: 2769\n","  time_since_restore: 62.64800977706909\n","  time_this_iter_s: 5.2720396518707275\n","  time_total_s: 62.64800977706909\n","  timestamp: 1649851381\n","  timesteps_since_restore: 0\n","  training_iteration: 14\n","  trial_id: 825a7_00009\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-03-01\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 12\n","  iterations_since_restore: 13\n","  mean_reward: -139.94327331708206\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.37777777777778\n","    ram_util_percent: 20.43333333333333\n","  pid: 2771\n","  time_since_restore: 62.861457109451294\n","  time_this_iter_s: 6.152527332305908\n","  time_total_s: 62.861457109451294\n","  timestamp: 1649851381\n","  timesteps_since_restore: 0\n","  training_iteration: 13\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00000:\n","  date: 2022-04-13_12-03-02\n","  done: false\n","  experiment_id: 696b6ae5d0474799847a48a1fd9db44c\n","  hostname: aa9ef03c8f27\n","  iterations: 13\n","  iterations_since_restore: 14\n","  mean_reward: -133.7002170009945\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.58571428571428\n","    ram_util_percent: 20.457142857142856\n","  pid: 2770\n","  time_since_restore: 63.25470495223999\n","  time_this_iter_s: 4.561752557754517\n","  time_total_s: 63.25470495223999\n","  timestamp: 1649851382\n","  timesteps_since_restore: 0\n","  training_iteration: 14\n","  trial_id: 825a7_00000\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00008:\n","  date: 2022-04-13_12-03-02\n","  done: false\n","  experiment_id: cd76c37ed72a4c299a0583e20567f167\n","  hostname: aa9ef03c8f27\n","  iterations: 12\n","  iterations_since_restore: 13\n","  mean_reward: -140.86177773733237\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.58999999999999\n","    ram_util_percent: 20.439999999999998\n","  pid: 2767\n","  time_since_restore: 63.40568566322327\n","  time_this_iter_s: 6.501122236251831\n","  time_total_s: 63.40568566322327\n","  timestamp: 1649851382\n","  timesteps_since_restore: 0\n","  training_iteration: 13\n","  trial_id: 825a7_00008\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00006:\n","  date: 2022-04-13_12-03-02\n","  done: false\n","  experiment_id: 1452367bf557484fb196e21a6489d80a\n","  hostname: aa9ef03c8f27\n","  iterations: 14\n","  iterations_since_restore: 15\n","  mean_reward: -165.69983184780187\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.457142857142856\n","    ram_util_percent: 20.47142857142857\n","  pid: 2772\n","  time_since_restore: 64.0069842338562\n","  time_this_iter_s: 4.355348110198975\n","  time_total_s: 64.0069842338562\n","  timestamp: 1649851382\n","  timesteps_since_restore: 0\n","  training_iteration: 15\n","  trial_id: 825a7_00006\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-03-03\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 12\n","  iterations_since_restore: 13\n","  mean_reward: -147.55912024006042\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.475\n","    ram_util_percent: 20.4625\n","  pid: 2775\n","  time_since_restore: 64.24899983406067\n","  time_this_iter_s: 5.3188698291778564\n","  time_total_s: 64.24899983406067\n","  timestamp: 1649851383\n","  timesteps_since_restore: 0\n","  training_iteration: 13\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00011:\n","  date: 2022-04-13_12-03-04\n","  done: false\n","  experiment_id: f576928441b043f48c9de3d6907ccbdd\n","  hostname: aa9ef03c8f27\n","  iterations: 13\n","  iterations_since_restore: 14\n","  mean_reward: -159.63761427136654\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.949999999999996\n","    ram_util_percent: 20.4875\n","  pid: 2768\n","  time_since_restore: 66.053790807724\n","  time_this_iter_s: 6.250727653503418\n","  time_total_s: 66.053790807724\n","  timestamp: 1649851384\n","  timesteps_since_restore: 0\n","  training_iteration: 14\n","  trial_id: 825a7_00011\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00001:\n","  date: 2022-04-13_12-03-05\n","  done: false\n","  experiment_id: bee5f156b4e14866b4e9e4f5ab3fad72\n","  hostname: aa9ef03c8f27\n","  iterations: 14\n","  iterations_since_restore: 15\n","  mean_reward: -190.08521949786643\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.142857142857146\n","    ram_util_percent: 20.514285714285712\n","  pid: 2778\n","  time_since_restore: 66.3537290096283\n","  time_this_iter_s: 4.911877393722534\n","  time_total_s: 66.3537290096283\n","  timestamp: 1649851385\n","  timesteps_since_restore: 0\n","  training_iteration: 15\n","  trial_id: 825a7_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:03:05 (running for 00:01:11.55)<br>Memory usage on this node: 7.3/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00004 with mean_reward=-128.01672040093334 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.9143838356374548, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         63.2547</td><td style=\"text-align: right;\">          13</td><td style=\"text-align: right;\">     -133.7  </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         66.3537</td><td style=\"text-align: right;\">          14</td><td style=\"text-align: right;\">     -190.085</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         64.6197</td><td style=\"text-align: right;\">          14</td><td style=\"text-align: right;\">     -179.028</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         64.249 </td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">     -147.559</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         61.2106</td><td style=\"text-align: right;\">          11</td><td style=\"text-align: right;\">     -128.017</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         65.8619</td><td style=\"text-align: right;\">          13</td><td style=\"text-align: right;\">     -170.31 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         64.007 </td><td style=\"text-align: right;\">          14</td><td style=\"text-align: right;\">     -165.7  </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         62.8615</td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">     -139.943</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         63.4057</td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">     -140.862</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         62.648 </td><td style=\"text-align: right;\">          13</td><td style=\"text-align: right;\">     -162.657</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         62.0348</td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">     -136.48 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         66.0538</td><td style=\"text-align: right;\">          13</td><td style=\"text-align: right;\">     -159.638</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-03-06\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 12\n","  iterations_since_restore: 13\n","  mean_reward: -127.47590387359703\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.224999999999994\n","    ram_util_percent: 20.525\n","  pid: 2776\n","  time_since_restore: 67.40777134895325\n","  time_this_iter_s: 6.197147607803345\n","  time_total_s: 67.40777134895325\n","  timestamp: 1649851386\n","  timesteps_since_restore: 0\n","  training_iteration: 13\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-03-06\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 13\n","  iterations_since_restore: 14\n","  mean_reward: -139.2183530859299\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.25714285714286\n","    ram_util_percent: 20.54285714285714\n","  pid: 2771\n","  time_since_restore: 68.076180934906\n","  time_this_iter_s: 5.214723825454712\n","  time_total_s: 68.076180934906\n","  timestamp: 1649851386\n","  timesteps_since_restore: 0\n","  training_iteration: 14\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00002:\n","  date: 2022-04-13_12-03-07\n","  done: false\n","  experiment_id: 315539c1caa744e78ed8486a6a2213a0\n","  hostname: aa9ef03c8f27\n","  iterations: 15\n","  iterations_since_restore: 16\n","  mean_reward: -183.17250293882287\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.714285714285715\n","    ram_util_percent: 20.557142857142857\n","  pid: 2774\n","  time_since_restore: 69.05950927734375\n","  time_this_iter_s: 4.439805030822754\n","  time_total_s: 69.05950927734375\n","  timestamp: 1649851387\n","  timesteps_since_restore: 0\n","  training_iteration: 16\n","  trial_id: 825a7_00002\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-03-08\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 13\n","  iterations_since_restore: 14\n","  mean_reward: -153.88003301948987\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.0375\n","    ram_util_percent: 20.5625\n","  pid: 2775\n","  time_since_restore: 69.79640913009644\n","  time_this_iter_s: 5.547409296035767\n","  time_total_s: 69.79640913009644\n","  timestamp: 1649851388\n","  timesteps_since_restore: 0\n","  training_iteration: 14\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00005:\n","  date: 2022-04-13_12-03-09\n","  done: false\n","  experiment_id: d42ae5be5b334ba6981aa7673828d6d2\n","  hostname: aa9ef03c8f27\n","  iterations: 14\n","  iterations_since_restore: 15\n","  mean_reward: -171.15473159124411\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 43.885714285714286\n","    ram_util_percent: 20.557142857142857\n","  pid: 2773\n","  time_since_restore: 70.87165594100952\n","  time_this_iter_s: 5.009794235229492\n","  time_total_s: 70.87165594100952\n","  timestamp: 1649851389\n","  timesteps_since_restore: 0\n","  training_iteration: 15\n","  trial_id: 825a7_00005\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00011:\n","  date: 2022-04-13_12-03-10\n","  done: false\n","  experiment_id: f576928441b043f48c9de3d6907ccbdd\n","  hostname: aa9ef03c8f27\n","  iterations: 14\n","  iterations_since_restore: 15\n","  mean_reward: -159.9434560849378\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.725\n","    ram_util_percent: 20.55\n","  pid: 2768\n","  time_since_restore: 71.10257363319397\n","  time_this_iter_s: 5.048782825469971\n","  time_total_s: 71.10257363319397\n","  timestamp: 1649851390\n","  timesteps_since_restore: 0\n","  training_iteration: 15\n","  trial_id: 825a7_00011\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-03-10\n","  done: false\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  hostname: aa9ef03c8f27\n","  iterations: 14\n","  iterations_since_restore: 15\n","  mean_reward: -144.8841669688775\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.885714285714286\n","    ram_util_percent: 20.542857142857144\n","  pid: 2777\n","  time_since_restore: 71.52448630332947\n","  time_this_iter_s: 4.962264776229858\n","  time_total_s: 71.52448630332947\n","  timestamp: 1649851390\n","  timesteps_since_restore: 0\n","  training_iteration: 15\n","  trial_id: 825a7_00010\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:03:10 (running for 00:01:16.77)<br>Memory usage on this node: 7.2/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00004 with mean_reward=-127.47590387359703 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.9143838356374548, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         67.806 </td><td style=\"text-align: right;\">          14</td><td style=\"text-align: right;\">     -136.476</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         70.932 </td><td style=\"text-align: right;\">          15</td><td style=\"text-align: right;\">     -187.635</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         69.0595</td><td style=\"text-align: right;\">          15</td><td style=\"text-align: right;\">     -183.173</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         69.7964</td><td style=\"text-align: right;\">          13</td><td style=\"text-align: right;\">     -153.88 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         67.4078</td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">     -127.476</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         70.8717</td><td style=\"text-align: right;\">          14</td><td style=\"text-align: right;\">     -171.155</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         68.4258</td><td style=\"text-align: right;\">          15</td><td style=\"text-align: right;\">     -161.919</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         68.0762</td><td style=\"text-align: right;\">          13</td><td style=\"text-align: right;\">     -139.218</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         68.1533</td><td style=\"text-align: right;\">          13</td><td style=\"text-align: right;\">     -142.308</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         67.1562</td><td style=\"text-align: right;\">          14</td><td style=\"text-align: right;\">     -164.634</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         71.5245</td><td style=\"text-align: right;\">          14</td><td style=\"text-align: right;\">     -144.884</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         71.1026</td><td style=\"text-align: right;\">          14</td><td style=\"text-align: right;\">     -159.943</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00009:\n","  date: 2022-04-13_12-03-10\n","  done: false\n","  experiment_id: 95c2bb28a0b642edb97e6a45503efe15\n","  hostname: aa9ef03c8f27\n","  iterations: 15\n","  iterations_since_restore: 16\n","  mean_reward: -163.90669522803861\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 44.6\n","    ram_util_percent: 20.55\n","  pid: 2769\n","  time_since_restore: 71.66766047477722\n","  time_this_iter_s: 4.5114898681640625\n","  time_total_s: 71.66766047477722\n","  timestamp: 1649851390\n","  timesteps_since_restore: 0\n","  training_iteration: 16\n","  trial_id: 825a7_00009\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00000:\n","  date: 2022-04-13_12-03-11\n","  done: false\n","  experiment_id: 696b6ae5d0474799847a48a1fd9db44c\n","  hostname: aa9ef03c8f27\n","  iterations: 15\n","  iterations_since_restore: 16\n","  mean_reward: -138.26261312776293\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 43.68571428571429\n","    ram_util_percent: 20.52857142857143\n","  pid: 2770\n","  time_since_restore: 72.41333603858948\n","  time_this_iter_s: 4.607362508773804\n","  time_total_s: 72.41333603858948\n","  timestamp: 1649851391\n","  timesteps_since_restore: 0\n","  training_iteration: 16\n","  trial_id: 825a7_00000\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00006:\n","  date: 2022-04-13_12-03-11\n","  done: false\n","  experiment_id: 1452367bf557484fb196e21a6489d80a\n","  hostname: aa9ef03c8f27\n","  iterations: 16\n","  iterations_since_restore: 17\n","  mean_reward: -152.32839230197712\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.98333333333334\n","    ram_util_percent: 20.516666666666666\n","  pid: 2772\n","  time_since_restore: 72.85725998878479\n","  time_this_iter_s: 4.431501388549805\n","  time_total_s: 72.85725998878479\n","  timestamp: 1649851391\n","  timesteps_since_restore: 0\n","  training_iteration: 17\n","  trial_id: 825a7_00006\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-03-12\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 13\n","  iterations_since_restore: 14\n","  mean_reward: -126.96080644780884\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 43.8111111111111\n","    ram_util_percent: 20.533333333333335\n","  pid: 2776\n","  time_since_restore: 73.45681881904602\n","  time_this_iter_s: 6.049047470092773\n","  time_total_s: 73.45681881904602\n","  timestamp: 1649851392\n","  timesteps_since_restore: 0\n","  training_iteration: 14\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00008:\n","  date: 2022-04-13_12-03-12\n","  done: false\n","  experiment_id: cd76c37ed72a4c299a0583e20567f167\n","  hostname: aa9ef03c8f27\n","  iterations: 14\n","  iterations_since_restore: 15\n","  mean_reward: -139.0423458198129\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 44.1375\n","    ram_util_percent: 20.5125\n","  pid: 2767\n","  time_since_restore: 73.43972587585449\n","  time_this_iter_s: 5.286463737487793\n","  time_total_s: 73.43972587585449\n","  timestamp: 1649851392\n","  timesteps_since_restore: 0\n","  training_iteration: 15\n","  trial_id: 825a7_00008\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-03-12\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 14\n","  iterations_since_restore: 15\n","  mean_reward: -138.5945062998288\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.912499999999994\n","    ram_util_percent: 20.525\n","  pid: 2771\n","  time_since_restore: 73.56852197647095\n","  time_this_iter_s: 5.492341041564941\n","  time_total_s: 73.56852197647095\n","  timestamp: 1649851392\n","  timesteps_since_restore: 0\n","  training_iteration: 15\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-03-14\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 14\n","  iterations_since_restore: 15\n","  mean_reward: -153.0463166498106\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.300000000000004\n","    ram_util_percent: 20.514285714285712\n","  pid: 2775\n","  time_since_restore: 75.14403319358826\n","  time_this_iter_s: 5.347624063491821\n","  time_total_s: 75.14403319358826\n","  timestamp: 1649851394\n","  timesteps_since_restore: 0\n","  training_iteration: 15\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00001:\n","  date: 2022-04-13_12-03-15\n","  done: false\n","  experiment_id: bee5f156b4e14866b4e9e4f5ab3fad72\n","  hostname: aa9ef03c8f27\n","  iterations: 16\n","  iterations_since_restore: 17\n","  mean_reward: -187.46178532475\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.7375\n","    ram_util_percent: 20.5375\n","  pid: 2778\n","  time_since_restore: 76.4100890159607\n","  time_this_iter_s: 5.478071928024292\n","  time_total_s: 76.4100890159607\n","  timestamp: 1649851395\n","  timesteps_since_restore: 0\n","  training_iteration: 17\n","  trial_id: 825a7_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:03:16 (running for 00:01:22.39)<br>Memory usage on this node: 7.3/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00004 with mean_reward=-126.96080644780884 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.9143838356374548, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         72.4133</td><td style=\"text-align: right;\">          15</td><td style=\"text-align: right;\">     -138.263</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         76.4101</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">     -187.462</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         73.5815</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">     -190.069</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         75.144 </td><td style=\"text-align: right;\">          14</td><td style=\"text-align: right;\">     -153.046</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         73.4568</td><td style=\"text-align: right;\">          13</td><td style=\"text-align: right;\">     -126.961</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         75.3891</td><td style=\"text-align: right;\">          15</td><td style=\"text-align: right;\">     -161.944</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         77.159 </td><td style=\"text-align: right;\">          17</td><td style=\"text-align: right;\">     -151.668</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         73.5685</td><td style=\"text-align: right;\">          14</td><td style=\"text-align: right;\">     -138.595</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         73.4397</td><td style=\"text-align: right;\">          14</td><td style=\"text-align: right;\">     -139.042</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         76.2152</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">     -164.237</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         76.0933</td><td style=\"text-align: right;\">          15</td><td style=\"text-align: right;\">     -138.567</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         75.9886</td><td style=\"text-align: right;\">          15</td><td style=\"text-align: right;\">     -155.604</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00000:\n","  date: 2022-04-13_12-03-16\n","  done: false\n","  experiment_id: 696b6ae5d0474799847a48a1fd9db44c\n","  hostname: aa9ef03c8f27\n","  iterations: 16\n","  iterations_since_restore: 17\n","  mean_reward: -136.65190983132686\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.01428571428572\n","    ram_util_percent: 20.571428571428573\n","  pid: 2770\n","  time_since_restore: 77.56830191612244\n","  time_this_iter_s: 5.154965877532959\n","  time_total_s: 77.56830191612244\n","  timestamp: 1649851396\n","  timesteps_since_restore: 0\n","  training_iteration: 17\n","  trial_id: 825a7_00000\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00002:\n","  date: 2022-04-13_12-03-16\n","  done: false\n","  experiment_id: 315539c1caa744e78ed8486a6a2213a0\n","  hostname: aa9ef03c8f27\n","  iterations: 17\n","  iterations_since_restore: 18\n","  mean_reward: -190.59099700507022\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.70000000000001\n","    ram_util_percent: 20.583333333333332\n","  pid: 2774\n","  time_since_restore: 77.85273790359497\n","  time_this_iter_s: 4.271188497543335\n","  time_total_s: 77.85273790359497\n","  timestamp: 1649851396\n","  timesteps_since_restore: 0\n","  training_iteration: 18\n","  trial_id: 825a7_00002\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-03-17\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 15\n","  iterations_since_restore: 16\n","  mean_reward: -138.7281124860968\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.7\n","    ram_util_percent: 20.587500000000002\n","  pid: 2771\n","  time_since_restore: 78.86150527000427\n","  time_this_iter_s: 5.292983293533325\n","  time_total_s: 78.86150527000427\n","  timestamp: 1649851397\n","  timesteps_since_restore: 0\n","  training_iteration: 16\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00008:\n","  date: 2022-04-13_12-03-17\n","  done: false\n","  experiment_id: cd76c37ed72a4c299a0583e20567f167\n","  hostname: aa9ef03c8f27\n","  iterations: 15\n","  iterations_since_restore: 16\n","  mean_reward: -143.2745300942396\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.725\n","    ram_util_percent: 20.587500000000002\n","  pid: 2767\n","  time_since_restore: 78.9456512928009\n","  time_this_iter_s: 5.505925416946411\n","  time_total_s: 78.9456512928009\n","  timestamp: 1649851397\n","  timesteps_since_restore: 0\n","  training_iteration: 16\n","  trial_id: 825a7_00008\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-03-18\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 14\n","  iterations_since_restore: 15\n","  mean_reward: -125.75569971939373\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.766666666666666\n","    ram_util_percent: 20.6\n","  pid: 2776\n","  time_since_restore: 79.46917057037354\n","  time_this_iter_s: 6.012351751327515\n","  time_total_s: 79.46917057037354\n","  timestamp: 1649851398\n","  timesteps_since_restore: 0\n","  training_iteration: 15\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00005:\n","  date: 2022-04-13_12-03-19\n","  done: false\n","  experiment_id: d42ae5be5b334ba6981aa7673828d6d2\n","  hostname: aa9ef03c8f27\n","  iterations: 16\n","  iterations_since_restore: 17\n","  mean_reward: -159.7912595744555\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.542857142857144\n","    ram_util_percent: 20.62857142857143\n","  pid: 2773\n","  time_since_restore: 80.66397094726562\n","  time_this_iter_s: 5.2748565673828125\n","  time_total_s: 80.66397094726562\n","  timestamp: 1649851399\n","  timesteps_since_restore: 0\n","  training_iteration: 17\n","  trial_id: 825a7_00005\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00011:\n","  date: 2022-04-13_12-03-19\n","  done: false\n","  experiment_id: f576928441b043f48c9de3d6907ccbdd\n","  hostname: aa9ef03c8f27\n","  iterations: 16\n","  iterations_since_restore: 17\n","  mean_reward: -150.23025377001704\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.68571428571429\n","    ram_util_percent: 20.642857142857142\n","  pid: 2768\n","  time_since_restore: 80.93711447715759\n","  time_this_iter_s: 4.948511123657227\n","  time_total_s: 80.93711447715759\n","  timestamp: 1649851399\n","  timesteps_since_restore: 0\n","  training_iteration: 17\n","  trial_id: 825a7_00011\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-03-19\n","  done: false\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  hostname: aa9ef03c8f27\n","  iterations: 16\n","  iterations_since_restore: 17\n","  mean_reward: -138.02262374140005\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.714285714285715\n","    ram_util_percent: 20.642857142857142\n","  pid: 2777\n","  time_since_restore: 80.93307995796204\n","  time_this_iter_s: 4.839763879776001\n","  time_total_s: 80.93307995796204\n","  timestamp: 1649851399\n","  timesteps_since_restore: 0\n","  training_iteration: 17\n","  trial_id: 825a7_00010\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00009:\n","  date: 2022-04-13_12-03-19\n","  done: false\n","  experiment_id: 95c2bb28a0b642edb97e6a45503efe15\n","  hostname: aa9ef03c8f27\n","  iterations: 17\n","  iterations_since_restore: 18\n","  mean_reward: -162.22834841072452\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.68571428571429\n","    ram_util_percent: 20.642857142857142\n","  pid: 2769\n","  time_since_restore: 81.03611755371094\n","  time_this_iter_s: 4.8209381103515625\n","  time_total_s: 81.03611755371094\n","  timestamp: 1649851399\n","  timesteps_since_restore: 0\n","  training_iteration: 18\n","  trial_id: 825a7_00009\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-03-19\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 15\n","  iterations_since_restore: 16\n","  mean_reward: -152.58633347410202\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.65555555555555\n","    ram_util_percent: 20.633333333333333\n","  pid: 2775\n","  time_since_restore: 81.05536818504333\n","  time_this_iter_s: 5.911334991455078\n","  time_total_s: 81.05536818504333\n","  timestamp: 1649851399\n","  timesteps_since_restore: 0\n","  training_iteration: 16\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00006:\n","  date: 2022-04-13_12-03-20\n","  done: false\n","  experiment_id: 1452367bf557484fb196e21a6489d80a\n","  hostname: aa9ef03c8f27\n","  iterations: 18\n","  iterations_since_restore: 19\n","  mean_reward: -150.88345391480115\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.62857142857143\n","    ram_util_percent: 20.657142857142855\n","  pid: 2772\n","  time_since_restore: 81.69022870063782\n","  time_this_iter_s: 4.531185150146484\n","  time_total_s: 81.69022870063782\n","  timestamp: 1649851400\n","  timesteps_since_restore: 0\n","  training_iteration: 19\n","  trial_id: 825a7_00006\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:03:21 (running for 00:01:27.50)<br>Memory usage on this node: 7.3/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00004 with mean_reward=-125.75569971939373 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.9143838356374548, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         77.5683</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">     -136.652</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         80.961 </td><td style=\"text-align: right;\">          17</td><td style=\"text-align: right;\">     -185.928</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         82.2654</td><td style=\"text-align: right;\">          18</td><td style=\"text-align: right;\">     -189.853</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         81.0554</td><td style=\"text-align: right;\">          15</td><td style=\"text-align: right;\">     -152.586</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         79.4692</td><td style=\"text-align: right;\">          14</td><td style=\"text-align: right;\">     -125.756</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         80.664 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">     -159.791</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         81.6902</td><td style=\"text-align: right;\">          18</td><td style=\"text-align: right;\">     -150.883</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         78.8615</td><td style=\"text-align: right;\">          15</td><td style=\"text-align: right;\">     -138.728</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         78.9457</td><td style=\"text-align: right;\">          15</td><td style=\"text-align: right;\">     -143.275</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         81.0361</td><td style=\"text-align: right;\">          17</td><td style=\"text-align: right;\">     -162.228</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         80.9331</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">     -138.023</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         80.9371</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">     -150.23 </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00000:\n","  date: 2022-04-13_12-03-21\n","  done: false\n","  experiment_id: 696b6ae5d0474799847a48a1fd9db44c\n","  hostname: aa9ef03c8f27\n","  iterations: 17\n","  iterations_since_restore: 18\n","  mean_reward: -135.94799819694748\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.77142857142858\n","    ram_util_percent: 20.671428571428574\n","  pid: 2770\n","  time_since_restore: 82.77135109901428\n","  time_this_iter_s: 5.203049182891846\n","  time_total_s: 82.77135109901428\n","  timestamp: 1649851401\n","  timesteps_since_restore: 0\n","  training_iteration: 18\n","  trial_id: 825a7_00000\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-03-23\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 16\n","  iterations_since_restore: 17\n","  mean_reward: -138.1920055289847\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.8875\n","    ram_util_percent: 20.725\n","  pid: 2771\n","  time_since_restore: 84.80544424057007\n","  time_this_iter_s: 5.943938970565796\n","  time_total_s: 84.80544424057007\n","  timestamp: 1649851403\n","  timesteps_since_restore: 0\n","  training_iteration: 17\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-03-23\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 15\n","  iterations_since_restore: 16\n","  mean_reward: -124.9947866167774\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.785714285714285\n","    ram_util_percent: 20.728571428571428\n","  pid: 2776\n","  time_since_restore: 84.94083166122437\n","  time_this_iter_s: 5.47166109085083\n","  time_total_s: 84.94083166122437\n","  timestamp: 1649851403\n","  timesteps_since_restore: 0\n","  training_iteration: 16\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00001:\n","  date: 2022-04-13_12-03-24\n","  done: false\n","  experiment_id: bee5f156b4e14866b4e9e4f5ab3fad72\n","  hostname: aa9ef03c8f27\n","  iterations: 18\n","  iterations_since_restore: 19\n","  mean_reward: -186.67005633353236\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.11666666666667\n","    ram_util_percent: 20.749999999999996\n","  pid: 2778\n","  time_since_restore: 85.5629734992981\n","  time_this_iter_s: 4.601970434188843\n","  time_total_s: 85.5629734992981\n","  timestamp: 1649851404\n","  timesteps_since_restore: 0\n","  training_iteration: 19\n","  trial_id: 825a7_00001\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00002:\n","  date: 2022-04-13_12-03-25\n","  done: false\n","  experiment_id: 315539c1caa744e78ed8486a6a2213a0\n","  hostname: aa9ef03c8f27\n","  iterations: 19\n","  iterations_since_restore: 20\n","  mean_reward: -192.34836039392925\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.0\n","    ram_util_percent: 20.771428571428572\n","  pid: 2774\n","  time_since_restore: 86.59628105163574\n","  time_this_iter_s: 4.330924034118652\n","  time_total_s: 86.59628105163574\n","  timestamp: 1649851405\n","  timesteps_since_restore: 0\n","  training_iteration: 20\n","  trial_id: 825a7_00002\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00006:\n","  date: 2022-04-13_12-03-25\n","  done: false\n","  experiment_id: 1452367bf557484fb196e21a6489d80a\n","  hostname: aa9ef03c8f27\n","  iterations: 19\n","  iterations_since_restore: 20\n","  mean_reward: -147.83361597215765\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.04285714285714\n","    ram_util_percent: 20.771428571428572\n","  pid: 2772\n","  time_since_restore: 86.92906475067139\n","  time_this_iter_s: 5.238836050033569\n","  time_total_s: 86.92906475067139\n","  timestamp: 1649851405\n","  timesteps_since_restore: 0\n","  training_iteration: 20\n","  trial_id: 825a7_00006\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:03:26 (running for 00:01:32.56)<br>Memory usage on this node: 7.3/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00004 with mean_reward=-124.9947866167774 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.9143838356374548, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         87.3574</td><td style=\"text-align: right;\">          18</td><td style=\"text-align: right;\">     -139.522</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         85.563 </td><td style=\"text-align: right;\">          18</td><td style=\"text-align: right;\">     -186.67 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         86.5963</td><td style=\"text-align: right;\">          19</td><td style=\"text-align: right;\">     -192.348</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         85.9937</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">     -153.254</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         84.9408</td><td style=\"text-align: right;\">          15</td><td style=\"text-align: right;\">     -124.995</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         85.0439</td><td style=\"text-align: right;\">          17</td><td style=\"text-align: right;\">     -166.358</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         86.9291</td><td style=\"text-align: right;\">          19</td><td style=\"text-align: right;\">     -147.834</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         84.8054</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">     -138.192</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         83.89  </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">     -144.486</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         85.4677</td><td style=\"text-align: right;\">          18</td><td style=\"text-align: right;\">     -160.741</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         85.8372</td><td style=\"text-align: right;\">          17</td><td style=\"text-align: right;\">     -134.246</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         85.8551</td><td style=\"text-align: right;\">          17</td><td style=\"text-align: right;\">     -144.653</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00008:\n","  date: 2022-04-13_12-03-27\n","  done: false\n","  experiment_id: cd76c37ed72a4c299a0583e20567f167\n","  hostname: aa9ef03c8f27\n","  iterations: 17\n","  iterations_since_restore: 18\n","  mean_reward: -140.79383902652935\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.92857142857142\n","    ram_util_percent: 20.82857142857143\n","  pid: 2767\n","  time_since_restore: 88.74509978294373\n","  time_this_iter_s: 4.855083465576172\n","  time_total_s: 88.74509978294373\n","  timestamp: 1649851407\n","  timesteps_since_restore: 0\n","  training_iteration: 18\n","  trial_id: 825a7_00008\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00005:\n","  date: 2022-04-13_12-03-28\n","  done: false\n","  experiment_id: d42ae5be5b334ba6981aa7673828d6d2\n","  hostname: aa9ef03c8f27\n","  iterations: 18\n","  iterations_since_restore: 19\n","  mean_reward: -165.30237978163288\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.91428571428572\n","    ram_util_percent: 20.842857142857145\n","  pid: 2773\n","  time_since_restore: 89.743488073349\n","  time_this_iter_s: 4.699617385864258\n","  time_total_s: 89.743488073349\n","  timestamp: 1649851408\n","  timesteps_since_restore: 0\n","  training_iteration: 19\n","  trial_id: 825a7_00005\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00009:\n","  date: 2022-04-13_12-03-28\n","  done: false\n","  experiment_id: 95c2bb28a0b642edb97e6a45503efe15\n","  hostname: aa9ef03c8f27\n","  iterations: 19\n","  iterations_since_restore: 20\n","  mean_reward: -158.189860245039\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.06666666666666\n","    ram_util_percent: 20.850000000000005\n","  pid: 2769\n","  time_since_restore: 89.8591787815094\n","  time_this_iter_s: 4.391517877578735\n","  time_total_s: 89.8591787815094\n","  timestamp: 1649851408\n","  timesteps_since_restore: 0\n","  training_iteration: 20\n","  trial_id: 825a7_00009\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-03-28\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 16\n","  iterations_since_restore: 17\n","  mean_reward: -124.55562262721362\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.9875\n","    ram_util_percent: 20.85\n","  pid: 2776\n","  time_since_restore: 90.05314493179321\n","  time_this_iter_s: 5.112313270568848\n","  time_total_s: 90.05314493179321\n","  timestamp: 1649851408\n","  timesteps_since_restore: 0\n","  training_iteration: 17\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00011:\n","  date: 2022-04-13_12-03-29\n","  done: false\n","  experiment_id: f576928441b043f48c9de3d6907ccbdd\n","  hostname: aa9ef03c8f27\n","  iterations: 18\n","  iterations_since_restore: 19\n","  mean_reward: -139.0642511760935\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.0\n","    ram_util_percent: 20.871428571428574\n","  pid: 2768\n","  time_since_restore: 90.86788010597229\n","  time_this_iter_s: 5.0128114223480225\n","  time_total_s: 90.86788010597229\n","  timestamp: 1649851409\n","  timesteps_since_restore: 0\n","  training_iteration: 19\n","  trial_id: 825a7_00011\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-03-29\n","  done: false\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  hostname: aa9ef03c8f27\n","  iterations: 18\n","  iterations_since_restore: 19\n","  mean_reward: -130.95776563190228\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.98571428571428\n","    ram_util_percent: 20.871428571428574\n","  pid: 2777\n","  time_since_restore: 90.9932107925415\n","  time_this_iter_s: 5.156052589416504\n","  time_total_s: 90.9932107925415\n","  timestamp: 1649851409\n","  timesteps_since_restore: 0\n","  training_iteration: 19\n","  trial_id: 825a7_00010\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-03-30\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 17\n","  iterations_since_restore: 18\n","  mean_reward: -138.93836663941485\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.01111111111111\n","    ram_util_percent: 20.855555555555558\n","  pid: 2771\n","  time_since_restore: 91.13021850585938\n","  time_this_iter_s: 6.324774265289307\n","  time_total_s: 91.13021850585938\n","  timestamp: 1649851410\n","  timesteps_since_restore: 0\n","  training_iteration: 18\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-03-30\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 17\n","  iterations_since_restore: 18\n","  mean_reward: -160.32105601201303\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.125\n","    ram_util_percent: 20.875\n","  pid: 2775\n","  time_since_restore: 91.60453271865845\n","  time_this_iter_s: 5.610809087753296\n","  time_total_s: 91.60453271865845\n","  timestamp: 1649851410\n","  timesteps_since_restore: 0\n","  training_iteration: 18\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00000:\n","  date: 2022-04-13_12-03-30\n","  done: false\n","  experiment_id: 696b6ae5d0474799847a48a1fd9db44c\n","  hostname: aa9ef03c8f27\n","  iterations: 19\n","  iterations_since_restore: 20\n","  mean_reward: -140.1353653783102\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.78333333333333\n","    ram_util_percent: 20.900000000000002\n","  pid: 2770\n","  time_since_restore: 91.87089014053345\n","  time_this_iter_s: 4.513443946838379\n","  time_total_s: 91.87089014053345\n","  timestamp: 1649851410\n","  timesteps_since_restore: 0\n","  training_iteration: 20\n","  trial_id: 825a7_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:03:31 (running for 00:01:38.08)<br>Memory usage on this node: 7.4/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00004 with mean_reward=-124.55562262721362 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.9143838356374548, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         91.8709</td><td style=\"text-align: right;\">          19</td><td style=\"text-align: right;\">     -140.135</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         90.1102</td><td style=\"text-align: right;\">          19</td><td style=\"text-align: right;\">     -183.05 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         90.8208</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     -194.684</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         91.6045</td><td style=\"text-align: right;\">          17</td><td style=\"text-align: right;\">     -160.321</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         90.0531</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">     -124.556</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         89.7435</td><td style=\"text-align: right;\">          18</td><td style=\"text-align: right;\">     -165.302</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         91.8469</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     -150.047</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         91.1302</td><td style=\"text-align: right;\">          17</td><td style=\"text-align: right;\">     -138.938</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         88.7451</td><td style=\"text-align: right;\">          17</td><td style=\"text-align: right;\">     -140.794</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         89.8592</td><td style=\"text-align: right;\">          19</td><td style=\"text-align: right;\">     -158.19 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         90.9932</td><td style=\"text-align: right;\">          18</td><td style=\"text-align: right;\">     -130.958</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         90.8679</td><td style=\"text-align: right;\">          18</td><td style=\"text-align: right;\">     -139.064</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00001:\n","  date: 2022-04-13_12-03-33\n","  done: false\n","  experiment_id: bee5f156b4e14866b4e9e4f5ab3fad72\n","  hostname: aa9ef03c8f27\n","  iterations: 20\n","  iterations_since_restore: 21\n","  mean_reward: -182.9706810628872\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.31666666666667\n","    ram_util_percent: 20.95\n","  pid: 2778\n","  time_since_restore: 94.67800569534302\n","  time_this_iter_s: 4.5678393840789795\n","  time_total_s: 94.67800569534302\n","  timestamp: 1649851413\n","  timesteps_since_restore: 0\n","  training_iteration: 21\n","  trial_id: 825a7_00001\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00002:\n","  date: 2022-04-13_12-03-34\n","  done: false\n","  experiment_id: 315539c1caa744e78ed8486a6a2213a0\n","  hostname: aa9ef03c8f27\n","  iterations: 21\n","  iterations_since_restore: 22\n","  mean_reward: -192.36745761552646\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.366666666666674\n","    ram_util_percent: 20.966666666666665\n","  pid: 2774\n","  time_since_restore: 95.44122695922852\n","  time_this_iter_s: 4.620377540588379\n","  time_total_s: 95.44122695922852\n","  timestamp: 1649851414\n","  timesteps_since_restore: 0\n","  training_iteration: 22\n","  trial_id: 825a7_00002\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-03-34\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 17\n","  iterations_since_restore: 18\n","  mean_reward: -126.24523077134813\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.75\n","    ram_util_percent: 20.9625\n","  pid: 2776\n","  time_since_restore: 95.93972039222717\n","  time_this_iter_s: 5.88657546043396\n","  time_total_s: 95.93972039222717\n","  timestamp: 1649851414\n","  timesteps_since_restore: 0\n","  training_iteration: 18\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00006:\n","  date: 2022-04-13_12-03-35\n","  done: false\n","  experiment_id: 1452367bf557484fb196e21a6489d80a\n","  hostname: aa9ef03c8f27\n","  iterations: 21\n","  iterations_since_restore: 22\n","  mean_reward: -143.82593442331407\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.385714285714286\n","    ram_util_percent: 20.985714285714288\n","  pid: 2772\n","  time_since_restore: 96.43680691719055\n","  time_this_iter_s: 4.589886426925659\n","  time_total_s: 96.43680691719055\n","  timestamp: 1649851415\n","  timesteps_since_restore: 0\n","  training_iteration: 22\n","  trial_id: 825a7_00006\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-03-36\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 18\n","  iterations_since_restore: 19\n","  mean_reward: -139.09593691071868\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.37777777777778\n","    ram_util_percent: 20.98888888888889\n","  pid: 2771\n","  time_since_restore: 97.39934468269348\n","  time_this_iter_s: 6.2691261768341064\n","  time_total_s: 97.39934468269348\n","  timestamp: 1649851416\n","  timesteps_since_restore: 0\n","  training_iteration: 19\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00008:\n","  date: 2022-04-13_12-03-36\n","  done: false\n","  experiment_id: cd76c37ed72a4c299a0583e20567f167\n","  hostname: aa9ef03c8f27\n","  iterations: 19\n","  iterations_since_restore: 20\n","  mean_reward: -143.6579152573302\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.957142857142856\n","    ram_util_percent: 21.02857142857143\n","  pid: 2767\n","  time_since_restore: 97.92900896072388\n","  time_this_iter_s: 4.663572549819946\n","  time_total_s: 97.92900896072388\n","  timestamp: 1649851416\n","  timesteps_since_restore: 0\n","  training_iteration: 20\n","  trial_id: 825a7_00008\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:03:36 (running for 00:01:43.17)<br>Memory usage on this node: 7.4/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00004 with mean_reward=-126.24523077134813 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.9143838356374548, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         96.4044</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     -139.16 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         94.678 </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     -182.971</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         95.4412</td><td style=\"text-align: right;\">          21</td><td style=\"text-align: right;\">     -192.367</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         96.2595</td><td style=\"text-align: right;\">          18</td><td style=\"text-align: right;\">     -161.64 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         95.9397</td><td style=\"text-align: right;\">          17</td><td style=\"text-align: right;\">     -126.245</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         94.281 </td><td style=\"text-align: right;\">          19</td><td style=\"text-align: right;\">     -155.294</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         96.4368</td><td style=\"text-align: right;\">          21</td><td style=\"text-align: right;\">     -143.826</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         97.3993</td><td style=\"text-align: right;\">          18</td><td style=\"text-align: right;\">     -139.096</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         97.929 </td><td style=\"text-align: right;\">          19</td><td style=\"text-align: right;\">     -143.658</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         94.389 </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     -156.919</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         95.5605</td><td style=\"text-align: right;\">          19</td><td style=\"text-align: right;\">     -138.641</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         95.4373</td><td style=\"text-align: right;\">          19</td><td style=\"text-align: right;\">     -132.514</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00005:\n","  date: 2022-04-13_12-03-37\n","  done: false\n","  experiment_id: d42ae5be5b334ba6981aa7673828d6d2\n","  hostname: aa9ef03c8f27\n","  iterations: 20\n","  iterations_since_restore: 21\n","  mean_reward: -154.3577576669521\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.91428571428571\n","    ram_util_percent: 21.04285714285714\n","  pid: 2773\n","  time_since_restore: 98.82400393486023\n","  time_this_iter_s: 4.543042421340942\n","  time_total_s: 98.82400393486023\n","  timestamp: 1649851417\n","  timesteps_since_restore: 0\n","  training_iteration: 21\n","  trial_id: 825a7_00005\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00009:\n","  date: 2022-04-13_12-03-37\n","  done: false\n","  experiment_id: 95c2bb28a0b642edb97e6a45503efe15\n","  hostname: aa9ef03c8f27\n","  iterations: 21\n","  iterations_since_restore: 22\n","  mean_reward: -155.15449917825285\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.26666666666667\n","    ram_util_percent: 21.049999999999997\n","  pid: 2769\n","  time_since_restore: 98.98382663726807\n","  time_this_iter_s: 4.594832181930542\n","  time_total_s: 98.98382663726807\n","  timestamp: 1649851417\n","  timesteps_since_restore: 0\n","  training_iteration: 22\n","  trial_id: 825a7_00009\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00011:\n","  date: 2022-04-13_12-03-39\n","  done: false\n","  experiment_id: f576928441b043f48c9de3d6907ccbdd\n","  hostname: aa9ef03c8f27\n","  iterations: 20\n","  iterations_since_restore: 21\n","  mean_reward: -127.49099108779066\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.75714285714286\n","    ram_util_percent: 21.071428571428573\n","  pid: 2768\n","  time_since_restore: 100.3526656627655\n","  time_this_iter_s: 4.9153220653533936\n","  time_total_s: 100.3526656627655\n","  timestamp: 1649851419\n","  timesteps_since_restore: 0\n","  training_iteration: 21\n","  trial_id: 825a7_00011\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-03-39\n","  done: false\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  hostname: aa9ef03c8f27\n","  iterations: 20\n","  iterations_since_restore: 21\n","  mean_reward: -141.06851428100902\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.7375\n","    ram_util_percent: 21.075000000000003\n","  pid: 2777\n","  time_since_restore: 100.79240131378174\n","  time_this_iter_s: 5.231937885284424\n","  time_total_s: 100.79240131378174\n","  timestamp: 1649851419\n","  timesteps_since_restore: 0\n","  training_iteration: 21\n","  trial_id: 825a7_00010\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00000:\n","  date: 2022-04-13_12-03-40\n","  done: false\n","  experiment_id: 696b6ae5d0474799847a48a1fd9db44c\n","  hostname: aa9ef03c8f27\n","  iterations: 21\n","  iterations_since_restore: 22\n","  mean_reward: -135.3715955427609\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.385714285714286\n","    ram_util_percent: 21.099999999999998\n","  pid: 2770\n","  time_since_restore: 101.8968665599823\n","  time_this_iter_s: 5.49243426322937\n","  time_total_s: 101.8968665599823\n","  timestamp: 1649851420\n","  timesteps_since_restore: 0\n","  training_iteration: 22\n","  trial_id: 825a7_00000\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-03-40\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 18\n","  iterations_since_restore: 19\n","  mean_reward: -126.03123912954713\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.2\n","    ram_util_percent: 21.1\n","  pid: 2776\n","  time_since_restore: 101.93157744407654\n","  time_this_iter_s: 5.991857051849365\n","  time_total_s: 101.93157744407654\n","  timestamp: 1649851420\n","  timesteps_since_restore: 0\n","  training_iteration: 19\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-03-41\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 19\n","  iterations_since_restore: 20\n","  mean_reward: -158.53702845364538\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.58888888888889\n","    ram_util_percent: 21.11111111111111\n","  pid: 2775\n","  time_since_restore: 102.20349311828613\n","  time_this_iter_s: 5.9439966678619385\n","  time_total_s: 102.20349311828613\n","  timestamp: 1649851421\n","  timesteps_since_restore: 0\n","  training_iteration: 20\n","  trial_id: 825a7_00003\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:03:42 (running for 00:01:48.40)<br>Memory usage on this node: 7.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00004 with mean_reward=-126.03123912954713 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.9143838356374548, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">        101.897 </td><td style=\"text-align: right;\">          21</td><td style=\"text-align: right;\">     -135.372</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         99.3227</td><td style=\"text-align: right;\">          21</td><td style=\"text-align: right;\">     -183.331</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         99.8999</td><td style=\"text-align: right;\">          22</td><td style=\"text-align: right;\">     -196.949</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">        102.203 </td><td style=\"text-align: right;\">          19</td><td style=\"text-align: right;\">     -158.537</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">        101.932 </td><td style=\"text-align: right;\">          18</td><td style=\"text-align: right;\">     -126.031</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         98.824 </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     -154.358</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">        101.08  </td><td style=\"text-align: right;\">          22</td><td style=\"text-align: right;\">     -145    </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         97.3993</td><td style=\"text-align: right;\">          18</td><td style=\"text-align: right;\">     -139.096</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         97.929 </td><td style=\"text-align: right;\">          19</td><td style=\"text-align: right;\">     -143.658</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         98.9838</td><td style=\"text-align: right;\">          21</td><td style=\"text-align: right;\">     -155.154</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">        100.792 </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     -141.069</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">        100.353 </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     -127.491</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00008:\n","  date: 2022-04-13_12-03-42\n","  done: false\n","  experiment_id: cd76c37ed72a4c299a0583e20567f167\n","  hostname: aa9ef03c8f27\n","  iterations: 20\n","  iterations_since_restore: 21\n","  mean_reward: -147.1357694140801\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.385714285714286\n","    ram_util_percent: 21.142857142857142\n","  pid: 2767\n","  time_since_restore: 103.3570647239685\n","  time_this_iter_s: 5.428055763244629\n","  time_total_s: 103.3570647239685\n","  timestamp: 1649851422\n","  timesteps_since_restore: 0\n","  training_iteration: 21\n","  trial_id: 825a7_00008\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-03-43\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 19\n","  iterations_since_restore: 20\n","  mean_reward: -138.93308226920715\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.36999999999999\n","    ram_util_percent: 21.15\n","  pid: 2771\n","  time_since_restore: 104.30979657173157\n","  time_this_iter_s: 6.910451889038086\n","  time_total_s: 104.30979657173157\n","  timestamp: 1649851423\n","  timesteps_since_restore: 0\n","  training_iteration: 20\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00002:\n","  date: 2022-04-13_12-03-43\n","  done: false\n","  experiment_id: 315539c1caa744e78ed8486a6a2213a0\n","  hostname: aa9ef03c8f27\n","  iterations: 23\n","  iterations_since_restore: 24\n","  mean_reward: -197.2897081916477\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.21666666666667\n","    ram_util_percent: 21.183333333333334\n","  pid: 2774\n","  time_since_restore: 104.40287733078003\n","  time_this_iter_s: 4.502944231033325\n","  time_total_s: 104.40287733078003\n","  timestamp: 1649851423\n","  timesteps_since_restore: 0\n","  training_iteration: 24\n","  trial_id: 825a7_00002\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00001:\n","  date: 2022-04-13_12-03-43\n","  done: false\n","  experiment_id: bee5f156b4e14866b4e9e4f5ab3fad72\n","  hostname: aa9ef03c8f27\n","  iterations: 22\n","  iterations_since_restore: 23\n","  mean_reward: -179.22736954237232\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.01428571428572\n","    ram_util_percent: 21.171428571428574\n","  pid: 2778\n","  time_since_restore: 104.71700382232666\n","  time_this_iter_s: 5.3942718505859375\n","  time_total_s: 104.71700382232666\n","  timestamp: 1649851423\n","  timesteps_since_restore: 0\n","  training_iteration: 23\n","  trial_id: 825a7_00001\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-03-44\n","  done: false\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  hostname: aa9ef03c8f27\n","  iterations: 21\n","  iterations_since_restore: 22\n","  mean_reward: -138.67616085701266\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.51428571428572\n","    ram_util_percent: 21.214285714285715\n","  pid: 2777\n","  time_since_restore: 105.87209010124207\n","  time_this_iter_s: 5.079688787460327\n","  time_total_s: 105.87209010124207\n","  timestamp: 1649851424\n","  timesteps_since_restore: 0\n","  training_iteration: 22\n","  trial_id: 825a7_00010\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00006:\n","  date: 2022-04-13_12-03-45\n","  done: false\n","  experiment_id: 1452367bf557484fb196e21a6489d80a\n","  hostname: aa9ef03c8f27\n","  iterations: 23\n","  iterations_since_restore: 24\n","  mean_reward: -139.58706054367607\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.37142857142857\n","    ram_util_percent: 21.185714285714287\n","  pid: 2772\n","  time_since_restore: 106.08790802955627\n","  time_this_iter_s: 5.007641792297363\n","  time_total_s: 106.08790802955627\n","  timestamp: 1649851425\n","  timesteps_since_restore: 0\n","  training_iteration: 24\n","  trial_id: 825a7_00006\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-03-46\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 19\n","  iterations_since_restore: 20\n","  mean_reward: -125.61044111798206\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.0\n","    ram_util_percent: 21.225\n","  pid: 2776\n","  time_since_restore: 107.14136481285095\n","  time_this_iter_s: 5.209787368774414\n","  time_total_s: 107.14136481285095\n","  timestamp: 1649851426\n","  timesteps_since_restore: 0\n","  training_iteration: 20\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00000:\n","  date: 2022-04-13_12-03-46\n","  done: false\n","  experiment_id: 696b6ae5d0474799847a48a1fd9db44c\n","  hostname: aa9ef03c8f27\n","  iterations: 22\n","  iterations_since_restore: 23\n","  mean_reward: -132.01018232239232\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.825\n","    ram_util_percent: 21.225\n","  pid: 2770\n","  time_since_restore: 107.49018883705139\n","  time_this_iter_s: 5.593322277069092\n","  time_total_s: 107.49018883705139\n","  timestamp: 1649851426\n","  timesteps_since_restore: 0\n","  training_iteration: 23\n","  trial_id: 825a7_00000\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00005:\n","  date: 2022-04-13_12-03-46\n","  done: false\n","  experiment_id: d42ae5be5b334ba6981aa7673828d6d2\n","  hostname: aa9ef03c8f27\n","  iterations: 22\n","  iterations_since_restore: 23\n","  mean_reward: -149.06286506180527\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.07142857142857\n","    ram_util_percent: 21.257142857142856\n","  pid: 2773\n","  time_since_restore: 108.04632139205933\n","  time_this_iter_s: 4.723665952682495\n","  time_total_s: 108.04632139205933\n","  timestamp: 1649851426\n","  timesteps_since_restore: 0\n","  training_iteration: 23\n","  trial_id: 825a7_00005\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00009:\n","  date: 2022-04-13_12-03-47\n","  done: false\n","  experiment_id: 95c2bb28a0b642edb97e6a45503efe15\n","  hostname: aa9ef03c8f27\n","  iterations: 23\n","  iterations_since_restore: 24\n","  mean_reward: -154.86308729022608\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.63333333333333\n","    ram_util_percent: 21.249999999999996\n","  pid: 2769\n","  time_since_restore: 108.17880392074585\n","  time_this_iter_s: 4.645947217941284\n","  time_total_s: 108.17880392074585\n","  timestamp: 1649851427\n","  timesteps_since_restore: 0\n","  training_iteration: 24\n","  trial_id: 825a7_00009\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00008:\n","  date: 2022-04-13_12-03-47\n","  done: false\n","  experiment_id: cd76c37ed72a4c299a0583e20567f167\n","  hostname: aa9ef03c8f27\n","  iterations: 21\n","  iterations_since_restore: 22\n","  mean_reward: -141.2507269849633\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.075\n","    ram_util_percent: 21.262500000000003\n","  pid: 2767\n","  time_since_restore: 108.61186599731445\n","  time_this_iter_s: 5.254801273345947\n","  time_total_s: 108.61186599731445\n","  timestamp: 1649851427\n","  timesteps_since_restore: 0\n","  training_iteration: 22\n","  trial_id: 825a7_00008\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:03:47 (running for 00:01:53.85)<br>Memory usage on this node: 7.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00004 with mean_reward=-125.61044111798206 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.9143838356374548, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         107.49 </td><td style=\"text-align: right;\">          22</td><td style=\"text-align: right;\">     -132.01 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         104.717</td><td style=\"text-align: right;\">          22</td><td style=\"text-align: right;\">     -179.227</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         104.403</td><td style=\"text-align: right;\">          23</td><td style=\"text-align: right;\">     -197.29 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         106.627</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     -158.757</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         107.141</td><td style=\"text-align: right;\">          19</td><td style=\"text-align: right;\">     -125.61 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         108.046</td><td style=\"text-align: right;\">          22</td><td style=\"text-align: right;\">     -149.063</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         106.088</td><td style=\"text-align: right;\">          23</td><td style=\"text-align: right;\">     -139.587</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         104.31 </td><td style=\"text-align: right;\">          19</td><td style=\"text-align: right;\">     -138.933</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         108.612</td><td style=\"text-align: right;\">          21</td><td style=\"text-align: right;\">     -141.251</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         108.179</td><td style=\"text-align: right;\">          23</td><td style=\"text-align: right;\">     -154.863</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         105.872</td><td style=\"text-align: right;\">          21</td><td style=\"text-align: right;\">     -138.676</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         104.866</td><td style=\"text-align: right;\">          21</td><td style=\"text-align: right;\">     -127.235</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00011:\n","  date: 2022-04-13_12-03-48\n","  done: false\n","  experiment_id: f576928441b043f48c9de3d6907ccbdd\n","  hostname: aa9ef03c8f27\n","  iterations: 22\n","  iterations_since_restore: 23\n","  mean_reward: -125.66583385560017\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.266666666666666\n","    ram_util_percent: 21.3\n","  pid: 2768\n","  time_since_restore: 109.38272452354431\n","  time_this_iter_s: 4.516493082046509\n","  time_total_s: 109.38272452354431\n","  timestamp: 1649851428\n","  timesteps_since_restore: 0\n","  training_iteration: 23\n","  trial_id: 825a7_00011\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-03-48\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 20\n","  iterations_since_restore: 21\n","  mean_reward: -138.14522138087358\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.2625\n","    ram_util_percent: 21.3\n","  pid: 2771\n","  time_since_restore: 109.83581018447876\n","  time_this_iter_s: 5.526013612747192\n","  time_total_s: 109.83581018447876\n","  timestamp: 1649851428\n","  timesteps_since_restore: 0\n","  training_iteration: 21\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-03-51\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 21\n","  iterations_since_restore: 22\n","  mean_reward: -155.5256410539285\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.9625\n","    ram_util_percent: 21.35\n","  pid: 2775\n","  time_since_restore: 112.25604891777039\n","  time_this_iter_s: 5.629135847091675\n","  time_total_s: 112.25604891777039\n","  timestamp: 1649851431\n","  timesteps_since_restore: 0\n","  training_iteration: 22\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-03-51\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 20\n","  iterations_since_restore: 21\n","  mean_reward: -125.59557295621379\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.8375\n","    ram_util_percent: 21.3625\n","  pid: 2776\n","  time_since_restore: 112.83141231536865\n","  time_this_iter_s: 5.6900475025177\n","  time_total_s: 112.83141231536865\n","  timestamp: 1649851431\n","  timesteps_since_restore: 0\n","  training_iteration: 21\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00009:\n","  date: 2022-04-13_12-03-52\n","  done: false\n","  experiment_id: 95c2bb28a0b642edb97e6a45503efe15\n","  hostname: aa9ef03c8f27\n","  iterations: 24\n","  iterations_since_restore: 25\n","  mean_reward: -154.35256344629758\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.1125\n","    ram_util_percent: 21.375\n","  pid: 2769\n","  time_since_restore: 113.59298133850098\n","  time_this_iter_s: 5.414177417755127\n","  time_total_s: 113.59298133850098\n","  timestamp: 1649851432\n","  timesteps_since_restore: 0\n","  training_iteration: 25\n","  trial_id: 825a7_00009\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:03:52 (running for 00:01:59.15)<br>Memory usage on this node: 7.6/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00011 with mean_reward=-123.61925438778543 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.5616905067242305, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': False, 'hiddens': [256], 'double_q': False, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         112.152</td><td style=\"text-align: right;\">          23</td><td style=\"text-align: right;\">     -132.625</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         109.318</td><td style=\"text-align: right;\">          23</td><td style=\"text-align: right;\">     -177.442</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         109.061</td><td style=\"text-align: right;\">          24</td><td style=\"text-align: right;\">     -198.643</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         112.256</td><td style=\"text-align: right;\">          21</td><td style=\"text-align: right;\">     -155.526</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         112.831</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     -125.596</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         112.585</td><td style=\"text-align: right;\">          23</td><td style=\"text-align: right;\">     -147.235</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         110.604</td><td style=\"text-align: right;\">          24</td><td style=\"text-align: right;\">     -129.271</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         109.836</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">     -138.145</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         113.164</td><td style=\"text-align: right;\">          22</td><td style=\"text-align: right;\">     -138.635</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         113.593</td><td style=\"text-align: right;\">          24</td><td style=\"text-align: right;\">     -154.353</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         110.766</td><td style=\"text-align: right;\">          22</td><td style=\"text-align: right;\">     -138.648</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         113.924</td><td style=\"text-align: right;\">          23</td><td style=\"text-align: right;\">     -123.619</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00001:\n","  date: 2022-04-13_12-03-52\n","  done: false\n","  experiment_id: bee5f156b4e14866b4e9e4f5ab3fad72\n","  hostname: aa9ef03c8f27\n","  iterations: 24\n","  iterations_since_restore: 25\n","  mean_reward: -177.9832292524061\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.75714285714286\n","    ram_util_percent: 21.400000000000002\n","  pid: 2778\n","  time_since_restore: 114.03088021278381\n","  time_this_iter_s: 4.713129997253418\n","  time_total_s: 114.03088021278381\n","  timestamp: 1649851432\n","  timesteps_since_restore: 0\n","  training_iteration: 25\n","  trial_id: 825a7_00001\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00002:\n","  date: 2022-04-13_12-03-54\n","  done: false\n","  experiment_id: 315539c1caa744e78ed8486a6a2213a0\n","  hostname: aa9ef03c8f27\n","  iterations: 25\n","  iterations_since_restore: 26\n","  mean_reward: -199.01940082146632\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.637499999999996\n","    ram_util_percent: 21.412499999999998\n","  pid: 2774\n","  time_since_restore: 115.21563172340393\n","  time_this_iter_s: 6.154607534408569\n","  time_total_s: 115.21563172340393\n","  timestamp: 1649851434\n","  timesteps_since_restore: 0\n","  training_iteration: 26\n","  trial_id: 825a7_00002\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00006:\n","  date: 2022-04-13_12-03-54\n","  done: false\n","  experiment_id: 1452367bf557484fb196e21a6489d80a\n","  hostname: aa9ef03c8f27\n","  iterations: 25\n","  iterations_since_restore: 26\n","  mean_reward: -128.06420898207006\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.75\n","    ram_util_percent: 21.416666666666668\n","  pid: 2772\n","  time_since_restore: 115.23695802688599\n","  time_this_iter_s: 4.632531404495239\n","  time_total_s: 115.23695802688599\n","  timestamp: 1649851434\n","  timesteps_since_restore: 0\n","  training_iteration: 26\n","  trial_id: 825a7_00006\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-03-54\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 21\n","  iterations_since_restore: 22\n","  mean_reward: -137.52420575145314\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.525000000000006\n","    ram_util_percent: 21.424999999999997\n","  pid: 2771\n","  time_since_restore: 115.44644546508789\n","  time_this_iter_s: 5.610635280609131\n","  time_total_s: 115.44644546508789\n","  timestamp: 1649851434\n","  timesteps_since_restore: 0\n","  training_iteration: 22\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-03-54\n","  done: false\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  hostname: aa9ef03c8f27\n","  iterations: 23\n","  iterations_since_restore: 24\n","  mean_reward: -133.45979834418918\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.557142857142864\n","    ram_util_percent: 21.428571428571427\n","  pid: 2777\n","  time_since_restore: 115.73520398139954\n","  time_this_iter_s: 4.9687159061431885\n","  time_total_s: 115.73520398139954\n","  timestamp: 1649851434\n","  timesteps_since_restore: 0\n","  training_iteration: 24\n","  trial_id: 825a7_00010\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00000:\n","  date: 2022-04-13_12-03-56\n","  done: false\n","  experiment_id: 696b6ae5d0474799847a48a1fd9db44c\n","  hostname: aa9ef03c8f27\n","  iterations: 24\n","  iterations_since_restore: 25\n","  mean_reward: -130.39133620359337\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.84285714285714\n","    ram_util_percent: 21.457142857142856\n","  pid: 2770\n","  time_since_restore: 117.29431867599487\n","  time_this_iter_s: 5.142814636230469\n","  time_total_s: 117.29431867599487\n","  timestamp: 1649851436\n","  timesteps_since_restore: 0\n","  training_iteration: 25\n","  trial_id: 825a7_00000\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-03-56\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 22\n","  iterations_since_restore: 23\n","  mean_reward: -145.72102770868693\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.699999999999996\n","    ram_util_percent: 21.457142857142856\n","  pid: 2775\n","  time_since_restore: 117.38956427574158\n","  time_this_iter_s: 5.133515357971191\n","  time_total_s: 117.38956427574158\n","  timestamp: 1649851436\n","  timesteps_since_restore: 0\n","  training_iteration: 23\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00005:\n","  date: 2022-04-13_12-03-56\n","  done: false\n","  experiment_id: d42ae5be5b334ba6981aa7673828d6d2\n","  hostname: aa9ef03c8f27\n","  iterations: 24\n","  iterations_since_restore: 25\n","  mean_reward: -144.95178291491933\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.74285714285714\n","    ram_util_percent: 21.457142857142856\n","  pid: 2773\n","  time_since_restore: 117.38072681427002\n","  time_this_iter_s: 4.795236349105835\n","  time_total_s: 117.38072681427002\n","  timestamp: 1649851436\n","  timesteps_since_restore: 0\n","  training_iteration: 25\n","  trial_id: 825a7_00005\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00008:\n","  date: 2022-04-13_12-03-56\n","  done: false\n","  experiment_id: cd76c37ed72a4c299a0583e20567f167\n","  hostname: aa9ef03c8f27\n","  iterations: 23\n","  iterations_since_restore: 24\n","  mean_reward: -137.65271740881641\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.971428571428575\n","    ram_util_percent: 21.47142857142857\n","  pid: 2767\n","  time_since_restore: 117.7697126865387\n","  time_this_iter_s: 4.606037139892578\n","  time_total_s: 117.7697126865387\n","  timestamp: 1649851436\n","  timesteps_since_restore: 0\n","  training_iteration: 24\n","  trial_id: 825a7_00008\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00011:\n","  date: 2022-04-13_12-03-57\n","  done: false\n","  experiment_id: f576928441b043f48c9de3d6907ccbdd\n","  hostname: aa9ef03c8f27\n","  iterations: 24\n","  iterations_since_restore: 25\n","  mean_reward: -116.98503991050822\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.71666666666667\n","    ram_util_percent: 21.5\n","  pid: 2768\n","  time_since_restore: 118.79970002174377\n","  time_this_iter_s: 4.875540494918823\n","  time_total_s: 118.79970002174377\n","  timestamp: 1649851437\n","  timesteps_since_restore: 0\n","  training_iteration: 25\n","  trial_id: 825a7_00011\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-03-57\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 21\n","  iterations_since_restore: 22\n","  mean_reward: -124.37588598523668\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.900000000000006\n","    ram_util_percent: 21.48888888888889\n","  pid: 2776\n","  time_since_restore: 119.07960438728333\n","  time_this_iter_s: 6.248192071914673\n","  time_total_s: 119.07960438728333\n","  timestamp: 1649851437\n","  timesteps_since_restore: 0\n","  training_iteration: 22\n","  trial_id: 825a7_00004\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:03:57 (running for 00:02:04.29)<br>Memory usage on this node: 7.6/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00011 with mean_reward=-116.98503991050822 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.5616905067242305, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': False, 'hiddens': [256], 'double_q': False, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         117.294</td><td style=\"text-align: right;\">          24</td><td style=\"text-align: right;\">     -130.391</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         118.493</td><td style=\"text-align: right;\">          25</td><td style=\"text-align: right;\">     -177.207</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         115.216</td><td style=\"text-align: right;\">          25</td><td style=\"text-align: right;\">     -199.019</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         117.39 </td><td style=\"text-align: right;\">          22</td><td style=\"text-align: right;\">     -145.721</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         119.08 </td><td style=\"text-align: right;\">          21</td><td style=\"text-align: right;\">     -124.376</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         117.381</td><td style=\"text-align: right;\">          24</td><td style=\"text-align: right;\">     -144.952</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         115.237</td><td style=\"text-align: right;\">          25</td><td style=\"text-align: right;\">     -128.064</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         115.446</td><td style=\"text-align: right;\">          21</td><td style=\"text-align: right;\">     -137.524</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         117.77 </td><td style=\"text-align: right;\">          23</td><td style=\"text-align: right;\">     -137.653</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         118.328</td><td style=\"text-align: right;\">          25</td><td style=\"text-align: right;\">     -146.823</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         115.735</td><td style=\"text-align: right;\">          23</td><td style=\"text-align: right;\">     -133.46 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         118.8  </td><td style=\"text-align: right;\">          24</td><td style=\"text-align: right;\">     -116.985</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-04-00\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 22\n","  iterations_since_restore: 23\n","  mean_reward: -137.3178835138623\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.7375\n","    ram_util_percent: 21.55\n","  pid: 2771\n","  time_since_restore: 121.29248642921448\n","  time_this_iter_s: 5.846040964126587\n","  time_total_s: 121.29248642921448\n","  timestamp: 1649851440\n","  timesteps_since_restore: 0\n","  training_iteration: 23\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00005:\n","  date: 2022-04-13_12-04-01\n","  done: false\n","  experiment_id: d42ae5be5b334ba6981aa7673828d6d2\n","  hostname: aa9ef03c8f27\n","  iterations: 25\n","  iterations_since_restore: 26\n","  mean_reward: -134.84478370321278\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.475\n","    ram_util_percent: 21.575000000000003\n","  pid: 2773\n","  time_since_restore: 122.46407866477966\n","  time_this_iter_s: 5.0833518505096436\n","  time_total_s: 122.46407866477966\n","  timestamp: 1649851441\n","  timesteps_since_restore: 0\n","  training_iteration: 26\n","  trial_id: 825a7_00005\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00009:\n","  date: 2022-04-13_12-04-01\n","  done: false\n","  experiment_id: 95c2bb28a0b642edb97e6a45503efe15\n","  hostname: aa9ef03c8f27\n","  iterations: 26\n","  iterations_since_restore: 27\n","  mean_reward: -147.58896663321616\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.285714285714285\n","    ram_util_percent: 21.585714285714285\n","  pid: 2769\n","  time_since_restore: 122.90751218795776\n","  time_this_iter_s: 4.579166650772095\n","  time_total_s: 122.90751218795776\n","  timestamp: 1649851441\n","  timesteps_since_restore: 0\n","  training_iteration: 27\n","  trial_id: 825a7_00009\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00001:\n","  date: 2022-04-13_12-04-02\n","  done: false\n","  experiment_id: bee5f156b4e14866b4e9e4f5ab3fad72\n","  hostname: aa9ef03c8f27\n","  iterations: 26\n","  iterations_since_restore: 27\n","  mean_reward: -172.47581296471833\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.542857142857144\n","    ram_util_percent: 21.61428571428571\n","  pid: 2778\n","  time_since_restore: 123.57495999336243\n","  time_this_iter_s: 5.081702470779419\n","  time_total_s: 123.57495999336243\n","  timestamp: 1649851442\n","  timesteps_since_restore: 0\n","  training_iteration: 27\n","  trial_id: 825a7_00001\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00011:\n","  date: 2022-04-13_12-04-02\n","  done: false\n","  experiment_id: f576928441b043f48c9de3d6907ccbdd\n","  hostname: aa9ef03c8f27\n","  iterations: 25\n","  iterations_since_restore: 26\n","  mean_reward: -114.65980642105667\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.575\n","    ram_util_percent: 21.625\n","  pid: 2768\n","  time_since_restore: 123.93953943252563\n","  time_this_iter_s: 5.13983941078186\n","  time_total_s: 123.93953943252563\n","  timestamp: 1649851442\n","  timesteps_since_restore: 0\n","  training_iteration: 26\n","  trial_id: 825a7_00011\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00006:\n","  date: 2022-04-13_12-04-03\n","  done: false\n","  experiment_id: 1452367bf557484fb196e21a6489d80a\n","  hostname: aa9ef03c8f27\n","  iterations: 27\n","  iterations_since_restore: 28\n","  mean_reward: -125.62542702368793\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.86666666666667\n","    ram_util_percent: 21.633333333333336\n","  pid: 2772\n","  time_since_restore: 124.33607459068298\n","  time_this_iter_s: 4.4901511669158936\n","  time_total_s: 124.33607459068298\n","  timestamp: 1649851443\n","  timesteps_since_restore: 0\n","  training_iteration: 28\n","  trial_id: 825a7_00006\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:04:03 (running for 00:02:09.57)<br>Memory usage on this node: 7.6/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00011 with mean_reward=-114.65980642105667 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.5616905067242305, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': False, 'hiddens': [256], 'double_q': False, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         122.01 </td><td style=\"text-align: right;\">          25</td><td style=\"text-align: right;\">     -129.075</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         123.575</td><td style=\"text-align: right;\">          26</td><td style=\"text-align: right;\">     -172.476</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         120.087</td><td style=\"text-align: right;\">          26</td><td style=\"text-align: right;\">     -195.52 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         122.346</td><td style=\"text-align: right;\">          23</td><td style=\"text-align: right;\">     -140.23 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         119.08 </td><td style=\"text-align: right;\">          21</td><td style=\"text-align: right;\">     -124.376</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         122.464</td><td style=\"text-align: right;\">          25</td><td style=\"text-align: right;\">     -134.845</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         124.336</td><td style=\"text-align: right;\">          27</td><td style=\"text-align: right;\">     -125.625</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         121.292</td><td style=\"text-align: right;\">          22</td><td style=\"text-align: right;\">     -137.318</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         122.609</td><td style=\"text-align: right;\">          24</td><td style=\"text-align: right;\">     -137.01 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         122.908</td><td style=\"text-align: right;\">          26</td><td style=\"text-align: right;\">     -147.589</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         120.562</td><td style=\"text-align: right;\">          24</td><td style=\"text-align: right;\">     -130.516</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         123.94 </td><td style=\"text-align: right;\">          25</td><td style=\"text-align: right;\">     -114.66 </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-04-04\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 22\n","  iterations_since_restore: 23\n","  mean_reward: -124.52458407658064\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.300000000000004\n","    ram_util_percent: 21.644444444444442\n","  pid: 2776\n","  time_since_restore: 125.17396593093872\n","  time_this_iter_s: 6.0943615436553955\n","  time_total_s: 125.17396593093872\n","  timestamp: 1649851444\n","  timesteps_since_restore: 0\n","  training_iteration: 23\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00002:\n","  date: 2022-04-13_12-04-04\n","  done: false\n","  experiment_id: 315539c1caa744e78ed8486a6a2213a0\n","  hostname: aa9ef03c8f27\n","  iterations: 27\n","  iterations_since_restore: 28\n","  mean_reward: -194.1663605816571\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.7375\n","    ram_util_percent: 21.65\n","  pid: 2774\n","  time_since_restore: 125.25964260101318\n","  time_this_iter_s: 5.1724841594696045\n","  time_total_s: 125.25964260101318\n","  timestamp: 1649851444\n","  timesteps_since_restore: 0\n","  training_iteration: 28\n","  trial_id: 825a7_00002\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-04-04\n","  done: false\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  hostname: aa9ef03c8f27\n","  iterations: 25\n","  iterations_since_restore: 26\n","  mean_reward: -129.29617440411468\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.67142857142857\n","    ram_util_percent: 21.657142857142855\n","  pid: 2777\n","  time_since_restore: 125.569655418396\n","  time_this_iter_s: 5.007388114929199\n","  time_total_s: 125.569655418396\n","  timestamp: 1649851444\n","  timesteps_since_restore: 0\n","  training_iteration: 26\n","  trial_id: 825a7_00010\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00000:\n","  date: 2022-04-13_12-04-05\n","  done: false\n","  experiment_id: 696b6ae5d0474799847a48a1fd9db44c\n","  hostname: aa9ef03c8f27\n","  iterations: 26\n","  iterations_since_restore: 27\n","  mean_reward: -124.89015010321222\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.642857142857146\n","    ram_util_percent: 21.685714285714283\n","  pid: 2770\n","  time_since_restore: 126.84455347061157\n","  time_this_iter_s: 4.8342297077178955\n","  time_total_s: 126.84455347061157\n","  timestamp: 1649851445\n","  timesteps_since_restore: 0\n","  training_iteration: 27\n","  trial_id: 825a7_00000\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-04-06\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 24\n","  iterations_since_restore: 25\n","  mean_reward: -136.71509469902443\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.75\n","    ram_util_percent: 21.6875\n","  pid: 2775\n","  time_since_restore: 127.37393617630005\n","  time_this_iter_s: 5.027789831161499\n","  time_total_s: 127.37393617630005\n","  timestamp: 1649851446\n","  timesteps_since_restore: 0\n","  training_iteration: 25\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00005:\n","  date: 2022-04-13_12-04-06\n","  done: false\n","  experiment_id: d42ae5be5b334ba6981aa7673828d6d2\n","  hostname: aa9ef03c8f27\n","  iterations: 26\n","  iterations_since_restore: 27\n","  mean_reward: -131.06770846779912\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.685714285714276\n","    ram_util_percent: 21.714285714285715\n","  pid: 2773\n","  time_since_restore: 127.47615170478821\n","  time_this_iter_s: 5.012073040008545\n","  time_total_s: 127.47615170478821\n","  timestamp: 1649851446\n","  timesteps_since_restore: 0\n","  training_iteration: 27\n","  trial_id: 825a7_00005\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00008:\n","  date: 2022-04-13_12-04-06\n","  done: false\n","  experiment_id: cd76c37ed72a4c299a0583e20567f167\n","  hostname: aa9ef03c8f27\n","  iterations: 25\n","  iterations_since_restore: 26\n","  mean_reward: -132.7630470635476\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.528571428571425\n","    ram_util_percent: 21.714285714285715\n","  pid: 2767\n","  time_since_restore: 127.60829401016235\n","  time_this_iter_s: 4.999687433242798\n","  time_total_s: 127.60829401016235\n","  timestamp: 1649851446\n","  timesteps_since_restore: 0\n","  training_iteration: 26\n","  trial_id: 825a7_00008\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:04:08 (running for 00:02:15.20)<br>Memory usage on this node: 7.7/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00011 with mean_reward=-112.19604900969733 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.5616905067242305, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': False, 'hiddens': [256], 'double_q': False, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         126.845</td><td style=\"text-align: right;\">          26</td><td style=\"text-align: right;\">     -124.89 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         128.285</td><td style=\"text-align: right;\">          27</td><td style=\"text-align: right;\">     -175.855</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         125.26 </td><td style=\"text-align: right;\">          27</td><td style=\"text-align: right;\">     -194.166</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         127.374</td><td style=\"text-align: right;\">          24</td><td style=\"text-align: right;\">     -136.715</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         125.174</td><td style=\"text-align: right;\">          22</td><td style=\"text-align: right;\">     -124.525</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         127.476</td><td style=\"text-align: right;\">          26</td><td style=\"text-align: right;\">     -131.068</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         128.919</td><td style=\"text-align: right;\">          28</td><td style=\"text-align: right;\">     -122.171</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         126.11 </td><td style=\"text-align: right;\">          23</td><td style=\"text-align: right;\">     -138.23 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         127.608</td><td style=\"text-align: right;\">          25</td><td style=\"text-align: right;\">     -132.763</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         127.597</td><td style=\"text-align: right;\">          27</td><td style=\"text-align: right;\">     -149.612</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         125.57 </td><td style=\"text-align: right;\">          25</td><td style=\"text-align: right;\">     -129.296</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         128.889</td><td style=\"text-align: right;\">          26</td><td style=\"text-align: right;\">     -112.196</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-04-09\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 23\n","  iterations_since_restore: 24\n","  mean_reward: -123.99565458043578\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.32857142857143\n","    ram_util_percent: 21.75714285714286\n","  pid: 2776\n","  time_since_restore: 130.47546648979187\n","  time_this_iter_s: 5.301500558853149\n","  time_total_s: 130.47546648979187\n","  timestamp: 1649851449\n","  timesteps_since_restore: 0\n","  training_iteration: 24\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00002:\n","  date: 2022-04-13_12-04-09\n","  done: false\n","  experiment_id: 315539c1caa744e78ed8486a6a2213a0\n","  hostname: aa9ef03c8f27\n","  iterations: 28\n","  iterations_since_restore: 29\n","  mean_reward: -190.70319699972057\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.97142857142857\n","    ram_util_percent: 21.771428571428572\n","  pid: 2774\n","  time_since_restore: 130.66925811767578\n","  time_this_iter_s: 5.409615516662598\n","  time_total_s: 130.66925811767578\n","  timestamp: 1649851449\n","  timesteps_since_restore: 0\n","  training_iteration: 29\n","  trial_id: 825a7_00002\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00009:\n","  date: 2022-04-13_12-04-11\n","  done: false\n","  experiment_id: 95c2bb28a0b642edb97e6a45503efe15\n","  hostname: aa9ef03c8f27\n","  iterations: 28\n","  iterations_since_restore: 29\n","  mean_reward: -144.78570709819493\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.771428571428565\n","    ram_util_percent: 21.814285714285717\n","  pid: 2769\n","  time_since_restore: 132.41792178153992\n","  time_this_iter_s: 4.820728063583374\n","  time_total_s: 132.41792178153992\n","  timestamp: 1649851451\n","  timesteps_since_restore: 0\n","  training_iteration: 29\n","  trial_id: 825a7_00009\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-04-11\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 24\n","  iterations_since_restore: 25\n","  mean_reward: -138.23086371982657\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.8\n","    ram_util_percent: 21.788888888888888\n","  pid: 2771\n","  time_since_restore: 132.57059335708618\n","  time_this_iter_s: 6.460859060287476\n","  time_total_s: 132.57059335708618\n","  timestamp: 1649851451\n","  timesteps_since_restore: 0\n","  training_iteration: 25\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00001:\n","  date: 2022-04-13_12-04-11\n","  done: false\n","  experiment_id: bee5f156b4e14866b4e9e4f5ab3fad72\n","  hostname: aa9ef03c8f27\n","  iterations: 28\n","  iterations_since_restore: 29\n","  mean_reward: -171.9316591057675\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.98571428571429\n","    ram_util_percent: 21.82857142857143\n","  pid: 2778\n","  time_since_restore: 132.96185302734375\n","  time_this_iter_s: 4.676454305648804\n","  time_total_s: 132.96185302734375\n","  timestamp: 1649851451\n","  timesteps_since_restore: 0\n","  training_iteration: 29\n","  trial_id: 825a7_00001\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-04-11\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 25\n","  iterations_since_restore: 26\n","  mean_reward: -129.66587633789425\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.9125\n","    ram_util_percent: 21.825000000000003\n","  pid: 2775\n","  time_since_restore: 133.08229804039001\n","  time_this_iter_s: 5.708361864089966\n","  time_total_s: 133.08229804039001\n","  timestamp: 1649851451\n","  timesteps_since_restore: 0\n","  training_iteration: 26\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00011:\n","  date: 2022-04-13_12-04-12\n","  done: false\n","  experiment_id: f576928441b043f48c9de3d6907ccbdd\n","  hostname: aa9ef03c8f27\n","  iterations: 27\n","  iterations_since_restore: 28\n","  mean_reward: -111.08196830142339\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.01428571428572\n","    ram_util_percent: 21.842857142857145\n","  pid: 2768\n","  time_since_restore: 133.66268157958984\n","  time_this_iter_s: 4.773841142654419\n","  time_total_s: 133.66268157958984\n","  timestamp: 1649851452\n","  timesteps_since_restore: 0\n","  training_iteration: 28\n","  trial_id: 825a7_00011\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00006:\n","  date: 2022-04-13_12-04-12\n","  done: false\n","  experiment_id: 1452367bf557484fb196e21a6489d80a\n","  hostname: aa9ef03c8f27\n","  iterations: 29\n","  iterations_since_restore: 30\n","  mean_reward: -123.27666135798763\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.728571428571435\n","    ram_util_percent: 21.842857142857145\n","  pid: 2772\n","  time_since_restore: 133.72863698005676\n","  time_this_iter_s: 4.80947470664978\n","  time_total_s: 133.72863698005676\n","  timestamp: 1649851452\n","  timesteps_since_restore: 0\n","  training_iteration: 30\n","  trial_id: 825a7_00006\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:04:14 (running for 00:02:20.60)<br>Memory usage on this node: 7.7/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00011 with mean_reward=-111.08196830142339 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.5616905067242305, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': False, 'hiddens': [256], 'double_q': False, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         131.402</td><td style=\"text-align: right;\">          27</td><td style=\"text-align: right;\">     -121.689</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         132.962</td><td style=\"text-align: right;\">          28</td><td style=\"text-align: right;\">     -171.932</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         135.361</td><td style=\"text-align: right;\">          29</td><td style=\"text-align: right;\">     -191.455</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         133.082</td><td style=\"text-align: right;\">          25</td><td style=\"text-align: right;\">     -129.666</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         130.475</td><td style=\"text-align: right;\">          23</td><td style=\"text-align: right;\">     -123.996</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         132.061</td><td style=\"text-align: right;\">          27</td><td style=\"text-align: right;\">     -130.48 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         133.729</td><td style=\"text-align: right;\">          29</td><td style=\"text-align: right;\">     -123.277</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         132.571</td><td style=\"text-align: right;\">          24</td><td style=\"text-align: right;\">     -138.231</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         132.267</td><td style=\"text-align: right;\">          26</td><td style=\"text-align: right;\">     -131.207</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         132.418</td><td style=\"text-align: right;\">          28</td><td style=\"text-align: right;\">     -144.786</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         130.405</td><td style=\"text-align: right;\">          26</td><td style=\"text-align: right;\">     -131.862</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         133.663</td><td style=\"text-align: right;\">          27</td><td style=\"text-align: right;\">     -111.082</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00000:\n","  date: 2022-04-13_12-04-14\n","  done: false\n","  experiment_id: 696b6ae5d0474799847a48a1fd9db44c\n","  hostname: aa9ef03c8f27\n","  iterations: 28\n","  iterations_since_restore: 29\n","  mean_reward: -117.43730369020423\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.92857142857143\n","    ram_util_percent: 21.88571428571429\n","  pid: 2770\n","  time_since_restore: 136.06027579307556\n","  time_this_iter_s: 4.658374071121216\n","  time_total_s: 136.06027579307556\n","  timestamp: 1649851454\n","  timesteps_since_restore: 0\n","  training_iteration: 29\n","  trial_id: 825a7_00000\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-04-15\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 24\n","  iterations_since_restore: 25\n","  mean_reward: -123.69634312685815\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.611111111111114\n","    ram_util_percent: 21.87777777777778\n","  pid: 2776\n","  time_since_restore: 136.5524606704712\n","  time_this_iter_s: 6.076994180679321\n","  time_total_s: 136.5524606704712\n","  timestamp: 1649851455\n","  timesteps_since_restore: 0\n","  training_iteration: 25\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00005:\n","  date: 2022-04-13_12-04-15\n","  done: false\n","  experiment_id: d42ae5be5b334ba6981aa7673828d6d2\n","  hostname: aa9ef03c8f27\n","  iterations: 28\n","  iterations_since_restore: 29\n","  mean_reward: -133.78186362534476\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.60000000000001\n","    ram_util_percent: 21.900000000000002\n","  pid: 2773\n","  time_since_restore: 136.63671040534973\n","  time_this_iter_s: 4.575378179550171\n","  time_total_s: 136.63671040534973\n","  timestamp: 1649851455\n","  timesteps_since_restore: 0\n","  training_iteration: 29\n","  trial_id: 825a7_00005\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00008:\n","  date: 2022-04-13_12-04-16\n","  done: false\n","  experiment_id: cd76c37ed72a4c299a0583e20567f167\n","  hostname: aa9ef03c8f27\n","  iterations: 27\n","  iterations_since_restore: 28\n","  mean_reward: -130.93923945418015\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.228571428571435\n","    ram_util_percent: 21.900000000000002\n","  pid: 2767\n","  time_since_restore: 137.11683654785156\n","  time_this_iter_s: 4.850208282470703\n","  time_total_s: 137.11683654785156\n","  timestamp: 1649851456\n","  timesteps_since_restore: 0\n","  training_iteration: 28\n","  trial_id: 825a7_00008\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-04-16\n","  done: false\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  hostname: aa9ef03c8f27\n","  iterations: 27\n","  iterations_since_restore: 28\n","  mean_reward: -132.77611233736462\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.6\n","    ram_util_percent: 21.89\n","  pid: 2777\n","  time_since_restore: 137.3201460838318\n","  time_this_iter_s: 6.914924144744873\n","  time_total_s: 137.3201460838318\n","  timestamp: 1649851456\n","  timesteps_since_restore: 0\n","  training_iteration: 28\n","  trial_id: 825a7_00010\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00009:\n","  date: 2022-04-13_12-04-16\n","  done: false\n","  experiment_id: 95c2bb28a0b642edb97e6a45503efe15\n","  hostname: aa9ef03c8f27\n","  iterations: 29\n","  iterations_since_restore: 30\n","  mean_reward: -147.2691139111203\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.614285714285714\n","    ram_util_percent: 21.928571428571427\n","  pid: 2769\n","  time_since_restore: 137.43018317222595\n","  time_this_iter_s: 5.012261390686035\n","  time_total_s: 137.43018317222595\n","  timestamp: 1649851456\n","  timesteps_since_restore: 0\n","  training_iteration: 30\n","  trial_id: 825a7_00009\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-04-17\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 26\n","  iterations_since_restore: 27\n","  mean_reward: -127.02858087127159\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.62857142857143\n","    ram_util_percent: 21.928571428571427\n","  pid: 2775\n","  time_since_restore: 138.17463326454163\n","  time_this_iter_s: 5.092335224151611\n","  time_total_s: 138.17463326454163\n","  timestamp: 1649851457\n","  timesteps_since_restore: 0\n","  training_iteration: 27\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-04-17\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 25\n","  iterations_since_restore: 26\n","  mean_reward: -137.90879838271442\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.712500000000006\n","    ram_util_percent: 21.924999999999997\n","  pid: 2771\n","  time_since_restore: 138.25143313407898\n","  time_this_iter_s: 5.680839776992798\n","  time_total_s: 138.25143313407898\n","  timestamp: 1649851457\n","  timesteps_since_restore: 0\n","  training_iteration: 26\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00011:\n","  date: 2022-04-13_12-04-18\n","  done: false\n","  experiment_id: f576928441b043f48c9de3d6907ccbdd\n","  hostname: aa9ef03c8f27\n","  iterations: 28\n","  iterations_since_restore: 29\n","  mean_reward: -105.43977030772434\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.775000000000006\n","    ram_util_percent: 21.95\n","  pid: 2768\n","  time_since_restore: 139.31130456924438\n","  time_this_iter_s: 5.648622989654541\n","  time_total_s: 139.31130456924438\n","  timestamp: 1649851458\n","  timesteps_since_restore: 0\n","  training_iteration: 29\n","  trial_id: 825a7_00011\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:04:19 (running for 00:02:25.60)<br>Memory usage on this node: 7.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00011 with mean_reward=-105.43977030772434 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.5616905067242305, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': False, 'hiddens': [256], 'double_q': False, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         136.06 </td><td style=\"text-align: right;\">          28</td><td style=\"text-align: right;\">     -117.437</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         137.513</td><td style=\"text-align: right;\">          29</td><td style=\"text-align: right;\">     -173.997</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         135.361</td><td style=\"text-align: right;\">          29</td><td style=\"text-align: right;\">     -191.455</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         138.175</td><td style=\"text-align: right;\">          26</td><td style=\"text-align: right;\">     -127.029</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         136.552</td><td style=\"text-align: right;\">          24</td><td style=\"text-align: right;\">     -123.696</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         136.637</td><td style=\"text-align: right;\">          28</td><td style=\"text-align: right;\">     -133.782</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         138.439</td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     -121.419</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         138.251</td><td style=\"text-align: right;\">          25</td><td style=\"text-align: right;\">     -137.909</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         137.117</td><td style=\"text-align: right;\">          27</td><td style=\"text-align: right;\">     -130.939</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         137.43 </td><td style=\"text-align: right;\">          29</td><td style=\"text-align: right;\">     -147.269</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         137.32 </td><td style=\"text-align: right;\">          27</td><td style=\"text-align: right;\">     -132.776</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         139.311</td><td style=\"text-align: right;\">          28</td><td style=\"text-align: right;\">     -105.44 </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00002:\n","  date: 2022-04-13_12-04-19\n","  done: false\n","  experiment_id: 315539c1caa744e78ed8486a6a2213a0\n","  hostname: aa9ef03c8f27\n","  iterations: 30\n","  iterations_since_restore: 31\n","  mean_reward: -187.55687700436266\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.91428571428571\n","    ram_util_percent: 21.97142857142857\n","  pid: 2774\n","  time_since_restore: 140.53300595283508\n","  time_this_iter_s: 5.172390937805176\n","  time_total_s: 140.53300595283508\n","  timestamp: 1649851459\n","  timesteps_since_restore: 0\n","  training_iteration: 31\n","  trial_id: 825a7_00002\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00001:\n","  date: 2022-04-13_12-04-20\n","  done: false\n","  experiment_id: bee5f156b4e14866b4e9e4f5ab3fad72\n","  hostname: aa9ef03c8f27\n","  iterations: 30\n","  iterations_since_restore: 31\n","  mean_reward: -165.1377829408198\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.300000000000004\n","    ram_util_percent: 22.02857142857143\n","  pid: 2778\n","  time_since_restore: 142.05881357192993\n","  time_this_iter_s: 4.545544862747192\n","  time_total_s: 142.05881357192993\n","  timestamp: 1649851460\n","  timesteps_since_restore: 0\n","  training_iteration: 31\n","  trial_id: 825a7_00001\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-04-21\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 25\n","  iterations_since_restore: 26\n","  mean_reward: -122.42100379086052\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.849999999999994\n","    ram_util_percent: 22.0375\n","  pid: 2776\n","  time_since_restore: 142.1031939983368\n","  time_this_iter_s: 5.550733327865601\n","  time_total_s: 142.1031939983368\n","  timestamp: 1649851461\n","  timesteps_since_restore: 0\n","  training_iteration: 26\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-04-21\n","  done: false\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  hostname: aa9ef03c8f27\n","  iterations: 28\n","  iterations_since_restore: 29\n","  mean_reward: -133.3812197750971\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.15\n","    ram_util_percent: 22.05\n","  pid: 2777\n","  time_since_restore: 142.8984534740448\n","  time_this_iter_s: 5.578307390213013\n","  time_total_s: 142.8984534740448\n","  timestamp: 1649851461\n","  timesteps_since_restore: 0\n","  training_iteration: 29\n","  trial_id: 825a7_00010\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00006:\n","  date: 2022-04-13_12-04-21\n","  done: false\n","  experiment_id: 1452367bf557484fb196e21a6489d80a\n","  hostname: aa9ef03c8f27\n","  iterations: 31\n","  iterations_since_restore: 32\n","  mean_reward: -113.6624895660547\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.18571428571429\n","    ram_util_percent: 22.04285714285714\n","  pid: 2772\n","  time_since_restore: 142.98450088500977\n","  time_this_iter_s: 4.545379161834717\n","  time_total_s: 142.98450088500977\n","  timestamp: 1649851461\n","  timesteps_since_restore: 0\n","  training_iteration: 32\n","  trial_id: 825a7_00006\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-04-22\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 26\n","  iterations_since_restore: 27\n","  mean_reward: -137.14869754635743\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.957142857142856\n","    ram_util_percent: 22.057142857142853\n","  pid: 2771\n","  time_since_restore: 143.29190111160278\n","  time_this_iter_s: 5.040467977523804\n","  time_total_s: 143.29190111160278\n","  timestamp: 1649851462\n","  timesteps_since_restore: 0\n","  training_iteration: 27\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00000:\n","  date: 2022-04-13_12-04-24\n","  done: false\n","  experiment_id: 696b6ae5d0474799847a48a1fd9db44c\n","  hostname: aa9ef03c8f27\n","  iterations: 30\n","  iterations_since_restore: 31\n","  mean_reward: -114.96895877685412\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.74285714285714\n","    ram_util_percent: 22.11428571428571\n","  pid: 2770\n","  time_since_restore: 145.5740990638733\n","  time_this_iter_s: 4.82487678527832\n","  time_total_s: 145.5740990638733\n","  timestamp: 1649851464\n","  timesteps_since_restore: 0\n","  training_iteration: 31\n","  trial_id: 825a7_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:04:24 (running for 00:02:30.78)<br>Memory usage on this node: 7.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00011 with mean_reward=-103.2582531759722 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.5616905067242305, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': False, 'hiddens': [256], 'double_q': False, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         145.574</td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     -114.969</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         142.059</td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     -165.138</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         145.11 </td><td style=\"text-align: right;\">          31</td><td style=\"text-align: right;\">     -179.344</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         142.87 </td><td style=\"text-align: right;\">          27</td><td style=\"text-align: right;\">     -124.335</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         142.103</td><td style=\"text-align: right;\">          25</td><td style=\"text-align: right;\">     -122.421</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         141.278</td><td style=\"text-align: right;\">          29</td><td style=\"text-align: right;\">     -126.697</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         142.985</td><td style=\"text-align: right;\">          31</td><td style=\"text-align: right;\">     -113.662</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         143.292</td><td style=\"text-align: right;\">          26</td><td style=\"text-align: right;\">     -137.149</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         141.976</td><td style=\"text-align: right;\">          28</td><td style=\"text-align: right;\">     -123.581</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         141.822</td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     -147.329</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         142.898</td><td style=\"text-align: right;\">          28</td><td style=\"text-align: right;\">     -133.381</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         143.938</td><td style=\"text-align: right;\">          29</td><td style=\"text-align: right;\">     -103.258</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00005:\n","  date: 2022-04-13_12-04-24\n","  done: false\n","  experiment_id: d42ae5be5b334ba6981aa7673828d6d2\n","  hostname: aa9ef03c8f27\n","  iterations: 30\n","  iterations_since_restore: 31\n","  mean_reward: -127.80168941598178\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.057142857142864\n","    ram_util_percent: 22.11428571428571\n","  pid: 2773\n","  time_since_restore: 145.77182030677795\n","  time_this_iter_s: 4.493345499038696\n","  time_total_s: 145.77182030677795\n","  timestamp: 1649851464\n","  timesteps_since_restore: 0\n","  training_iteration: 31\n","  trial_id: 825a7_00005\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00009:\n","  date: 2022-04-13_12-04-25\n","  done: false\n","  experiment_id: 95c2bb28a0b642edb97e6a45503efe15\n","  hostname: aa9ef03c8f27\n","  iterations: 31\n","  iterations_since_restore: 32\n","  mean_reward: -148.31303339884735\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.75\n","    ram_util_percent: 22.116666666666664\n","  pid: 2769\n","  time_since_restore: 146.30734300613403\n","  time_this_iter_s: 4.485832214355469\n","  time_total_s: 146.30734300613403\n","  timestamp: 1649851465\n","  timesteps_since_restore: 0\n","  training_iteration: 32\n","  trial_id: 825a7_00009\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00008:\n","  date: 2022-04-13_12-04-25\n","  done: false\n","  experiment_id: cd76c37ed72a4c299a0583e20567f167\n","  hostname: aa9ef03c8f27\n","  iterations: 29\n","  iterations_since_restore: 30\n","  mean_reward: -114.24980752464671\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.17142857142858\n","    ram_util_percent: 22.128571428571426\n","  pid: 2767\n","  time_since_restore: 146.56688904762268\n","  time_this_iter_s: 4.590872526168823\n","  time_total_s: 146.56688904762268\n","  timestamp: 1649851465\n","  timesteps_since_restore: 0\n","  training_iteration: 30\n","  trial_id: 825a7_00008\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-04-26\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 26\n","  iterations_since_restore: 27\n","  mean_reward: -122.30100631402362\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.42857142857143\n","    ram_util_percent: 22.142857142857142\n","  pid: 2776\n","  time_since_restore: 147.28009819984436\n","  time_this_iter_s: 5.176904201507568\n","  time_total_s: 147.28009819984436\n","  timestamp: 1649851466\n","  timesteps_since_restore: 0\n","  training_iteration: 27\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-04-26\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 28\n","  iterations_since_restore: 29\n","  mean_reward: -126.05501352399303\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.15\n","    ram_util_percent: 22.150000000000002\n","  pid: 2775\n","  time_since_restore: 147.67271327972412\n","  time_this_iter_s: 4.802386522293091\n","  time_total_s: 147.67271327972412\n","  timestamp: 1649851466\n","  timesteps_since_restore: 0\n","  training_iteration: 29\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-04-26\n","  done: false\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  hostname: aa9ef03c8f27\n","  iterations: 29\n","  iterations_since_restore: 30\n","  mean_reward: -132.6801754998639\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.271428571428565\n","    ram_util_percent: 22.157142857142855\n","  pid: 2777\n","  time_since_restore: 147.93466424942017\n","  time_this_iter_s: 5.036210775375366\n","  time_total_s: 147.93466424942017\n","  timestamp: 1649851466\n","  timesteps_since_restore: 0\n","  training_iteration: 30\n","  trial_id: 825a7_00010\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00006:\n","  date: 2022-04-13_12-04-27\n","  done: false\n","  experiment_id: 1452367bf557484fb196e21a6489d80a\n","  hostname: aa9ef03c8f27\n","  iterations: 32\n","  iterations_since_restore: 33\n","  mean_reward: -108.83308844987731\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.0\n","    ram_util_percent: 22.157142857142855\n","  pid: 2772\n","  time_since_restore: 148.16310119628906\n","  time_this_iter_s: 5.178600311279297\n","  time_total_s: 148.16310119628906\n","  timestamp: 1649851467\n","  timesteps_since_restore: 0\n","  training_iteration: 33\n","  trial_id: 825a7_00006\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00011:\n","  date: 2022-04-13_12-04-28\n","  done: false\n","  experiment_id: f576928441b043f48c9de3d6907ccbdd\n","  hostname: aa9ef03c8f27\n","  iterations: 30\n","  iterations_since_restore: 31\n","  mean_reward: -97.88525001416834\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.2\n","    ram_util_percent: 22.174999999999997\n","  pid: 2768\n","  time_since_restore: 149.25493955612183\n","  time_this_iter_s: 5.3173322677612305\n","  time_total_s: 149.25493955612183\n","  timestamp: 1649851468\n","  timesteps_since_restore: 0\n","  training_iteration: 31\n","  trial_id: 825a7_00011\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-04-28\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 27\n","  iterations_since_restore: 28\n","  mean_reward: -137.32873636044334\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.17777777777778\n","    ram_util_percent: 22.166666666666668\n","  pid: 2771\n","  time_since_restore: 149.31764817237854\n","  time_this_iter_s: 6.025747060775757\n","  time_total_s: 149.31764817237854\n","  timestamp: 1649851468\n","  timesteps_since_restore: 0\n","  training_iteration: 28\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00002:\n","  date: 2022-04-13_12-04-28\n","  done: false\n","  experiment_id: 315539c1caa744e78ed8486a6a2213a0\n","  hostname: aa9ef03c8f27\n","  iterations: 32\n","  iterations_since_restore: 33\n","  mean_reward: -180.3414313785133\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.0\n","    ram_util_percent: 22.214285714285715\n","  pid: 2774\n","  time_since_restore: 149.78285670280457\n","  time_this_iter_s: 4.673172473907471\n","  time_total_s: 149.78285670280457\n","  timestamp: 1649851468\n","  timesteps_since_restore: 0\n","  training_iteration: 33\n","  trial_id: 825a7_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:04:29 (running for 00:02:36.18)<br>Memory usage on this node: 7.9/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00011 with mean_reward=-97.88525001416834 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.5616905067242305, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': False, 'hiddens': [256], 'double_q': False, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         150.084</td><td style=\"text-align: right;\">          31</td><td style=\"text-align: right;\">    -113.839 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         146.694</td><td style=\"text-align: right;\">          31</td><td style=\"text-align: right;\">    -165.729 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         149.783</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">    -180.341 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         147.673</td><td style=\"text-align: right;\">          28</td><td style=\"text-align: right;\">    -126.055 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         147.28 </td><td style=\"text-align: right;\">          26</td><td style=\"text-align: right;\">    -122.301 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         150.319</td><td style=\"text-align: right;\">          31</td><td style=\"text-align: right;\">    -129.568 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         148.163</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">    -108.833 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         149.318</td><td style=\"text-align: right;\">          27</td><td style=\"text-align: right;\">    -137.329 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         146.567</td><td style=\"text-align: right;\">          29</td><td style=\"text-align: right;\">    -114.25  </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         150.936</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">    -149.399 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         147.935</td><td style=\"text-align: right;\">          29</td><td style=\"text-align: right;\">    -132.68  </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         149.255</td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     -97.8853</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00001:\n","  date: 2022-04-13_12-04-30\n","  done: false\n","  experiment_id: bee5f156b4e14866b4e9e4f5ab3fad72\n","  hostname: aa9ef03c8f27\n","  iterations: 32\n","  iterations_since_restore: 33\n","  mean_reward: -158.90472875015436\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.542857142857144\n","    ram_util_percent: 22.242857142857144\n","  pid: 2778\n","  time_since_restore: 151.2947826385498\n","  time_this_iter_s: 4.601181507110596\n","  time_total_s: 151.2947826385498\n","  timestamp: 1649851470\n","  timesteps_since_restore: 0\n","  training_iteration: 33\n","  trial_id: 825a7_00001\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-04-31\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 29\n","  iterations_since_restore: 30\n","  mean_reward: -126.47880340310034\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.037499999999994\n","    ram_util_percent: 22.262500000000003\n","  pid: 2775\n","  time_since_restore: 152.7021746635437\n","  time_this_iter_s: 5.02946138381958\n","  time_total_s: 152.7021746635437\n","  timestamp: 1649851471\n","  timesteps_since_restore: 0\n","  training_iteration: 30\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-04-31\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 27\n","  iterations_since_restore: 28\n","  mean_reward: -121.63895808511104\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.4125\n","    ram_util_percent: 22.262500000000003\n","  pid: 2776\n","  time_since_restore: 152.9122498035431\n","  time_this_iter_s: 5.6321516036987305\n","  time_total_s: 152.9122498035431\n","  timestamp: 1649851471\n","  timesteps_since_restore: 0\n","  training_iteration: 28\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-04-32\n","  done: false\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  hostname: aa9ef03c8f27\n","  iterations: 30\n","  iterations_since_restore: 31\n","  mean_reward: -132.1835423399236\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.962500000000006\n","    ram_util_percent: 22.275\n","  pid: 2777\n","  time_since_restore: 153.87671518325806\n","  time_this_iter_s: 5.942050933837891\n","  time_total_s: 153.87671518325806\n","  timestamp: 1649851472\n","  timesteps_since_restore: 0\n","  training_iteration: 31\n","  trial_id: 825a7_00010\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00000:\n","  date: 2022-04-13_12-04-33\n","  done: false\n","  experiment_id: 696b6ae5d0474799847a48a1fd9db44c\n","  hostname: aa9ef03c8f27\n","  iterations: 32\n","  iterations_since_restore: 33\n","  mean_reward: -109.94866588374825\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.866666666666674\n","    ram_util_percent: 22.316666666666666\n","  pid: 2770\n","  time_since_restore: 154.45982766151428\n","  time_this_iter_s: 4.376053333282471\n","  time_total_s: 154.45982766151428\n","  timestamp: 1649851473\n","  timesteps_since_restore: 0\n","  training_iteration: 33\n","  trial_id: 825a7_00000\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00005:\n","  date: 2022-04-13_12-04-33\n","  done: false\n","  experiment_id: d42ae5be5b334ba6981aa7673828d6d2\n","  hostname: aa9ef03c8f27\n","  iterations: 32\n","  iterations_since_restore: 33\n","  mean_reward: -128.3088144261824\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.74285714285714\n","    ram_util_percent: 22.32857142857143\n","  pid: 2773\n","  time_since_restore: 154.9685344696045\n","  time_this_iter_s: 4.64970588684082\n","  time_total_s: 154.9685344696045\n","  timestamp: 1649851473\n","  timesteps_since_restore: 0\n","  training_iteration: 33\n","  trial_id: 825a7_00005\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00009:\n","  date: 2022-04-13_12-04-34\n","  done: false\n","  experiment_id: 95c2bb28a0b642edb97e6a45503efe15\n","  hostname: aa9ef03c8f27\n","  iterations: 33\n","  iterations_since_restore: 34\n","  mean_reward: -143.1552890364654\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.48571428571428\n","    ram_util_percent: 22.342857142857145\n","  pid: 2769\n","  time_since_restore: 155.62403559684753\n","  time_this_iter_s: 4.687795639038086\n","  time_total_s: 155.62403559684753\n","  timestamp: 1649851474\n","  timesteps_since_restore: 0\n","  training_iteration: 34\n","  trial_id: 825a7_00009\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-04-34\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 28\n","  iterations_since_restore: 29\n","  mean_reward: -137.06866188321783\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.0\n","    ram_util_percent: 22.333333333333336\n","  pid: 2771\n","  time_since_restore: 155.62577390670776\n","  time_this_iter_s: 6.308125734329224\n","  time_total_s: 155.62577390670776\n","  timestamp: 1649851474\n","  timesteps_since_restore: 0\n","  training_iteration: 29\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00008:\n","  date: 2022-04-13_12-04-34\n","  done: false\n","  experiment_id: cd76c37ed72a4c299a0583e20567f167\n","  hostname: aa9ef03c8f27\n","  iterations: 31\n","  iterations_since_restore: 32\n","  mean_reward: -101.44802879425158\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.699999999999996\n","    ram_util_percent: 22.350000000000005\n","  pid: 2767\n","  time_since_restore: 155.9225172996521\n","  time_this_iter_s: 4.6202709674835205\n","  time_total_s: 155.9225172996521\n","  timestamp: 1649851474\n","  timesteps_since_restore: 0\n","  training_iteration: 32\n","  trial_id: 825a7_00008\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:04:34 (running for 00:02:41.19)<br>Memory usage on this node: 7.9/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00011 with mean_reward=-95.91997804915205 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.5616905067242305, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': False, 'hiddens': [256], 'double_q': False, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         154.46 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">     -109.949</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         156.004</td><td style=\"text-align: right;\">          33</td><td style=\"text-align: right;\">     -156.359</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         154.186</td><td style=\"text-align: right;\">          33</td><td style=\"text-align: right;\">     -182.432</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         152.702</td><td style=\"text-align: right;\">          29</td><td style=\"text-align: right;\">     -126.479</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         152.912</td><td style=\"text-align: right;\">          27</td><td style=\"text-align: right;\">     -121.639</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         154.969</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">     -128.309</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         152.929</td><td style=\"text-align: right;\">          33</td><td style=\"text-align: right;\">     -106.566</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         155.626</td><td style=\"text-align: right;\">          28</td><td style=\"text-align: right;\">     -137.069</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         155.923</td><td style=\"text-align: right;\">          31</td><td style=\"text-align: right;\">     -101.448</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         155.624</td><td style=\"text-align: right;\">          33</td><td style=\"text-align: right;\">     -143.155</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         153.877</td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     -132.184</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         154.105</td><td style=\"text-align: right;\">          31</td><td style=\"text-align: right;\">      -95.92 </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00006:\n","  date: 2022-04-13_12-04-36\n","  done: false\n","  experiment_id: 1452367bf557484fb196e21a6489d80a\n","  hostname: aa9ef03c8f27\n","  iterations: 34\n","  iterations_since_restore: 35\n","  mean_reward: -103.56732235175824\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.93333333333333\n","    ram_util_percent: 22.383333333333336\n","  pid: 2772\n","  time_since_restore: 157.2974317073822\n","  time_this_iter_s: 4.3687965869903564\n","  time_total_s: 157.2974317073822\n","  timestamp: 1649851476\n","  timesteps_since_restore: 0\n","  training_iteration: 35\n","  trial_id: 825a7_00006\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-04-37\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 30\n","  iterations_since_restore: 31\n","  mean_reward: -124.76509782755937\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.885714285714286\n","    ram_util_percent: 22.38571428571429\n","  pid: 2775\n","  time_since_restore: 158.18798184394836\n","  time_this_iter_s: 5.485807180404663\n","  time_total_s: 158.18798184394836\n","  timestamp: 1649851477\n","  timesteps_since_restore: 0\n","  training_iteration: 31\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-04-37\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 28\n","  iterations_since_restore: 29\n","  mean_reward: -121.86092649137748\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.7\n","    ram_util_percent: 22.3875\n","  pid: 2776\n","  time_since_restore: 158.55892300605774\n","  time_this_iter_s: 5.646673202514648\n","  time_total_s: 158.55892300605774\n","  timestamp: 1649851477\n","  timesteps_since_restore: 0\n","  training_iteration: 29\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00002:\n","  date: 2022-04-13_12-04-37\n","  done: false\n","  experiment_id: 315539c1caa744e78ed8486a6a2213a0\n","  hostname: aa9ef03c8f27\n","  iterations: 34\n","  iterations_since_restore: 35\n","  mean_reward: -185.44069970937164\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.98333333333333\n","    ram_util_percent: 22.400000000000002\n","  pid: 2774\n","  time_since_restore: 158.64747977256775\n","  time_this_iter_s: 4.461501121520996\n","  time_total_s: 158.64747977256775\n","  timestamp: 1649851477\n","  timesteps_since_restore: 0\n","  training_iteration: 35\n","  trial_id: 825a7_00002\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00011:\n","  date: 2022-04-13_12-04-37\n","  done: false\n","  experiment_id: f576928441b043f48c9de3d6907ccbdd\n","  hostname: aa9ef03c8f27\n","  iterations: 32\n","  iterations_since_restore: 33\n","  mean_reward: -86.34970783381867\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.96666666666667\n","    ram_util_percent: 22.400000000000002\n","  pid: 2768\n","  time_since_restore: 158.93554520606995\n","  time_this_iter_s: 4.831021785736084\n","  time_total_s: 158.93554520606995\n","  timestamp: 1649851477\n","  timesteps_since_restore: 0\n","  training_iteration: 33\n","  trial_id: 825a7_00011\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-04-39\n","  done: false\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  hostname: aa9ef03c8f27\n","  iterations: 31\n","  iterations_since_restore: 32\n","  mean_reward: -132.0532073762245\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.730000000000004\n","    ram_util_percent: 22.43\n","  pid: 2777\n","  time_since_restore: 160.40288376808167\n","  time_this_iter_s: 6.526168584823608\n","  time_total_s: 160.40288376808167\n","  timestamp: 1649851479\n","  timesteps_since_restore: 0\n","  training_iteration: 32\n","  trial_id: 825a7_00010\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00001:\n","  date: 2022-04-13_12-04-39\n","  done: false\n","  experiment_id: bee5f156b4e14866b4e9e4f5ab3fad72\n","  hostname: aa9ef03c8f27\n","  iterations: 34\n","  iterations_since_restore: 35\n","  mean_reward: -152.05632348967202\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.685714285714276\n","    ram_util_percent: 22.442857142857143\n","  pid: 2778\n","  time_since_restore: 160.498703956604\n","  time_this_iter_s: 4.49509859085083\n","  time_total_s: 160.498703956604\n","  timestamp: 1649851479\n","  timesteps_since_restore: 0\n","  training_iteration: 35\n","  trial_id: 825a7_00001\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00009:\n","  date: 2022-04-13_12-04-39\n","  done: false\n","  experiment_id: 95c2bb28a0b642edb97e6a45503efe15\n","  hostname: aa9ef03c8f27\n","  iterations: 34\n","  iterations_since_restore: 35\n","  mean_reward: -142.34797796085678\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.114285714285714\n","    ram_util_percent: 22.457142857142856\n","  pid: 2769\n","  time_since_restore: 160.96991658210754\n","  time_this_iter_s: 5.34588098526001\n","  time_total_s: 160.96991658210754\n","  timestamp: 1649851479\n","  timesteps_since_restore: 0\n","  training_iteration: 35\n","  trial_id: 825a7_00009\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-04-40\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 29\n","  iterations_since_restore: 30\n","  mean_reward: -137.37553729172146\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.6\n","    ram_util_percent: 22.455555555555556\n","  pid: 2771\n","  time_since_restore: 161.89324522018433\n","  time_this_iter_s: 6.2674713134765625\n","  time_total_s: 161.89324522018433\n","  timestamp: 1649851480\n","  timesteps_since_restore: 0\n","  training_iteration: 30\n","  trial_id: 825a7_00007\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:04:40 (running for 00:02:47.14)<br>Memory usage on this node: 7.9/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00011 with mean_reward=-86.34970783381867 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.5616905067242305, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': False, 'hiddens': [256], 'double_q': False, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         159.171</td><td style=\"text-align: right;\">          33</td><td style=\"text-align: right;\">    -105.269 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         160.499</td><td style=\"text-align: right;\">          34</td><td style=\"text-align: right;\">    -152.056 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         158.647</td><td style=\"text-align: right;\">          34</td><td style=\"text-align: right;\">    -185.441 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         158.188</td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">    -124.765 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         158.559</td><td style=\"text-align: right;\">          28</td><td style=\"text-align: right;\">    -121.861 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         159.49 </td><td style=\"text-align: right;\">          33</td><td style=\"text-align: right;\">    -125.313 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         157.297</td><td style=\"text-align: right;\">          34</td><td style=\"text-align: right;\">    -103.567 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         161.893</td><td style=\"text-align: right;\">          29</td><td style=\"text-align: right;\">    -137.376 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         160.539</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">     -94.0109</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         160.97 </td><td style=\"text-align: right;\">          34</td><td style=\"text-align: right;\">    -142.348 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         160.403</td><td style=\"text-align: right;\">          31</td><td style=\"text-align: right;\">    -132.053 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         158.936</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">     -86.3497</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-04-42\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 31\n","  iterations_since_restore: 32\n","  mean_reward: -118.12490369491884\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.7375\n","    ram_util_percent: 22.5\n","  pid: 2775\n","  time_since_restore: 163.39963340759277\n","  time_this_iter_s: 5.211651563644409\n","  time_total_s: 163.39963340759277\n","  timestamp: 1649851482\n","  timesteps_since_restore: 0\n","  training_iteration: 32\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00000:\n","  date: 2022-04-13_12-04-42\n","  done: false\n","  experiment_id: 696b6ae5d0474799847a48a1fd9db44c\n","  hostname: aa9ef03c8f27\n","  iterations: 34\n","  iterations_since_restore: 35\n","  mean_reward: -105.711545248504\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.51666666666666\n","    ram_util_percent: 22.516666666666666\n","  pid: 2770\n","  time_since_restore: 163.5805869102478\n","  time_this_iter_s: 4.409993886947632\n","  time_total_s: 163.5805869102478\n","  timestamp: 1649851482\n","  timesteps_since_restore: 0\n","  training_iteration: 35\n","  trial_id: 825a7_00000\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00005:\n","  date: 2022-04-13_12-04-42\n","  done: false\n","  experiment_id: d42ae5be5b334ba6981aa7673828d6d2\n","  hostname: aa9ef03c8f27\n","  iterations: 34\n","  iterations_since_restore: 35\n","  mean_reward: -121.38430320044414\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.699999999999996\n","    ram_util_percent: 22.52857142857143\n","  pid: 2773\n","  time_since_restore: 164.01116228103638\n","  time_this_iter_s: 4.521551847457886\n","  time_total_s: 164.01116228103638\n","  timestamp: 1649851482\n","  timesteps_since_restore: 0\n","  training_iteration: 35\n","  trial_id: 825a7_00005\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-04-43\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 29\n","  iterations_since_restore: 30\n","  mean_reward: -121.27671336318468\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.5\n","    ram_util_percent: 22.525\n","  pid: 2776\n","  time_since_restore: 164.22475862503052\n","  time_this_iter_s: 5.665835618972778\n","  time_total_s: 164.22475862503052\n","  timestamp: 1649851483\n","  timesteps_since_restore: 0\n","  training_iteration: 30\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00008:\n","  date: 2022-04-13_12-04-44\n","  done: false\n","  experiment_id: cd76c37ed72a4c299a0583e20567f167\n","  hostname: aa9ef03c8f27\n","  iterations: 33\n","  iterations_since_restore: 34\n","  mean_reward: -85.95331124305338\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.98571428571428\n","    ram_util_percent: 22.557142857142853\n","  pid: 2767\n","  time_since_restore: 165.30382585525513\n","  time_this_iter_s: 4.764960765838623\n","  time_total_s: 165.30382585525513\n","  timestamp: 1649851484\n","  timesteps_since_restore: 0\n","  training_iteration: 34\n","  trial_id: 825a7_00008\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-04-44\n","  done: false\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  hostname: aa9ef03c8f27\n","  iterations: 32\n","  iterations_since_restore: 33\n","  mean_reward: -132.1599507475063\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.971428571428575\n","    ram_util_percent: 22.557142857142853\n","  pid: 2777\n","  time_since_restore: 165.5227656364441\n","  time_this_iter_s: 5.119881868362427\n","  time_total_s: 165.5227656364441\n","  timestamp: 1649851484\n","  timesteps_since_restore: 0\n","  training_iteration: 33\n","  trial_id: 825a7_00010\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00001:\n","  date: 2022-04-13_12-04-44\n","  done: false\n","  experiment_id: bee5f156b4e14866b4e9e4f5ab3fad72\n","  hostname: aa9ef03c8f27\n","  iterations: 35\n","  iterations_since_restore: 36\n","  mean_reward: -146.4451890806526\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.714285714285715\n","    ram_util_percent: 22.557142857142853\n","  pid: 2778\n","  time_since_restore: 165.6204218864441\n","  time_this_iter_s: 5.121717929840088\n","  time_total_s: 165.6204218864441\n","  timestamp: 1649851484\n","  timesteps_since_restore: 0\n","  training_iteration: 36\n","  trial_id: 825a7_00001\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00006:\n","  date: 2022-04-13_12-04-45\n","  done: false\n","  experiment_id: 1452367bf557484fb196e21a6489d80a\n","  hostname: aa9ef03c8f27\n","  iterations: 36\n","  iterations_since_restore: 37\n","  mean_reward: -109.15361528627571\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.81666666666666\n","    ram_util_percent: 22.583333333333332\n","  pid: 2772\n","  time_since_restore: 166.417724609375\n","  time_this_iter_s: 4.5196850299835205\n","  time_total_s: 166.417724609375\n","  timestamp: 1649851485\n","  timesteps_since_restore: 0\n","  training_iteration: 37\n","  trial_id: 825a7_00006\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:04:46 (running for 00:02:52.65)<br>Memory usage on this node: 8.0/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00011 with mean_reward=-75.112161561675 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.5616905067242305, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': False, 'hiddens': [256], 'double_q': False, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         163.581</td><td style=\"text-align: right;\">          34</td><td style=\"text-align: right;\">    -105.712 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         165.62 </td><td style=\"text-align: right;\">          35</td><td style=\"text-align: right;\">    -146.445 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         163.068</td><td style=\"text-align: right;\">          35</td><td style=\"text-align: right;\">    -179.707 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         163.4  </td><td style=\"text-align: right;\">          31</td><td style=\"text-align: right;\">    -118.125 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         164.225</td><td style=\"text-align: right;\">          29</td><td style=\"text-align: right;\">    -121.277 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         164.011</td><td style=\"text-align: right;\">          34</td><td style=\"text-align: right;\">    -121.384 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         166.418</td><td style=\"text-align: right;\">          36</td><td style=\"text-align: right;\">    -109.154 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         161.893</td><td style=\"text-align: right;\">          29</td><td style=\"text-align: right;\">    -137.376 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         165.304</td><td style=\"text-align: right;\">          33</td><td style=\"text-align: right;\">     -85.9533</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         165.452</td><td style=\"text-align: right;\">          35</td><td style=\"text-align: right;\">    -142.118 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         165.523</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">    -132.16  </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         163.519</td><td style=\"text-align: right;\">          33</td><td style=\"text-align: right;\">     -75.1122</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00002:\n","  date: 2022-04-13_12-04-46\n","  done: false\n","  experiment_id: 315539c1caa744e78ed8486a6a2213a0\n","  hostname: aa9ef03c8f27\n","  iterations: 36\n","  iterations_since_restore: 37\n","  mean_reward: -177.5407848754086\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.74285714285714\n","    ram_util_percent: 22.599999999999998\n","  pid: 2774\n","  time_since_restore: 167.5719132423401\n","  time_this_iter_s: 4.5042383670806885\n","  time_total_s: 167.5719132423401\n","  timestamp: 1649851486\n","  timesteps_since_restore: 0\n","  training_iteration: 37\n","  trial_id: 825a7_00002\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00011:\n","  date: 2022-04-13_12-04-47\n","  done: false\n","  experiment_id: f576928441b043f48c9de3d6907ccbdd\n","  hostname: aa9ef03c8f27\n","  iterations: 34\n","  iterations_since_restore: 35\n","  mean_reward: -64.56587556131535\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.714285714285715\n","    ram_util_percent: 22.61428571428571\n","  pid: 2768\n","  time_since_restore: 168.14729166030884\n","  time_this_iter_s: 4.628399610519409\n","  time_total_s: 168.14729166030884\n","  timestamp: 1649851487\n","  timesteps_since_restore: 0\n","  training_iteration: 35\n","  trial_id: 825a7_00011\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-04-47\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 30\n","  iterations_since_restore: 31\n","  mean_reward: -137.59948939440514\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.78888888888889\n","    ram_util_percent: 22.6\n","  pid: 2771\n","  time_since_restore: 168.3103539943695\n","  time_this_iter_s: 6.417108774185181\n","  time_total_s: 168.3103539943695\n","  timestamp: 1649851487\n","  timesteps_since_restore: 0\n","  training_iteration: 31\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-04-47\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 32\n","  iterations_since_restore: 33\n","  mean_reward: -118.53265408426554\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.875\n","    ram_util_percent: 22.625\n","  pid: 2775\n","  time_since_restore: 169.08328342437744\n","  time_this_iter_s: 5.683650016784668\n","  time_total_s: 169.08328342437744\n","  timestamp: 1649851487\n","  timesteps_since_restore: 0\n","  training_iteration: 33\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00009:\n","  date: 2022-04-13_12-04-48\n","  done: false\n","  experiment_id: 95c2bb28a0b642edb97e6a45503efe15\n","  hostname: aa9ef03c8f27\n","  iterations: 36\n","  iterations_since_restore: 37\n","  mean_reward: -137.68682323217985\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.87142857142857\n","    ram_util_percent: 22.657142857142855\n","  pid: 2769\n","  time_since_restore: 169.92126202583313\n","  time_this_iter_s: 4.469078063964844\n","  time_total_s: 169.92126202583313\n","  timestamp: 1649851488\n","  timesteps_since_restore: 0\n","  training_iteration: 37\n","  trial_id: 825a7_00009\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-04-48\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 30\n","  iterations_since_restore: 31\n","  mean_reward: -120.83928036636449\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.7375\n","    ram_util_percent: 22.6375\n","  pid: 2776\n","  time_since_restore: 169.95849180221558\n","  time_this_iter_s: 5.733733177185059\n","  time_total_s: 169.95849180221558\n","  timestamp: 1649851488\n","  timesteps_since_restore: 0\n","  training_iteration: 31\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-04-50\n","  done: false\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  hostname: aa9ef03c8f27\n","  iterations: 33\n","  iterations_since_restore: 34\n","  mean_reward: -134.95138568992888\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.650000000000006\n","    ram_util_percent: 22.6625\n","  pid: 2777\n","  time_since_restore: 171.53856134414673\n","  time_this_iter_s: 6.015795707702637\n","  time_total_s: 171.53856134414673\n","  timestamp: 1649851490\n","  timesteps_since_restore: 0\n","  training_iteration: 34\n","  trial_id: 825a7_00010\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00000:\n","  date: 2022-04-13_12-04-51\n","  done: false\n","  experiment_id: 696b6ae5d0474799847a48a1fd9db44c\n","  hostname: aa9ef03c8f27\n","  iterations: 36\n","  iterations_since_restore: 37\n","  mean_reward: -102.62761261354125\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.166666666666664\n","    ram_util_percent: 22.71666666666667\n","  pid: 2770\n","  time_since_restore: 172.70533752441406\n","  time_this_iter_s: 4.573140621185303\n","  time_total_s: 172.70533752441406\n","  timestamp: 1649851491\n","  timesteps_since_restore: 0\n","  training_iteration: 37\n","  trial_id: 825a7_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:04:51 (running for 00:02:57.91)<br>Memory usage on this node: 8.0/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00011 with mean_reward=-64.56587556131535 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.5616905067242305, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': False, 'hiddens': [256], 'double_q': False, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         172.705</td><td style=\"text-align: right;\">          36</td><td style=\"text-align: right;\">    -102.628 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         170.545</td><td style=\"text-align: right;\">          36</td><td style=\"text-align: right;\">    -144.798 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         172.08 </td><td style=\"text-align: right;\">          37</td><td style=\"text-align: right;\">    -175.594 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         169.083</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">    -118.533 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         169.958</td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">    -120.839 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         168.658</td><td style=\"text-align: right;\">          35</td><td style=\"text-align: right;\">    -121.381 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         170.855</td><td style=\"text-align: right;\">          37</td><td style=\"text-align: right;\">     -99.0833</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         168.31 </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">    -137.599 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         170.202</td><td style=\"text-align: right;\">          34</td><td style=\"text-align: right;\">     -74.6432</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         169.921</td><td style=\"text-align: right;\">          36</td><td style=\"text-align: right;\">    -137.687 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         171.539</td><td style=\"text-align: right;\">          33</td><td style=\"text-align: right;\">    -134.951 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         168.147</td><td style=\"text-align: right;\">          34</td><td style=\"text-align: right;\">     -64.5659</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00005:\n","  date: 2022-04-13_12-04-52\n","  done: false\n","  experiment_id: d42ae5be5b334ba6981aa7673828d6d2\n","  hostname: aa9ef03c8f27\n","  iterations: 36\n","  iterations_since_restore: 37\n","  mean_reward: -122.23412018177694\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.77142857142858\n","    ram_util_percent: 22.72857142857143\n","  pid: 2773\n","  time_since_restore: 173.23210644721985\n","  time_this_iter_s: 4.573866605758667\n","  time_total_s: 173.23210644721985\n","  timestamp: 1649851492\n","  timesteps_since_restore: 0\n","  training_iteration: 37\n","  trial_id: 825a7_00005\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-04-53\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 31\n","  iterations_since_restore: 32\n","  mean_reward: -137.59830144331033\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.888888888888886\n","    ram_util_percent: 22.744444444444444\n","  pid: 2771\n","  time_since_restore: 174.59344601631165\n","  time_this_iter_s: 6.283092021942139\n","  time_total_s: 174.59344601631165\n","  timestamp: 1649851493\n","  timesteps_since_restore: 0\n","  training_iteration: 32\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00008:\n","  date: 2022-04-13_12-04-53\n","  done: false\n","  experiment_id: cd76c37ed72a4c299a0583e20567f167\n","  hostname: aa9ef03c8f27\n","  iterations: 35\n","  iterations_since_restore: 36\n","  mean_reward: -75.93335256973788\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.0\n","    ram_util_percent: 22.75714285714286\n","  pid: 2767\n","  time_since_restore: 174.79756665229797\n","  time_this_iter_s: 4.595634460449219\n","  time_total_s: 174.79756665229797\n","  timestamp: 1649851493\n","  timesteps_since_restore: 0\n","  training_iteration: 36\n","  trial_id: 825a7_00008\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-04-53\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 33\n","  iterations_since_restore: 34\n","  mean_reward: -119.00255142085298\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.875\n","    ram_util_percent: 22.75\n","  pid: 2775\n","  time_since_restore: 174.96659684181213\n","  time_this_iter_s: 5.883313417434692\n","  time_total_s: 174.96659684181213\n","  timestamp: 1649851493\n","  timesteps_since_restore: 0\n","  training_iteration: 34\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00001:\n","  date: 2022-04-13_12-04-53\n","  done: false\n","  experiment_id: bee5f156b4e14866b4e9e4f5ab3fad72\n","  hostname: aa9ef03c8f27\n","  iterations: 37\n","  iterations_since_restore: 38\n","  mean_reward: -133.139872866063\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.971428571428575\n","    ram_util_percent: 22.771428571428572\n","  pid: 2778\n","  time_since_restore: 175.0761308670044\n","  time_this_iter_s: 4.530769109725952\n","  time_total_s: 175.0761308670044\n","  timestamp: 1649851493\n","  timesteps_since_restore: 0\n","  training_iteration: 38\n","  trial_id: 825a7_00001\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00006:\n","  date: 2022-04-13_12-04-54\n","  done: false\n","  experiment_id: 1452367bf557484fb196e21a6489d80a\n","  hostname: aa9ef03c8f27\n","  iterations: 38\n","  iterations_since_restore: 39\n","  mean_reward: -97.85012821115944\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.05\n","    ram_util_percent: 22.78333333333333\n","  pid: 2772\n","  time_since_restore: 175.1947000026703\n","  time_this_iter_s: 4.3400046825408936\n","  time_total_s: 175.1947000026703\n","  timestamp: 1649851494\n","  timesteps_since_restore: 0\n","  training_iteration: 39\n","  trial_id: 825a7_00006\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-04-54\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 31\n","  iterations_since_restore: 32\n","  mean_reward: -120.74553910161866\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.912499999999994\n","    ram_util_percent: 22.762500000000003\n","  pid: 2776\n","  time_since_restore: 175.3462724685669\n","  time_this_iter_s: 5.387780666351318\n","  time_total_s: 175.3462724685669\n","  timestamp: 1649851494\n","  timesteps_since_restore: 0\n","  training_iteration: 32\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00002:\n","  date: 2022-04-13_12-04-55\n","  done: false\n","  experiment_id: 315539c1caa744e78ed8486a6a2213a0\n","  hostname: aa9ef03c8f27\n","  iterations: 38\n","  iterations_since_restore: 39\n","  mean_reward: -171.0397577720738\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.01428571428571\n","    ram_util_percent: 22.814285714285717\n","  pid: 2774\n","  time_since_restore: 176.59009528160095\n","  time_this_iter_s: 4.510481834411621\n","  time_total_s: 176.59009528160095\n","  timestamp: 1649851495\n","  timesteps_since_restore: 0\n","  training_iteration: 39\n","  trial_id: 825a7_00002\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-04-56\n","  done: false\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  hostname: aa9ef03c8f27\n","  iterations: 34\n","  iterations_since_restore: 35\n","  mean_reward: -133.95474586076668\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.82222222222222\n","    ram_util_percent: 22.811111111111114\n","  pid: 2777\n","  time_since_restore: 177.4248344898224\n","  time_this_iter_s: 5.886273145675659\n","  time_total_s: 177.4248344898224\n","  timestamp: 1649851496\n","  timesteps_since_restore: 0\n","  training_iteration: 35\n","  trial_id: 825a7_00010\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00011:\n","  date: 2022-04-13_12-04-56\n","  done: false\n","  experiment_id: f576928441b043f48c9de3d6907ccbdd\n","  hostname: aa9ef03c8f27\n","  iterations: 36\n","  iterations_since_restore: 37\n","  mean_reward: -58.97675749796783\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.028571428571425\n","    ram_util_percent: 22.82857142857143\n","  pid: 2768\n","  time_since_restore: 177.66033720970154\n","  time_this_iter_s: 4.679287672042847\n","  time_total_s: 177.66033720970154\n","  timestamp: 1649851496\n","  timesteps_since_restore: 0\n","  training_iteration: 37\n","  trial_id: 825a7_00011\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:04:56 (running for 00:03:03.21)<br>Memory usage on this node: 8.1/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00011 with mean_reward=-58.97675749796783 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.5616905067242305, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': False, 'hiddens': [256], 'double_q': False, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         177.173</td><td style=\"text-align: right;\">          37</td><td style=\"text-align: right;\">    -104.757 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         175.076</td><td style=\"text-align: right;\">          37</td><td style=\"text-align: right;\">    -133.14  </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>RUNNING </td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         176.59 </td><td style=\"text-align: right;\">          38</td><td style=\"text-align: right;\">    -171.04  </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         174.967</td><td style=\"text-align: right;\">          33</td><td style=\"text-align: right;\">    -119.003 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         175.346</td><td style=\"text-align: right;\">          31</td><td style=\"text-align: right;\">    -120.746 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         177.981</td><td style=\"text-align: right;\">          37</td><td style=\"text-align: right;\">    -111.359 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>RUNNING </td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         175.195</td><td style=\"text-align: right;\">          38</td><td style=\"text-align: right;\">     -97.8501</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         174.593</td><td style=\"text-align: right;\">          31</td><td style=\"text-align: right;\">    -137.598 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         174.798</td><td style=\"text-align: right;\">          35</td><td style=\"text-align: right;\">     -75.9334</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         174.801</td><td style=\"text-align: right;\">          37</td><td style=\"text-align: right;\">    -129.97  </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         177.425</td><td style=\"text-align: right;\">          34</td><td style=\"text-align: right;\">    -133.955 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         177.66 </td><td style=\"text-align: right;\">          36</td><td style=\"text-align: right;\">     -58.9768</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00009:\n","  date: 2022-04-13_12-04-58\n","  done: false\n","  experiment_id: 95c2bb28a0b642edb97e6a45503efe15\n","  hostname: aa9ef03c8f27\n","  iterations: 38\n","  iterations_since_restore: 39\n","  mean_reward: -128.207902530118\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.74285714285714\n","    ram_util_percent: 22.88571428571429\n","  pid: 2769\n","  time_since_restore: 179.59958696365356\n","  time_this_iter_s: 4.798554182052612\n","  time_total_s: 179.59958696365356\n","  timestamp: 1649851498\n","  timesteps_since_restore: 0\n","  training_iteration: 39\n","  trial_id: 825a7_00009\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00006:\n","  date: 2022-04-13_12-04-58\n","  done: true\n","  experiment_id: 1452367bf557484fb196e21a6489d80a\n","  experiment_tag: 6_double_q=True,dueling=False,gamma=0.013286\n","  hostname: aa9ef03c8f27\n","  iterations: 39\n","  iterations_since_restore: 40\n","  mean_reward: -90.46039961573175\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.5\n","    ram_util_percent: 22.883333333333336\n","  pid: 2772\n","  time_since_restore: 179.58980774879456\n","  time_this_iter_s: 4.395107746124268\n","  time_total_s: 179.58980774879456\n","  timestamp: 1649851498\n","  timesteps_since_restore: 0\n","  training_iteration: 40\n","  trial_id: 825a7_00006\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-04-59\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 32\n","  iterations_since_restore: 33\n","  mean_reward: -136.81855739252111\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.4375\n","    ram_util_percent: 22.7125\n","  pid: 2771\n","  time_since_restore: 180.4820384979248\n","  time_this_iter_s: 5.888592481613159\n","  time_total_s: 180.4820384979248\n","  timestamp: 1649851499\n","  timesteps_since_restore: 0\n","  training_iteration: 33\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-04-59\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 32\n","  iterations_since_restore: 33\n","  mean_reward: -120.70592885474673\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.44285714285714\n","    ram_util_percent: 22.7\n","  pid: 2776\n","  time_since_restore: 180.7118480205536\n","  time_this_iter_s: 5.365575551986694\n","  time_total_s: 180.7118480205536\n","  timestamp: 1649851499\n","  timesteps_since_restore: 0\n","  training_iteration: 33\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-04-59\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 34\n","  iterations_since_restore: 35\n","  mean_reward: -119.2400953310674\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.02222222222222\n","    ram_util_percent: 22.58888888888889\n","  pid: 2775\n","  time_since_restore: 180.82077407836914\n","  time_this_iter_s: 5.854177236557007\n","  time_total_s: 180.82077407836914\n","  timestamp: 1649851499\n","  timesteps_since_restore: 0\n","  training_iteration: 35\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00002:\n","  date: 2022-04-13_12-05-00\n","  done: true\n","  experiment_id: 315539c1caa744e78ed8486a6a2213a0\n","  experiment_tag: 2_double_q=True,dueling=False,gamma=0.066208\n","  hostname: aa9ef03c8f27\n","  iterations: 39\n","  iterations_since_restore: 40\n","  mean_reward: -160.45017549481074\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 39.68333333333333\n","    ram_util_percent: 22.466666666666665\n","  pid: 2774\n","  time_since_restore: 181.08728790283203\n","  time_this_iter_s: 4.497192621231079\n","  time_total_s: 181.08728790283203\n","  timestamp: 1649851500\n","  timesteps_since_restore: 0\n","  training_iteration: 40\n","  trial_id: 825a7_00002\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00000:\n","  date: 2022-04-13_12-05-00\n","  done: false\n","  experiment_id: 696b6ae5d0474799847a48a1fd9db44c\n","  hostname: aa9ef03c8f27\n","  iterations: 38\n","  iterations_since_restore: 39\n","  mean_reward: -107.56191369797348\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 37.98333333333334\n","    ram_util_percent: 22.466666666666665\n","  pid: 2770\n","  time_since_restore: 181.63203239440918\n","  time_this_iter_s: 4.45949125289917\n","  time_total_s: 181.63203239440918\n","  timestamp: 1649851500\n","  timesteps_since_restore: 0\n","  training_iteration: 39\n","  trial_id: 825a7_00000\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00005:\n","  date: 2022-04-13_12-05-01\n","  done: false\n","  experiment_id: d42ae5be5b334ba6981aa7673828d6d2\n","  hostname: aa9ef03c8f27\n","  iterations: 38\n","  iterations_since_restore: 39\n","  mean_reward: -107.19321700377576\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 38.228571428571435\n","    ram_util_percent: 21.75714285714285\n","  pid: 2773\n","  time_since_restore: 182.4885983467102\n","  time_this_iter_s: 4.507125616073608\n","  time_total_s: 182.4885983467102\n","  timestamp: 1649851501\n","  timesteps_since_restore: 0\n","  training_iteration: 39\n","  trial_id: 825a7_00005\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-05-02\n","  done: false\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  hostname: aa9ef03c8f27\n","  iterations: 35\n","  iterations_since_restore: 36\n","  mean_reward: -133.38424038023228\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 37.725\n","    ram_util_percent: 21.612499999999997\n","  pid: 2777\n","  time_since_restore: 183.31983304023743\n","  time_this_iter_s: 5.894998550415039\n","  time_total_s: 183.31983304023743\n","  timestamp: 1649851502\n","  timesteps_since_restore: 0\n","  training_iteration: 36\n","  trial_id: 825a7_00010\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:05:02 (running for 00:03:08.56)<br>Memory usage on this node: 7.1/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00011 with mean_reward=-57.60240487743788 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.5616905067242305, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': False, 'hiddens': [256], 'double_q': False, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (10 RUNNING, 2 TERMINATED)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status    </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>RUNNING   </td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         181.632</td><td style=\"text-align: right;\">          38</td><td style=\"text-align: right;\">    -107.562 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>RUNNING   </td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         179.713</td><td style=\"text-align: right;\">          38</td><td style=\"text-align: right;\">    -126.737 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING   </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         180.821</td><td style=\"text-align: right;\">          34</td><td style=\"text-align: right;\">    -119.24  </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING   </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         180.712</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">    -120.706 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>RUNNING   </td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         182.489</td><td style=\"text-align: right;\">          38</td><td style=\"text-align: right;\">    -107.193 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING   </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         180.482</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">    -136.819 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING   </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         179.692</td><td style=\"text-align: right;\">          36</td><td style=\"text-align: right;\">     -76.2156</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>RUNNING   </td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         179.6  </td><td style=\"text-align: right;\">          38</td><td style=\"text-align: right;\">    -128.208 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING   </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         183.32 </td><td style=\"text-align: right;\">          35</td><td style=\"text-align: right;\">    -133.384 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING   </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         182.162</td><td style=\"text-align: right;\">          37</td><td style=\"text-align: right;\">     -57.6024</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>TERMINATED</td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         181.087</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -160.45  </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>TERMINATED</td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         179.59 </td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -90.4604</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00001:\n","  date: 2022-04-13_12-05-03\n","  done: false\n","  experiment_id: bee5f156b4e14866b4e9e4f5ab3fad72\n","  hostname: aa9ef03c8f27\n","  iterations: 39\n","  iterations_since_restore: 40\n","  mean_reward: -117.778401148697\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 35.63333333333333\n","    ram_util_percent: 21.133333333333333\n","  pid: 2778\n","  time_since_restore: 184.13691115379333\n","  time_this_iter_s: 4.423507213592529\n","  time_total_s: 184.13691115379333\n","  timestamp: 1649851503\n","  timesteps_since_restore: 0\n","  training_iteration: 40\n","  trial_id: 825a7_00001\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00001:\n","  date: 2022-04-13_12-05-03\n","  done: true\n","  experiment_id: bee5f156b4e14866b4e9e4f5ab3fad72\n","  experiment_tag: 1_double_q=False,dueling=True,gamma=0.094572\n","  hostname: aa9ef03c8f27\n","  iterations: 39\n","  iterations_since_restore: 40\n","  mean_reward: -117.778401148697\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 35.63333333333333\n","    ram_util_percent: 21.133333333333333\n","  pid: 2778\n","  time_since_restore: 184.13691115379333\n","  time_this_iter_s: 4.423507213592529\n","  time_total_s: 184.13691115379333\n","  timestamp: 1649851503\n","  timesteps_since_restore: 0\n","  training_iteration: 40\n","  trial_id: 825a7_00001\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00009:\n","  date: 2022-04-13_12-05-03\n","  done: true\n","  experiment_id: 95c2bb28a0b642edb97e6a45503efe15\n","  experiment_tag: 9_double_q=False,dueling=True,gamma=0.42818\n","  hostname: aa9ef03c8f27\n","  iterations: 39\n","  iterations_since_restore: 40\n","  mean_reward: -118.15242991393576\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 34.666666666666664\n","    ram_util_percent: 20.683333333333334\n","  pid: 2769\n","  time_since_restore: 184.1911699771881\n","  time_this_iter_s: 4.591583013534546\n","  time_total_s: 184.1911699771881\n","  timestamp: 1649851503\n","  timesteps_since_restore: 0\n","  training_iteration: 40\n","  trial_id: 825a7_00009\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00008:\n","  date: 2022-04-13_12-05-03\n","  done: false\n","  experiment_id: cd76c37ed72a4c299a0583e20567f167\n","  hostname: aa9ef03c8f27\n","  iterations: 37\n","  iterations_since_restore: 38\n","  mean_reward: -73.97164847753956\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 35.78333333333333\n","    ram_util_percent: 20.733333333333334\n","  pid: 2767\n","  time_since_restore: 184.19654989242554\n","  time_this_iter_s: 4.504814624786377\n","  time_total_s: 184.19654989242554\n","  timestamp: 1649851503\n","  timesteps_since_restore: 0\n","  training_iteration: 38\n","  trial_id: 825a7_00008\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-05-04\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 33\n","  iterations_since_restore: 34\n","  mean_reward: -136.33525452359248\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 33.171428571428564\n","    ram_util_percent: 20.042857142857144\n","  pid: 2771\n","  time_since_restore: 185.54932236671448\n","  time_this_iter_s: 5.067283868789673\n","  time_total_s: 185.54932236671448\n","  timestamp: 1649851504\n","  timesteps_since_restore: 0\n","  training_iteration: 34\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00000:\n","  date: 2022-04-13_12-05-04\n","  done: true\n","  experiment_id: 696b6ae5d0474799847a48a1fd9db44c\n","  experiment_tag: 0_double_q=True,dueling=True,gamma=0.30299\n","  hostname: aa9ef03c8f27\n","  iterations: 39\n","  iterations_since_restore: 40\n","  mean_reward: -104.41670717756713\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 31.433333333333334\n","    ram_util_percent: 19.349999999999998\n","  pid: 2770\n","  time_since_restore: 185.8951015472412\n","  time_this_iter_s: 4.263069152832031\n","  time_total_s: 185.8951015472412\n","  timestamp: 1649851504\n","  timesteps_since_restore: 0\n","  training_iteration: 40\n","  trial_id: 825a7_00000\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-05-05\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 33\n","  iterations_since_restore: 34\n","  mean_reward: -120.67189086188269\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 31.322222222222226\n","    ram_util_percent: 19.477777777777774\n","  pid: 2776\n","  time_since_restore: 186.49779534339905\n","  time_this_iter_s: 5.785947322845459\n","  time_total_s: 186.49779534339905\n","  timestamp: 1649851505\n","  timesteps_since_restore: 0\n","  training_iteration: 34\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00005:\n","  date: 2022-04-13_12-05-05\n","  done: true\n","  experiment_id: d42ae5be5b334ba6981aa7673828d6d2\n","  experiment_tag: 5_double_q=False,dueling=True,gamma=0.5307\n","  hostname: aa9ef03c8f27\n","  iterations: 39\n","  iterations_since_restore: 40\n","  mean_reward: -98.07556717176617\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 29.683333333333337\n","    ram_util_percent: 18.650000000000002\n","  pid: 2773\n","  time_since_restore: 186.58615946769714\n","  time_this_iter_s: 4.0975611209869385\n","  time_total_s: 186.58615946769714\n","  timestamp: 1649851505\n","  timesteps_since_restore: 0\n","  training_iteration: 40\n","  trial_id: 825a7_00005\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00011:\n","  date: 2022-04-13_12-05-05\n","  done: false\n","  experiment_id: f576928441b043f48c9de3d6907ccbdd\n","  hostname: aa9ef03c8f27\n","  iterations: 38\n","  iterations_since_restore: 39\n","  mean_reward: -53.76418363841071\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 29.766666666666666\n","    ram_util_percent: 18.650000000000002\n","  pid: 2768\n","  time_since_restore: 186.59727954864502\n","  time_this_iter_s: 4.435216188430786\n","  time_total_s: 186.59727954864502\n","  timestamp: 1649851505\n","  timesteps_since_restore: 0\n","  training_iteration: 39\n","  trial_id: 825a7_00011\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:05:07 (running for 00:03:13.66)<br>Memory usage on this node: 5.2/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00011 with mean_reward=-53.76418363841071 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.5616905067242305, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': False, 'hiddens': [256], 'double_q': False, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (6 RUNNING, 6 TERMINATED)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status    </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING   </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         185.358</td><td style=\"text-align: right;\">          35</td><td style=\"text-align: right;\">    -117.448 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING   </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         186.498</td><td style=\"text-align: right;\">          33</td><td style=\"text-align: right;\">    -120.672 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING   </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         185.549</td><td style=\"text-align: right;\">          33</td><td style=\"text-align: right;\">    -136.335 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>RUNNING   </td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         188.425</td><td style=\"text-align: right;\">          38</td><td style=\"text-align: right;\">     -71.9177</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING   </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         183.32 </td><td style=\"text-align: right;\">          35</td><td style=\"text-align: right;\">    -133.384 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>RUNNING   </td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         186.597</td><td style=\"text-align: right;\">          38</td><td style=\"text-align: right;\">     -53.7642</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>TERMINATED</td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         185.895</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -104.417 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>TERMINATED</td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         184.137</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -117.778 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>TERMINATED</td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         181.087</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -160.45  </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>TERMINATED</td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         186.586</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -98.0756</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>TERMINATED</td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         179.59 </td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -90.4604</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>TERMINATED</td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         184.191</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -118.152 </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-05-08\n","  done: false\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  hostname: aa9ef03c8f27\n","  iterations: 36\n","  iterations_since_restore: 37\n","  mean_reward: -132.52373781364975\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 25.275\n","    ram_util_percent: 17.15\n","  pid: 2777\n","  time_since_restore: 189.17814755439758\n","  time_this_iter_s: 5.858314514160156\n","  time_total_s: 189.17814755439758\n","  timestamp: 1649851508\n","  timesteps_since_restore: 0\n","  training_iteration: 37\n","  trial_id: 825a7_00010\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-05-08\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 36\n","  iterations_since_restore: 37\n","  mean_reward: -114.24296872197908\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 21.46666666666667\n","    ram_util_percent: 15.65\n","  pid: 2775\n","  time_since_restore: 189.46623134613037\n","  time_this_iter_s: 4.108633279800415\n","  time_total_s: 189.46623134613037\n","  timestamp: 1649851508\n","  timesteps_since_restore: 0\n","  training_iteration: 37\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-05-09\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 34\n","  iterations_since_restore: 35\n","  mean_reward: -136.08654083176063\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 21.442857142857143\n","    ram_util_percent: 15.528571428571428\n","  pid: 2771\n","  time_since_restore: 190.6143717765808\n","  time_this_iter_s: 5.065049409866333\n","  time_total_s: 190.6143717765808\n","  timestamp: 1649851509\n","  timesteps_since_restore: 0\n","  training_iteration: 35\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00011:\n","  date: 2022-04-13_12-05-09\n","  done: true\n","  experiment_id: f576928441b043f48c9de3d6907ccbdd\n","  experiment_tag: 11_double_q=False,dueling=False,gamma=0.56169\n","  hostname: aa9ef03c8f27\n","  iterations: 39\n","  iterations_since_restore: 40\n","  mean_reward: -51.40065961122843\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 19.45\n","    ram_util_percent: 14.983333333333333\n","  pid: 2768\n","  time_since_restore: 190.60580253601074\n","  time_this_iter_s: 4.008522987365723\n","  time_total_s: 190.60580253601074\n","  timestamp: 1649851509\n","  timesteps_since_restore: 0\n","  training_iteration: 40\n","  trial_id: 825a7_00011\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-05-10\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 34\n","  iterations_since_restore: 35\n","  mean_reward: -120.6768799963641\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 18.842857142857145\n","    ram_util_percent: 14.957142857142856\n","  pid: 2776\n","  time_since_restore: 191.79510378837585\n","  time_this_iter_s: 5.297308444976807\n","  time_total_s: 191.79510378837585\n","  timestamp: 1649851510\n","  timesteps_since_restore: 0\n","  training_iteration: 35\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00008:\n","  date: 2022-04-13_12-05-11\n","  done: false\n","  experiment_id: cd76c37ed72a4c299a0583e20567f167\n","  hostname: aa9ef03c8f27\n","  iterations: 39\n","  iterations_since_restore: 40\n","  mean_reward: -73.16757371255453\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 18.683333333333334\n","    ram_util_percent: 14.4\n","  pid: 2767\n","  time_since_restore: 192.27345371246338\n","  time_this_iter_s: 3.848233699798584\n","  time_total_s: 192.27345371246338\n","  timestamp: 1649851511\n","  timesteps_since_restore: 0\n","  training_iteration: 40\n","  trial_id: 825a7_00008\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00008:\n","  date: 2022-04-13_12-05-11\n","  done: true\n","  experiment_id: cd76c37ed72a4c299a0583e20567f167\n","  experiment_tag: 8_double_q=True,dueling=True,gamma=0.49559\n","  hostname: aa9ef03c8f27\n","  iterations: 39\n","  iterations_since_restore: 40\n","  mean_reward: -73.16757371255453\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 18.683333333333334\n","    ram_util_percent: 14.4\n","  pid: 2767\n","  time_since_restore: 192.27345371246338\n","  time_this_iter_s: 3.848233699798584\n","  time_total_s: 192.27345371246338\n","  timestamp: 1649851511\n","  timesteps_since_restore: 0\n","  training_iteration: 40\n","  trial_id: 825a7_00008\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:05:12 (running for 00:03:18.92)<br>Memory usage on this node: 4.2/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00011 with mean_reward=-51.40065961122843 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.5616905067242305, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': False, 'hiddens': [256], 'double_q': False, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (4 RUNNING, 8 TERMINATED)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status    </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING   </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         189.466</td><td style=\"text-align: right;\">          36</td><td style=\"text-align: right;\">    -114.243 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING   </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         191.795</td><td style=\"text-align: right;\">          34</td><td style=\"text-align: right;\">    -120.677 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING   </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         190.614</td><td style=\"text-align: right;\">          34</td><td style=\"text-align: right;\">    -136.087 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING   </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         193.684</td><td style=\"text-align: right;\">          37</td><td style=\"text-align: right;\">    -125.191 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>TERMINATED</td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         185.895</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -104.417 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>TERMINATED</td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         184.137</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -117.778 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>TERMINATED</td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         181.087</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -160.45  </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>TERMINATED</td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         186.586</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -98.0756</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>TERMINATED</td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         179.59 </td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -90.4604</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>TERMINATED</td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         192.273</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -73.1676</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>TERMINATED</td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         184.191</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -118.152 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>TERMINATED</td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         190.606</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -51.4007</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-05-13\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 37\n","  iterations_since_restore: 38\n","  mean_reward: -114.56670655498097\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 15.5\n","    ram_util_percent: 13.4\n","  pid: 2775\n","  time_since_restore: 194.906263589859\n","  time_this_iter_s: 5.440032243728638\n","  time_total_s: 194.906263589859\n","  timestamp: 1649851513\n","  timesteps_since_restore: 0\n","  training_iteration: 38\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-05-15\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 35\n","  iterations_since_restore: 36\n","  mean_reward: -120.80301155214457\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 13.428571428571429\n","    ram_util_percent: 12.4\n","  pid: 2776\n","  time_since_restore: 196.86018586158752\n","  time_this_iter_s: 5.06508207321167\n","  time_total_s: 196.86018586158752\n","  timestamp: 1649851515\n","  timesteps_since_restore: 0\n","  training_iteration: 36\n","  trial_id: 825a7_00004\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-05-16\n","  done: false\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  hostname: aa9ef03c8f27\n","  iterations: 38\n","  iterations_since_restore: 39\n","  mean_reward: -121.12408507276281\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 12.866666666666667\n","    ram_util_percent: 12.0\n","  pid: 2777\n","  time_since_restore: 198.03611969947815\n","  time_this_iter_s: 4.351749897003174\n","  time_total_s: 198.03611969947815\n","  timestamp: 1649851516\n","  timesteps_since_restore: 0\n","  training_iteration: 39\n","  trial_id: 825a7_00010\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:05:17 (running for 00:03:24.25)<br>Memory usage on this node: 4.3/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00011 with mean_reward=-51.40065961122843 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.5616905067242305, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': False, 'hiddens': [256], 'double_q': False, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (4 RUNNING, 8 TERMINATED)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status    </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>RUNNING   </td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         199.064</td><td style=\"text-align: right;\">          38</td><td style=\"text-align: right;\">    -115.73  </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING   </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         196.86 </td><td style=\"text-align: right;\">          35</td><td style=\"text-align: right;\">    -120.803 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING   </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         195.534</td><td style=\"text-align: right;\">          35</td><td style=\"text-align: right;\">    -136.01  </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>RUNNING   </td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         198.036</td><td style=\"text-align: right;\">          38</td><td style=\"text-align: right;\">    -121.124 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>TERMINATED</td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         185.895</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -104.417 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>TERMINATED</td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         184.137</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -117.778 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>TERMINATED</td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         181.087</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -160.45  </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>TERMINATED</td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         186.586</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -98.0756</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>TERMINATED</td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         179.59 </td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -90.4604</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>TERMINATED</td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         192.273</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -73.1676</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>TERMINATED</td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         184.191</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -118.152 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>TERMINATED</td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         190.606</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -51.4007</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-05-19\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 36\n","  iterations_since_restore: 37\n","  mean_reward: -136.10401394304813\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 12.9375\n","    ram_util_percent: 12.0625\n","  pid: 2771\n","  time_since_restore: 201.02864027023315\n","  time_this_iter_s: 5.494492769241333\n","  time_total_s: 201.02864027023315\n","  timestamp: 1649851519\n","  timesteps_since_restore: 0\n","  training_iteration: 37\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00010:\n","  date: 2022-04-13_12-05-21\n","  done: true\n","  experiment_id: 94bc6a39e2d24df9b8cd863d6ae0fa07\n","  experiment_tag: 10_double_q=True,dueling=False,gamma=0.7473\n","  hostname: aa9ef03c8f27\n","  iterations: 39\n","  iterations_since_restore: 40\n","  mean_reward: -123.83672877975565\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 12.933333333333335\n","    ram_util_percent: 12.1\n","  pid: 2777\n","  time_since_restore: 202.1762945652008\n","  time_this_iter_s: 4.140174865722656\n","  time_total_s: 202.1762945652008\n","  timestamp: 1649851521\n","  timesteps_since_restore: 0\n","  training_iteration: 40\n","  trial_id: 825a7_00010\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-05-22\n","  done: false\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  hostname: aa9ef03c8f27\n","  iterations: 39\n","  iterations_since_restore: 40\n","  mean_reward: -115.76758824868546\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 12.100000000000001\n","    ram_util_percent: 11.866666666666667\n","  pid: 2775\n","  time_since_restore: 203.7069435119629\n","  time_this_iter_s: 4.642630577087402\n","  time_total_s: 203.7069435119629\n","  timestamp: 1649851522\n","  timesteps_since_restore: 0\n","  training_iteration: 40\n","  trial_id: 825a7_00003\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00003:\n","  date: 2022-04-13_12-05-22\n","  done: true\n","  experiment_id: 863168496cfe41e3b1c7e95677e0f8b2\n","  experiment_tag: 3_double_q=False,dueling=False,gamma=0.78009\n","  hostname: aa9ef03c8f27\n","  iterations: 39\n","  iterations_since_restore: 40\n","  mean_reward: -115.76758824868546\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 12.100000000000001\n","    ram_util_percent: 11.866666666666667\n","  pid: 2775\n","  time_since_restore: 203.7069435119629\n","  time_this_iter_s: 4.642630577087402\n","  time_total_s: 203.7069435119629\n","  timestamp: 1649851522\n","  timesteps_since_restore: 0\n","  training_iteration: 40\n","  trial_id: 825a7_00003\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:05:23 (running for 00:03:29.91)<br>Memory usage on this node: 3.3/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00011 with mean_reward=-51.40065961122843 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.5616905067242305, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': False, 'hiddens': [256], 'double_q': False, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (2 RUNNING, 10 TERMINATED)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status    </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING   </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         201.812</td><td style=\"text-align: right;\">          36</td><td style=\"text-align: right;\">    -120.583 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING   </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         201.029</td><td style=\"text-align: right;\">          36</td><td style=\"text-align: right;\">    -136.104 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>TERMINATED</td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         185.895</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -104.417 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>TERMINATED</td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         184.137</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -117.778 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>TERMINATED</td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         181.087</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -160.45  </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>TERMINATED</td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         203.707</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -115.768 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>TERMINATED</td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         186.586</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -98.0756</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>TERMINATED</td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         179.59 </td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -90.4604</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>TERMINATED</td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         192.273</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -73.1676</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>TERMINATED</td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         184.191</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -118.152 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>TERMINATED</td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         202.176</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -123.837 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>TERMINATED</td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         190.606</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -51.4007</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-05-25\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 37\n","  iterations_since_restore: 38\n","  mean_reward: -136.10220665000082\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 9.1875\n","    ram_util_percent: 10.375\n","  pid: 2771\n","  time_since_restore: 206.25595259666443\n","  time_this_iter_s: 5.227312326431274\n","  time_total_s: 206.25595259666443\n","  timestamp: 1649851525\n","  timesteps_since_restore: 0\n","  training_iteration: 38\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-05-25\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 37\n","  iterations_since_restore: 38\n","  mean_reward: -119.87177442222188\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 8.457142857142857\n","    ram_util_percent: 10.37142857142857\n","  pid: 2776\n","  time_since_restore: 206.46290707588196\n","  time_this_iter_s: 4.650487184524536\n","  time_total_s: 206.46290707588196\n","  timestamp: 1649851525\n","  timesteps_since_restore: 0\n","  training_iteration: 38\n","  trial_id: 825a7_00004\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:05:29 (running for 00:03:35.68)<br>Memory usage on this node: 3.3/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00011 with mean_reward=-51.40065961122843 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.5616905067242305, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': False, 'hiddens': [256], 'double_q': False, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (2 RUNNING, 10 TERMINATED)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status    </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING   </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         206.463</td><td style=\"text-align: right;\">          37</td><td style=\"text-align: right;\">    -119.872 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>RUNNING   </td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         206.256</td><td style=\"text-align: right;\">          37</td><td style=\"text-align: right;\">    -136.102 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>TERMINATED</td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         185.895</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -104.417 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>TERMINATED</td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         184.137</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -117.778 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>TERMINATED</td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         181.087</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -160.45  </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>TERMINATED</td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         203.707</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -115.768 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>TERMINATED</td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         186.586</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -98.0756</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>TERMINATED</td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         179.59 </td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -90.4604</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>TERMINATED</td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         192.273</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -73.1676</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>TERMINATED</td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         184.191</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -118.152 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>TERMINATED</td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         202.176</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -123.837 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>TERMINATED</td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         190.606</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -51.4007</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-05-33\n","  done: false\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  hostname: aa9ef03c8f27\n","  iterations: 39\n","  iterations_since_restore: 40\n","  mean_reward: -137.20928331052286\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 6.699999999999999\n","    ram_util_percent: 9.4\n","  pid: 2771\n","  time_since_restore: 214.94562482833862\n","  time_this_iter_s: 4.175777912139893\n","  time_total_s: 214.94562482833862\n","  timestamp: 1649851533\n","  timesteps_since_restore: 0\n","  training_iteration: 40\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00007:\n","  date: 2022-04-13_12-05-33\n","  done: true\n","  experiment_id: fad49a1612b0497e9c1fa9f25c1b4bef\n","  experiment_tag: 7_double_q=False,dueling=False,gamma=0.90798\n","  hostname: aa9ef03c8f27\n","  iterations: 39\n","  iterations_since_restore: 40\n","  mean_reward: -137.20928331052286\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 6.699999999999999\n","    ram_util_percent: 9.4\n","  pid: 2771\n","  time_since_restore: 214.94562482833862\n","  time_this_iter_s: 4.175777912139893\n","  time_total_s: 214.94562482833862\n","  timestamp: 1649851533\n","  timesteps_since_restore: 0\n","  training_iteration: 40\n","  trial_id: 825a7_00007\n","  \n","Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-05-34\n","  done: false\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  hostname: aa9ef03c8f27\n","  iterations: 39\n","  iterations_since_restore: 40\n","  mean_reward: -119.31391653395582\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 6.199999999999999\n","    ram_util_percent: 9.4\n","  pid: 2776\n","  time_since_restore: 215.60084104537964\n","  time_this_iter_s: 4.511471509933472\n","  time_total_s: 215.60084104537964\n","  timestamp: 1649851534\n","  timesteps_since_restore: 0\n","  training_iteration: 40\n","  trial_id: 825a7_00004\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:05:34 (running for 00:03:40.81)<br>Memory usage on this node: 2.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00011 with mean_reward=-51.40065961122843 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.5616905067242305, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': False, 'hiddens': [256], 'double_q': False, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (1 RUNNING, 11 TERMINATED)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status    </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>RUNNING   </td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         215.601</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -119.314 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>TERMINATED</td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         185.895</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -104.417 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>TERMINATED</td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         184.137</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -117.778 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>TERMINATED</td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         181.087</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -160.45  </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>TERMINATED</td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         203.707</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -115.768 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>TERMINATED</td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         186.586</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -98.0756</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>TERMINATED</td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         179.59 </td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -90.4604</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>TERMINATED</td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         214.946</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -137.209 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>TERMINATED</td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         192.273</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -73.1676</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>TERMINATED</td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         184.191</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -118.152 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>TERMINATED</td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         202.176</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -123.837 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>TERMINATED</td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         190.606</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -51.4007</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_825a7_00004:\n","  date: 2022-04-13_12-05-34\n","  done: true\n","  experiment_id: bde45c8f8c2e46b2a9a0b7a1a88b6b97\n","  experiment_tag: 4_double_q=True,dueling=True,gamma=0.91438\n","  hostname: aa9ef03c8f27\n","  iterations: 39\n","  iterations_since_restore: 40\n","  mean_reward: -119.31391653395582\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 6.199999999999999\n","    ram_util_percent: 9.4\n","  pid: 2776\n","  time_since_restore: 215.60084104537964\n","  time_this_iter_s: 4.511471509933472\n","  time_total_s: 215.60084104537964\n","  timestamp: 1649851534\n","  timesteps_since_restore: 0\n","  training_iteration: 40\n","  trial_id: 825a7_00004\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:05:34 (running for 00:03:40.84)<br>Memory usage on this node: 2.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: 825a7_00011 with mean_reward=-51.40065961122843 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.5616905067242305, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': False, 'hiddens': [256], 'double_q': False, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/objective_fn_2022-04-13_12-01-53<br>Number of trials: 12/12 (12 TERMINATED)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status    </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00000</td><td>TERMINATED</td><td>172.28.0.2:2770</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.302992 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         185.895</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -104.417 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00001</td><td>TERMINATED</td><td>172.28.0.2:2778</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0945719</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         184.137</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -117.778 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00002</td><td>TERMINATED</td><td>172.28.0.2:2774</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0662077</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         181.087</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -160.45  </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00003</td><td>TERMINATED</td><td>172.28.0.2:2775</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.780091 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         203.707</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -115.768 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00004</td><td>TERMINATED</td><td>172.28.0.2:2776</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.914384 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         215.601</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -119.314 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00005</td><td>TERMINATED</td><td>172.28.0.2:2773</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.530701 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         186.586</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -98.0756</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00006</td><td>TERMINATED</td><td>172.28.0.2:2772</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.0132863</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         179.59 </td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -90.4604</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00007</td><td>TERMINATED</td><td>172.28.0.2:2771</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.907981 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         214.946</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -137.209 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00008</td><td>TERMINATED</td><td>172.28.0.2:2767</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.495593 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         192.273</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -73.1676</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00009</td><td>TERMINATED</td><td>172.28.0.2:2769</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.428185 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         184.191</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -118.152 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00010</td><td>TERMINATED</td><td>172.28.0.2:2777</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.747298 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         202.176</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">    -123.837 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_825a7_00011</td><td>TERMINATED</td><td>172.28.0.2:2768</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.561691 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         190.606</td><td style=\"text-align: right;\">          39</td><td style=\"text-align: right;\">     -51.4007</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2022-04-13 12:05:34,919\tINFO tune.py:639 -- Total run time: 221.23 seconds (220.83 seconds for the tuning loop).\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters found were:  {'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.5616905067242305, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': False, 'hiddens': [256], 'double_q': False, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}\n"]}]},{"cell_type":"code","source":["df = analysis.dataframe(metric=\"mean_reward\", mode=\"max\")\n","df[['config/gamma', 'config/double_q', 'config/dueling', 'mean_reward']]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":425},"id":"oVEofybUd7xn","executionInfo":{"status":"ok","timestamp":1649851591880,"user_tz":-60,"elapsed":1186,"user":{"displayName":"k Yuichi","userId":"17236341909464291729"}},"outputId":"f1991dbe-8e10-4b73-d1c9-d70a4cd4ea1b"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    config/gamma  config/double_q  config/dueling  mean_reward\n","0       0.302992             True            True  -102.627613\n","1       0.094572            False            True  -117.778401\n","2       0.066208             True           False  -136.565895\n","3       0.780091            False           False  -114.242969\n","4       0.914384             True            True  -119.313917\n","5       0.530701            False            True   -98.075567\n","6       0.013286             True           False   -90.460400\n","7       0.907981            False           False  -135.542733\n","8       0.495593             True            True   -71.917700\n","9       0.428185            False            True  -118.152430\n","10      0.747298             True           False  -121.124085\n","11      0.561691            False           False   -51.400660"],"text/html":["\n","  <div id=\"df-0d469566-05b0-4e7c-9263-88ffe37bfec8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>config/gamma</th>\n","      <th>config/double_q</th>\n","      <th>config/dueling</th>\n","      <th>mean_reward</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.302992</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>-102.627613</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.094572</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>-117.778401</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.066208</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>-136.565895</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.780091</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>-114.242969</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.914384</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>-119.313917</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.530701</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>-98.075567</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.013286</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>-90.460400</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.907981</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>-135.542733</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.495593</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>-71.917700</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.428185</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>-118.152430</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.747298</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>-121.124085</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.561691</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>-51.400660</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d469566-05b0-4e7c-9263-88ffe37bfec8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0d469566-05b0-4e7c-9263-88ffe37bfec8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0d469566-05b0-4e7c-9263-88ffe37bfec8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3fQhxxi98ECW"},"outputs":[],"source":[""]}],"metadata":{"colab":{"name":"Lab07_new.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":0}