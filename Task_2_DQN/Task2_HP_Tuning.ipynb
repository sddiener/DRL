{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"xhRVpY12qvzD"},"outputs":[],"source":["#from google.colab import drive\n","#drive.mount('/content/gdrive')\n","#path = '/content/gdrive/My Drive/Colab Notebooks/707/Labs/'\n","#import sys\n","#sys.path.append(path)"]},{"cell_type":"code","source":["!pip install Box2D\n","!pip install box2d-py\n","!pip install gym[all]\n","!pip install gym[Box_2D]\n","!pip install torc\n","!pip install -U \"ray[rllib]\" torch\n","import gym \n","env = gym.make(\"LunarLander-v2\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FrHcoNvJFxl8","executionInfo":{"status":"ok","timestamp":1649850969257,"user_tz":-60,"elapsed":121333,"user":{"displayName":"k Yuichi","userId":"17236341909464291729"}},"outputId":"2981436e-8e04-4237-c6ec-455cef0d2a51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: Box2D in /usr/local/lib/python3.7/dist-packages (2.3.10)\n","Requirement already satisfied: box2d-py in /usr/local/lib/python3.7/dist-packages (2.3.8)\n","Requirement already satisfied: gym[all] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[all]) (1.5.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[all]) (1.4.1)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[all]) (1.3.0)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[all]) (1.21.5)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym[all]) (7.1.2)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from gym[all]) (2.4.1)\n","Requirement already satisfied: box2d-py~=2.3.5 in /usr/local/lib/python3.7/dist-packages (from gym[all]) (2.3.8)\n","Collecting mujoco-py<2.0,>=1.50\n","  Using cached mujoco-py-1.50.1.68.tar.gz (120 kB)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gym[all]) (4.1.2.30)\n","Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[all]) (0.2.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py~=0.2.0->gym[all]) (1.15.0)\n","Requirement already satisfied: glfw>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from mujoco-py<2.0,>=1.50->gym[all]) (2.5.3)\n","Requirement already satisfied: Cython>=0.27.2 in /usr/local/lib/python3.7/dist-packages (from mujoco-py<2.0,>=1.50->gym[all]) (0.29.28)\n","Requirement already satisfied: cffi>=1.10 in /usr/local/lib/python3.7/dist-packages (from mujoco-py<2.0,>=1.50->gym[all]) (1.15.0)\n","Requirement already satisfied: lockfile>=0.12.2 in /usr/local/lib/python3.7/dist-packages (from mujoco-py<2.0,>=1.50->gym[all]) (0.12.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.10->mujoco-py<2.0,>=1.50->gym[all]) (2.21)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[all]) (0.16.0)\n","Building wheels for collected packages: mujoco-py\n","  Building wheel for mujoco-py (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for mujoco-py\u001b[0m\n","\u001b[?25h  Running setup.py clean for mujoco-py\n","Failed to build mujoco-py\n","Installing collected packages: mujoco-py\n","    Running setup.py install for mujoco-py ... \u001b[?25l\u001b[?25herror\n","\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-nbj3qvf7/mujoco-py_8397aa03472a45909340414fb455142b/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-nbj3qvf7/mujoco-py_8397aa03472a45909340414fb455142b/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-_v5a1a3m/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/mujoco-py Check the logs for full command output.\u001b[0m\n","Requirement already satisfied: gym[Box_2D] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n","\u001b[33mWARNING: gym 0.17.3 does not provide the extra 'box_2d'\u001b[0m\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.4.1)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.21.5)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.5.0)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.3.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[Box_2D]) (0.16.0)\n","Requirement already satisfied: torc in /usr/local/lib/python3.7/dist-packages (0.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torc) (1.21.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torc) (1.4.1)\n","Collecting ray[rllib]\n","  Downloading ray-1.11.0-cp37-cp37m-manylinux2014_x86_64.whl (52.7 MB)\n","\u001b[K     |████████████████████████████████| 52.7 MB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n","Collecting torch\n","  Downloading torch-1.11.0-cp37-cp37m-manylinux1_x86_64.whl (750.6 MB)\n","\u001b[K     |████████████████████████████████| 750.6 MB 10 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n","Collecting redis>=3.5.0\n","  Downloading redis-4.2.2-py3-none-any.whl (226 kB)\n","\u001b[K     |████████████████████████████████| 226 kB 79.2 MB/s \n","\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (7.1.2)\n","Collecting grpcio<=1.43.0,>=1.28.1\n","  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n","\u001b[K     |████████████████████████████████| 4.1 MB 71.7 MB/s \n","\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (4.3.3)\n","Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (3.17.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (3.13)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (21.4.0)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (1.0.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (3.6.0)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (1.21.5)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (0.8.9)\n","Requirement already satisfied: gym<0.22 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (0.17.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (1.3.5)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (0.18.3)\n","Requirement already satisfied: matplotlib!=3.4.3 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (3.2.2)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (0.1.6)\n","Collecting tensorboardX>=1.9\n","  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 87.1 MB/s \n","\u001b[?25hCollecting lz4\n","  Downloading lz4-4.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 79.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (2.23.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (1.4.1)\n","Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.28.1->ray[rllib]) (1.15.0)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym<0.22->ray[rllib]) (1.5.0)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym<0.22->ray[rllib]) (1.3.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.4.3->ray[rllib]) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.4.3->ray[rllib]) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.4.3->ray[rllib]) (1.4.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.4.3->ray[rllib]) (3.0.7)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym<0.22->ray[rllib]) (0.16.0)\n","Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[rllib]) (21.3)\n","Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[rllib]) (4.11.3)\n","Collecting deprecated>=1.2.3\n","  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n","Collecting async-timeout>=4.0.2\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[rllib]) (1.14.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[rllib]) (3.7.0)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[rllib]) (5.4.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[rllib]) (0.18.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[rllib]) (2018.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[rllib]) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[rllib]) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[rllib]) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray[rllib]) (2.10)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->ray[rllib]) (2.6.3)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->ray[rllib]) (2021.11.2)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->ray[rllib]) (2.4.1)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->ray[rllib]) (1.3.0)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->ray[rllib]) (7.1.2)\n","Installing collected packages: deprecated, async-timeout, redis, grpcio, tensorboardX, ray, lz4, torch\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.44.0\n","    Uninstalling grpcio-1.44.0:\n","      Successfully uninstalled grpcio-1.44.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n","torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.11.0 which is incompatible.\n","torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.11.0 which is incompatible.\n","torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.11.0 which is incompatible.\u001b[0m\n","Successfully installed async-timeout-4.0.2 deprecated-1.2.13 grpcio-1.43.0 lz4-4.0.0 ray-1.11.0 redis-4.2.2 tensorboardX-2.5 torch-1.11.0\n"]}]},{"cell_type":"code","execution_count":19,"metadata":{"id":"XRSA3yCcxoCJ","executionInfo":{"status":"ok","timestamp":1649854478970,"user_tz":-60,"elapsed":148,"user":{"displayName":"k Yuichi","userId":"17236341909464291729"}}},"outputs":[],"source":["import ray\n","import ray.rllib.agents.dqn as dqn\n","\n","def evaluation_fn(result):\n","    return result['episode_reward_mean']\n","\n","\n","def objective_fn(config):\n","\n","    \n","    trainer = dqn.DQNTrainer(config=config)\n","\n","    for i in range(10):\n","      # Perform one iteration of training the policy with DQN\n","      result = trainer.train()\n","      intermediate_score = evaluation_fn(result)\n","      \n","      # Feed the score back back to Tune.\n","      tune.report(iterations=i, mean_reward=intermediate_score)\n","      "]},{"cell_type":"markdown","metadata":{"id":"QauOX-mbyqp_"},"source":["## Use DQN and train your algorithm on the Dungeon environment.\n","\n","You can take inspiration from:\n","https://docs.ray.io/en/latest/rllib/rllib-training.html#basic-python-api\n","\n","Experiment with the different parameters of the configuration:\n","https://docs.ray.io/en/latest/rllib/rllib-algorithms.html#deep-q-networks-dqn-rainbow-parametric-dqn\n","\n","\n","\n"]},{"cell_type":"code","source":["\n","import ray\n","import ray.rllib.agents.dqn as dqn\n","from ray.tune.logger import pretty_print\n","from ray import tune \n","\n","config = dqn.DEFAULT_CONFIG.copy()\n","config[\"dueling\"] = tune.grid_search([True, False])\n","config[\"double_q\"] = tune.grid_search([True, False])\n","config[\"model\"] = { \"fcnet_hiddens\": [128, 128, 128],\n","                    \"fcnet_activation\": 'relu',\n","    }\n","config[\"env\"] = \"LunarLander-v2\"\n","#config['lr'] = tune.loguniform(1e-4, 1e-1),\n","config[\"gamma\"] = tune.uniform(0, 1)\n","\n","analysis = tune.run(\n","        objective_fn,\n","        metric=\"mean_reward\",\n","        mode=\"max\",\n","        num_samples=3,\n","        name='HP_tuning_LunarLander',\n","        config=config)\n","\n","\n","print(\"Best hyperparameters found were: \", analysis.best_config)\n"],"metadata":{"id":"CvzsysIZfjTc","executionInfo":{"status":"ok","timestamp":1649854543244,"user_tz":-60,"elapsed":54183,"user":{"displayName":"k Yuichi","userId":"17236341909464291729"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"a51279a4-cab2-405a-bb13-f34e5b65c517"},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:54:57 (running for 00:00:00.17)<br>Memory usage on this node: 2.3/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Result logdir: /root/ray_results/HP_tuning_LunarLander<br>Number of trials: 12/12 (12 PENDING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc  </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00000</td><td>PENDING </td><td>     </td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.920612 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00001</td><td>PENDING </td><td>     </td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0806447</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00002</td><td>PENDING </td><td>     </td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.263824 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00003</td><td>PENDING </td><td>     </td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.15326  </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00004</td><td>PENDING </td><td>     </td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.0575363</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00005</td><td>PENDING </td><td>     </td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.835263 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00006</td><td>PENDING </td><td>     </td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.656405 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00007</td><td>PENDING </td><td>     </td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.867242 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00008</td><td>PENDING </td><td>     </td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.908645 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00009</td><td>PENDING </td><td>     </td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.592168 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00010</td><td>PENDING </td><td>     </td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.96893  </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00011</td><td>PENDING </td><td>     </td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.314437 </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[2m\u001b[36m(ImplicitFunc pid=5396)\u001b[0m 2022-04-13 12:55:02,868\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=5396)\u001b[0m 2022-04-13 12:55:02,889\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(objective_fn pid=5396)\u001b[0m 2022-04-13 12:55:02,890\tINFO simple_q.py:155 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n","\u001b[2m\u001b[36m(objective_fn pid=5396)\u001b[0m 2022-04-13 12:55:02,890\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n","\u001b[2m\u001b[36m(ImplicitFunc pid=5398)\u001b[0m 2022-04-13 12:55:02,882\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=5398)\u001b[0m 2022-04-13 12:55:02,903\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(objective_fn pid=5398)\u001b[0m 2022-04-13 12:55:02,904\tINFO simple_q.py:155 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n","\u001b[2m\u001b[36m(objective_fn pid=5398)\u001b[0m 2022-04-13 12:55:02,904\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n","\u001b[2m\u001b[36m(ImplicitFunc pid=5397)\u001b[0m 2022-04-13 12:55:02,906\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=5397)\u001b[0m 2022-04-13 12:55:02,927\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(objective_fn pid=5397)\u001b[0m 2022-04-13 12:55:02,928\tINFO simple_q.py:155 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n","\u001b[2m\u001b[36m(objective_fn pid=5397)\u001b[0m 2022-04-13 12:55:02,928\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n","\u001b[2m\u001b[36m(ImplicitFunc pid=5391)\u001b[0m 2022-04-13 12:55:02,911\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=5391)\u001b[0m 2022-04-13 12:55:02,932\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(objective_fn pid=5391)\u001b[0m 2022-04-13 12:55:02,932\tINFO simple_q.py:155 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n","\u001b[2m\u001b[36m(objective_fn pid=5391)\u001b[0m 2022-04-13 12:55:02,932\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n","\u001b[2m\u001b[36m(ImplicitFunc pid=5399)\u001b[0m 2022-04-13 12:55:02,859\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=5399)\u001b[0m 2022-04-13 12:55:02,880\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(objective_fn pid=5399)\u001b[0m 2022-04-13 12:55:02,880\tINFO simple_q.py:155 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n","\u001b[2m\u001b[36m(objective_fn pid=5399)\u001b[0m 2022-04-13 12:55:02,881\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n","\u001b[2m\u001b[36m(ImplicitFunc pid=5400)\u001b[0m 2022-04-13 12:55:02,900\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=5400)\u001b[0m 2022-04-13 12:55:02,921\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(objective_fn pid=5400)\u001b[0m 2022-04-13 12:55:02,922\tINFO simple_q.py:155 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n","\u001b[2m\u001b[36m(objective_fn pid=5400)\u001b[0m 2022-04-13 12:55:02,922\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n","\u001b[2m\u001b[36m(ImplicitFunc pid=5393)\u001b[0m 2022-04-13 12:55:02,864\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=5393)\u001b[0m 2022-04-13 12:55:02,884\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(objective_fn pid=5393)\u001b[0m 2022-04-13 12:55:02,885\tINFO simple_q.py:155 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n","\u001b[2m\u001b[36m(objective_fn pid=5393)\u001b[0m 2022-04-13 12:55:02,885\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n","\u001b[2m\u001b[36m(ImplicitFunc pid=5402)\u001b[0m 2022-04-13 12:55:02,907\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=5402)\u001b[0m 2022-04-13 12:55:02,928\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(objective_fn pid=5402)\u001b[0m 2022-04-13 12:55:02,928\tINFO simple_q.py:155 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n","\u001b[2m\u001b[36m(objective_fn pid=5402)\u001b[0m 2022-04-13 12:55:02,928\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n","\u001b[2m\u001b[36m(ImplicitFunc pid=5394)\u001b[0m 2022-04-13 12:55:02,906\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=5394)\u001b[0m 2022-04-13 12:55:02,928\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(objective_fn pid=5394)\u001b[0m 2022-04-13 12:55:02,929\tINFO simple_q.py:155 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n","\u001b[2m\u001b[36m(objective_fn pid=5394)\u001b[0m 2022-04-13 12:55:02,929\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n","\u001b[2m\u001b[36m(ImplicitFunc pid=5395)\u001b[0m 2022-04-13 12:55:02,911\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=5395)\u001b[0m 2022-04-13 12:55:02,932\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(objective_fn pid=5395)\u001b[0m 2022-04-13 12:55:02,933\tINFO simple_q.py:155 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n","\u001b[2m\u001b[36m(objective_fn pid=5395)\u001b[0m 2022-04-13 12:55:02,933\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n","\u001b[2m\u001b[36m(ImplicitFunc pid=5401)\u001b[0m 2022-04-13 12:55:02,959\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=5401)\u001b[0m 2022-04-13 12:55:02,985\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(objective_fn pid=5401)\u001b[0m 2022-04-13 12:55:02,986\tINFO simple_q.py:155 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n","\u001b[2m\u001b[36m(objective_fn pid=5401)\u001b[0m 2022-04-13 12:55:02,986\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n","\u001b[2m\u001b[36m(ImplicitFunc pid=5390)\u001b[0m 2022-04-13 12:55:02,972\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=5390)\u001b[0m 2022-04-13 12:55:02,994\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(objective_fn pid=5390)\u001b[0m 2022-04-13 12:55:02,995\tINFO simple_q.py:155 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n","\u001b[2m\u001b[36m(objective_fn pid=5390)\u001b[0m 2022-04-13 12:55:02,995\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:55:03 (running for 00:00:06.12)<br>Memory usage on this node: 6.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Result logdir: /root/ray_results/HP_tuning_LunarLander<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00000</td><td>RUNNING </td><td>172.28.0.2:5401</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.920612 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00001</td><td>RUNNING </td><td>172.28.0.2:5393</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0806447</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00002</td><td>RUNNING </td><td>172.28.0.2:5396</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.263824 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00003</td><td>RUNNING </td><td>172.28.0.2:5398</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.15326  </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00004</td><td>RUNNING </td><td>172.28.0.2:5399</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.0575363</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00005</td><td>RUNNING </td><td>172.28.0.2:5400</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.835263 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00006</td><td>RUNNING </td><td>172.28.0.2:5397</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.656405 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00007</td><td>RUNNING </td><td>172.28.0.2:5402</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.867242 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00008</td><td>RUNNING </td><td>172.28.0.2:5395</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.908645 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00009</td><td>RUNNING </td><td>172.28.0.2:5391</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.592168 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00010</td><td>RUNNING </td><td>172.28.0.2:5394</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.96893  </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00011</td><td>RUNNING </td><td>172.28.0.2:5390</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.314437 </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[2m\u001b[36m(objective_fn pid=5396)\u001b[0m 2022-04-13 12:55:04,058\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=5398)\u001b[0m 2022-04-13 12:55:04,066\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=5397)\u001b[0m 2022-04-13 12:55:04,125\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=5402)\u001b[0m 2022-04-13 12:55:04,140\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=5394)\u001b[0m 2022-04-13 12:55:04,128\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=5390)\u001b[0m 2022-04-13 12:55:04,139\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=5399)\u001b[0m 2022-04-13 12:55:04,419\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=5400)\u001b[0m 2022-04-13 12:55:04,419\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=5393)\u001b[0m 2022-04-13 12:55:04,377\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=5391)\u001b[0m 2022-04-13 12:55:04,468\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=5395)\u001b[0m 2022-04-13 12:55:04,507\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(objective_fn pid=5401)\u001b[0m 2022-04-13 12:55:04,549\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n"]},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_ec25e_00002:\n","  date: 2022-04-13_12-55-06\n","  done: false\n","  experiment_id: 72e9c57841e847a189aac6fa2efac696\n","  hostname: aa9ef03c8f27\n","  iterations: 0\n","  iterations_since_restore: 1\n","  mean_reward: -192.4890648134936\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 34.86\n","    ram_util_percent: 18.4\n","  pid: 5396\n","  time_since_restore: 3.3256022930145264\n","  time_this_iter_s: 3.3256022930145264\n","  time_total_s: 3.3256022930145264\n","  timestamp: 1649854506\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: ec25e_00002\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00003:\n","  date: 2022-04-13_12-55-06\n","  done: false\n","  experiment_id: 0f6a6d8406164452905142864f7bd02d\n","  hostname: aa9ef03c8f27\n","  iterations: 0\n","  iterations_since_restore: 1\n","  mean_reward: -152.74255867612288\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 34.88\n","    ram_util_percent: 18.42\n","  pid: 5398\n","  time_since_restore: 3.320237636566162\n","  time_this_iter_s: 3.320237636566162\n","  time_total_s: 3.320237636566162\n","  timestamp: 1649854506\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: ec25e_00003\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00007:\n","  date: 2022-04-13_12-55-06\n","  done: false\n","  experiment_id: 92914c8f16e34001974a042d922d5fd3\n","  hostname: aa9ef03c8f27\n","  iterations: 0\n","  iterations_since_restore: 1\n","  mean_reward: -214.62016146784347\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 35.2\n","    ram_util_percent: 18.42\n","  pid: 5402\n","  time_since_restore: 3.350632905960083\n","  time_this_iter_s: 3.350632905960083\n","  time_total_s: 3.350632905960083\n","  timestamp: 1649854506\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: ec25e_00007\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00010:\n","  date: 2022-04-13_12-55-06\n","  done: false\n","  experiment_id: 3e293415f2e9440294c56946092bc17b\n","  hostname: aa9ef03c8f27\n","  iterations: 0\n","  iterations_since_restore: 1\n","  mean_reward: -291.62152633298524\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 35.18\n","    ram_util_percent: 18.42\n","  pid: 5394\n","  time_since_restore: 3.380631446838379\n","  time_this_iter_s: 3.380631446838379\n","  time_total_s: 3.380631446838379\n","  timestamp: 1649854506\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: ec25e_00010\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00011:\n","  date: 2022-04-13_12-55-06\n","  done: false\n","  experiment_id: 9cc718012e4e4ba1a698ca9754aa24b8\n","  hostname: aa9ef03c8f27\n","  iterations: 0\n","  iterations_since_restore: 1\n","  mean_reward: -166.35232322217132\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 35.24\n","    ram_util_percent: 18.46\n","  pid: 5390\n","  time_since_restore: 3.3274223804473877\n","  time_this_iter_s: 3.3274223804473877\n","  time_total_s: 3.3274223804473877\n","  timestamp: 1649854506\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: ec25e_00011\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00006:\n","  date: 2022-04-13_12-55-06\n","  done: false\n","  experiment_id: f30daf9f4f3041dfaeebf39f36b101ea\n","  hostname: aa9ef03c8f27\n","  iterations: 0\n","  iterations_since_restore: 1\n","  mean_reward: -219.72996487363852\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 35.14\n","    ram_util_percent: 18.42\n","  pid: 5397\n","  time_since_restore: 3.4107823371887207\n","  time_this_iter_s: 3.4107823371887207\n","  time_total_s: 3.4107823371887207\n","  timestamp: 1649854506\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: ec25e_00006\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00001:\n","  date: 2022-04-13_12-55-06\n","  done: false\n","  experiment_id: b874d28dd2e1482581a83f6d4cd7168f\n","  hostname: aa9ef03c8f27\n","  iterations: 0\n","  iterations_since_restore: 1\n","  mean_reward: -134.36912948071242\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 34.983333333333334\n","    ram_util_percent: 18.466666666666665\n","  pid: 5393\n","  time_since_restore: 3.835225820541382\n","  time_this_iter_s: 3.835225820541382\n","  time_total_s: 3.835225820541382\n","  timestamp: 1649854506\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: ec25e_00001\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00005:\n","  date: 2022-04-13_12-55-06\n","  done: false\n","  experiment_id: 67acd45ddade45d1978bd50d6cb27f11\n","  hostname: aa9ef03c8f27\n","  iterations: 0\n","  iterations_since_restore: 1\n","  mean_reward: -235.27237584980335\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 35.06666666666667\n","    ram_util_percent: 18.483333333333334\n","  pid: 5400\n","  time_since_restore: 3.857668876647949\n","  time_this_iter_s: 3.857668876647949\n","  time_total_s: 3.857668876647949\n","  timestamp: 1649854506\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: ec25e_00005\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00004:\n","  date: 2022-04-13_12-55-06\n","  done: false\n","  experiment_id: 934b9fde491146e18e1c1cb97c8ed368\n","  hostname: aa9ef03c8f27\n","  iterations: 0\n","  iterations_since_restore: 1\n","  mean_reward: -196.7729278647237\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 34.983333333333334\n","    ram_util_percent: 18.466666666666665\n","  pid: 5399\n","  time_since_restore: 3.910987377166748\n","  time_this_iter_s: 3.910987377166748\n","  time_total_s: 3.910987377166748\n","  timestamp: 1649854506\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: ec25e_00004\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00009:\n","  date: 2022-04-13_12-55-06\n","  done: false\n","  experiment_id: ffe6dbf0660146ddac1f430fa95cce4e\n","  hostname: aa9ef03c8f27\n","  iterations: 0\n","  iterations_since_restore: 1\n","  mean_reward: -184.20573455477057\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 35.1\n","    ram_util_percent: 18.483333333333334\n","  pid: 5391\n","  time_since_restore: 3.8790953159332275\n","  time_this_iter_s: 3.8790953159332275\n","  time_total_s: 3.8790953159332275\n","  timestamp: 1649854506\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: ec25e_00009\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00008:\n","  date: 2022-04-13_12-55-06\n","  done: false\n","  experiment_id: b0db4c8b61f3442786d5c67caeccc3f7\n","  hostname: aa9ef03c8f27\n","  iterations: 0\n","  iterations_since_restore: 1\n","  mean_reward: -253.91061212865606\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 35.11666666666667\n","    ram_util_percent: 18.483333333333334\n","  pid: 5395\n","  time_since_restore: 3.960922956466675\n","  time_this_iter_s: 3.960922956466675\n","  time_total_s: 3.960922956466675\n","  timestamp: 1649854506\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: ec25e_00008\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00000:\n","  date: 2022-04-13_12-55-06\n","  done: false\n","  experiment_id: 28340671e869461788073defde6cebbc\n","  hostname: aa9ef03c8f27\n","  iterations: 0\n","  iterations_since_restore: 1\n","  mean_reward: -183.80117848936143\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 35.13333333333333\n","    ram_util_percent: 18.53333333333333\n","  pid: 5401\n","  time_since_restore: 3.9528346061706543\n","  time_this_iter_s: 3.9528346061706543\n","  time_total_s: 3.9528346061706543\n","  timestamp: 1649854506\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: ec25e_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:55:08 (running for 00:00:11.31)<br>Memory usage on this node: 6.7/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: ec25e_00001 with mean_reward=-134.36912948071242 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.08064465376679564, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': False, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/HP_tuning_LunarLander<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00000</td><td>RUNNING </td><td>172.28.0.2:5401</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.920612 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.95283</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">     -183.801</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00001</td><td>RUNNING </td><td>172.28.0.2:5393</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0806447</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.83523</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">     -134.369</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00002</td><td>RUNNING </td><td>172.28.0.2:5396</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.263824 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.3256 </td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">     -192.489</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00003</td><td>RUNNING </td><td>172.28.0.2:5398</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.15326  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.32024</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">     -152.743</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00004</td><td>RUNNING </td><td>172.28.0.2:5399</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.0575363</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.91099</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">     -196.773</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00005</td><td>RUNNING </td><td>172.28.0.2:5400</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.835263 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.85767</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">     -235.272</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00006</td><td>RUNNING </td><td>172.28.0.2:5397</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.656405 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.41078</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">     -219.73 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00007</td><td>RUNNING </td><td>172.28.0.2:5402</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.867242 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.35063</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">     -214.62 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00008</td><td>RUNNING </td><td>172.28.0.2:5395</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.908645 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.96092</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">     -253.911</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00009</td><td>RUNNING </td><td>172.28.0.2:5391</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.592168 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.8791 </td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">     -184.206</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00010</td><td>RUNNING </td><td>172.28.0.2:5394</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.96893  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.38063</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">     -291.622</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00011</td><td>RUNNING </td><td>172.28.0.2:5390</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.314437 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.32742</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">     -166.352</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:55:14 (running for 00:00:16.53)<br>Memory usage on this node: 6.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: ec25e_00003 with mean_reward=-140.97158264822679 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.15326028355436094, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': False, 'hiddens': [256], 'double_q': False, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/HP_tuning_LunarLander<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00000</td><td>RUNNING </td><td>172.28.0.2:5401</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.920612 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         8.2256 </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     -148.625</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00001</td><td>RUNNING </td><td>172.28.0.2:5393</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0806447</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         8.1224 </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     -153.174</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00002</td><td>RUNNING </td><td>172.28.0.2:5396</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.263824 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         7.48114</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     -182.733</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00003</td><td>RUNNING </td><td>172.28.0.2:5398</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.15326  </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         7.52962</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     -140.972</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00004</td><td>RUNNING </td><td>172.28.0.2:5399</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.0575363</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         8.14641</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     -163.541</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00005</td><td>RUNNING </td><td>172.28.0.2:5400</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.835263 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         8.15957</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     -180.798</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00006</td><td>RUNNING </td><td>172.28.0.2:5397</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.656405 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         7.55947</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     -208.044</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00007</td><td>RUNNING </td><td>172.28.0.2:5402</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.867242 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         7.51786</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     -177.133</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00008</td><td>RUNNING </td><td>172.28.0.2:5395</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.908645 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         8.26704</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     -200.87 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00009</td><td>RUNNING </td><td>172.28.0.2:5391</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.592168 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         8.19652</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     -158.028</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00010</td><td>RUNNING </td><td>172.28.0.2:5394</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.96893  </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         7.54301</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     -200.857</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00011</td><td>RUNNING </td><td>172.28.0.2:5390</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.314437 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         7.54818</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     -173.537</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_ec25e_00002:\n","  date: 2022-04-13_12-55-14\n","  done: false\n","  experiment_id: 72e9c57841e847a189aac6fa2efac696\n","  hostname: aa9ef03c8f27\n","  iterations: 2\n","  iterations_since_restore: 3\n","  mean_reward: -169.65149233129355\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.63333333333333\n","    ram_util_percent: 19.166666666666668\n","  pid: 5396\n","  time_since_restore: 11.659717082977295\n","  time_this_iter_s: 4.178580284118652\n","  time_total_s: 11.659717082977295\n","  timestamp: 1649854514\n","  timesteps_since_restore: 0\n","  training_iteration: 3\n","  trial_id: ec25e_00002\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00007:\n","  date: 2022-04-13_12-55-14\n","  done: false\n","  experiment_id: 92914c8f16e34001974a042d922d5fd3\n","  hostname: aa9ef03c8f27\n","  iterations: 2\n","  iterations_since_restore: 3\n","  mean_reward: -151.67844876357088\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.73333333333333\n","    ram_util_percent: 19.166666666666668\n","  pid: 5402\n","  time_since_restore: 11.678598165512085\n","  time_this_iter_s: 4.160736560821533\n","  time_total_s: 11.678598165512085\n","  timestamp: 1649854514\n","  timesteps_since_restore: 0\n","  training_iteration: 3\n","  trial_id: ec25e_00007\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00006:\n","  date: 2022-04-13_12-55-14\n","  done: false\n","  experiment_id: f30daf9f4f3041dfaeebf39f36b101ea\n","  hostname: aa9ef03c8f27\n","  iterations: 2\n","  iterations_since_restore: 3\n","  mean_reward: -185.26477656815314\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.699999999999996\n","    ram_util_percent: 19.166666666666668\n","  pid: 5397\n","  time_since_restore: 11.696932077407837\n","  time_this_iter_s: 4.137458801269531\n","  time_total_s: 11.696932077407837\n","  timestamp: 1649854514\n","  timesteps_since_restore: 0\n","  training_iteration: 3\n","  trial_id: ec25e_00006\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00003:\n","  date: 2022-04-13_12-55-14\n","  done: false\n","  experiment_id: 0f6a6d8406164452905142864f7bd02d\n","  hostname: aa9ef03c8f27\n","  iterations: 2\n","  iterations_since_restore: 3\n","  mean_reward: -144.60954042340825\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.63333333333333\n","    ram_util_percent: 19.166666666666668\n","  pid: 5398\n","  time_since_restore: 11.727717399597168\n","  time_this_iter_s: 4.198094606399536\n","  time_total_s: 11.727717399597168\n","  timestamp: 1649854514\n","  timesteps_since_restore: 0\n","  training_iteration: 3\n","  trial_id: ec25e_00003\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00010:\n","  date: 2022-04-13_12-55-14\n","  done: false\n","  experiment_id: 3e293415f2e9440294c56946092bc17b\n","  hostname: aa9ef03c8f27\n","  iterations: 2\n","  iterations_since_restore: 3\n","  mean_reward: -183.30208103090968\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.68333333333334\n","    ram_util_percent: 19.166666666666668\n","  pid: 5394\n","  time_since_restore: 11.761116027832031\n","  time_this_iter_s: 4.218108892440796\n","  time_total_s: 11.761116027832031\n","  timestamp: 1649854514\n","  timesteps_since_restore: 0\n","  training_iteration: 3\n","  trial_id: ec25e_00010\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00011:\n","  date: 2022-04-13_12-55-14\n","  done: false\n","  experiment_id: 9cc718012e4e4ba1a698ca9754aa24b8\n","  hostname: aa9ef03c8f27\n","  iterations: 2\n","  iterations_since_restore: 3\n","  mean_reward: -163.9871118405668\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.73333333333333\n","    ram_util_percent: 19.166666666666668\n","  pid: 5390\n","  time_since_restore: 11.758651494979858\n","  time_this_iter_s: 4.2104692459106445\n","  time_total_s: 11.758651494979858\n","  timestamp: 1649854514\n","  timesteps_since_restore: 0\n","  training_iteration: 3\n","  trial_id: ec25e_00011\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00004:\n","  date: 2022-04-13_12-55-15\n","  done: false\n","  experiment_id: 934b9fde491146e18e1c1cb97c8ed368\n","  hostname: aa9ef03c8f27\n","  iterations: 2\n","  iterations_since_restore: 3\n","  mean_reward: -155.34851167402485\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.73333333333333\n","    ram_util_percent: 19.2\n","  pid: 5399\n","  time_since_restore: 12.39995265007019\n","  time_this_iter_s: 4.253543138504028\n","  time_total_s: 12.39995265007019\n","  timestamp: 1649854515\n","  timesteps_since_restore: 0\n","  training_iteration: 3\n","  trial_id: ec25e_00004\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00001:\n","  date: 2022-04-13_12-55-15\n","  done: false\n","  experiment_id: b874d28dd2e1482581a83f6d4cd7168f\n","  hostname: aa9ef03c8f27\n","  iterations: 2\n","  iterations_since_restore: 3\n","  mean_reward: -148.61734609761817\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.76666666666667\n","    ram_util_percent: 19.2\n","  pid: 5393\n","  time_since_restore: 12.436275959014893\n","  time_this_iter_s: 4.313876152038574\n","  time_total_s: 12.436275959014893\n","  timestamp: 1649854515\n","  timesteps_since_restore: 0\n","  training_iteration: 3\n","  trial_id: ec25e_00001\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00005:\n","  date: 2022-04-13_12-55-15\n","  done: false\n","  experiment_id: 67acd45ddade45d1978bd50d6cb27f11\n","  hostname: aa9ef03c8f27\n","  iterations: 2\n","  iterations_since_restore: 3\n","  mean_reward: -175.51526635924913\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.71666666666667\n","    ram_util_percent: 19.2\n","  pid: 5400\n","  time_since_restore: 12.454155206680298\n","  time_this_iter_s: 4.294583320617676\n","  time_total_s: 12.454155206680298\n","  timestamp: 1649854515\n","  timesteps_since_restore: 0\n","  training_iteration: 3\n","  trial_id: ec25e_00005\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00009:\n","  date: 2022-04-13_12-55-15\n","  done: false\n","  experiment_id: ffe6dbf0660146ddac1f430fa95cce4e\n","  hostname: aa9ef03c8f27\n","  iterations: 2\n","  iterations_since_restore: 3\n","  mean_reward: -154.10260909089527\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.75\n","    ram_util_percent: 19.2\n","  pid: 5391\n","  time_since_restore: 12.45570182800293\n","  time_this_iter_s: 4.2591845989227295\n","  time_total_s: 12.45570182800293\n","  timestamp: 1649854515\n","  timesteps_since_restore: 0\n","  training_iteration: 3\n","  trial_id: ec25e_00009\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00008:\n","  date: 2022-04-13_12-55-15\n","  done: false\n","  experiment_id: b0db4c8b61f3442786d5c67caeccc3f7\n","  hostname: aa9ef03c8f27\n","  iterations: 2\n","  iterations_since_restore: 3\n","  mean_reward: -185.24053734239408\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.73333333333334\n","    ram_util_percent: 19.2\n","  pid: 5395\n","  time_since_restore: 12.554059267044067\n","  time_this_iter_s: 4.287020921707153\n","  time_total_s: 12.554059267044067\n","  timestamp: 1649854515\n","  timesteps_since_restore: 0\n","  training_iteration: 3\n","  trial_id: ec25e_00008\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00000:\n","  date: 2022-04-13_12-55-15\n","  done: false\n","  experiment_id: 28340671e869461788073defde6cebbc\n","  hostname: aa9ef03c8f27\n","  iterations: 2\n","  iterations_since_restore: 3\n","  mean_reward: -143.01725018495034\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.76666666666667\n","    ram_util_percent: 19.2\n","  pid: 5401\n","  time_since_restore: 12.508417844772339\n","  time_this_iter_s: 4.28281569480896\n","  time_total_s: 12.508417844772339\n","  timestamp: 1649854515\n","  timesteps_since_restore: 0\n","  training_iteration: 3\n","  trial_id: ec25e_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:55:19 (running for 00:00:21.85)<br>Memory usage on this node: 6.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: ec25e_00000 with mean_reward=-143.01725018495034 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.9206117943788054, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/HP_tuning_LunarLander<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00000</td><td>RUNNING </td><td>172.28.0.2:5401</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.920612 </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         12.5084</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     -143.017</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00001</td><td>RUNNING </td><td>172.28.0.2:5393</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0806447</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         12.4363</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     -148.617</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00002</td><td>RUNNING </td><td>172.28.0.2:5396</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.263824 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         15.8053</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">     -163.475</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00003</td><td>RUNNING </td><td>172.28.0.2:5398</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.15326  </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         15.9568</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">     -146.213</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00004</td><td>RUNNING </td><td>172.28.0.2:5399</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.0575363</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         16.6521</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">     -148.319</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00005</td><td>RUNNING </td><td>172.28.0.2:5400</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.835263 </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         12.4542</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     -175.515</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00006</td><td>RUNNING </td><td>172.28.0.2:5397</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.656405 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         15.8463</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">     -168.125</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00007</td><td>RUNNING </td><td>172.28.0.2:5402</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.867242 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         15.8685</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">     -149.513</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00008</td><td>RUNNING </td><td>172.28.0.2:5395</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.908645 </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         12.5541</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     -185.241</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00009</td><td>RUNNING </td><td>172.28.0.2:5391</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.592168 </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         12.4557</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     -154.103</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00010</td><td>RUNNING </td><td>172.28.0.2:5394</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.96893  </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         15.945 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">     -169.077</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00011</td><td>RUNNING </td><td>172.28.0.2:5390</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.314437 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         16.0029</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">     -153.513</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_ec25e_00002:\n","  date: 2022-04-13_12-55-22\n","  done: false\n","  experiment_id: 72e9c57841e847a189aac6fa2efac696\n","  hostname: aa9ef03c8f27\n","  iterations: 4\n","  iterations_since_restore: 5\n","  mean_reward: -155.375747275981\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.6\n","    ram_util_percent: 19.36666666666667\n","  pid: 5396\n","  time_since_restore: 19.977721452713013\n","  time_this_iter_s: 4.172437906265259\n","  time_total_s: 19.977721452713013\n","  timestamp: 1649854522\n","  timesteps_since_restore: 0\n","  training_iteration: 5\n","  trial_id: ec25e_00002\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00006:\n","  date: 2022-04-13_12-55-22\n","  done: false\n","  experiment_id: f30daf9f4f3041dfaeebf39f36b101ea\n","  hostname: aa9ef03c8f27\n","  iterations: 4\n","  iterations_since_restore: 5\n","  mean_reward: -150.3750735246665\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.699999999999996\n","    ram_util_percent: 19.36666666666667\n","  pid: 5397\n","  time_since_restore: 20.05396604537964\n","  time_this_iter_s: 4.20766544342041\n","  time_total_s: 20.05396604537964\n","  timestamp: 1649854522\n","  timesteps_since_restore: 0\n","  training_iteration: 5\n","  trial_id: ec25e_00006\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00010:\n","  date: 2022-04-13_12-55-23\n","  done: false\n","  experiment_id: 3e293415f2e9440294c56946092bc17b\n","  hostname: aa9ef03c8f27\n","  iterations: 4\n","  iterations_since_restore: 5\n","  mean_reward: -153.24988379910738\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.71666666666666\n","    ram_util_percent: 19.36666666666667\n","  pid: 5394\n","  time_since_restore: 20.15247130393982\n","  time_this_iter_s: 4.20749044418335\n","  time_total_s: 20.15247130393982\n","  timestamp: 1649854523\n","  timesteps_since_restore: 0\n","  training_iteration: 5\n","  trial_id: ec25e_00010\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00007:\n","  date: 2022-04-13_12-55-23\n","  done: false\n","  experiment_id: 92914c8f16e34001974a042d922d5fd3\n","  hostname: aa9ef03c8f27\n","  iterations: 4\n","  iterations_since_restore: 5\n","  mean_reward: -137.63683657510916\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.666666666666664\n","    ram_util_percent: 19.36666666666667\n","  pid: 5402\n","  time_since_restore: 20.17758297920227\n","  time_this_iter_s: 4.309091329574585\n","  time_total_s: 20.17758297920227\n","  timestamp: 1649854523\n","  timesteps_since_restore: 0\n","  training_iteration: 5\n","  trial_id: ec25e_00007\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00003:\n","  date: 2022-04-13_12-55-23\n","  done: false\n","  experiment_id: 0f6a6d8406164452905142864f7bd02d\n","  hostname: aa9ef03c8f27\n","  iterations: 4\n","  iterations_since_restore: 5\n","  mean_reward: -141.0649676544556\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.516666666666666\n","    ram_util_percent: 19.36666666666667\n","  pid: 5398\n","  time_since_restore: 20.235174417495728\n","  time_this_iter_s: 4.278390645980835\n","  time_total_s: 20.235174417495728\n","  timestamp: 1649854523\n","  timesteps_since_restore: 0\n","  training_iteration: 5\n","  trial_id: ec25e_00003\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00011:\n","  date: 2022-04-13_12-55-23\n","  done: false\n","  experiment_id: 9cc718012e4e4ba1a698ca9754aa24b8\n","  hostname: aa9ef03c8f27\n","  iterations: 4\n","  iterations_since_restore: 5\n","  mean_reward: -148.33623063492408\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.72857142857142\n","    ram_util_percent: 19.400000000000002\n","  pid: 5390\n","  time_since_restore: 20.523802280426025\n","  time_this_iter_s: 4.5208635330200195\n","  time_total_s: 20.523802280426025\n","  timestamp: 1649854523\n","  timesteps_since_restore: 0\n","  training_iteration: 5\n","  trial_id: ec25e_00011\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00004:\n","  date: 2022-04-13_12-55-23\n","  done: false\n","  experiment_id: 934b9fde491146e18e1c1cb97c8ed368\n","  hostname: aa9ef03c8f27\n","  iterations: 4\n","  iterations_since_restore: 5\n","  mean_reward: -147.95342374971827\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.6\n","    ram_util_percent: 19.400000000000002\n","  pid: 5399\n","  time_since_restore: 20.951485633850098\n","  time_this_iter_s: 4.299357175827026\n","  time_total_s: 20.951485633850098\n","  timestamp: 1649854523\n","  timesteps_since_restore: 0\n","  training_iteration: 5\n","  trial_id: ec25e_00004\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00001:\n","  date: 2022-04-13_12-55-23\n","  done: false\n","  experiment_id: b874d28dd2e1482581a83f6d4cd7168f\n","  hostname: aa9ef03c8f27\n","  iterations: 4\n","  iterations_since_restore: 5\n","  mean_reward: -141.7581998685584\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.55\n","    ram_util_percent: 19.400000000000002\n","  pid: 5393\n","  time_since_restore: 21.044149160385132\n","  time_this_iter_s: 4.340317964553833\n","  time_total_s: 21.044149160385132\n","  timestamp: 1649854523\n","  timesteps_since_restore: 0\n","  training_iteration: 5\n","  trial_id: ec25e_00001\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00009:\n","  date: 2022-04-13_12-55-23\n","  done: false\n","  experiment_id: ffe6dbf0660146ddac1f430fa95cce4e\n","  hostname: aa9ef03c8f27\n","  iterations: 4\n","  iterations_since_restore: 5\n","  mean_reward: -137.9638547128798\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.63333333333333\n","    ram_util_percent: 19.400000000000002\n","  pid: 5391\n","  time_since_restore: 21.028398275375366\n","  time_this_iter_s: 4.283315181732178\n","  time_total_s: 21.028398275375366\n","  timestamp: 1649854523\n","  timesteps_since_restore: 0\n","  training_iteration: 5\n","  trial_id: ec25e_00009\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00005:\n","  date: 2022-04-13_12-55-23\n","  done: false\n","  experiment_id: 67acd45ddade45d1978bd50d6cb27f11\n","  hostname: aa9ef03c8f27\n","  iterations: 4\n","  iterations_since_restore: 5\n","  mean_reward: -148.20796435936762\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.63333333333333\n","    ram_util_percent: 19.400000000000002\n","  pid: 5400\n","  time_since_restore: 21.06031894683838\n","  time_this_iter_s: 4.327640056610107\n","  time_total_s: 21.06031894683838\n","  timestamp: 1649854523\n","  timesteps_since_restore: 0\n","  training_iteration: 5\n","  trial_id: ec25e_00005\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00000:\n","  date: 2022-04-13_12-55-24\n","  done: false\n","  experiment_id: 28340671e869461788073defde6cebbc\n","  hostname: aa9ef03c8f27\n","  iterations: 4\n","  iterations_since_restore: 5\n","  mean_reward: -129.9259122917414\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.650000000000006\n","    ram_util_percent: 19.416666666666668\n","  pid: 5401\n","  time_since_restore: 21.058560848236084\n","  time_this_iter_s: 4.275158405303955\n","  time_total_s: 21.058560848236084\n","  timestamp: 1649854524\n","  timesteps_since_restore: 0\n","  training_iteration: 5\n","  trial_id: ec25e_00000\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00008:\n","  date: 2022-04-13_12-55-24\n","  done: false\n","  experiment_id: b0db4c8b61f3442786d5c67caeccc3f7\n","  hostname: aa9ef03c8f27\n","  iterations: 4\n","  iterations_since_restore: 5\n","  mean_reward: -165.3320001130438\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 42.53333333333333\n","    ram_util_percent: 19.433333333333334\n","  pid: 5395\n","  time_since_restore: 21.278341054916382\n","  time_this_iter_s: 4.412222146987915\n","  time_total_s: 21.278341054916382\n","  timestamp: 1649854524\n","  timesteps_since_restore: 0\n","  training_iteration: 5\n","  trial_id: ec25e_00008\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:55:25 (running for 00:00:27.54)<br>Memory usage on this node: 6.9/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: ec25e_00000 with mean_reward=-129.9259122917414 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.9206117943788054, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/HP_tuning_LunarLander<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00000</td><td>RUNNING </td><td>172.28.0.2:5401</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.920612 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         21.0586</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">     -129.926</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00001</td><td>RUNNING </td><td>172.28.0.2:5393</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0806447</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         21.0441</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">     -141.758</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00002</td><td>RUNNING </td><td>172.28.0.2:5396</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.263824 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         19.9777</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">     -155.376</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00003</td><td>RUNNING </td><td>172.28.0.2:5398</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.15326  </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         20.2352</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">     -141.065</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00004</td><td>RUNNING </td><td>172.28.0.2:5399</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.0575363</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         20.9515</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">     -147.953</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00005</td><td>RUNNING </td><td>172.28.0.2:5400</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.835263 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         21.0603</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">     -148.208</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00006</td><td>RUNNING </td><td>172.28.0.2:5397</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.656405 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         20.054 </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">     -150.375</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00007</td><td>RUNNING </td><td>172.28.0.2:5402</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.867242 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         20.1776</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">     -137.637</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00008</td><td>RUNNING </td><td>172.28.0.2:5395</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.908645 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         21.2783</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">     -165.332</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00009</td><td>RUNNING </td><td>172.28.0.2:5391</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.592168 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         21.0284</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">     -137.964</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00010</td><td>RUNNING </td><td>172.28.0.2:5394</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.96893  </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         20.1525</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">     -153.25 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00011</td><td>RUNNING </td><td>172.28.0.2:5390</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.314437 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         20.5238</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">     -148.336</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:55:30 (running for 00:00:33.22)<br>Memory usage on this node: 6.9/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: ec25e_00000 with mean_reward=-121.62701598285592 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.9206117943788054, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/HP_tuning_LunarLander<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00000</td><td>RUNNING </td><td>172.28.0.2:5401</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.920612 </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         25.8318</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">     -121.627</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00001</td><td>RUNNING </td><td>172.28.0.2:5393</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0806447</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         25.5678</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">     -143.748</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00002</td><td>RUNNING </td><td>172.28.0.2:5396</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.263824 </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         24.1709</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">     -144.13 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00003</td><td>RUNNING </td><td>172.28.0.2:5398</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.15326  </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         24.7656</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">     -137.059</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00004</td><td>RUNNING </td><td>172.28.0.2:5399</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.0575363</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         25.6438</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">     -152.087</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00005</td><td>RUNNING </td><td>172.28.0.2:5400</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.835263 </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         25.7828</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">     -143.149</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00006</td><td>RUNNING </td><td>172.28.0.2:5397</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.656405 </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         24.5293</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">     -151.316</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00007</td><td>RUNNING </td><td>172.28.0.2:5402</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.867242 </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         25.1362</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">     -134.708</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00008</td><td>RUNNING </td><td>172.28.0.2:5395</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.908645 </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         25.9637</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">     -159.804</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00009</td><td>RUNNING </td><td>172.28.0.2:5391</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.592168 </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         25.5586</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">     -127.73 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00010</td><td>RUNNING </td><td>172.28.0.2:5394</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.96893  </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         24.4056</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">     -148.759</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00011</td><td>RUNNING </td><td>172.28.0.2:5390</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.314437 </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         25.5061</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">     -143.952</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_ec25e_00002:\n","  date: 2022-04-13_12-55-31\n","  done: false\n","  experiment_id: 72e9c57841e847a189aac6fa2efac696\n","  hostname: aa9ef03c8f27\n","  iterations: 6\n","  iterations_since_restore: 7\n","  mean_reward: -139.91308322699493\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.9\n","    ram_util_percent: 19.583333333333332\n","  pid: 5396\n","  time_since_restore: 28.589675188064575\n","  time_this_iter_s: 4.41878342628479\n","  time_total_s: 28.589675188064575\n","  timestamp: 1649854531\n","  timesteps_since_restore: 0\n","  training_iteration: 7\n","  trial_id: ec25e_00002\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00006:\n","  date: 2022-04-13_12-55-31\n","  done: false\n","  experiment_id: f30daf9f4f3041dfaeebf39f36b101ea\n","  hostname: aa9ef03c8f27\n","  iterations: 6\n","  iterations_since_restore: 7\n","  mean_reward: -149.41868252673405\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.82857142857143\n","    ram_util_percent: 19.585714285714285\n","  pid: 5397\n","  time_since_restore: 29.077231645584106\n","  time_this_iter_s: 4.547889947891235\n","  time_total_s: 29.077231645584106\n","  timestamp: 1649854531\n","  timesteps_since_restore: 0\n","  training_iteration: 7\n","  trial_id: ec25e_00006\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00010:\n","  date: 2022-04-13_12-55-32\n","  done: false\n","  experiment_id: 3e293415f2e9440294c56946092bc17b\n","  hostname: aa9ef03c8f27\n","  iterations: 6\n","  iterations_since_restore: 7\n","  mean_reward: -146.5945998143424\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.75714285714286\n","    ram_util_percent: 19.585714285714285\n","  pid: 5394\n","  time_since_restore: 29.17916703224182\n","  time_this_iter_s: 4.773577928543091\n","  time_total_s: 29.17916703224182\n","  timestamp: 1649854532\n","  timesteps_since_restore: 0\n","  training_iteration: 7\n","  trial_id: ec25e_00010\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00003:\n","  date: 2022-04-13_12-55-32\n","  done: false\n","  experiment_id: 0f6a6d8406164452905142864f7bd02d\n","  hostname: aa9ef03c8f27\n","  iterations: 6\n","  iterations_since_restore: 7\n","  mean_reward: -135.56337100319547\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.0\n","    ram_util_percent: 19.61428571428571\n","  pid: 5398\n","  time_since_restore: 29.62997817993164\n","  time_this_iter_s: 4.864422082901001\n","  time_total_s: 29.62997817993164\n","  timestamp: 1649854532\n","  timesteps_since_restore: 0\n","  training_iteration: 7\n","  trial_id: ec25e_00003\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00001:\n","  date: 2022-04-13_12-55-32\n","  done: false\n","  experiment_id: b874d28dd2e1482581a83f6d4cd7168f\n","  hostname: aa9ef03c8f27\n","  iterations: 6\n","  iterations_since_restore: 7\n","  mean_reward: -150.1873932173548\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.11666666666667\n","    ram_util_percent: 19.616666666666667\n","  pid: 5393\n","  time_since_restore: 29.90601348876953\n","  time_this_iter_s: 4.3382487297058105\n","  time_total_s: 29.90601348876953\n","  timestamp: 1649854532\n","  timesteps_since_restore: 0\n","  training_iteration: 7\n","  trial_id: ec25e_00001\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00004:\n","  date: 2022-04-13_12-55-32\n","  done: false\n","  experiment_id: 934b9fde491146e18e1c1cb97c8ed368\n","  hostname: aa9ef03c8f27\n","  iterations: 6\n","  iterations_since_restore: 7\n","  mean_reward: -151.70456482401883\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.199999999999996\n","    ram_util_percent: 19.616666666666667\n","  pid: 5399\n","  time_since_restore: 29.93228793144226\n","  time_this_iter_s: 4.288491487503052\n","  time_total_s: 29.93228793144226\n","  timestamp: 1649854532\n","  timesteps_since_restore: 0\n","  training_iteration: 7\n","  trial_id: ec25e_00004\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00008:\n","  date: 2022-04-13_12-55-33\n","  done: false\n","  experiment_id: b0db4c8b61f3442786d5c67caeccc3f7\n","  hostname: aa9ef03c8f27\n","  iterations: 6\n","  iterations_since_restore: 7\n","  mean_reward: -154.11700241837053\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.15714285714285\n","    ram_util_percent: 19.62857142857143\n","  pid: 5395\n","  time_since_restore: 30.437426805496216\n","  time_this_iter_s: 4.473696947097778\n","  time_total_s: 30.437426805496216\n","  timestamp: 1649854533\n","  timesteps_since_restore: 0\n","  training_iteration: 7\n","  trial_id: ec25e_00008\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00009:\n","  date: 2022-04-13_12-55-33\n","  done: false\n","  experiment_id: ffe6dbf0660146ddac1f430fa95cce4e\n","  hostname: aa9ef03c8f27\n","  iterations: 6\n","  iterations_since_restore: 7\n","  mean_reward: -129.44628376335217\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.142857142857146\n","    ram_util_percent: 19.62857142857143\n","  pid: 5391\n","  time_since_restore: 30.727335929870605\n","  time_this_iter_s: 5.1686999797821045\n","  time_total_s: 30.727335929870605\n","  timestamp: 1649854533\n","  timesteps_since_restore: 0\n","  training_iteration: 7\n","  trial_id: ec25e_00009\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00011:\n","  date: 2022-04-13_12-55-34\n","  done: false\n","  experiment_id: 9cc718012e4e4ba1a698ca9754aa24b8\n","  hostname: aa9ef03c8f27\n","  iterations: 6\n","  iterations_since_restore: 7\n","  mean_reward: -143.5323850136222\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.9875\n","    ram_util_percent: 19.6375\n","  pid: 5390\n","  time_since_restore: 31.08322024345398\n","  time_this_iter_s: 5.577090263366699\n","  time_total_s: 31.08322024345398\n","  timestamp: 1649854534\n","  timesteps_since_restore: 0\n","  training_iteration: 7\n","  trial_id: ec25e_00011\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00000:\n","  date: 2022-04-13_12-55-34\n","  done: false\n","  experiment_id: 28340671e869461788073defde6cebbc\n","  hostname: aa9ef03c8f27\n","  iterations: 6\n","  iterations_since_restore: 7\n","  mean_reward: -119.29134632078963\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.1875\n","    ram_util_percent: 19.6375\n","  pid: 5401\n","  time_since_restore: 31.139798879623413\n","  time_this_iter_s: 5.3079516887664795\n","  time_total_s: 31.139798879623413\n","  timestamp: 1649854534\n","  timesteps_since_restore: 0\n","  training_iteration: 7\n","  trial_id: ec25e_00000\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00007:\n","  date: 2022-04-13_12-55-34\n","  done: false\n","  experiment_id: 92914c8f16e34001974a042d922d5fd3\n","  hostname: aa9ef03c8f27\n","  iterations: 6\n","  iterations_since_restore: 7\n","  mean_reward: -127.51911279310517\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.01111111111111\n","    ram_util_percent: 19.633333333333333\n","  pid: 5402\n","  time_since_restore: 31.248961925506592\n","  time_this_iter_s: 6.112756252288818\n","  time_total_s: 31.248961925506592\n","  timestamp: 1649854534\n","  timesteps_since_restore: 0\n","  training_iteration: 7\n","  trial_id: ec25e_00007\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00005:\n","  date: 2022-04-13_12-55-34\n","  done: false\n","  experiment_id: 67acd45ddade45d1978bd50d6cb27f11\n","  hostname: aa9ef03c8f27\n","  iterations: 6\n","  iterations_since_restore: 7\n","  mean_reward: -145.51042544255958\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 41.075\n","    ram_util_percent: 19.6375\n","  pid: 5400\n","  time_since_restore: 31.371974229812622\n","  time_this_iter_s: 5.589138746261597\n","  time_total_s: 31.371974229812622\n","  timestamp: 1649854534\n","  timesteps_since_restore: 0\n","  training_iteration: 7\n","  trial_id: ec25e_00005\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:55:36 (running for 00:00:38.79)<br>Memory usage on this node: 7.0/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: ec25e_00000 with mean_reward=-119.29134632078963 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.9206117943788054, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/HP_tuning_LunarLander<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00000</td><td>RUNNING </td><td>172.28.0.2:5401</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.920612 </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         31.1398</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">     -119.291</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00001</td><td>RUNNING </td><td>172.28.0.2:5393</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0806447</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         29.906 </td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">     -150.187</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00002</td><td>RUNNING </td><td>172.28.0.2:5396</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.263824 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         32.9196</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">     -141.975</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00003</td><td>RUNNING </td><td>172.28.0.2:5398</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.15326  </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         29.63  </td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">     -135.563</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00004</td><td>RUNNING </td><td>172.28.0.2:5399</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.0575363</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         29.9323</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">     -151.705</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00005</td><td>RUNNING </td><td>172.28.0.2:5400</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.835263 </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         31.372 </td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">     -145.51 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00006</td><td>RUNNING </td><td>172.28.0.2:5397</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.656405 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         33.5411</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">     -155.645</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00007</td><td>RUNNING </td><td>172.28.0.2:5402</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.867242 </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         31.249 </td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">     -127.519</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00008</td><td>RUNNING </td><td>172.28.0.2:5395</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.908645 </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         30.4374</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">     -154.117</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00009</td><td>RUNNING </td><td>172.28.0.2:5391</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.592168 </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         30.7273</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">     -129.446</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00010</td><td>RUNNING </td><td>172.28.0.2:5394</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.96893  </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         29.1792</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">     -146.595</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00011</td><td>RUNNING </td><td>172.28.0.2:5390</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.314437 </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         31.0832</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">     -143.532</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_ec25e_00010:\n","  date: 2022-04-13_12-55-37\n","  done: false\n","  experiment_id: 3e293415f2e9440294c56946092bc17b\n","  hostname: aa9ef03c8f27\n","  iterations: 7\n","  iterations_since_restore: 8\n","  mean_reward: -146.18443343575382\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.9875\n","    ram_util_percent: 19.7125\n","  pid: 5394\n","  time_since_restore: 34.54517912864685\n","  time_this_iter_s: 5.366012096405029\n","  time_total_s: 34.54517912864685\n","  timestamp: 1649854537\n","  timesteps_since_restore: 0\n","  training_iteration: 8\n","  trial_id: ec25e_00010\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00008:\n","  date: 2022-04-13_12-55-39\n","  done: false\n","  experiment_id: b0db4c8b61f3442786d5c67caeccc3f7\n","  hostname: aa9ef03c8f27\n","  iterations: 7\n","  iterations_since_restore: 8\n","  mean_reward: -152.85357210040164\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.91111111111112\n","    ram_util_percent: 19.744444444444444\n","  pid: 5395\n","  time_since_restore: 36.64423680305481\n","  time_this_iter_s: 6.206809997558594\n","  time_total_s: 36.64423680305481\n","  timestamp: 1649854539\n","  timesteps_since_restore: 0\n","  training_iteration: 8\n","  trial_id: ec25e_00008\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00000:\n","  date: 2022-04-13_12-55-39\n","  done: false\n","  experiment_id: 28340671e869461788073defde6cebbc\n","  hostname: aa9ef03c8f27\n","  iterations: 7\n","  iterations_since_restore: 8\n","  mean_reward: -119.11020701037121\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.8375\n","    ram_util_percent: 19.75\n","  pid: 5401\n","  time_since_restore: 36.79022192955017\n","  time_this_iter_s: 5.650423049926758\n","  time_total_s: 36.79022192955017\n","  timestamp: 1649854539\n","  timesteps_since_restore: 0\n","  training_iteration: 8\n","  trial_id: ec25e_00000\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00007:\n","  date: 2022-04-13_12-55-39\n","  done: false\n","  experiment_id: 92914c8f16e34001974a042d922d5fd3\n","  hostname: aa9ef03c8f27\n","  iterations: 7\n","  iterations_since_restore: 8\n","  mean_reward: -128.669492079147\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.787499999999994\n","    ram_util_percent: 19.75\n","  pid: 5402\n","  time_since_restore: 36.962270736694336\n","  time_this_iter_s: 5.713308811187744\n","  time_total_s: 36.962270736694336\n","  timestamp: 1649854539\n","  timesteps_since_restore: 0\n","  training_iteration: 8\n","  trial_id: ec25e_00007\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00002:\n","  date: 2022-04-13_12-55-40\n","  done: false\n","  experiment_id: 72e9c57841e847a189aac6fa2efac696\n","  hostname: aa9ef03c8f27\n","  iterations: 8\n","  iterations_since_restore: 9\n","  mean_reward: -143.69522379869588\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.82857142857142\n","    ram_util_percent: 19.771428571428572\n","  pid: 5396\n","  time_since_restore: 37.59855580329895\n","  time_this_iter_s: 4.678966522216797\n","  time_total_s: 37.59855580329895\n","  timestamp: 1649854540\n","  timesteps_since_restore: 0\n","  training_iteration: 9\n","  trial_id: ec25e_00002\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00006:\n","  date: 2022-04-13_12-55-41\n","  done: false\n","  experiment_id: f30daf9f4f3041dfaeebf39f36b101ea\n","  hostname: aa9ef03c8f27\n","  iterations: 8\n","  iterations_since_restore: 9\n","  mean_reward: -155.85653760663374\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.81428571428571\n","    ram_util_percent: 19.785714285714285\n","  pid: 5397\n","  time_since_restore: 38.31972002983093\n","  time_this_iter_s: 4.7786335945129395\n","  time_total_s: 38.31972002983093\n","  timestamp: 1649854541\n","  timesteps_since_restore: 0\n","  training_iteration: 9\n","  trial_id: ec25e_00006\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00001:\n","  date: 2022-04-13_12-55-41\n","  done: false\n","  experiment_id: b874d28dd2e1482581a83f6d4cd7168f\n","  hostname: aa9ef03c8f27\n","  iterations: 8\n","  iterations_since_restore: 9\n","  mean_reward: -158.08288500785144\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.91666666666667\n","    ram_util_percent: 19.8\n","  pid: 5393\n","  time_since_restore: 38.80372500419617\n","  time_this_iter_s: 4.4948813915252686\n","  time_total_s: 38.80372500419617\n","  timestamp: 1649854541\n","  timesteps_since_restore: 0\n","  training_iteration: 9\n","  trial_id: ec25e_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:55:41 (running for 00:00:44.01)<br>Memory usage on this node: 7.0/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: ec25e_00000 with mean_reward=-119.11020701037121 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.9206117943788054, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/HP_tuning_LunarLander<br>Number of trials: 12/12 (12 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00000</td><td>RUNNING </td><td>172.28.0.2:5401</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.920612 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         36.7902</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">     -119.11 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00001</td><td>RUNNING </td><td>172.28.0.2:5393</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0806447</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         38.8037</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     -158.083</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00002</td><td>RUNNING </td><td>172.28.0.2:5396</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.263824 </td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         37.5986</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     -143.695</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00003</td><td>RUNNING </td><td>172.28.0.2:5398</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.15326  </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         34.279 </td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">     -130.48 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00004</td><td>RUNNING </td><td>172.28.0.2:5399</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.0575363</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         34.5601</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">     -147.929</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00005</td><td>RUNNING </td><td>172.28.0.2:5400</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.835263 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         36.0923</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">     -153.294</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00006</td><td>RUNNING </td><td>172.28.0.2:5397</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.656405 </td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         38.3197</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     -155.857</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00007</td><td>RUNNING </td><td>172.28.0.2:5402</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.867242 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         36.9623</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">     -128.669</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00008</td><td>RUNNING </td><td>172.28.0.2:5395</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.908645 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         36.6442</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">     -152.854</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00009</td><td>RUNNING </td><td>172.28.0.2:5391</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.592168 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         35.5278</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">     -131.424</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00010</td><td>RUNNING </td><td>172.28.0.2:5394</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.96893  </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         34.5452</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">     -146.184</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00011</td><td>RUNNING </td><td>172.28.0.2:5390</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.314437 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         35.6591</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">     -142.5  </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_ec25e_00003:\n","  date: 2022-04-13_12-55-41\n","  done: false\n","  experiment_id: 0f6a6d8406164452905142864f7bd02d\n","  hostname: aa9ef03c8f27\n","  iterations: 8\n","  iterations_since_restore: 9\n","  mean_reward: -141.71098219400798\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.699999999999996\n","    ram_util_percent: 19.814285714285713\n","  pid: 5398\n","  time_since_restore: 38.79541873931885\n","  time_this_iter_s: 4.5164475440979\n","  time_total_s: 38.79541873931885\n","  timestamp: 1649854541\n","  timesteps_since_restore: 0\n","  training_iteration: 9\n","  trial_id: ec25e_00003\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00004:\n","  date: 2022-04-13_12-55-41\n","  done: false\n","  experiment_id: 934b9fde491146e18e1c1cb97c8ed368\n","  hostname: aa9ef03c8f27\n","  iterations: 8\n","  iterations_since_restore: 9\n","  mean_reward: -149.8924945501053\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.81666666666667\n","    ram_util_percent: 19.816666666666666\n","  pid: 5399\n","  time_since_restore: 38.85782027244568\n","  time_this_iter_s: 4.29767370223999\n","  time_total_s: 38.85782027244568\n","  timestamp: 1649854541\n","  timesteps_since_restore: 0\n","  training_iteration: 9\n","  trial_id: ec25e_00004\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00009:\n","  date: 2022-04-13_12-55-42\n","  done: false\n","  experiment_id: ffe6dbf0660146ddac1f430fa95cce4e\n","  hostname: aa9ef03c8f27\n","  iterations: 8\n","  iterations_since_restore: 9\n","  mean_reward: -134.68657583024407\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.81666666666666\n","    ram_util_percent: 19.816666666666666\n","  pid: 5391\n","  time_since_restore: 40.02408695220947\n","  time_this_iter_s: 4.496320009231567\n","  time_total_s: 40.02408695220947\n","  timestamp: 1649854542\n","  timesteps_since_restore: 0\n","  training_iteration: 9\n","  trial_id: ec25e_00009\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00011:\n","  date: 2022-04-13_12-55-43\n","  done: false\n","  experiment_id: 9cc718012e4e4ba1a698ca9754aa24b8\n","  hostname: aa9ef03c8f27\n","  iterations: 8\n","  iterations_since_restore: 9\n","  mean_reward: -137.388312107287\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.51666666666667\n","    ram_util_percent: 19.833333333333332\n","  pid: 5390\n","  time_since_restore: 40.189565658569336\n","  time_this_iter_s: 4.530444145202637\n","  time_total_s: 40.189565658569336\n","  timestamp: 1649854543\n","  timesteps_since_restore: 0\n","  training_iteration: 9\n","  trial_id: ec25e_00011\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00010:\n","  date: 2022-04-13_12-55-43\n","  done: false\n","  experiment_id: 3e293415f2e9440294c56946092bc17b\n","  hostname: aa9ef03c8f27\n","  iterations: 8\n","  iterations_since_restore: 9\n","  mean_reward: -144.1971390900923\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.400000000000006\n","    ram_util_percent: 19.825000000000003\n","  pid: 5394\n","  time_since_restore: 40.370827198028564\n","  time_this_iter_s: 5.825648069381714\n","  time_total_s: 40.370827198028564\n","  timestamp: 1649854543\n","  timesteps_since_restore: 0\n","  training_iteration: 9\n","  trial_id: ec25e_00010\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00002:\n","  date: 2022-04-13_12-55-44\n","  done: true\n","  experiment_id: 72e9c57841e847a189aac6fa2efac696\n","  experiment_tag: 2_double_q=True,dueling=False,gamma=0.26382\n","  hostname: aa9ef03c8f27\n","  iterations: 9\n","  iterations_since_restore: 10\n","  mean_reward: -142.20590273878716\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.36666666666667\n","    ram_util_percent: 19.86666666666667\n","  pid: 5396\n","  time_since_restore: 42.013221740722656\n","  time_this_iter_s: 4.414665937423706\n","  time_total_s: 42.013221740722656\n","  timestamp: 1649854544\n","  timesteps_since_restore: 0\n","  training_iteration: 10\n","  trial_id: ec25e_00002\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00007:\n","  date: 2022-04-13_12-55-45\n","  done: false\n","  experiment_id: 92914c8f16e34001974a042d922d5fd3\n","  hostname: aa9ef03c8f27\n","  iterations: 8\n","  iterations_since_restore: 9\n","  mean_reward: -128.43090617420796\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 39.925\n","    ram_util_percent: 19.725\n","  pid: 5402\n","  time_since_restore: 42.23565888404846\n","  time_this_iter_s: 5.273388147354126\n","  time_total_s: 42.23565888404846\n","  timestamp: 1649854545\n","  timesteps_since_restore: 0\n","  training_iteration: 9\n","  trial_id: ec25e_00007\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00005:\n","  date: 2022-04-13_12-55-45\n","  done: false\n","  experiment_id: 67acd45ddade45d1978bd50d6cb27f11\n","  hostname: aa9ef03c8f27\n","  iterations: 8\n","  iterations_since_restore: 9\n","  mean_reward: -153.34615144789348\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.34444444444444\n","    ram_util_percent: 19.78888888888889\n","  pid: 5400\n","  time_since_restore: 42.27122449874878\n","  time_this_iter_s: 6.178967237472534\n","  time_total_s: 42.27122449874878\n","  timestamp: 1649854545\n","  timesteps_since_restore: 0\n","  training_iteration: 9\n","  trial_id: ec25e_00005\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00000:\n","  date: 2022-04-13_12-55-45\n","  done: false\n","  experiment_id: 28340671e869461788073defde6cebbc\n","  hostname: aa9ef03c8f27\n","  iterations: 8\n","  iterations_since_restore: 9\n","  mean_reward: -118.81558470802344\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 40.225\n","    ram_util_percent: 19.725\n","  pid: 5401\n","  time_since_restore: 42.879295110702515\n","  time_this_iter_s: 6.089073181152344\n","  time_total_s: 42.879295110702515\n","  timestamp: 1649854545\n","  timesteps_since_restore: 0\n","  training_iteration: 9\n","  trial_id: ec25e_00000\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00003:\n","  date: 2022-04-13_12-55-45\n","  done: true\n","  experiment_id: 0f6a6d8406164452905142864f7bd02d\n","  experiment_tag: 3_double_q=False,dueling=False,gamma=0.15326\n","  hostname: aa9ef03c8f27\n","  iterations: 9\n","  iterations_since_restore: 10\n","  mean_reward: -157.54660454225888\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 39.31666666666666\n","    ram_util_percent: 19.516666666666666\n","  pid: 5398\n","  time_since_restore: 43.08013987541199\n","  time_this_iter_s: 4.28472113609314\n","  time_total_s: 43.08013987541199\n","  timestamp: 1649854545\n","  timesteps_since_restore: 0\n","  training_iteration: 10\n","  trial_id: ec25e_00003\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00004:\n","  date: 2022-04-13_12-55-46\n","  done: true\n","  experiment_id: 934b9fde491146e18e1c1cb97c8ed368\n","  experiment_tag: 4_double_q=True,dueling=True,gamma=0.057536\n","  hostname: aa9ef03c8f27\n","  iterations: 9\n","  iterations_since_restore: 10\n","  mean_reward: -157.7882252884305\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 39.733333333333334\n","    ram_util_percent: 19.7\n","  pid: 5399\n","  time_since_restore: 43.2534863948822\n","  time_this_iter_s: 4.395666122436523\n","  time_total_s: 43.2534863948822\n","  timestamp: 1649854546\n","  timesteps_since_restore: 0\n","  training_iteration: 10\n","  trial_id: ec25e_00004\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00006:\n","  date: 2022-04-13_12-55-46\n","  done: true\n","  experiment_id: f30daf9f4f3041dfaeebf39f36b101ea\n","  experiment_tag: 6_double_q=True,dueling=False,gamma=0.65641\n","  hostname: aa9ef03c8f27\n","  iterations: 9\n","  iterations_since_restore: 10\n","  mean_reward: -154.59730391259885\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 39.34285714285714\n","    ram_util_percent: 19.6\n","  pid: 5397\n","  time_since_restore: 43.244160652160645\n","  time_this_iter_s: 4.924440622329712\n","  time_total_s: 43.244160652160645\n","  timestamp: 1649854546\n","  timesteps_since_restore: 0\n","  training_iteration: 10\n","  trial_id: ec25e_00006\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00001:\n","  date: 2022-04-13_12-55-46\n","  done: true\n","  experiment_id: b874d28dd2e1482581a83f6d4cd7168f\n","  experiment_tag: 1_double_q=False,dueling=True,gamma=0.080645\n","  hostname: aa9ef03c8f27\n","  iterations: 9\n","  iterations_since_restore: 10\n","  mean_reward: -157.90120021519303\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 39.628571428571426\n","    ram_util_percent: 19.571428571428573\n","  pid: 5393\n","  time_since_restore: 43.63345193862915\n","  time_this_iter_s: 4.829726934432983\n","  time_total_s: 43.63345193862915\n","  timestamp: 1649854546\n","  timesteps_since_restore: 0\n","  training_iteration: 10\n","  trial_id: ec25e_00001\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00008:\n","  date: 2022-04-13_12-55-46\n","  done: false\n","  experiment_id: b0db4c8b61f3442786d5c67caeccc3f7\n","  hostname: aa9ef03c8f27\n","  iterations: 8\n","  iterations_since_restore: 9\n","  mean_reward: -152.92238491696082\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 38.86999999999999\n","    ram_util_percent: 19.42\n","  pid: 5395\n","  time_since_restore: 43.69040322303772\n","  time_this_iter_s: 7.04616641998291\n","  time_total_s: 43.69040322303772\n","  timestamp: 1649854546\n","  timesteps_since_restore: 0\n","  training_iteration: 9\n","  trial_id: ec25e_00008\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:55:47 (running for 00:00:49.89)<br>Memory usage on this node: 5.1/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 7.0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: ec25e_00000 with mean_reward=-118.81558470802344 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.9206117943788054, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/HP_tuning_LunarLander<br>Number of trials: 12/12 (7 RUNNING, 5 TERMINATED)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status    </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00000</td><td>RUNNING   </td><td>172.28.0.2:5401</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.920612 </td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         42.8793</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     -118.816</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00005</td><td>RUNNING   </td><td>172.28.0.2:5400</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.835263 </td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         42.2712</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     -153.346</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00007</td><td>RUNNING   </td><td>172.28.0.2:5402</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.867242 </td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         42.2357</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     -128.431</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00008</td><td>RUNNING   </td><td>172.28.0.2:5395</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.908645 </td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         43.6904</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     -152.922</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00009</td><td>RUNNING   </td><td>172.28.0.2:5391</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.592168 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         44.6361</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -145.417</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00010</td><td>RUNNING   </td><td>172.28.0.2:5394</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.96893  </td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         40.3708</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     -144.197</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00011</td><td>RUNNING   </td><td>172.28.0.2:5390</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.314437 </td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         40.1896</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">     -137.388</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00001</td><td>TERMINATED</td><td>172.28.0.2:5393</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0806447</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         43.6335</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -157.901</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00002</td><td>TERMINATED</td><td>172.28.0.2:5396</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.263824 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         42.0132</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -142.206</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00003</td><td>TERMINATED</td><td>172.28.0.2:5398</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.15326  </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         43.0801</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -157.547</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00004</td><td>TERMINATED</td><td>172.28.0.2:5399</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.0575363</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         43.2535</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -157.788</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00006</td><td>TERMINATED</td><td>172.28.0.2:5397</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.656405 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         43.2442</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -154.597</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for objective_fn_LunarLander-v2_ec25e_00009:\n","  date: 2022-04-13_12-55-47\n","  done: true\n","  experiment_id: ffe6dbf0660146ddac1f430fa95cce4e\n","  experiment_tag: 9_double_q=False,dueling=True,gamma=0.59217\n","  hostname: aa9ef03c8f27\n","  iterations: 9\n","  iterations_since_restore: 10\n","  mean_reward: -145.41683203308696\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 35.6\n","    ram_util_percent: 18.185714285714287\n","  pid: 5391\n","  time_since_restore: 44.63611960411072\n","  time_this_iter_s: 4.612032651901245\n","  time_total_s: 44.63611960411072\n","  timestamp: 1649854547\n","  timesteps_since_restore: 0\n","  training_iteration: 10\n","  trial_id: ec25e_00009\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00011:\n","  date: 2022-04-13_12-55-47\n","  done: true\n","  experiment_id: 9cc718012e4e4ba1a698ca9754aa24b8\n","  experiment_tag: 11_double_q=False,dueling=False,gamma=0.31444\n","  hostname: aa9ef03c8f27\n","  iterations: 9\n","  iterations_since_restore: 10\n","  mean_reward: -140.1744855914592\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 34.7\n","    ram_util_percent: 18.0\n","  pid: 5390\n","  time_since_restore: 44.64238715171814\n","  time_this_iter_s: 4.452821493148804\n","  time_total_s: 44.64238715171814\n","  timestamp: 1649854547\n","  timesteps_since_restore: 0\n","  training_iteration: 10\n","  trial_id: ec25e_00011\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00010:\n","  date: 2022-04-13_12-55-48\n","  done: false\n","  experiment_id: 3e293415f2e9440294c56946092bc17b\n","  hostname: aa9ef03c8f27\n","  iterations: 9\n","  iterations_since_restore: 10\n","  mean_reward: -146.72047040213346\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 29.725\n","    ram_util_percent: 17.05\n","  pid: 5394\n","  time_since_restore: 45.97270941734314\n","  time_this_iter_s: 5.601882219314575\n","  time_total_s: 45.97270941734314\n","  timestamp: 1649854548\n","  timesteps_since_restore: 0\n","  training_iteration: 10\n","  trial_id: ec25e_00010\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00010:\n","  date: 2022-04-13_12-55-48\n","  done: true\n","  experiment_id: 3e293415f2e9440294c56946092bc17b\n","  experiment_tag: 10_double_q=True,dueling=False,gamma=0.96893\n","  hostname: aa9ef03c8f27\n","  iterations: 9\n","  iterations_since_restore: 10\n","  mean_reward: -146.72047040213346\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 29.725\n","    ram_util_percent: 17.05\n","  pid: 5394\n","  time_since_restore: 45.97270941734314\n","  time_this_iter_s: 5.601882219314575\n","  time_total_s: 45.97270941734314\n","  timestamp: 1649854548\n","  timesteps_since_restore: 0\n","  training_iteration: 10\n","  trial_id: ec25e_00010\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00007:\n","  date: 2022-04-13_12-55-49\n","  done: true\n","  experiment_id: 92914c8f16e34001974a042d922d5fd3\n","  experiment_tag: 7_double_q=False,dueling=False,gamma=0.86724\n","  hostname: aa9ef03c8f27\n","  iterations: 9\n","  iterations_since_restore: 10\n","  mean_reward: -130.10743430049249\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 22.38333333333333\n","    ram_util_percent: 14.633333333333335\n","  pid: 5402\n","  time_since_restore: 46.8652400970459\n","  time_this_iter_s: 4.6295812129974365\n","  time_total_s: 46.8652400970459\n","  timestamp: 1649854549\n","  timesteps_since_restore: 0\n","  training_iteration: 10\n","  trial_id: ec25e_00007\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00005:\n","  date: 2022-04-13_12-55-49\n","  done: true\n","  experiment_id: 67acd45ddade45d1978bd50d6cb27f11\n","  experiment_tag: 5_double_q=False,dueling=True,gamma=0.83526\n","  hostname: aa9ef03c8f27\n","  iterations: 9\n","  iterations_since_restore: 10\n","  mean_reward: -161.41946459000673\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 23.61666666666667\n","    ram_util_percent: 14.899999999999999\n","  pid: 5400\n","  time_since_restore: 47.009496212005615\n","  time_this_iter_s: 4.738271713256836\n","  time_total_s: 47.009496212005615\n","  timestamp: 1649854549\n","  timesteps_since_restore: 0\n","  training_iteration: 10\n","  trial_id: ec25e_00005\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00000:\n","  date: 2022-04-13_12-55-51\n","  done: false\n","  experiment_id: 28340671e869461788073defde6cebbc\n","  hostname: aa9ef03c8f27\n","  iterations: 9\n","  iterations_since_restore: 10\n","  mean_reward: -120.59513809005244\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 19.625\n","    ram_util_percent: 13.012500000000001\n","  pid: 5401\n","  time_since_restore: 48.1191189289093\n","  time_this_iter_s: 5.239823818206787\n","  time_total_s: 48.1191189289093\n","  timestamp: 1649854551\n","  timesteps_since_restore: 0\n","  training_iteration: 10\n","  trial_id: ec25e_00000\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00000:\n","  date: 2022-04-13_12-55-51\n","  done: true\n","  experiment_id: 28340671e869461788073defde6cebbc\n","  experiment_tag: 0_double_q=True,dueling=True,gamma=0.92061\n","  hostname: aa9ef03c8f27\n","  iterations: 9\n","  iterations_since_restore: 10\n","  mean_reward: -120.59513809005244\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 19.625\n","    ram_util_percent: 13.012500000000001\n","  pid: 5401\n","  time_since_restore: 48.1191189289093\n","  time_this_iter_s: 5.239823818206787\n","  time_total_s: 48.1191189289093\n","  timestamp: 1649854551\n","  timesteps_since_restore: 0\n","  training_iteration: 10\n","  trial_id: ec25e_00000\n","  \n","Result for objective_fn_LunarLander-v2_ec25e_00008:\n","  date: 2022-04-13_12-55-51\n","  done: true\n","  experiment_id: b0db4c8b61f3442786d5c67caeccc3f7\n","  experiment_tag: 8_double_q=True,dueling=True,gamma=0.90864\n","  hostname: aa9ef03c8f27\n","  iterations: 9\n","  iterations_since_restore: 10\n","  mean_reward: -151.81169201788376\n","  node_ip: 172.28.0.2\n","  perf:\n","    cpu_util_percent: 15.35\n","    ram_util_percent: 12.049999999999999\n","  pid: 5395\n","  time_since_restore: 48.482994556427\n","  time_this_iter_s: 4.792591333389282\n","  time_total_s: 48.482994556427\n","  timestamp: 1649854551\n","  timesteps_since_restore: 0\n","  training_iteration: 10\n","  trial_id: ec25e_00008\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 12:55:51 (running for 00:00:53.76)<br>Memory usage on this node: 3.1/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/40 CPUs, 0/0 GPUs, 0.0/20.1 GiB heap, 0.0/10.05 GiB objects<br>Current best trial: ec25e_00000 with mean_reward=-120.59513809005244 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.9206117943788054, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}<br>Result logdir: /root/ray_results/HP_tuning_LunarLander<br>Number of trials: 12/12 (12 TERMINATED)<br><table>\n","<thead>\n","<tr><th>Trial name                             </th><th>status    </th><th>loc            </th><th>double_q  </th><th>dueling  </th><th style=\"text-align: right;\">    gamma</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  mean_reward</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00000</td><td>TERMINATED</td><td>172.28.0.2:5401</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.920612 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         48.1191</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -120.595</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00001</td><td>TERMINATED</td><td>172.28.0.2:5393</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.0806447</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         43.6335</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -157.901</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00002</td><td>TERMINATED</td><td>172.28.0.2:5396</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.263824 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         42.0132</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -142.206</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00003</td><td>TERMINATED</td><td>172.28.0.2:5398</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.15326  </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         43.0801</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -157.547</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00004</td><td>TERMINATED</td><td>172.28.0.2:5399</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.0575363</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         43.2535</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -157.788</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00005</td><td>TERMINATED</td><td>172.28.0.2:5400</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.835263 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         47.0095</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -161.419</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00006</td><td>TERMINATED</td><td>172.28.0.2:5397</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.656405 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         43.2442</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -154.597</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00007</td><td>TERMINATED</td><td>172.28.0.2:5402</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.867242 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         46.8652</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -130.107</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00008</td><td>TERMINATED</td><td>172.28.0.2:5395</td><td>True      </td><td>True     </td><td style=\"text-align: right;\">0.908645 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         48.483 </td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -151.812</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00009</td><td>TERMINATED</td><td>172.28.0.2:5391</td><td>False     </td><td>True     </td><td style=\"text-align: right;\">0.592168 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         44.6361</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -145.417</td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00010</td><td>TERMINATED</td><td>172.28.0.2:5394</td><td>True      </td><td>False    </td><td style=\"text-align: right;\">0.96893  </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         45.9727</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -146.72 </td></tr>\n","<tr><td>objective_fn_LunarLander-v2_ec25e_00011</td><td>TERMINATED</td><td>172.28.0.2:5390</td><td>False     </td><td>False    </td><td style=\"text-align: right;\">0.314437 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         44.6424</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">     -140.174</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2022-04-13 12:55:51,590\tINFO tune.py:639 -- Total run time: 53.93 seconds (53.74 seconds for the tuning loop).\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters found were:  {'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.9206117943788054, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}\n"]}]},{"cell_type":"code","source":["print(\"Best hyperparameters found were: \", analysis.best_config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LZrhxjMh8XbX","executionInfo":{"status":"ok","timestamp":1649854548503,"user_tz":-60,"elapsed":286,"user":{"displayName":"k Yuichi","userId":"17236341909464291729"}},"outputId":"14f6baea-d500-435b-e982-c51167dba7fb"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Best hyperparameters found were:  {'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.9206117943788054, 'lr': 0.0005, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [128, 128, 128], 'fcnet_activation': 'relu'}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'LunarLander-v2', 'observation_space': None, 'action_space': None, 'env_config': {}, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'eager_max_retraces': 20, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'always_attach_evaluation_results': False, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_reporting': 1, 'min_train_timesteps_per_reporting': None, 'min_sample_timesteps_per_reporting': None, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': False, 'simple_optimizer': -1, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': 1000, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'target_network_update_freq': 500, 'buffer_size': -1, 'replay_buffer_config': {'type': 'MultiAgentReplayBuffer', 'capacity': 50000}, 'store_buffer_in_checkpoints': False, 'replay_sequence_length': 1, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'worker_side_prioritization': False}\n"]}]},{"cell_type":"code","source":["df = analysis.dataframe(metric=\"mean_reward\", mode=\"max\")\n","df[['config/gamma', 'config/double_q', 'config/dueling', 'mean_reward']]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":425},"id":"oVEofybUd7xn","executionInfo":{"status":"ok","timestamp":1649854559874,"user_tz":-60,"elapsed":213,"user":{"displayName":"k Yuichi","userId":"17236341909464291729"}},"outputId":"ee3c9f52-3c14-4219-e444-69766d4da665"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    config/gamma  config/double_q  config/dueling  mean_reward\n","0       0.920612             True            True  -118.815585\n","1       0.080645            False            True  -134.369129\n","2       0.263824             True           False  -139.913083\n","3       0.153260            False           False  -130.480041\n","4       0.057536             True            True  -147.929386\n","5       0.835263            False            True  -143.148969\n","6       0.656405             True           False  -149.418683\n","7       0.867242            False           False  -127.519113\n","8       0.908645             True            True  -151.811692\n","9       0.592168            False            True  -127.730261\n","10      0.968930             True           False  -144.197139\n","11      0.314437            False           False  -137.388312"],"text/html":["\n","  <div id=\"df-4f62e073-d432-4305-a9f6-1d4c4e987c1e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>config/gamma</th>\n","      <th>config/double_q</th>\n","      <th>config/dueling</th>\n","      <th>mean_reward</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.920612</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>-118.815585</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.080645</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>-134.369129</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.263824</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>-139.913083</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.153260</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>-130.480041</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.057536</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>-147.929386</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.835263</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>-143.148969</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.656405</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>-149.418683</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.867242</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>-127.519113</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.908645</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>-151.811692</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.592168</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>-127.730261</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.968930</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>-144.197139</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.314437</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>-137.388312</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f62e073-d432-4305-a9f6-1d4c4e987c1e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4f62e073-d432-4305-a9f6-1d4c4e987c1e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4f62e073-d432-4305-a9f6-1d4c4e987c1e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["https://docs.ray.io/en/latest/tune/api_docs/analysis.html"],"metadata":{"id":"2FkkWE-WAGXZ"}},{"cell_type":"code","execution_count":24,"metadata":{"id":"3fQhxxi98ECW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649854563762,"user_tz":-60,"elapsed":209,"user":{"displayName":"k Yuichi","userId":"17236341909464291729"}},"outputId":"b784e171-9528-4caa-da6b-32cc7f554864"},"outputs":[{"output_type":"stream","name":"stderr","text":["2022-04-13 12:56:12,105\tINFO experiment_analysis.py:696 -- No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"]}],"source":["from ray.tune import ExperimentAnalysis\n","analysis_result = ExperimentAnalysis(\"~/ray_results/HP_tuning_LunarLander\")"]},{"cell_type":"code","source":[""],"metadata":{"id":"g6mk-tRQ_7AK"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"Task2_HP_Tuning.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":0}