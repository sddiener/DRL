{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PPO_RL","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMFc8t2L9hfzg2Me42v/zNv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RLAbE_Z-bgQf","executionInfo":{"status":"ok","timestamp":1649862677023,"user_tz":-60,"elapsed":19476,"user":{"displayName":"k Yuichi","userId":"17236341909464291729"}},"outputId":"31c1e9dd-6fd8-4ade-c35a-0240a3dfe78f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: Box2D in /usr/local/lib/python3.7/dist-packages (2.3.10)\n","Requirement already satisfied: box2d-py in /usr/local/lib/python3.7/dist-packages (2.3.8)\n","Requirement already satisfied: gym[all] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[all]) (1.3.0)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[all]) (1.21.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[all]) (1.4.1)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[all]) (1.5.0)\n","Collecting mujoco-py<2.0,>=1.50\n","  Using cached mujoco-py-1.50.1.68.tar.gz (120 kB)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gym[all]) (4.1.2.30)\n","Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[all]) (0.2.9)\n","Requirement already satisfied: box2d-py~=2.3.5 in /usr/local/lib/python3.7/dist-packages (from gym[all]) (2.3.8)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym[all]) (7.1.2)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from gym[all]) (2.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py~=0.2.0->gym[all]) (1.15.0)\n","Requirement already satisfied: glfw>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from mujoco-py<2.0,>=1.50->gym[all]) (2.5.3)\n","Requirement already satisfied: Cython>=0.27.2 in /usr/local/lib/python3.7/dist-packages (from mujoco-py<2.0,>=1.50->gym[all]) (0.29.28)\n","Requirement already satisfied: cffi>=1.10 in /usr/local/lib/python3.7/dist-packages (from mujoco-py<2.0,>=1.50->gym[all]) (1.15.0)\n","Requirement already satisfied: lockfile>=0.12.2 in /usr/local/lib/python3.7/dist-packages (from mujoco-py<2.0,>=1.50->gym[all]) (0.12.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.10->mujoco-py<2.0,>=1.50->gym[all]) (2.21)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[all]) (0.16.0)\n","Building wheels for collected packages: mujoco-py\n","  Building wheel for mujoco-py (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for mujoco-py\u001b[0m\n","\u001b[?25h  Running setup.py clean for mujoco-py\n","Failed to build mujoco-py\n","Installing collected packages: mujoco-py\n","    Running setup.py install for mujoco-py ... \u001b[?25l\u001b[?25herror\n","\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-l5_z76g1/mujoco-py_595fa138e0fd405ba900bef16600f7c9/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-l5_z76g1/mujoco-py_595fa138e0fd405ba900bef16600f7c9/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-xztx5_t0/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/mujoco-py Check the logs for full command output.\u001b[0m\n","Requirement already satisfied: gym[Box_2D] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n","\u001b[33mWARNING: gym 0.17.3 does not provide the extra 'box_2d'\u001b[0m\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.5.0)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.21.5)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.3.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.4.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[Box_2D]) (0.16.0)\n","Requirement already satisfied: torc in /usr/local/lib/python3.7/dist-packages (0.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torc) (1.21.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torc) (1.4.1)\n","Requirement already satisfied: ray[rllib] in /usr/local/lib/python3.7/dist-packages (1.11.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (3.6.0)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (1.0.3)\n","Requirement already satisfied: grpcio<=1.43.0,>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (1.43.0)\n","Requirement already satisfied: redis>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (4.2.2)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (21.4.0)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (4.3.3)\n","Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (3.17.3)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (1.21.5)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (7.1.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (3.13)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (0.18.3)\n","Requirement already satisfied: matplotlib!=3.4.3 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (3.2.2)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (0.8.9)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (1.4.1)\n","Requirement already satisfied: lz4 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (4.0.0)\n","Requirement already satisfied: gym<0.22 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (0.17.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (2.23.0)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (0.1.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (1.3.5)\n","Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]) (2.5)\n","Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.28.1->ray[rllib]) (1.15.0)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym<0.22->ray[rllib]) (1.5.0)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym<0.22->ray[rllib]) (1.3.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.4.3->ray[rllib]) (1.4.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.4.3->ray[rllib]) (3.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.4.3->ray[rllib]) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.4.3->ray[rllib]) (2.8.2)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym<0.22->ray[rllib]) (0.16.0)\n","Requirement already satisfied: async-timeout>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[rllib]) (4.0.2)\n","Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[rllib]) (21.3)\n","Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[rllib]) (4.11.3)\n","Requirement already satisfied: deprecated>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[rllib]) (1.2.13)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[rllib]) (1.14.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[rllib]) (3.7.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[rllib]) (0.18.1)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[rllib]) (5.4.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[rllib]) (2018.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray[rllib]) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[rllib]) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[rllib]) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[rllib]) (3.0.4)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->ray[rllib]) (1.3.0)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->ray[rllib]) (7.1.2)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->ray[rllib]) (2.4.1)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->ray[rllib]) (2021.11.2)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->ray[rllib]) (2.6.3)\n"]}],"source":["!pip install Box2D\n","!pip install box2d-py\n","!pip install gym[all]\n","!pip install gym[Box_2D]\n","!pip install torc\n","!pip install -U \"ray[rllib]\" torch\n","import gym \n","env = gym.make(\"LunarLander-v2\")"]},{"cell_type":"code","source":["import ray\n","import ray.rllib.agents.ppo as ppo\n","from ray.tune.logger import pretty_print\n","\n","config = ppo.DEFAULT_CONFIG.copy()\n","config[\"num_gpus\"] = 0\n","config[\"num_workers\"] = 1\n","trainer = ppo.PPOTrainer(config=config, env=\"LunarLander-v2\")\n","\n","# Can optionally call trainer.restore(path) to load a checkpoint.\n","\n","for i in range(10):\n","   # Perform one iteration of training the policy with PPO\n","   result = trainer.train()\n","   print(pretty_print(result))\n","\n","   if i % 2 == 0:\n","       checkpoint = trainer.save()\n","       print(\"checkpoint saved at\", checkpoint)\n","\n","# Also, in case you have trained a model outside of ray/RLlib and have created\n","# an h5-file with weight values in it, e.g.\n","# my_keras_model_trained_outside_rllib.save_weights(\"model.h5\")\n","# (see: https://keras.io/models/about-keras-models/)\n","\n","# ... you can load the h5-weights into your Trainer's Policy's ModelV2\n","# (tf or torch) by doing:\n","\n","# NOTE: In order for this to work, your (custom) model needs to implement\n","# the `import_from_h5` method.\n","# See https://github.com/ray-project/ray/blob/master/rllib/tests/test_model_imports.py\n","# for detailed examples for tf- and torch trainers/models."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t1X8pmoNbmNd","executionInfo":{"status":"ok","timestamp":1649863054134,"user_tz":-60,"elapsed":75228,"user":{"displayName":"k Yuichi","userId":"17236341909464291729"}},"outputId":"13da3610-694d-4d21-a85c-78280a0496e3"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-04-13 15:16:32,820\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n"]},{"output_type":"stream","name":"stdout","text":["agent_timesteps_total: 4000\n","custom_metrics: {}\n","date: 2022-04-13_15-16-39\n","done: false\n","episode_len_mean: 91.69767441860465\n","episode_media: {}\n","episode_reward_max: 5.342911674179149\n","episode_reward_mean: -179.5412097896658\n","episode_reward_min: -497.7353577572593\n","episodes_this_iter: 43\n","episodes_total: 43\n","experiment_id: 9ff33c87e168401f88c3645a3dfee3af\n","hostname: 2783ca1d819b\n","info:\n","  learner:\n","    default_policy:\n","      custom_metrics: {}\n","      learner_stats:\n","        cur_kl_coeff: 0.20000000298023224\n","        cur_lr: 4.999999873689376e-05\n","        entropy: 1.3742985725402832\n","        entropy_coeff: 0.0\n","        kl: 0.0121202003210783\n","        model: {}\n","        policy_loss: -0.002560756867751479\n","        total_loss: 10934.6796875\n","        vf_explained_var: -0.002811410930007696\n","        vf_loss: 10934.6806640625\n","  num_agent_steps_sampled: 4000\n","  num_agent_steps_trained: 4000\n","  num_steps_sampled: 4000\n","  num_steps_trained: 4000\n","  num_steps_trained_this_iter: 4000\n","iterations_since_restore: 1\n","node_ip: 172.28.0.2\n","num_healthy_workers: 1\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 5.018181818181818\n","  ram_util_percent: 11.400000000000002\n","pid: 179\n","policy_reward_max: {}\n","policy_reward_mean: {}\n","policy_reward_min: {}\n","sampler_perf:\n","  mean_action_processing_ms: 0.06879248996878587\n","  mean_env_render_ms: 0.0\n","  mean_env_wait_ms: 0.2497371748905425\n","  mean_inference_ms: 0.6779357511620021\n","  mean_raw_obs_processing_ms: 0.10756056656154564\n","time_since_restore: 7.129072666168213\n","time_this_iter_s: 7.129072666168213\n","time_total_s: 7.129072666168213\n","timers:\n","  learn_throughput: 1527.917\n","  learn_time_ms: 2617.943\n","  load_throughput: 10034220.096\n","  load_time_ms: 0.399\n","  sample_throughput: 888.019\n","  sample_time_ms: 4504.406\n","  update_time_ms: 2.707\n","timestamp: 1649862999\n","timesteps_since_restore: 4000\n","timesteps_this_iter: 4000\n","timesteps_total: 4000\n","training_iteration: 1\n","trial_id: default\n","\n","checkpoint saved at /root/ray_results/PPOTrainer_LunarLander-v2_2022-04-13_15-16-27o_df27hv/checkpoint_000001/checkpoint-1\n","agent_timesteps_total: 8000\n","custom_metrics: {}\n","date: 2022-04-13_15-16-46\n","done: false\n","episode_len_mean: 88.21111111111111\n","episode_media: {}\n","episode_reward_max: 5.342911674179149\n","episode_reward_mean: -170.3263623295786\n","episode_reward_min: -512.2960676383841\n","episodes_this_iter: 47\n","episodes_total: 90\n","experiment_id: 9ff33c87e168401f88c3645a3dfee3af\n","hostname: 2783ca1d819b\n","info:\n","  learner:\n","    default_policy:\n","      custom_metrics: {}\n","      learner_stats:\n","        cur_kl_coeff: 0.20000000298023224\n","        cur_lr: 4.999999873689376e-05\n","        entropy: 1.3410389423370361\n","        entropy_coeff: 0.0\n","        kl: 0.01674206368625164\n","        model: {}\n","        policy_loss: -0.008538094349205494\n","        total_loss: 5948.74169921875\n","        vf_explained_var: -0.0035736856516450644\n","        vf_loss: 5948.74658203125\n","  num_agent_steps_sampled: 8000\n","  num_agent_steps_trained: 8000\n","  num_steps_sampled: 8000\n","  num_steps_trained: 8000\n","  num_steps_trained_this_iter: 4000\n","iterations_since_restore: 2\n","node_ip: 172.28.0.2\n","num_healthy_workers: 1\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 4.9\n","  ram_util_percent: 11.4\n","pid: 179\n","policy_reward_max: {}\n","policy_reward_mean: {}\n","policy_reward_min: {}\n","sampler_perf:\n","  mean_action_processing_ms: 0.06847395462233477\n","  mean_env_render_ms: 0.0\n","  mean_env_wait_ms: 0.24639860466952362\n","  mean_inference_ms: 0.67206996379045\n","  mean_raw_obs_processing_ms: 0.10727901473118834\n","time_since_restore: 13.915634870529175\n","time_this_iter_s: 6.786562204360962\n","time_total_s: 13.915634870529175\n","timers:\n","  learn_throughput: 1580.278\n","  learn_time_ms: 2531.2\n","  load_throughput: 9866048.809\n","  load_time_ms: 0.405\n","  sample_throughput: 694.402\n","  sample_time_ms: 5760.352\n","  update_time_ms: 2.594\n","timestamp: 1649863006\n","timesteps_since_restore: 8000\n","timesteps_this_iter: 4000\n","timesteps_total: 8000\n","training_iteration: 2\n","trial_id: default\n","\n","agent_timesteps_total: 12000\n","custom_metrics: {}\n","date: 2022-04-13_15-16-53\n","done: false\n","episode_len_mean: 85.26\n","episode_media: {}\n","episode_reward_max: 21.777245174205746\n","episode_reward_mean: -151.0119713152105\n","episode_reward_min: -512.2960676383841\n","episodes_this_iter: 47\n","episodes_total: 137\n","experiment_id: 9ff33c87e168401f88c3645a3dfee3af\n","hostname: 2783ca1d819b\n","info:\n","  learner:\n","    default_policy:\n","      custom_metrics: {}\n","      learner_stats:\n","        cur_kl_coeff: 0.20000000298023224\n","        cur_lr: 4.999999873689376e-05\n","        entropy: 1.3181095123291016\n","        entropy_coeff: 0.0\n","        kl: 0.015907172113656998\n","        model: {}\n","        policy_loss: -0.004494672175496817\n","        total_loss: 4050.13623046875\n","        vf_explained_var: -0.004208311438560486\n","        vf_loss: 4050.1376953125\n","  num_agent_steps_sampled: 12000\n","  num_agent_steps_trained: 12000\n","  num_steps_sampled: 12000\n","  num_steps_trained: 12000\n","  num_steps_trained_this_iter: 4000\n","iterations_since_restore: 3\n","node_ip: 172.28.0.2\n","num_healthy_workers: 1\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 4.95\n","  ram_util_percent: 11.400000000000002\n","pid: 179\n","policy_reward_max: {}\n","policy_reward_mean: {}\n","policy_reward_min: {}\n","sampler_perf:\n","  mean_action_processing_ms: 0.06842996209170399\n","  mean_env_render_ms: 0.0\n","  mean_env_wait_ms: 0.2422545991096301\n","  mean_inference_ms: 0.668836351373879\n","  mean_raw_obs_processing_ms: 0.10736632424790375\n","time_since_restore: 20.76601004600525\n","time_this_iter_s: 6.850375175476074\n","time_total_s: 20.76601004600525\n","timers:\n","  learn_throughput: 1603.549\n","  learn_time_ms: 2494.466\n","  load_throughput: 9616287.352\n","  load_time_ms: 0.416\n","  sample_throughput: 651.549\n","  sample_time_ms: 6139.215\n","  update_time_ms: 2.56\n","timestamp: 1649863013\n","timesteps_since_restore: 12000\n","timesteps_this_iter: 4000\n","timesteps_total: 12000\n","training_iteration: 3\n","trial_id: default\n","\n","checkpoint saved at /root/ray_results/PPOTrainer_LunarLander-v2_2022-04-13_15-16-27o_df27hv/checkpoint_000003/checkpoint-3\n","agent_timesteps_total: 16000\n","custom_metrics: {}\n","date: 2022-04-13_15-17-00\n","done: false\n","episode_len_mean: 85.98\n","episode_media: {}\n","episode_reward_max: 21.777245174205746\n","episode_reward_mean: -126.95043165533214\n","episode_reward_min: -341.5667533513429\n","episodes_this_iter: 46\n","episodes_total: 183\n","experiment_id: 9ff33c87e168401f88c3645a3dfee3af\n","hostname: 2783ca1d819b\n","info:\n","  learner:\n","    default_policy:\n","      custom_metrics: {}\n","      learner_stats:\n","        cur_kl_coeff: 0.20000000298023224\n","        cur_lr: 4.999999873689376e-05\n","        entropy: 1.3084030151367188\n","        entropy_coeff: 0.0\n","        kl: 0.00720147555693984\n","        model: {}\n","        policy_loss: -0.002852923469617963\n","        total_loss: 1421.1265869140625\n","        vf_explained_var: -0.0015336974756792188\n","        vf_loss: 1421.1279296875\n","  num_agent_steps_sampled: 16000\n","  num_agent_steps_trained: 16000\n","  num_steps_sampled: 16000\n","  num_steps_trained: 16000\n","  num_steps_trained_this_iter: 4000\n","iterations_since_restore: 4\n","node_ip: 172.28.0.2\n","num_healthy_workers: 1\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 4.790000000000001\n","  ram_util_percent: 11.400000000000002\n","pid: 179\n","policy_reward_max: {}\n","policy_reward_mean: {}\n","policy_reward_min: {}\n","sampler_perf:\n","  mean_action_processing_ms: 0.06854195442347785\n","  mean_env_render_ms: 0.0\n","  mean_env_wait_ms: 0.23906674124134192\n","  mean_inference_ms: 0.6690516571191573\n","  mean_raw_obs_processing_ms: 0.10752083155135025\n","time_since_restore: 27.562764167785645\n","time_this_iter_s: 6.7967541217803955\n","time_total_s: 27.562764167785645\n","timers:\n","  learn_throughput: 1610.752\n","  learn_time_ms: 2483.312\n","  load_throughput: 9848673.907\n","  load_time_ms: 0.406\n","  sample_throughput: 634.322\n","  sample_time_ms: 6305.942\n","  update_time_ms: 2.614\n","timestamp: 1649863020\n","timesteps_since_restore: 16000\n","timesteps_this_iter: 4000\n","timesteps_total: 16000\n","training_iteration: 4\n","trial_id: default\n","\n","agent_timesteps_total: 20000\n","custom_metrics: {}\n","date: 2022-04-13_15-17-07\n","done: false\n","episode_len_mean: 88.29\n","episode_media: {}\n","episode_reward_max: 21.777245174205746\n","episode_reward_mean: -106.62030668642583\n","episode_reward_min: -302.3913987158635\n","episodes_this_iter: 45\n","episodes_total: 228\n","experiment_id: 9ff33c87e168401f88c3645a3dfee3af\n","hostname: 2783ca1d819b\n","info:\n","  learner:\n","    default_policy:\n","      custom_metrics: {}\n","      learner_stats:\n","        cur_kl_coeff: 0.20000000298023224\n","        cur_lr: 4.999999873689376e-05\n","        entropy: 1.2964190244674683\n","        entropy_coeff: 0.0\n","        kl: 0.011443515308201313\n","        model: {}\n","        policy_loss: -0.013516295701265335\n","        total_loss: 1661.631103515625\n","        vf_explained_var: -0.003116917796432972\n","        vf_loss: 1661.6424560546875\n","  num_agent_steps_sampled: 20000\n","  num_agent_steps_trained: 20000\n","  num_steps_sampled: 20000\n","  num_steps_trained: 20000\n","  num_steps_trained_this_iter: 4000\n","iterations_since_restore: 5\n","node_ip: 172.28.0.2\n","num_healthy_workers: 1\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 5.42\n","  ram_util_percent: 11.400000000000002\n","pid: 179\n","policy_reward_max: {}\n","policy_reward_mean: {}\n","policy_reward_min: {}\n","sampler_perf:\n","  mean_action_processing_ms: 0.0684982193440429\n","  mean_env_render_ms: 0.0\n","  mean_env_wait_ms: 0.23702252381286468\n","  mean_inference_ms: 0.6672667435329072\n","  mean_raw_obs_processing_ms: 0.10743432456766025\n","time_since_restore: 34.34185171127319\n","time_this_iter_s: 6.779087543487549\n","time_total_s: 34.34185171127319\n","timers:\n","  learn_throughput: 1612.944\n","  learn_time_ms: 2479.938\n","  load_throughput: 9939109.005\n","  load_time_ms: 0.402\n","  sample_throughput: 624.851\n","  sample_time_ms: 6401.526\n","  update_time_ms: 2.665\n","timestamp: 1649863027\n","timesteps_since_restore: 20000\n","timesteps_this_iter: 4000\n","timesteps_total: 20000\n","training_iteration: 5\n","trial_id: default\n","\n","checkpoint saved at /root/ray_results/PPOTrainer_LunarLander-v2_2022-04-13_15-16-27o_df27hv/checkpoint_000005/checkpoint-5\n","agent_timesteps_total: 24000\n","custom_metrics: {}\n","date: 2022-04-13_15-17-14\n","done: false\n","episode_len_mean: 91.0\n","episode_media: {}\n","episode_reward_max: -21.420749963954407\n","episode_reward_mean: -97.36209082120496\n","episode_reward_min: -302.3913987158635\n","episodes_this_iter: 43\n","episodes_total: 271\n","experiment_id: 9ff33c87e168401f88c3645a3dfee3af\n","hostname: 2783ca1d819b\n","info:\n","  learner:\n","    default_policy:\n","      custom_metrics: {}\n","      learner_stats:\n","        cur_kl_coeff: 0.20000000298023224\n","        cur_lr: 4.999999873689376e-05\n","        entropy: 1.257373571395874\n","        entropy_coeff: 0.0\n","        kl: 0.0092436783015728\n","        model: {}\n","        policy_loss: -0.02458781562745571\n","        total_loss: 1035.90380859375\n","        vf_explained_var: -0.000624843523837626\n","        vf_loss: 1035.9266357421875\n","  num_agent_steps_sampled: 24000\n","  num_agent_steps_trained: 24000\n","  num_steps_sampled: 24000\n","  num_steps_trained: 24000\n","  num_steps_trained_this_iter: 4000\n","iterations_since_restore: 6\n","node_ip: 172.28.0.2\n","num_healthy_workers: 1\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 5.41\n","  ram_util_percent: 11.400000000000002\n","pid: 179\n","policy_reward_max: {}\n","policy_reward_mean: {}\n","policy_reward_min: {}\n","sampler_perf:\n","  mean_action_processing_ms: 0.06850422728170417\n","  mean_env_render_ms: 0.0\n","  mean_env_wait_ms: 0.23692967488489572\n","  mean_inference_ms: 0.6662735103974738\n","  mean_raw_obs_processing_ms: 0.10741559845833079\n","time_since_restore: 41.25823712348938\n","time_this_iter_s: 6.9163854122161865\n","time_total_s: 41.25823712348938\n","timers:\n","  learn_throughput: 1614.827\n","  learn_time_ms: 2477.046\n","  load_throughput: 9378859.219\n","  load_time_ms: 0.426\n","  sample_throughput: 615.951\n","  sample_time_ms: 6494.027\n","  update_time_ms: 2.756\n","timestamp: 1649863034\n","timesteps_since_restore: 24000\n","timesteps_this_iter: 4000\n","timesteps_total: 24000\n","training_iteration: 6\n","trial_id: default\n","\n","agent_timesteps_total: 28000\n","custom_metrics: {}\n","date: 2022-04-13_15-17-21\n","done: false\n","episode_len_mean: 94.29\n","episode_media: {}\n","episode_reward_max: -8.710378490773238\n","episode_reward_mean: -81.58693076194987\n","episode_reward_min: -302.3913987158635\n","episodes_this_iter: 41\n","episodes_total: 312\n","experiment_id: 9ff33c87e168401f88c3645a3dfee3af\n","hostname: 2783ca1d819b\n","info:\n","  learner:\n","    default_policy:\n","      custom_metrics: {}\n","      learner_stats:\n","        cur_kl_coeff: 0.20000000298023224\n","        cur_lr: 4.999999873689376e-05\n","        entropy: 1.2217875719070435\n","        entropy_coeff: 0.0\n","        kl: 0.010472468100488186\n","        model: {}\n","        policy_loss: -0.0006761477561667562\n","        total_loss: 792.2073974609375\n","        vf_explained_var: -0.0008279847097583115\n","        vf_loss: 792.2059326171875\n","  num_agent_steps_sampled: 28000\n","  num_agent_steps_trained: 28000\n","  num_steps_sampled: 28000\n","  num_steps_trained: 28000\n","  num_steps_trained_this_iter: 4000\n","iterations_since_restore: 7\n","node_ip: 172.28.0.2\n","num_healthy_workers: 1\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 4.888888888888889\n","  ram_util_percent: 11.4\n","pid: 179\n","policy_reward_max: {}\n","policy_reward_mean: {}\n","policy_reward_min: {}\n","sampler_perf:\n","  mean_action_processing_ms: 0.0685355598516467\n","  mean_env_render_ms: 0.0\n","  mean_env_wait_ms: 0.23779366007248393\n","  mean_inference_ms: 0.6668075007727134\n","  mean_raw_obs_processing_ms: 0.10738921888184581\n","time_since_restore: 48.141194581985474\n","time_this_iter_s: 6.882957458496094\n","time_total_s: 48.141194581985474\n","timers:\n","  learn_throughput: 1618.907\n","  learn_time_ms: 2470.803\n","  load_throughput: 9474829.528\n","  load_time_ms: 0.422\n","  sample_throughput: 610.071\n","  sample_time_ms: 6556.619\n","  update_time_ms: 2.846\n","timestamp: 1649863041\n","timesteps_since_restore: 28000\n","timesteps_this_iter: 4000\n","timesteps_total: 28000\n","training_iteration: 7\n","trial_id: default\n","\n","checkpoint saved at /root/ray_results/PPOTrainer_LunarLander-v2_2022-04-13_15-16-27o_df27hv/checkpoint_000007/checkpoint-7\n","agent_timesteps_total: 32000\n","custom_metrics: {}\n","date: 2022-04-13_15-17-28\n","done: false\n","episode_len_mean: 97.89\n","episode_media: {}\n","episode_reward_max: 29.10735532613205\n","episode_reward_mean: -63.665089522761974\n","episode_reward_min: -293.75135053648603\n","episodes_this_iter: 40\n","episodes_total: 352\n","experiment_id: 9ff33c87e168401f88c3645a3dfee3af\n","hostname: 2783ca1d819b\n","info:\n","  learner:\n","    default_policy:\n","      custom_metrics: {}\n","      learner_stats:\n","        cur_kl_coeff: 0.20000000298023224\n","        cur_lr: 4.999999873689376e-05\n","        entropy: 1.1750564575195312\n","        entropy_coeff: 0.0\n","        kl: 0.014569059014320374\n","        model: {}\n","        policy_loss: -0.01778135448694229\n","        total_loss: 1003.2002563476562\n","        vf_explained_var: -0.0010926390532404184\n","        vf_loss: 1003.2152099609375\n","  num_agent_steps_sampled: 32000\n","  num_agent_steps_trained: 32000\n","  num_steps_sampled: 32000\n","  num_steps_trained: 32000\n","  num_steps_trained_this_iter: 4000\n","iterations_since_restore: 8\n","node_ip: 172.28.0.2\n","num_healthy_workers: 1\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 5.08\n","  ram_util_percent: 11.400000000000002\n","pid: 179\n","policy_reward_max: {}\n","policy_reward_mean: {}\n","policy_reward_min: {}\n","sampler_perf:\n","  mean_action_processing_ms: 0.06854587285743344\n","  mean_env_render_ms: 0.0\n","  mean_env_wait_ms: 0.23935501836316345\n","  mean_inference_ms: 0.666828255810234\n","  mean_raw_obs_processing_ms: 0.10733974579752167\n","time_since_restore: 55.00188612937927\n","time_this_iter_s: 6.860691547393799\n","time_total_s: 55.00188612937927\n","timers:\n","  learn_throughput: 1622.277\n","  learn_time_ms: 2465.67\n","  load_throughput: 9094574.333\n","  load_time_ms: 0.44\n","  sample_throughput: 606.115\n","  sample_time_ms: 6599.404\n","  update_time_ms: 2.845\n","timestamp: 1649863048\n","timesteps_since_restore: 32000\n","timesteps_this_iter: 4000\n","timesteps_total: 32000\n","training_iteration: 8\n","trial_id: default\n","\n","agent_timesteps_total: 36000\n","custom_metrics: {}\n","date: 2022-04-13_15-17-35\n","done: false\n","episode_len_mean: 98.88\n","episode_media: {}\n","episode_reward_max: 29.10735532613205\n","episode_reward_mean: -49.410207200493545\n","episode_reward_min: -193.09084153312443\n","episodes_this_iter: 41\n","episodes_total: 393\n","experiment_id: 9ff33c87e168401f88c3645a3dfee3af\n","hostname: 2783ca1d819b\n","info:\n","  learner:\n","    default_policy:\n","      custom_metrics: {}\n","      learner_stats:\n","        cur_kl_coeff: 0.20000000298023224\n","        cur_lr: 4.999999873689376e-05\n","        entropy: 1.2038002014160156\n","        entropy_coeff: 0.0\n","        kl: 0.006962665356695652\n","        model: {}\n","        policy_loss: -0.02140822634100914\n","        total_loss: 1028.57275390625\n","        vf_explained_var: -0.0007881768397055566\n","        vf_loss: 1028.5928955078125\n","  num_agent_steps_sampled: 36000\n","  num_agent_steps_trained: 36000\n","  num_steps_sampled: 36000\n","  num_steps_trained: 36000\n","  num_steps_trained_this_iter: 4000\n","iterations_since_restore: 9\n","node_ip: 172.28.0.2\n","num_healthy_workers: 1\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 5.027272727272727\n","  ram_util_percent: 11.400000000000002\n","pid: 179\n","policy_reward_max: {}\n","policy_reward_mean: {}\n","policy_reward_min: {}\n","sampler_perf:\n","  mean_action_processing_ms: 0.06882570392673021\n","  mean_env_render_ms: 0.0\n","  mean_env_wait_ms: 0.24192923984891762\n","  mean_inference_ms: 0.6686369056197924\n","  mean_raw_obs_processing_ms: 0.10761496934844013\n","time_since_restore: 62.20071768760681\n","time_this_iter_s: 7.198831558227539\n","time_total_s: 62.20071768760681\n","timers:\n","  learn_throughput: 1625.839\n","  learn_time_ms: 2460.268\n","  load_throughput: 8756375.783\n","  load_time_ms: 0.457\n","  sample_throughput: 599.707\n","  sample_time_ms: 6669.921\n","  update_time_ms: 2.878\n","timestamp: 1649863055\n","timesteps_since_restore: 36000\n","timesteps_this_iter: 4000\n","timesteps_total: 36000\n","training_iteration: 9\n","trial_id: default\n","\n","checkpoint saved at /root/ray_results/PPOTrainer_LunarLander-v2_2022-04-13_15-16-27o_df27hv/checkpoint_000009/checkpoint-9\n","agent_timesteps_total: 40000\n","custom_metrics: {}\n","date: 2022-04-13_15-17-42\n","done: false\n","episode_len_mean: 103.09\n","episode_media: {}\n","episode_reward_max: 3.363543305102553\n","episode_reward_mean: -49.85007913492453\n","episode_reward_min: -207.49439932862208\n","episodes_this_iter: 36\n","episodes_total: 429\n","experiment_id: 9ff33c87e168401f88c3645a3dfee3af\n","hostname: 2783ca1d819b\n","info:\n","  learner:\n","    default_policy:\n","      custom_metrics: {}\n","      learner_stats:\n","        cur_kl_coeff: 0.20000000298023224\n","        cur_lr: 4.999999873689376e-05\n","        entropy: 1.1451972723007202\n","        entropy_coeff: 0.0\n","        kl: 0.010127299465239048\n","        model: {}\n","        policy_loss: -0.013139862567186356\n","        total_loss: 1348.7403564453125\n","        vf_explained_var: -0.00012743780098389834\n","        vf_loss: 1348.7513427734375\n","  num_agent_steps_sampled: 40000\n","  num_agent_steps_trained: 40000\n","  num_steps_sampled: 40000\n","  num_steps_trained: 40000\n","  num_steps_trained_this_iter: 4000\n","iterations_since_restore: 10\n","node_ip: 172.28.0.2\n","num_healthy_workers: 1\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 4.988888888888889\n","  ram_util_percent: 11.4\n","pid: 179\n","policy_reward_max: {}\n","policy_reward_mean: {}\n","policy_reward_min: {}\n","sampler_perf:\n","  mean_action_processing_ms: 0.06899227294706167\n","  mean_env_render_ms: 0.0\n","  mean_env_wait_ms: 0.2440956835737847\n","  mean_inference_ms: 0.6691788797588265\n","  mean_raw_obs_processing_ms: 0.10771411953112338\n","time_since_restore: 68.94235181808472\n","time_this_iter_s: 6.741634130477905\n","time_total_s: 68.94235181808472\n","timers:\n","  learn_throughput: 1630.489\n","  learn_time_ms: 2453.251\n","  load_throughput: 8633808.152\n","  load_time_ms: 0.463\n","  sample_throughput: 598.509\n","  sample_time_ms: 6683.276\n","  update_time_ms: 3.22\n","timestamp: 1649863062\n","timesteps_since_restore: 40000\n","timesteps_this_iter: 4000\n","timesteps_total: 40000\n","training_iteration: 10\n","trial_id: default\n","\n"]}]},{"cell_type":"code","source":["import ray\n","from ray import tune\n","\n","tune.run(\n","    \"PPO\",\n","    config={\n","        \"env\": \"LunarLander-v2\",\n","        \"num_gpus\": 0,\n","        \"num_workers\": 1,\n","        \"lr\": tune.grid_search([0.01, 0.001, 0.0001]),\n","    },\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"UEFWSr9EcQEg","executionInfo":{"status":"ok","timestamp":1649864415977,"user_tz":-60,"elapsed":1354535,"user":{"displayName":"k Yuichi","userId":"17236341909464291729"}},"outputId":"fa03064c-029b-48dd-ac51-817e8403001b"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[2m\u001b[36m(PPOTrainer pid=608)\u001b[0m 2022-04-13 15:17:53,665\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(PPOTrainer pid=608)\u001b[0m 2022-04-13 15:17:53,666\tINFO ppo.py:250 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n","\u001b[2m\u001b[36m(PPOTrainer pid=608)\u001b[0m 2022-04-13 15:17:53,666\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:17:59 (running for 00:00:09.51)<br>Memory usage on this node: 4.6/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (2 PENDING, 1 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.001 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.0001</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[2m\u001b[36m(PPOTrainer pid=608)\u001b[0m 2022-04-13 15:17:59,316\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(PPOTrainer pid=604)\u001b[0m 2022-04-13 15:18:03,177\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(PPOTrainer pid=604)\u001b[0m 2022-04-13 15:18:03,178\tINFO ppo.py:250 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n","\u001b[2m\u001b[36m(PPOTrainer pid=604)\u001b[0m 2022-04-13 15:18:03,178\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n","\u001b[2m\u001b[36m(PPOTrainer pid=608)\u001b[0m 2022-04-13 15:18:03,868\tWARNING deprecation.py:46 -- DeprecationWarning: `slice` has been deprecated. Use `SampleBatch[start:stop]` instead. This will raise an error in the future!\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:18:08 (running for 00:00:19.06)<br>Memory usage on this node: 5.2/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (1 PENDING, 2 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.0001</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[2m\u001b[36m(PPOTrainer pid=604)\u001b[0m 2022-04-13 15:18:08,861\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(PPOTrainer pid=601)\u001b[0m 2022-04-13 15:18:12,828\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n","\u001b[2m\u001b[36m(PPOTrainer pid=601)\u001b[0m 2022-04-13 15:18:12,829\tINFO ppo.py:250 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n","\u001b[2m\u001b[36m(PPOTrainer pid=601)\u001b[0m 2022-04-13 15:18:12,829\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n","\u001b[2m\u001b[36m(PPOTrainer pid=604)\u001b[0m 2022-04-13 15:18:13,313\tWARNING deprecation.py:46 -- DeprecationWarning: `slice` has been deprecated. Use `SampleBatch[start:stop]` instead. This will raise an error in the future!\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:18:18 (running for 00:00:29.03)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 4000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-18-15\n","  done: false\n","  episode_len_mean: 94.26190476190476\n","  episode_media: {}\n","  episode_reward_max: 28.228435891723137\n","  episode_reward_mean: -186.8297663811089\n","  episode_reward_min: -428.9795016425371\n","  episodes_this_iter: 42\n","  episodes_total: 42\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.20000000298023224\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.3698352575302124\n","          entropy_coeff: 0.0\n","          kl: 0.01644648239016533\n","          model: {}\n","          policy_loss: -0.009474735707044601\n","          total_loss: 8529.9306640625\n","          vf_explained_var: -0.001211304566822946\n","          vf_loss: 8529.9365234375\n","    num_agent_steps_sampled: 4000\n","    num_agent_steps_trained: 4000\n","    num_steps_sampled: 4000\n","    num_steps_trained: 4000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 1\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 7.236363636363635\n","    ram_util_percent: 15.454545454545455\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06762536517741291\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2489225234546771\n","    mean_inference_ms: 0.665993906205608\n","    mean_raw_obs_processing_ms: 0.10772682195662024\n","  time_since_restore: 7.015735149383545\n","  time_this_iter_s: 7.015735149383545\n","  time_total_s: 7.015735149383545\n","  timers:\n","    learn_throughput: 1561.393\n","    learn_time_ms: 2561.816\n","    load_throughput: 10267574.051\n","    load_time_ms: 0.39\n","    sample_throughput: 898.484\n","    sample_time_ms: 4451.944\n","    update_time_ms: 3.153\n","  timestamp: 1649863095\n","  timesteps_since_restore: 4000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 4000\n","  training_iteration: 1\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:18:18 (running for 00:00:29.07)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.01574</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\"> -186.83</td><td style=\"text-align: right;\">             28.2284</td><td style=\"text-align: right;\">             -428.98</td><td style=\"text-align: right;\">           94.2619</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 4000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-18-06\n","  done: false\n","  episode_len_mean: 90.72093023255815\n","  episode_media: {}\n","  episode_reward_max: 26.661148648272345\n","  episode_reward_mean: -178.80111803341228\n","  episode_reward_min: -458.8611678036421\n","  episodes_this_iter: 43\n","  episodes_total: 43\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.20000000298023224\n","          cur_lr: 0.009999999776482582\n","          entropy: 1.232786774635315\n","          entropy_coeff: 0.0\n","          kl: 0.19931147992610931\n","          model: {}\n","          policy_loss: 0.07809796929359436\n","          total_loss: 8194.54296875\n","          vf_explained_var: -0.0001835773728089407\n","          vf_loss: 8194.4248046875\n","    num_agent_steps_sampled: 4000\n","    num_agent_steps_trained: 4000\n","    num_steps_sampled: 4000\n","    num_steps_trained: 4000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 1\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 7.036363636363637\n","    ram_util_percent: 13.8\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06619753524143378\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2505208992475391\n","    mean_inference_ms: 0.6914616107821494\n","    mean_raw_obs_processing_ms: 0.10855893318845582\n","  time_since_restore: 7.175666093826294\n","  time_this_iter_s: 7.175666093826294\n","  time_total_s: 7.175666093826294\n","  timers:\n","    learn_throughput: 1529.592\n","    learn_time_ms: 2615.076\n","    load_throughput: 10936907.432\n","    load_time_ms: 0.366\n","    sample_throughput: 878.549\n","    sample_time_ms: 4552.96\n","    update_time_ms: 2.381\n","  timestamp: 1649863086\n","  timesteps_since_restore: 4000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 4000\n","  training_iteration: 1\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"stream","name":"stderr","text":["\u001b[2m\u001b[36m(PPOTrainer pid=601)\u001b[0m 2022-04-13 15:18:18,827\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n","\u001b[2m\u001b[36m(PPOTrainer pid=601)\u001b[0m 2022-04-13 15:18:23,645\tWARNING deprecation.py:46 -- DeprecationWarning: `slice` has been deprecated. Use `SampleBatch[start:stop]` instead. This will raise an error in the future!\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:18:23 (running for 00:00:34.18)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.17567</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\">-178.801</td><td style=\"text-align: right;\">             26.6611</td><td style=\"text-align: right;\">            -458.861</td><td style=\"text-align: right;\">           90.7209</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.01574</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\">-186.83 </td><td style=\"text-align: right;\">             28.2284</td><td style=\"text-align: right;\">            -428.98 </td><td style=\"text-align: right;\">           94.2619</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 8000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-18-25\n","  done: false\n","  episode_len_mean: 94.10588235294118\n","  episode_media: {}\n","  episode_reward_max: 28.228435891723137\n","  episode_reward_mean: -156.98978386336486\n","  episode_reward_min: -428.9795016425371\n","  episodes_this_iter: 43\n","  episodes_total: 85\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.20000000298023224\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.3543466329574585\n","          entropy_coeff: 0.0\n","          kl: 0.015890225768089294\n","          model: {}\n","          policy_loss: -0.025181345641613007\n","          total_loss: 2864.295166015625\n","          vf_explained_var: -0.0007374089327640831\n","          vf_loss: 2864.317138671875\n","    num_agent_steps_sampled: 8000\n","    num_agent_steps_trained: 8000\n","    num_steps_sampled: 8000\n","    num_steps_trained: 8000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 2\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 10.685714285714285\n","    ram_util_percent: 16.38571428571429\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06769568270814733\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.24919670085555135\n","    mean_inference_ms: 0.6665301752219115\n","    mean_raw_obs_processing_ms: 0.10787513836858537\n","  time_since_restore: 14.126539707183838\n","  time_this_iter_s: 7.110804557800293\n","  time_total_s: 14.126539707183838\n","  timers:\n","    learn_throughput: 1532.641\n","    learn_time_ms: 2609.875\n","    load_throughput: 10314919.152\n","    load_time_ms: 0.388\n","    sample_throughput: 553.135\n","    sample_time_ms: 7231.503\n","    update_time_ms: 3.303\n","  timestamp: 1649863105\n","  timesteps_since_restore: 8000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 8000\n","  training_iteration: 2\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 8000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-18-26\n","  done: false\n","  episode_len_mean: 93.98823529411764\n","  episode_media: {}\n","  episode_reward_max: 26.661148648272345\n","  episode_reward_mean: -266.7489078291401\n","  episode_reward_min: -628.681080261533\n","  episodes_this_iter: 42\n","  episodes_total: 85\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.30000001192092896\n","          cur_lr: 0.009999999776482582\n","          entropy: 1.182176947593689\n","          entropy_coeff: 0.0\n","          kl: 0.11020269989967346\n","          model: {}\n","          policy_loss: 0.049876321107149124\n","          total_loss: 27494.91796875\n","          vf_explained_var: 4.3318927055224776e-05\n","          vf_loss: 27494.833984375\n","    num_agent_steps_sampled: 8000\n","    num_agent_steps_trained: 8000\n","    num_steps_sampled: 8000\n","    num_steps_trained: 8000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 2\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 8.892857142857144\n","    ram_util_percent: 15.857142857142852\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06644389231018653\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2507648873436888\n","    mean_inference_ms: 0.6925855712556468\n","    mean_raw_obs_processing_ms: 0.10869189587173408\n","  time_since_restore: 14.46340560913086\n","  time_this_iter_s: 7.287739515304565\n","  time_total_s: 14.46340560913086\n","  timers:\n","    learn_throughput: 1499.979\n","    learn_time_ms: 2666.704\n","    load_throughput: 10485760.0\n","    load_time_ms: 0.381\n","    sample_throughput: 330.936\n","    sample_time_ms: 12086.927\n","    update_time_ms: 2.729\n","  timestamp: 1649863106\n","  timesteps_since_restore: 8000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 8000\n","  training_iteration: 2\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 4000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-18-26\n","  done: false\n","  episode_len_mean: 93.57142857142857\n","  episode_media: {}\n","  episode_reward_max: -68.15826898279985\n","  episode_reward_mean: -219.6297903287107\n","  episode_reward_min: -463.6983594094048\n","  episodes_this_iter: 42\n","  episodes_total: 42\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.20000000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 1.368234634399414\n","          entropy_coeff: 0.0\n","          kl: 0.0183393731713295\n","          model: {}\n","          policy_loss: -0.003913606982678175\n","          total_loss: 12633.3330078125\n","          vf_explained_var: -0.002872997894883156\n","          vf_loss: 12633.3330078125\n","    num_agent_steps_sampled: 4000\n","    num_agent_steps_trained: 4000\n","    num_steps_sampled: 4000\n","    num_steps_trained: 4000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 1\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.245454545454544\n","    ram_util_percent: 16.400000000000002\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07320880532354095\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2648714809708523\n","    mean_inference_ms: 0.7267400521810159\n","    mean_raw_obs_processing_ms: 0.11556567444976526\n","  time_since_restore: 7.690065145492554\n","  time_this_iter_s: 7.690065145492554\n","  time_total_s: 7.690065145492554\n","  timers:\n","    learn_throughput: 1393.736\n","    learn_time_ms: 2869.985\n","    load_throughput: 9228391.639\n","    load_time_ms: 0.433\n","    sample_throughput: 830.088\n","    sample_time_ms: 4818.767\n","    update_time_ms: 2.875\n","  timestamp: 1649863106\n","  timesteps_since_restore: 4000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 4000\n","  training_iteration: 1\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:18:29 (running for 00:00:39.81)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        14.4634 </td><td style=\"text-align: right;\">8000</td><td style=\"text-align: right;\">-266.749</td><td style=\"text-align: right;\">             26.6611</td><td style=\"text-align: right;\">            -628.681</td><td style=\"text-align: right;\">           93.9882</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        14.1265 </td><td style=\"text-align: right;\">8000</td><td style=\"text-align: right;\">-156.99 </td><td style=\"text-align: right;\">             28.2284</td><td style=\"text-align: right;\">            -428.98 </td><td style=\"text-align: right;\">           94.1059</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.69007</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\">-219.63 </td><td style=\"text-align: right;\">            -68.1583</td><td style=\"text-align: right;\">            -463.698</td><td style=\"text-align: right;\">           93.5714</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 12000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-18-33\n","  done: false\n","  episode_len_mean: 90.03\n","  episode_media: {}\n","  episode_reward_max: 28.228435891723137\n","  episode_reward_mean: -118.06953915239352\n","  episode_reward_min: -389.80754528038915\n","  episodes_this_iter: 46\n","  episodes_total: 131\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.20000000298023224\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.3245933055877686\n","          entropy_coeff: 0.0\n","          kl: 0.020377805456519127\n","          model: {}\n","          policy_loss: -0.017879819497466087\n","          total_loss: 1388.7783203125\n","          vf_explained_var: 2.1180734620429575e-05\n","          vf_loss: 1388.792236328125\n","    num_agent_steps_sampled: 12000\n","    num_agent_steps_trained: 12000\n","    num_steps_sampled: 12000\n","    num_steps_trained: 12000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 3\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.35\n","    ram_util_percent: 16.4\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06796794131323805\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.24895302696824392\n","    mean_inference_ms: 0.6730665120045516\n","    mean_raw_obs_processing_ms: 0.10833091075935805\n","  time_since_restore: 21.332792282104492\n","  time_this_iter_s: 7.206252574920654\n","  time_total_s: 21.332792282104492\n","  timers:\n","    learn_throughput: 1536.569\n","    learn_time_ms: 2603.202\n","    load_throughput: 10244585.386\n","    load_time_ms: 0.39\n","    sample_throughput: 551.061\n","    sample_time_ms: 7258.727\n","    update_time_ms: 3.086\n","  timestamp: 1649863113\n","  timesteps_since_restore: 12000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 12000\n","  training_iteration: 3\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 12000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-18-33\n","  done: false\n","  episode_len_mean: 94.99\n","  episode_media: {}\n","  episode_reward_max: 10.719933278499639\n","  episode_reward_mean: -302.9925148013757\n","  episode_reward_min: -628.681080261533\n","  episodes_this_iter: 41\n","  episodes_total: 126\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.44999998807907104\n","          cur_lr: 0.009999999776482582\n","          entropy: 1.1068227291107178\n","          entropy_coeff: 0.0\n","          kl: 0.09982521086931229\n","          model: {}\n","          policy_loss: 0.04558626562356949\n","          total_loss: 17439.494140625\n","          vf_explained_var: -1.0580593880149536e-05\n","          vf_loss: 17439.404296875\n","    num_agent_steps_sampled: 12000\n","    num_agent_steps_trained: 12000\n","    num_steps_sampled: 12000\n","    num_steps_trained: 12000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 3\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.319999999999999\n","    ram_util_percent: 16.4\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06670830879608446\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.24872451147264513\n","    mean_inference_ms: 0.691811581815414\n","    mean_raw_obs_processing_ms: 0.10878714751349453\n","  time_since_restore: 21.530633687973022\n","  time_this_iter_s: 7.067228078842163\n","  time_total_s: 21.530633687973022\n","  timers:\n","    learn_throughput: 1508.897\n","    learn_time_ms: 2650.944\n","    load_throughput: 10153650.999\n","    load_time_ms: 0.394\n","    sample_throughput: 382.378\n","    sample_time_ms: 10460.857\n","    update_time_ms: 2.664\n","  timestamp: 1649863113\n","  timesteps_since_restore: 12000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 12000\n","  training_iteration: 3\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 8000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-18-34\n","  done: false\n","  episode_len_mean: 92.87058823529412\n","  episode_media: {}\n","  episode_reward_max: -57.90614746693773\n","  episode_reward_mean: -173.24721662887742\n","  episode_reward_min: -463.6983594094048\n","  episodes_this_iter: 43\n","  episodes_total: 85\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.20000000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 1.3527048826217651\n","          entropy_coeff: 0.0\n","          kl: 0.008746050298213959\n","          model: {}\n","          policy_loss: 0.01361691765487194\n","          total_loss: 3943.285400390625\n","          vf_explained_var: -0.011647731997072697\n","          vf_loss: 3943.270263671875\n","    num_agent_steps_sampled: 8000\n","    num_agent_steps_trained: 8000\n","    num_steps_sampled: 8000\n","    num_steps_trained: 8000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 2\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.981818181818182\n","    ram_util_percent: 16.400000000000002\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07424738481180311\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2673318634989039\n","    mean_inference_ms: 0.7333774998674918\n","    mean_raw_obs_processing_ms: 0.11716776689964092\n","  time_since_restore: 15.233716487884521\n","  time_this_iter_s: 7.543651342391968\n","  time_total_s: 15.233716487884521\n","  timers:\n","    learn_throughput: 1473.648\n","    learn_time_ms: 2714.353\n","    load_throughput: 8430761.809\n","    load_time_ms: 0.474\n","    sample_throughput: 629.7\n","    sample_time_ms: 6352.227\n","    update_time_ms: 2.6\n","  timestamp: 1649863114\n","  timesteps_since_restore: 8000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 8000\n","  training_iteration: 2\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:18:35 (running for 00:00:45.32)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         21.5306</td><td style=\"text-align: right;\">12000</td><td style=\"text-align: right;\">-302.993</td><td style=\"text-align: right;\">             10.7199</td><td style=\"text-align: right;\">            -628.681</td><td style=\"text-align: right;\">           94.99  </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         21.3328</td><td style=\"text-align: right;\">12000</td><td style=\"text-align: right;\">-118.07 </td><td style=\"text-align: right;\">             28.2284</td><td style=\"text-align: right;\">            -389.808</td><td style=\"text-align: right;\">           90.03  </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         15.2337</td><td style=\"text-align: right;\"> 8000</td><td style=\"text-align: right;\">-173.247</td><td style=\"text-align: right;\">            -57.9061</td><td style=\"text-align: right;\">            -463.698</td><td style=\"text-align: right;\">           92.8706</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:18:40 (running for 00:00:50.42)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         21.5306</td><td style=\"text-align: right;\">12000</td><td style=\"text-align: right;\">-302.993</td><td style=\"text-align: right;\">             10.7199</td><td style=\"text-align: right;\">            -628.681</td><td style=\"text-align: right;\">           94.99  </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         21.3328</td><td style=\"text-align: right;\">12000</td><td style=\"text-align: right;\">-118.07 </td><td style=\"text-align: right;\">             28.2284</td><td style=\"text-align: right;\">            -389.808</td><td style=\"text-align: right;\">           90.03  </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         15.2337</td><td style=\"text-align: right;\"> 8000</td><td style=\"text-align: right;\">-173.247</td><td style=\"text-align: right;\">            -57.9061</td><td style=\"text-align: right;\">            -463.698</td><td style=\"text-align: right;\">           92.8706</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 16000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-18-40\n","  done: false\n","  episode_len_mean: 90.94\n","  episode_media: {}\n","  episode_reward_max: 5.8650244846787984\n","  episode_reward_mean: -88.62449059789016\n","  episode_reward_min: -250.47410314594057\n","  episodes_this_iter: 41\n","  episodes_total: 172\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.30000001192092896\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.3038382530212402\n","          entropy_coeff: 0.0\n","          kl: 0.01666807010769844\n","          model: {}\n","          policy_loss: -0.023974917829036713\n","          total_loss: 893.8885498046875\n","          vf_explained_var: 0.08452312648296356\n","          vf_loss: 893.9075317382812\n","    num_agent_steps_sampled: 16000\n","    num_agent_steps_trained: 16000\n","    num_steps_sampled: 16000\n","    num_steps_trained: 16000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 4\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 15.109090909090908\n","    ram_util_percent: 16.44545454545454\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.068326563756536\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.24998332672596377\n","    mean_inference_ms: 0.6795449335640802\n","    mean_raw_obs_processing_ms: 0.1089255768126457\n","  time_since_restore: 28.529225826263428\n","  time_this_iter_s: 7.1964335441589355\n","  time_total_s: 28.529225826263428\n","  timers:\n","    learn_throughput: 1538.235\n","    learn_time_ms: 2600.382\n","    load_throughput: 10245628.092\n","    load_time_ms: 0.39\n","    sample_throughput: 551.226\n","    sample_time_ms: 7256.553\n","    update_time_ms: 3.078\n","  timestamp: 1649863120\n","  timesteps_since_restore: 16000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 16000\n","  training_iteration: 4\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 16000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-18-40\n","  done: false\n","  episode_len_mean: 98.34\n","  episode_media: {}\n","  episode_reward_max: 2.332571398882166\n","  episode_reward_mean: -314.5581881438492\n","  episode_reward_min: -628.681080261533\n","  episodes_this_iter: 40\n","  episodes_total: 166\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.675000011920929\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.8922367095947266\n","          entropy_coeff: 0.0\n","          kl: 0.05603184178471565\n","          model: {}\n","          policy_loss: 0.018562234938144684\n","          total_loss: 12018.48828125\n","          vf_explained_var: 0.00034318052348680794\n","          vf_loss: 12018.4326171875\n","    num_agent_steps_sampled: 16000\n","    num_agent_steps_trained: 16000\n","    num_steps_sampled: 16000\n","    num_steps_trained: 16000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 4\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.9\n","    ram_util_percent: 16.439999999999998\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06726370449449418\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.24491448154534448\n","    mean_inference_ms: 0.6932991528639337\n","    mean_raw_obs_processing_ms: 0.10911974304315301\n","  time_since_restore: 28.775554418563843\n","  time_this_iter_s: 7.24492073059082\n","  time_total_s: 28.775554418563843\n","  timers:\n","    learn_throughput: 1506.913\n","    learn_time_ms: 2654.433\n","    load_throughput: 10058282.974\n","    load_time_ms: 0.398\n","    sample_throughput: 414.252\n","    sample_time_ms: 9655.96\n","    update_time_ms: 2.623\n","  timestamp: 1649863120\n","  timesteps_since_restore: 16000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 16000\n","  training_iteration: 4\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 12000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-18-41\n","  done: false\n","  episode_len_mean: 93.15\n","  episode_media: {}\n","  episode_reward_max: 14.15891846076751\n","  episode_reward_mean: -140.65174740860823\n","  episode_reward_min: -463.6983594094048\n","  episodes_this_iter: 44\n","  episodes_total: 129\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.20000000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 1.3415828943252563\n","          entropy_coeff: 0.0\n","          kl: 0.015282596461474895\n","          model: {}\n","          policy_loss: -0.011277816258370876\n","          total_loss: 3126.959716796875\n","          vf_explained_var: -0.0022116240579634905\n","          vf_loss: 3126.9677734375\n","    num_agent_steps_sampled: 12000\n","    num_agent_steps_trained: 12000\n","    num_steps_sampled: 12000\n","    num_steps_trained: 12000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 3\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.409090909090908\n","    ram_util_percent: 16.44545454545454\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07549416452011876\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2705453689432519\n","    mean_inference_ms: 0.741394746067893\n","    mean_raw_obs_processing_ms: 0.11864019821563059\n","  time_since_restore: 22.80765700340271\n","  time_this_iter_s: 7.5739405155181885\n","  time_total_s: 22.80765700340271\n","  timers:\n","    learn_throughput: 1507.467\n","    learn_time_ms: 2653.458\n","    load_throughput: 8640626.266\n","    load_time_ms: 0.463\n","    sample_throughput: 590.037\n","    sample_time_ms: 6779.24\n","    update_time_ms: 2.51\n","  timestamp: 1649863121\n","  timesteps_since_restore: 12000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 12000\n","  training_iteration: 3\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:18:45 (running for 00:00:55.94)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         28.7756</td><td style=\"text-align: right;\">16000</td><td style=\"text-align: right;\">-314.558 </td><td style=\"text-align: right;\">             2.33257</td><td style=\"text-align: right;\">            -628.681</td><td style=\"text-align: right;\">             98.34</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         28.5292</td><td style=\"text-align: right;\">16000</td><td style=\"text-align: right;\"> -88.6245</td><td style=\"text-align: right;\">             5.86502</td><td style=\"text-align: right;\">            -250.474</td><td style=\"text-align: right;\">             90.94</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         22.8077</td><td style=\"text-align: right;\">12000</td><td style=\"text-align: right;\">-140.652 </td><td style=\"text-align: right;\">            14.1589 </td><td style=\"text-align: right;\">            -463.698</td><td style=\"text-align: right;\">             93.15</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 20000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-18-47\n","  done: false\n","  episode_len_mean: 95.07\n","  episode_media: {}\n","  episode_reward_max: -2.832481329647024\n","  episode_reward_mean: -72.09286455011868\n","  episode_reward_min: -200.47966009659905\n","  episodes_this_iter: 41\n","  episodes_total: 213\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.30000001192092896\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.2598003149032593\n","          entropy_coeff: 0.0\n","          kl: 0.02017286792397499\n","          model: {}\n","          policy_loss: -0.033441297709941864\n","          total_loss: 626.0748901367188\n","          vf_explained_var: 0.4178558588027954\n","          vf_loss: 626.102294921875\n","    num_agent_steps_sampled: 20000\n","    num_agent_steps_trained: 20000\n","    num_steps_sampled: 20000\n","    num_steps_trained: 20000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 5\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.569999999999999\n","    ram_util_percent: 16.5\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0686364307825598\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.252004124507307\n","    mean_inference_ms: 0.6826906519434055\n","    mean_raw_obs_processing_ms: 0.10933700086927554\n","  time_since_restore: 35.72657036781311\n","  time_this_iter_s: 7.197344541549683\n","  time_total_s: 35.72657036781311\n","  timers:\n","    learn_throughput: 1537.972\n","    learn_time_ms: 2600.828\n","    load_throughput: 9591365.196\n","    load_time_ms: 0.417\n","    sample_throughput: 551.614\n","    sample_time_ms: 7251.441\n","    update_time_ms: 3.092\n","  timestamp: 1649863127\n","  timesteps_since_restore: 20000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 20000\n","  training_iteration: 5\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 20000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-18-47\n","  done: false\n","  episode_len_mean: 96.43\n","  episode_media: {}\n","  episode_reward_max: 2.332571398882166\n","  episode_reward_mean: -242.45879007917318\n","  episode_reward_min: -546.0366993017234\n","  episodes_this_iter: 43\n","  episodes_total: 209\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.8564329743385315\n","          entropy_coeff: 0.0\n","          kl: 0.04158635064959526\n","          model: {}\n","          policy_loss: -0.00011310602712910622\n","          total_loss: 5381.6494140625\n","          vf_explained_var: 0.02946893498301506\n","          vf_loss: 5381.607421875\n","    num_agent_steps_sampled: 20000\n","    num_agent_steps_trained: 20000\n","    num_steps_sampled: 20000\n","    num_steps_trained: 20000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 5\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 15.709090909090907\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06779279675272058\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.23909489345820448\n","    mean_inference_ms: 0.6959037593465248\n","    mean_raw_obs_processing_ms: 0.10951387772649125\n","  time_since_restore: 35.88871097564697\n","  time_this_iter_s: 7.11315655708313\n","  time_total_s: 35.88871097564697\n","  timers:\n","    learn_throughput: 1503.735\n","    learn_time_ms: 2660.044\n","    load_throughput: 9662068.648\n","    load_time_ms: 0.414\n","    sample_throughput: 437.055\n","    sample_time_ms: 9152.163\n","    update_time_ms: 2.676\n","  timestamp: 1649863127\n","  timesteps_since_restore: 20000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 20000\n","  training_iteration: 5\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 16000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-18-49\n","  done: false\n","  episode_len_mean: 91.22\n","  episode_media: {}\n","  episode_reward_max: 14.15891846076751\n","  episode_reward_mean: -109.4688714615271\n","  episode_reward_min: -287.5318419314088\n","  episodes_this_iter: 44\n","  episodes_total: 173\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.20000000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 1.3069998025894165\n","          entropy_coeff: 0.0\n","          kl: 0.01626279205083847\n","          model: {}\n","          policy_loss: -0.006663928274065256\n","          total_loss: 1091.958740234375\n","          vf_explained_var: -6.187308463267982e-05\n","          vf_loss: 1091.9622802734375\n","    num_agent_steps_sampled: 16000\n","    num_agent_steps_trained: 16000\n","    num_steps_sampled: 16000\n","    num_steps_trained: 16000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 4\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.872727272727273\n","    ram_util_percent: 16.5\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07605666118369137\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.27163041634906043\n","    mean_inference_ms: 0.7437035980526128\n","    mean_raw_obs_processing_ms: 0.1191230979800768\n","  time_since_restore: 30.1222882270813\n","  time_this_iter_s: 7.314631223678589\n","  time_total_s: 30.1222882270813\n","  timers:\n","    learn_throughput: 1526.694\n","    learn_time_ms: 2620.04\n","    load_throughput: 8943078.891\n","    load_time_ms: 0.447\n","    sample_throughput: 577.387\n","    sample_time_ms: 6927.766\n","    update_time_ms: 2.51\n","  timestamp: 1649863129\n","  timesteps_since_restore: 16000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 16000\n","  training_iteration: 4\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:18:51 (running for 00:01:01.38)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         35.8887</td><td style=\"text-align: right;\">20000</td><td style=\"text-align: right;\">-242.459 </td><td style=\"text-align: right;\">             2.33257</td><td style=\"text-align: right;\">            -546.037</td><td style=\"text-align: right;\">             96.43</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         35.7266</td><td style=\"text-align: right;\">20000</td><td style=\"text-align: right;\"> -72.0929</td><td style=\"text-align: right;\">            -2.83248</td><td style=\"text-align: right;\">            -200.48 </td><td style=\"text-align: right;\">             95.07</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         30.1223</td><td style=\"text-align: right;\">16000</td><td style=\"text-align: right;\">-109.469 </td><td style=\"text-align: right;\">            14.1589 </td><td style=\"text-align: right;\">            -287.532</td><td style=\"text-align: right;\">             91.22</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 24000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-18-55\n","  done: false\n","  episode_len_mean: 93.35\n","  episode_media: {}\n","  episode_reward_max: -6.802510745349878\n","  episode_reward_mean: -237.95918101104394\n","  episode_reward_min: -535.7740396757213\n","  episodes_this_iter: 44\n","  episodes_total: 253\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.5187499523162842\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.9657609462738037\n","          entropy_coeff: 0.0\n","          kl: 0.04038712754845619\n","          model: {}\n","          policy_loss: 0.018865536898374557\n","          total_loss: 11094.16015625\n","          vf_explained_var: 0.06041158735752106\n","          vf_loss: 11094.0791015625\n","    num_agent_steps_sampled: 24000\n","    num_agent_steps_trained: 24000\n","    num_steps_sampled: 24000\n","    num_steps_trained: 24000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 6\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.85\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06811012414004698\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.23502063687236494\n","    mean_inference_ms: 0.6978499534355492\n","    mean_raw_obs_processing_ms: 0.109880624568481\n","  time_since_restore: 43.25865697860718\n","  time_this_iter_s: 7.369946002960205\n","  time_total_s: 43.25865697860718\n","  timers:\n","    learn_throughput: 1486.741\n","    learn_time_ms: 2690.449\n","    load_throughput: 9078580.087\n","    load_time_ms: 0.441\n","    sample_throughput: 452.752\n","    sample_time_ms: 8834.859\n","    update_time_ms: 2.726\n","  timestamp: 1649863135\n","  timesteps_since_restore: 24000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 24000\n","  training_iteration: 6\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 24000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-18-55\n","  done: false\n","  episode_len_mean: 101.98\n","  episode_media: {}\n","  episode_reward_max: 24.906278053031727\n","  episode_reward_mean: -62.611993839326004\n","  episode_reward_min: -200.47966009659905\n","  episodes_this_iter: 37\n","  episodes_total: 250\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.44999998807907104\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.199705719947815\n","          entropy_coeff: 0.0\n","          kl: 0.018399758264422417\n","          model: {}\n","          policy_loss: -0.036049820482730865\n","          total_loss: 610.2581176757812\n","          vf_explained_var: 0.5895872712135315\n","          vf_loss: 610.285888671875\n","    num_agent_steps_sampled: 24000\n","    num_agent_steps_trained: 24000\n","    num_steps_sampled: 24000\n","    num_steps_trained: 24000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 6\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 15.045454545454545\n","    ram_util_percent: 16.5\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0690014363515541\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.25532547618178064\n","    mean_inference_ms: 0.6856839818034061\n","    mean_raw_obs_processing_ms: 0.10971986060458289\n","  time_since_restore: 43.36930251121521\n","  time_this_iter_s: 7.6427321434021\n","  time_total_s: 43.36930251121521\n","  timers:\n","    learn_throughput: 1518.15\n","    learn_time_ms: 2634.786\n","    load_throughput: 9605276.336\n","    load_time_ms: 0.416\n","    sample_throughput: 548.774\n","    sample_time_ms: 7288.973\n","    update_time_ms: 3.067\n","  timestamp: 1649863135\n","  timesteps_since_restore: 24000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 24000\n","  training_iteration: 6\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:18:56 (running for 00:01:06.64)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         43.2587</td><td style=\"text-align: right;\">24000</td><td style=\"text-align: right;\">-237.959</td><td style=\"text-align: right;\">            -6.80251</td><td style=\"text-align: right;\">            -535.774</td><td style=\"text-align: right;\">             93.35</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         43.3693</td><td style=\"text-align: right;\">24000</td><td style=\"text-align: right;\"> -62.612</td><td style=\"text-align: right;\">            24.9063 </td><td style=\"text-align: right;\">            -200.48 </td><td style=\"text-align: right;\">            101.98</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         30.1223</td><td style=\"text-align: right;\">16000</td><td style=\"text-align: right;\">-109.469</td><td style=\"text-align: right;\">            14.1589 </td><td style=\"text-align: right;\">            -287.532</td><td style=\"text-align: right;\">             91.22</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 20000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-18-56\n","  done: false\n","  episode_len_mean: 92.71\n","  episode_media: {}\n","  episode_reward_max: 26.36506480021194\n","  episode_reward_mean: -96.3798486207219\n","  episode_reward_min: -331.3403702257293\n","  episodes_this_iter: 42\n","  episodes_total: 215\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.20000000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 1.249690055847168\n","          entropy_coeff: 0.0\n","          kl: 0.015953222289681435\n","          model: {}\n","          policy_loss: -0.021185021847486496\n","          total_loss: 1033.41650390625\n","          vf_explained_var: -0.0022934344597160816\n","          vf_loss: 1033.4344482421875\n","    num_agent_steps_sampled: 20000\n","    num_agent_steps_trained: 20000\n","    num_steps_sampled: 20000\n","    num_steps_trained: 20000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 5\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.709999999999999\n","    ram_util_percent: 16.5\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07582136986528738\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2709477346331753\n","    mean_inference_ms: 0.7415394147943766\n","    mean_raw_obs_processing_ms: 0.1187565082737403\n","  time_since_restore: 37.5881073474884\n","  time_this_iter_s: 7.4658191204071045\n","  time_total_s: 37.5881073474884\n","  timers:\n","    learn_throughput: 1527.733\n","    learn_time_ms: 2618.258\n","    load_throughput: 9114089.526\n","    load_time_ms: 0.439\n","    sample_throughput: 569.428\n","    sample_time_ms: 7024.591\n","    update_time_ms: 2.529\n","  timestamp: 1649863136\n","  timesteps_since_restore: 20000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 20000\n","  training_iteration: 5\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:19:01 (running for 00:01:11.88)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         43.2587</td><td style=\"text-align: right;\">24000</td><td style=\"text-align: right;\">-237.959 </td><td style=\"text-align: right;\">            -6.80251</td><td style=\"text-align: right;\">            -535.774</td><td style=\"text-align: right;\">             93.35</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         43.3693</td><td style=\"text-align: right;\">24000</td><td style=\"text-align: right;\"> -62.612 </td><td style=\"text-align: right;\">            24.9063 </td><td style=\"text-align: right;\">            -200.48 </td><td style=\"text-align: right;\">            101.98</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         37.5881</td><td style=\"text-align: right;\">20000</td><td style=\"text-align: right;\"> -96.3798</td><td style=\"text-align: right;\">            26.3651 </td><td style=\"text-align: right;\">            -331.34 </td><td style=\"text-align: right;\">             92.71</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 28000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-19-02\n","  done: false\n","  episode_len_mean: 87.54\n","  episode_media: {}\n","  episode_reward_max: -10.331802599170757\n","  episode_reward_mean: -224.2326368877142\n","  episode_reward_min: -535.7740396757213\n","  episodes_this_iter: 48\n","  episodes_total: 301\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 2.278125047683716\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.6063921451568604\n","          entropy_coeff: 0.0\n","          kl: 0.037142202258110046\n","          model: {}\n","          policy_loss: 0.008607479743659496\n","          total_loss: 2594.049072265625\n","          vf_explained_var: 0.22544227540493011\n","          vf_loss: 2593.956298828125\n","    num_agent_steps_sampled: 28000\n","    num_agent_steps_trained: 28000\n","    num_steps_sampled: 28000\n","    num_steps_trained: 28000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 7\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.11\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06832968459230891\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.23043041730279218\n","    mean_inference_ms: 0.6999549212464902\n","    mean_raw_obs_processing_ms: 0.11022531561831508\n","  time_since_restore: 50.24165940284729\n","  time_this_iter_s: 6.983002424240112\n","  time_total_s: 50.24165940284729\n","  timers:\n","    learn_throughput: 1497.844\n","    learn_time_ms: 2670.504\n","    load_throughput: 9248740.904\n","    load_time_ms: 0.432\n","    sample_throughput: 464.146\n","    sample_time_ms: 8617.969\n","    update_time_ms: 2.724\n","  timestamp: 1649863142\n","  timesteps_since_restore: 28000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 28000\n","  training_iteration: 7\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 28000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-19-04\n","  done: false\n","  episode_len_mean: 115.87\n","  episode_media: {}\n","  episode_reward_max: 51.35467298145145\n","  episode_reward_mean: -45.38546068148447\n","  episode_reward_min: -178.79245976968014\n","  episodes_this_iter: 27\n","  episodes_total: 277\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.44999998807907104\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.166463851928711\n","          entropy_coeff: 0.0\n","          kl: 0.01625770330429077\n","          model: {}\n","          policy_loss: -0.04660617187619209\n","          total_loss: 914.5790405273438\n","          vf_explained_var: 0.4938849210739136\n","          vf_loss: 914.6183471679688\n","    num_agent_steps_sampled: 28000\n","    num_agent_steps_trained: 28000\n","    num_steps_sampled: 28000\n","    num_steps_trained: 28000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 7\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.083333333333336\n","    ram_util_percent: 16.5\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06934403690763986\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.26919760871937926\n","    mean_inference_ms: 0.6896587512764747\n","    mean_raw_obs_processing_ms: 0.1099842271302337\n","  time_since_restore: 52.03984975814819\n","  time_this_iter_s: 8.670547246932983\n","  time_total_s: 52.03984975814819\n","  timers:\n","    learn_throughput: 1521.725\n","    learn_time_ms: 2628.595\n","    load_throughput: 9347382.362\n","    load_time_ms: 0.428\n","    sample_throughput: 531.692\n","    sample_time_ms: 7523.155\n","    update_time_ms: 3.119\n","  timestamp: 1649863144\n","  timesteps_since_restore: 28000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 28000\n","  training_iteration: 7\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 24000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-19-04\n","  done: false\n","  episode_len_mean: 98.04\n","  episode_media: {}\n","  episode_reward_max: 37.863465189458765\n","  episode_reward_mean: -84.51978140980631\n","  episode_reward_min: -338.1839186920269\n","  episodes_this_iter: 38\n","  episodes_total: 253\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.20000000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 1.238036870956421\n","          entropy_coeff: 0.0\n","          kl: 0.01089854259043932\n","          model: {}\n","          policy_loss: -0.008191346190869808\n","          total_loss: 2503.29150390625\n","          vf_explained_var: -0.022213447839021683\n","          vf_loss: 2503.29736328125\n","    num_agent_steps_sampled: 24000\n","    num_agent_steps_trained: 24000\n","    num_steps_sampled: 24000\n","    num_steps_trained: 24000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 6\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.954545454545455\n","    ram_util_percent: 16.5\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07546057373297593\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.27085347892442185\n","    mean_inference_ms: 0.7400006505540346\n","    mean_raw_obs_processing_ms: 0.11822697473602155\n","  time_since_restore: 45.26296138763428\n","  time_this_iter_s: 7.674854040145874\n","  time_total_s: 45.26296138763428\n","  timers:\n","    learn_throughput: 1510.568\n","    learn_time_ms: 2648.01\n","    load_throughput: 8894088.708\n","    load_time_ms: 0.45\n","    sample_throughput: 562.741\n","    sample_time_ms: 7108.064\n","    update_time_ms: 2.59\n","  timestamp: 1649863144\n","  timesteps_since_restore: 24000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 24000\n","  training_iteration: 6\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:19:07 (running for 00:01:17.51)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         50.2417</td><td style=\"text-align: right;\">28000</td><td style=\"text-align: right;\">-224.233 </td><td style=\"text-align: right;\">            -10.3318</td><td style=\"text-align: right;\">            -535.774</td><td style=\"text-align: right;\">             87.54</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         52.0398</td><td style=\"text-align: right;\">28000</td><td style=\"text-align: right;\"> -45.3855</td><td style=\"text-align: right;\">             51.3547</td><td style=\"text-align: right;\">            -178.792</td><td style=\"text-align: right;\">            115.87</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         45.263 </td><td style=\"text-align: right;\">24000</td><td style=\"text-align: right;\"> -84.5198</td><td style=\"text-align: right;\">             37.8635</td><td style=\"text-align: right;\">            -338.184</td><td style=\"text-align: right;\">             98.04</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 32000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-19-09\n","  done: false\n","  episode_len_mean: 82.65\n","  episode_media: {}\n","  episode_reward_max: -70.43528669682671\n","  episode_reward_mean: -178.595548060705\n","  episode_reward_min: -510.66625633273134\n","  episodes_this_iter: 49\n","  episodes_total: 350\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 3.417187452316284\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.6916742920875549\n","          entropy_coeff: 0.0\n","          kl: 0.0315868966281414\n","          model: {}\n","          policy_loss: 0.007508397568017244\n","          total_loss: 2183.100830078125\n","          vf_explained_var: 0.38983288407325745\n","          vf_loss: 2182.9853515625\n","    num_agent_steps_sampled: 32000\n","    num_agent_steps_trained: 32000\n","    num_steps_sampled: 32000\n","    num_steps_trained: 32000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 8\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.354545454545455\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06875726737687839\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.22529835056481864\n","    mean_inference_ms: 0.7058042007832487\n","    mean_raw_obs_processing_ms: 0.11092137664031144\n","  time_since_restore: 57.521605253219604\n","  time_this_iter_s: 7.2799458503723145\n","  time_total_s: 57.521605253219604\n","  timers:\n","    learn_throughput: 1505.965\n","    learn_time_ms: 2656.105\n","    load_throughput: 9296787.975\n","    load_time_ms: 0.43\n","    sample_throughput: 473.07\n","    sample_time_ms: 8455.4\n","    update_time_ms: 2.79\n","  timestamp: 1649863149\n","  timesteps_since_restore: 32000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 32000\n","  training_iteration: 8\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 32000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-19-11\n","  done: false\n","  episode_len_mean: 123.11\n","  episode_media: {}\n","  episode_reward_max: 51.35467298145145\n","  episode_reward_mean: -29.272706686141543\n","  episode_reward_min: -138.90106893731354\n","  episodes_this_iter: 34\n","  episodes_total: 311\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.44999998807907104\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.111158013343811\n","          entropy_coeff: 0.0\n","          kl: 0.017330698668956757\n","          model: {}\n","          policy_loss: -0.042837247252464294\n","          total_loss: 528.1013793945312\n","          vf_explained_var: 0.7268708348274231\n","          vf_loss: 528.1364135742188\n","    num_agent_steps_sampled: 32000\n","    num_agent_steps_trained: 32000\n","    num_steps_sampled: 32000\n","    num_steps_trained: 32000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 8\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.936363636363637\n","    ram_util_percent: 16.5\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06983188522136594\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.286113616593427\n","    mean_inference_ms: 0.6961012078634475\n","    mean_raw_obs_processing_ms: 0.11042252713021677\n","  time_since_restore: 59.635828256607056\n","  time_this_iter_s: 7.595978498458862\n","  time_total_s: 59.635828256607056\n","  timers:\n","    learn_throughput: 1523.601\n","    learn_time_ms: 2625.359\n","    load_throughput: 9479992.089\n","    load_time_ms: 0.422\n","    sample_throughput: 530.744\n","    sample_time_ms: 7536.593\n","    update_time_ms: 3.079\n","  timestamp: 1649863151\n","  timesteps_since_restore: 32000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 32000\n","  training_iteration: 8\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 28000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-19-12\n","  done: false\n","  episode_len_mean: 106.87\n","  episode_media: {}\n","  episode_reward_max: 37.863465189458765\n","  episode_reward_mean: -72.11841671161459\n","  episode_reward_min: -338.1839186920269\n","  episodes_this_iter: 25\n","  episodes_total: 278\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.20000000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 1.1714221239089966\n","          entropy_coeff: 0.0\n","          kl: 0.00881235208362341\n","          model: {}\n","          policy_loss: -0.013897356577217579\n","          total_loss: 1820.912109375\n","          vf_explained_var: 0.00861567072570324\n","          vf_loss: 1820.9241943359375\n","    num_agent_steps_sampled: 28000\n","    num_agent_steps_trained: 28000\n","    num_steps_sampled: 28000\n","    num_steps_trained: 28000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 7\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.225\n","    ram_util_percent: 16.5\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07527719652552069\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.27632410657013246\n","    mean_inference_ms: 0.740001747967994\n","    mean_raw_obs_processing_ms: 0.11781019896668266\n","  time_since_restore: 53.36749076843262\n","  time_this_iter_s: 8.10452938079834\n","  time_total_s: 53.36749076843262\n","  timers:\n","    learn_throughput: 1515.435\n","    learn_time_ms: 2639.506\n","    load_throughput: 9034580.506\n","    load_time_ms: 0.443\n","    sample_throughput: 548.965\n","    sample_time_ms: 7286.436\n","    update_time_ms: 2.583\n","  timestamp: 1649863152\n","  timesteps_since_restore: 28000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 28000\n","  training_iteration: 7\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:19:12 (running for 00:01:22.65)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         57.5216</td><td style=\"text-align: right;\">32000</td><td style=\"text-align: right;\">-178.596 </td><td style=\"text-align: right;\">            -70.4353</td><td style=\"text-align: right;\">            -510.666</td><td style=\"text-align: right;\">             82.65</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         59.6358</td><td style=\"text-align: right;\">32000</td><td style=\"text-align: right;\"> -29.2727</td><td style=\"text-align: right;\">             51.3547</td><td style=\"text-align: right;\">            -138.901</td><td style=\"text-align: right;\">            123.11</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         53.3675</td><td style=\"text-align: right;\">28000</td><td style=\"text-align: right;\"> -72.1184</td><td style=\"text-align: right;\">             37.8635</td><td style=\"text-align: right;\">            -338.184</td><td style=\"text-align: right;\">            106.87</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 36000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-19-16\n","  done: false\n","  episode_len_mean: 81.4\n","  episode_media: {}\n","  episode_reward_max: -11.658952144937473\n","  episode_reward_mean: -184.4831425930531\n","  episode_reward_min: -486.1677777616389\n","  episodes_this_iter: 49\n","  episodes_total: 399\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 5.125781059265137\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7564015984535217\n","          entropy_coeff: 0.0\n","          kl: 0.023030629381537437\n","          model: {}\n","          policy_loss: 0.006950438022613525\n","          total_loss: 1694.03466796875\n","          vf_explained_var: 0.25895437598228455\n","          vf_loss: 1693.90966796875\n","    num_agent_steps_sampled: 36000\n","    num_agent_steps_trained: 36000\n","    num_steps_sampled: 36000\n","    num_steps_trained: 36000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 9\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.24\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06933904587787498\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.22247010725645908\n","    mean_inference_ms: 0.7133503903913951\n","    mean_raw_obs_processing_ms: 0.11194786116906066\n","  time_since_restore: 64.76550197601318\n","  time_this_iter_s: 7.243896722793579\n","  time_total_s: 64.76550197601318\n","  timers:\n","    learn_throughput: 1517.074\n","    learn_time_ms: 2636.655\n","    load_throughput: 9411302.917\n","    load_time_ms: 0.425\n","    sample_throughput: 480.006\n","    sample_time_ms: 8333.228\n","    update_time_ms: 2.782\n","  timestamp: 1649863156\n","  timesteps_since_restore: 36000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 36000\n","  training_iteration: 9\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:19:17 (running for 00:01:28.03)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         64.7655</td><td style=\"text-align: right;\">36000</td><td style=\"text-align: right;\">-184.483 </td><td style=\"text-align: right;\">            -11.659 </td><td style=\"text-align: right;\">            -486.168</td><td style=\"text-align: right;\">             81.4 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         59.6358</td><td style=\"text-align: right;\">32000</td><td style=\"text-align: right;\"> -29.2727</td><td style=\"text-align: right;\">             51.3547</td><td style=\"text-align: right;\">            -138.901</td><td style=\"text-align: right;\">            123.11</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         53.3675</td><td style=\"text-align: right;\">28000</td><td style=\"text-align: right;\"> -72.1184</td><td style=\"text-align: right;\">             37.8635</td><td style=\"text-align: right;\">            -338.184</td><td style=\"text-align: right;\">            106.87</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 36000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-19-20\n","  done: false\n","  episode_len_mean: 137.44\n","  episode_media: {}\n","  episode_reward_max: 83.34404417662553\n","  episode_reward_mean: -22.354299920172565\n","  episode_reward_min: -319.1541031602992\n","  episodes_this_iter: 23\n","  episodes_total: 334\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.44999998807907104\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.1352709531784058\n","          entropy_coeff: 0.0\n","          kl: 0.02400701865553856\n","          model: {}\n","          policy_loss: -0.03468947857618332\n","          total_loss: 981.3302612304688\n","          vf_explained_var: 0.57994544506073\n","          vf_loss: 981.3541870117188\n","    num_agent_steps_sampled: 36000\n","    num_agent_steps_trained: 36000\n","    num_steps_sampled: 36000\n","    num_steps_trained: 36000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 9\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.19230769230769\n","    ram_util_percent: 16.5\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07011473751394333\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.306356859530365\n","    mean_inference_ms: 0.7002404918114893\n","    mean_raw_obs_processing_ms: 0.11063390701600533\n","  time_since_restore: 68.731924533844\n","  time_this_iter_s: 9.096096277236938\n","  time_total_s: 68.731924533844\n","  timers:\n","    learn_throughput: 1529.143\n","    learn_time_ms: 2615.845\n","    load_throughput: 9555432.477\n","    load_time_ms: 0.419\n","    sample_throughput: 518.044\n","    sample_time_ms: 7721.346\n","    update_time_ms: 3.047\n","  timestamp: 1649863160\n","  timesteps_since_restore: 36000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 36000\n","  training_iteration: 9\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 32000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-19-21\n","  done: false\n","  episode_len_mean: 134.93\n","  episode_media: {}\n","  episode_reward_max: 179.0541152047613\n","  episode_reward_mean: -56.28406639508634\n","  episode_reward_min: -338.1839186920269\n","  episodes_this_iter: 21\n","  episodes_total: 299\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.20000000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 1.1526474952697754\n","          entropy_coeff: 0.0\n","          kl: 0.008230745792388916\n","          model: {}\n","          policy_loss: -0.018199536949396133\n","          total_loss: 1229.8779296875\n","          vf_explained_var: -0.058512844145298004\n","          vf_loss: 1229.89453125\n","    num_agent_steps_sampled: 32000\n","    num_agent_steps_trained: 32000\n","    num_steps_sampled: 32000\n","    num_steps_trained: 32000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 8\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.184615384615382\n","    ram_util_percent: 16.5\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07518702835472196\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.29116998055716353\n","    mean_inference_ms: 0.7406523784617923\n","    mean_raw_obs_processing_ms: 0.1174413754510105\n","  time_since_restore: 62.51293134689331\n","  time_this_iter_s: 9.145440578460693\n","  time_total_s: 62.51293134689331\n","  timers:\n","    learn_throughput: 1521.127\n","    learn_time_ms: 2629.628\n","    load_throughput: 9149753.085\n","    load_time_ms: 0.437\n","    sample_throughput: 531.419\n","    sample_time_ms: 7527.012\n","    update_time_ms: 2.638\n","  timestamp: 1649863161\n","  timesteps_since_restore: 32000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 32000\n","  training_iteration: 8\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:19:23 (running for 00:01:33.93)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         64.7655</td><td style=\"text-align: right;\">36000</td><td style=\"text-align: right;\">-184.483 </td><td style=\"text-align: right;\">             -11.659</td><td style=\"text-align: right;\">            -486.168</td><td style=\"text-align: right;\">             81.4 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         68.7319</td><td style=\"text-align: right;\">36000</td><td style=\"text-align: right;\"> -22.3543</td><td style=\"text-align: right;\">              83.344</td><td style=\"text-align: right;\">            -319.154</td><td style=\"text-align: right;\">            137.44</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         62.5129</td><td style=\"text-align: right;\">32000</td><td style=\"text-align: right;\"> -56.2841</td><td style=\"text-align: right;\">             179.054</td><td style=\"text-align: right;\">            -338.184</td><td style=\"text-align: right;\">            134.93</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 40000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-19-24\n","  done: false\n","  episode_len_mean: 86.39\n","  episode_media: {}\n","  episode_reward_max: -11.658952144937473\n","  episode_reward_mean: -197.30414188970022\n","  episode_reward_min: -492.8172609514109\n","  episodes_this_iter: 43\n","  episodes_total: 442\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 7.688672065734863\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.8052018284797668\n","          entropy_coeff: 0.0\n","          kl: 0.056100159883499146\n","          model: {}\n","          policy_loss: 0.015088365413248539\n","          total_loss: 2497.423583984375\n","          vf_explained_var: 0.4492596983909607\n","          vf_loss: 2496.9775390625\n","    num_agent_steps_sampled: 40000\n","    num_agent_steps_trained: 40000\n","    num_steps_sampled: 40000\n","    num_steps_trained: 40000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 10\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.559999999999999\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06976526185390258\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.22140286741002846\n","    mean_inference_ms: 0.71815981804595\n","    mean_raw_obs_processing_ms: 0.1126426690326311\n","  time_since_restore: 71.99780130386353\n","  time_this_iter_s: 7.232299327850342\n","  time_total_s: 71.99780130386353\n","  timers:\n","    learn_throughput: 1525.686\n","    learn_time_ms: 2621.771\n","    load_throughput: 9318087.198\n","    load_time_ms: 0.429\n","    sample_throughput: 486.269\n","    sample_time_ms: 8225.907\n","    update_time_ms: 2.765\n","  timestamp: 1649863164\n","  timesteps_since_restore: 40000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 40000\n","  training_iteration: 10\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:19:29 (running for 00:01:39.30)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         71.9978</td><td style=\"text-align: right;\">40000</td><td style=\"text-align: right;\">-197.304 </td><td style=\"text-align: right;\">             -11.659</td><td style=\"text-align: right;\">            -492.817</td><td style=\"text-align: right;\">             86.39</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         68.7319</td><td style=\"text-align: right;\">36000</td><td style=\"text-align: right;\"> -22.3543</td><td style=\"text-align: right;\">              83.344</td><td style=\"text-align: right;\">            -319.154</td><td style=\"text-align: right;\">            137.44</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         62.5129</td><td style=\"text-align: right;\">32000</td><td style=\"text-align: right;\"> -56.2841</td><td style=\"text-align: right;\">             179.054</td><td style=\"text-align: right;\">            -338.184</td><td style=\"text-align: right;\">            134.93</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 40000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-19-29\n","  done: false\n","  episode_len_mean: 131.78\n","  episode_media: {}\n","  episode_reward_max: 83.34404417662553\n","  episode_reward_mean: -15.721755772741828\n","  episode_reward_min: -319.1541031602992\n","  episodes_this_iter: 26\n","  episodes_total: 360\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.675000011920929\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.103855848312378\n","          entropy_coeff: 0.0\n","          kl: 0.014395372942090034\n","          model: {}\n","          policy_loss: -0.030911898240447044\n","          total_loss: 525.3675537109375\n","          vf_explained_var: 0.7577821612358093\n","          vf_loss: 525.3887329101562\n","    num_agent_steps_sampled: 40000\n","    num_agent_steps_trained: 40000\n","    num_steps_sampled: 40000\n","    num_steps_trained: 40000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 10\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.315384615384614\n","    ram_util_percent: 16.5\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07044351271832597\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.3306678422715739\n","    mean_inference_ms: 0.705093869710581\n","    mean_raw_obs_processing_ms: 0.11089608038653725\n","  time_since_restore: 77.43225312232971\n","  time_this_iter_s: 8.700328588485718\n","  time_total_s: 77.43225312232971\n","  timers:\n","    learn_throughput: 1531.766\n","    learn_time_ms: 2611.365\n","    load_throughput: 9359152.07\n","    load_time_ms: 0.427\n","    sample_throughput: 511.473\n","    sample_time_ms: 7820.555\n","    update_time_ms: 3.008\n","  timestamp: 1649863169\n","  timesteps_since_restore: 40000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 40000\n","  training_iteration: 10\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 36000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-19-30\n","  done: false\n","  episode_len_mean: 150.31\n","  episode_media: {}\n","  episode_reward_max: 179.0541152047613\n","  episode_reward_mean: -42.405135420219686\n","  episode_reward_min: -303.70845955548407\n","  episodes_this_iter: 25\n","  episodes_total: 324\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.20000000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 1.1586824655532837\n","          entropy_coeff: 0.0\n","          kl: 0.012949267402291298\n","          model: {}\n","          policy_loss: -0.009456927888095379\n","          total_loss: 1384.7838134765625\n","          vf_explained_var: 0.0011892816983163357\n","          vf_loss: 1384.7908935546875\n","    num_agent_steps_sampled: 36000\n","    num_agent_steps_trained: 36000\n","    num_steps_sampled: 36000\n","    num_steps_trained: 36000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 9\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.523076923076921\n","    ram_util_percent: 16.5\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07510018189355144\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.31540541131034905\n","    mean_inference_ms: 0.7419106720333136\n","    mean_raw_obs_processing_ms: 0.11701821637744547\n","  time_since_restore: 71.31772494316101\n","  time_this_iter_s: 8.8047935962677\n","  time_total_s: 71.31772494316101\n","  timers:\n","    learn_throughput: 1522.345\n","    learn_time_ms: 2627.524\n","    load_throughput: 8428879.312\n","    load_time_ms: 0.475\n","    sample_throughput: 521.655\n","    sample_time_ms: 7667.898\n","    update_time_ms: 2.663\n","  timestamp: 1649863170\n","  timesteps_since_restore: 36000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 36000\n","  training_iteration: 9\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 44000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-19-31\n","  done: false\n","  episode_len_mean: 89.68\n","  episode_media: {}\n","  episode_reward_max: -11.658952144937473\n","  episode_reward_mean: -215.43102653908733\n","  episode_reward_min: -515.0990868329246\n","  episodes_this_iter: 44\n","  episodes_total: 486\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 11.533007621765137\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.8671213388442993\n","          entropy_coeff: 0.0\n","          kl: 0.014630410820245743\n","          model: {}\n","          policy_loss: 0.006805683020502329\n","          total_loss: 2064.702880859375\n","          vf_explained_var: 0.37794825434684753\n","          vf_loss: 2064.52734375\n","    num_agent_steps_sampled: 44000\n","    num_agent_steps_trained: 44000\n","    num_steps_sampled: 44000\n","    num_steps_trained: 44000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 11\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.609090909090908\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06998813193126074\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2206968270320858\n","    mean_inference_ms: 0.7200364290764446\n","    mean_raw_obs_processing_ms: 0.11297985834386795\n","  time_since_restore: 79.12604784965515\n","  time_this_iter_s: 7.128246545791626\n","  time_total_s: 79.12604784965515\n","  timers:\n","    learn_throughput: 1524.562\n","    learn_time_ms: 2623.704\n","    load_throughput: 9121026.422\n","    load_time_ms: 0.439\n","    sample_throughput: 472.138\n","    sample_time_ms: 8472.108\n","    update_time_ms: 2.78\n","  timestamp: 1649863171\n","  timesteps_since_restore: 44000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 44000\n","  training_iteration: 11\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:19:34 (running for 00:01:44.58)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         79.126 </td><td style=\"text-align: right;\">44000</td><td style=\"text-align: right;\">-215.431 </td><td style=\"text-align: right;\">             -11.659</td><td style=\"text-align: right;\">            -515.099</td><td style=\"text-align: right;\">             89.68</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         77.4323</td><td style=\"text-align: right;\">40000</td><td style=\"text-align: right;\"> -15.7218</td><td style=\"text-align: right;\">              83.344</td><td style=\"text-align: right;\">            -319.154</td><td style=\"text-align: right;\">            131.78</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         71.3177</td><td style=\"text-align: right;\">36000</td><td style=\"text-align: right;\"> -42.4051</td><td style=\"text-align: right;\">             179.054</td><td style=\"text-align: right;\">            -303.708</td><td style=\"text-align: right;\">            150.31</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 48000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-19-38\n","  done: false\n","  episode_len_mean: 88.82\n","  episode_media: {}\n","  episode_reward_max: -37.5617599429047\n","  episode_reward_mean: -219.89790893564142\n","  episode_reward_min: -515.0990868329246\n","  episodes_this_iter: 45\n","  episodes_total: 531\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 11.533007621765137\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7304579615592957\n","          entropy_coeff: 0.0\n","          kl: 0.02712262235581875\n","          model: {}\n","          policy_loss: 0.014185416512191296\n","          total_loss: 1314.79833984375\n","          vf_explained_var: 0.6224910020828247\n","          vf_loss: 1314.4715576171875\n","    num_agent_steps_sampled: 48000\n","    num_agent_steps_trained: 48000\n","    num_steps_sampled: 48000\n","    num_steps_trained: 48000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 12\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 11.766666666666667\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06993677896233554\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.21957954625516288\n","    mean_inference_ms: 0.718560975445987\n","    mean_raw_obs_processing_ms: 0.11290066601791102\n","  time_since_restore: 86.02794408798218\n","  time_this_iter_s: 6.901896238327026\n","  time_total_s: 86.02794408798218\n","  timers:\n","    learn_throughput: 1531.473\n","    learn_time_ms: 2611.865\n","    load_throughput: 9085955.05\n","    load_time_ms: 0.44\n","    sample_throughput: 555.036\n","    sample_time_ms: 7206.739\n","    update_time_ms: 2.812\n","  timestamp: 1649863178\n","  timesteps_since_restore: 48000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 48000\n","  training_iteration: 12\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 40000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-19-39\n","  done: false\n","  episode_len_mean: 162.74\n","  episode_media: {}\n","  episode_reward_max: 179.0541152047613\n","  episode_reward_mean: -27.357534000197802\n","  episode_reward_min: -303.70845955548407\n","  episodes_this_iter: 27\n","  episodes_total: 351\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.20000000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 1.1581840515136719\n","          entropy_coeff: 0.0\n","          kl: 0.008942211978137493\n","          model: {}\n","          policy_loss: -0.011105602607131004\n","          total_loss: 1091.0894775390625\n","          vf_explained_var: 0.005781469400972128\n","          vf_loss: 1091.098876953125\n","    num_agent_steps_sampled: 40000\n","    num_agent_steps_trained: 40000\n","    num_steps_sampled: 40000\n","    num_steps_trained: 40000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 10\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.75\n","    ram_util_percent: 16.5\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07500346248290218\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.34706754207085494\n","    mean_inference_ms: 0.7427327895550313\n","    mean_raw_obs_processing_ms: 0.11655851355896578\n","  time_since_restore: 79.95170140266418\n","  time_this_iter_s: 8.633976459503174\n","  time_total_s: 79.95170140266418\n","  timers:\n","    learn_throughput: 1522.428\n","    learn_time_ms: 2627.383\n","    load_throughput: 8483624.595\n","    load_time_ms: 0.471\n","    sample_throughput: 515.006\n","    sample_time_ms: 7766.899\n","    update_time_ms: 2.678\n","  timestamp: 1649863179\n","  timesteps_since_restore: 40000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 40000\n","  training_iteration: 10\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 44000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-19-39\n","  done: false\n","  episode_len_mean: 152.05\n","  episode_media: {}\n","  episode_reward_max: 96.6777147676511\n","  episode_reward_mean: -13.755390989786152\n","  episode_reward_min: -319.1541031602992\n","  episodes_this_iter: 20\n","  episodes_total: 380\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.675000011920929\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.1136798858642578\n","          entropy_coeff: 0.0\n","          kl: 0.012841586023569107\n","          model: {}\n","          policy_loss: -0.03916911408305168\n","          total_loss: 341.1315612792969\n","          vf_explained_var: 0.68746417760849\n","          vf_loss: 341.16204833984375\n","    num_agent_steps_sampled: 44000\n","    num_agent_steps_trained: 44000\n","    num_steps_sampled: 44000\n","    num_steps_trained: 44000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 11\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.407142857142858\n","    ram_util_percent: 16.5\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07065608480633466\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.3522381274584492\n","    mean_inference_ms: 0.708334111075613\n","    mean_raw_obs_processing_ms: 0.11106939886442625\n","  time_since_restore: 87.212641954422\n","  time_this_iter_s: 9.780388832092285\n","  time_total_s: 87.212641954422\n","  timers:\n","    learn_throughput: 1525.651\n","    learn_time_ms: 2621.832\n","    load_throughput: 9157868.996\n","    load_time_ms: 0.437\n","    sample_throughput: 479.115\n","    sample_time_ms: 8348.72\n","    update_time_ms: 2.976\n","  timestamp: 1649863179\n","  timesteps_since_restore: 44000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 44000\n","  training_iteration: 11\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:19:39 (running for 00:01:49.70)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         86.0279</td><td style=\"text-align: right;\">48000</td><td style=\"text-align: right;\">-219.898 </td><td style=\"text-align: right;\">            -37.5618</td><td style=\"text-align: right;\">            -515.099</td><td style=\"text-align: right;\">             88.82</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         87.2126</td><td style=\"text-align: right;\">44000</td><td style=\"text-align: right;\"> -13.7554</td><td style=\"text-align: right;\">             96.6777</td><td style=\"text-align: right;\">            -319.154</td><td style=\"text-align: right;\">            152.05</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         79.9517</td><td style=\"text-align: right;\">40000</td><td style=\"text-align: right;\"> -27.3575</td><td style=\"text-align: right;\">            179.054 </td><td style=\"text-align: right;\">            -303.708</td><td style=\"text-align: right;\">            162.74</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:19:44 (running for 00:01:54.81)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         86.0279</td><td style=\"text-align: right;\">48000</td><td style=\"text-align: right;\">-219.898 </td><td style=\"text-align: right;\">            -37.5618</td><td style=\"text-align: right;\">            -515.099</td><td style=\"text-align: right;\">             88.82</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         87.2126</td><td style=\"text-align: right;\">44000</td><td style=\"text-align: right;\"> -13.7554</td><td style=\"text-align: right;\">             96.6777</td><td style=\"text-align: right;\">            -319.154</td><td style=\"text-align: right;\">            152.05</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         79.9517</td><td style=\"text-align: right;\">40000</td><td style=\"text-align: right;\"> -27.3575</td><td style=\"text-align: right;\">            179.054 </td><td style=\"text-align: right;\">            -303.708</td><td style=\"text-align: right;\">            162.74</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 52000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-19-45\n","  done: false\n","  episode_len_mean: 87.5\n","  episode_media: {}\n","  episode_reward_max: -2.7976901439528206\n","  episode_reward_mean: -208.096021795243\n","  episode_reward_min: -498.97267075574985\n","  episodes_this_iter: 46\n","  episodes_total: 577\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 17.299510955810547\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7265269756317139\n","          entropy_coeff: 0.0\n","          kl: 0.025764690712094307\n","          model: {}\n","          policy_loss: 0.00958265084773302\n","          total_loss: 1057.926513671875\n","          vf_explained_var: 0.6077085137367249\n","          vf_loss: 1057.4710693359375\n","    num_agent_steps_sampled: 52000\n","    num_agent_steps_trained: 52000\n","    num_steps_sampled: 52000\n","    num_steps_trained: 52000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 13\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.136363636363637\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06997600511271912\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.21879058087121023\n","    mean_inference_ms: 0.7182034257726732\n","    mean_raw_obs_processing_ms: 0.11291871268815001\n","  time_since_restore: 93.2724449634552\n","  time_this_iter_s: 7.2445008754730225\n","  time_total_s: 93.2724449634552\n","  timers:\n","    learn_throughput: 1538.092\n","    learn_time_ms: 2600.625\n","    load_throughput: 9132942.842\n","    load_time_ms: 0.438\n","    sample_throughput: 553.733\n","    sample_time_ms: 7223.7\n","    update_time_ms: 2.874\n","  timestamp: 1649863185\n","  timesteps_since_restore: 52000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 52000\n","  training_iteration: 13\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 44000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-19-47\n","  done: false\n","  episode_len_mean: 171.63\n","  episode_media: {}\n","  episode_reward_max: 179.0541152047613\n","  episode_reward_mean: -14.465692952995436\n","  episode_reward_min: -160.4124601811961\n","  episodes_this_iter: 26\n","  episodes_total: 377\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.20000000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 1.1331895589828491\n","          entropy_coeff: 0.0\n","          kl: 0.008746380917727947\n","          model: {}\n","          policy_loss: -0.01523581799119711\n","          total_loss: 1357.225830078125\n","          vf_explained_var: 0.018551774322986603\n","          vf_loss: 1357.2392578125\n","    num_agent_steps_sampled: 44000\n","    num_agent_steps_trained: 44000\n","    num_steps_sampled: 44000\n","    num_steps_trained: 44000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 11\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.116666666666665\n","    ram_util_percent: 16.5\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07490075640938366\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.37668920403061956\n","    mean_inference_ms: 0.7431503204368264\n","    mean_raw_obs_processing_ms: 0.1162140349781165\n","  time_since_restore: 88.48349952697754\n","  time_this_iter_s: 8.531798124313354\n","  time_total_s: 88.48349952697754\n","  timers:\n","    learn_throughput: 1546.491\n","    learn_time_ms: 2586.501\n","    load_throughput: 8417226.57\n","    load_time_ms: 0.475\n","    sample_throughput: 490.276\n","    sample_time_ms: 8158.673\n","    update_time_ms: 2.639\n","  timestamp: 1649863187\n","  timesteps_since_restore: 44000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 44000\n","  training_iteration: 11\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:19:49 (running for 00:01:59.93)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         93.2724</td><td style=\"text-align: right;\">52000</td><td style=\"text-align: right;\">-208.096 </td><td style=\"text-align: right;\">            -2.79769</td><td style=\"text-align: right;\">            -498.973</td><td style=\"text-align: right;\">             87.5 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         87.2126</td><td style=\"text-align: right;\">44000</td><td style=\"text-align: right;\"> -13.7554</td><td style=\"text-align: right;\">            96.6777 </td><td style=\"text-align: right;\">            -319.154</td><td style=\"text-align: right;\">            152.05</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         88.4835</td><td style=\"text-align: right;\">44000</td><td style=\"text-align: right;\"> -14.4657</td><td style=\"text-align: right;\">           179.054  </td><td style=\"text-align: right;\">            -160.412</td><td style=\"text-align: right;\">            171.63</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 48000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-19-50\n","  done: false\n","  episode_len_mean: 179.72\n","  episode_media: {}\n","  episode_reward_max: 96.6777147676511\n","  episode_reward_mean: -13.597030925636881\n","  episode_reward_min: -319.1541031602992\n","  episodes_this_iter: 15\n","  episodes_total: 395\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.675000011920929\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.1329740285873413\n","          entropy_coeff: 0.0\n","          kl: 0.011017860844731331\n","          model: {}\n","          policy_loss: -0.041309356689453125\n","          total_loss: 237.5389404296875\n","          vf_explained_var: 0.6550437808036804\n","          vf_loss: 237.57281494140625\n","    num_agent_steps_sampled: 48000\n","    num_agent_steps_trained: 48000\n","    num_steps_sampled: 48000\n","    num_steps_trained: 48000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 12\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.39375\n","    ram_util_percent: 16.5\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.070797993347377\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.37874001801904483\n","    mean_inference_ms: 0.7107979204253709\n","    mean_raw_obs_processing_ms: 0.11116321380922574\n","  time_since_restore: 98.51325798034668\n","  time_this_iter_s: 11.300616025924683\n","  time_total_s: 98.51325798034668\n","  timers:\n","    learn_throughput: 1537.808\n","    learn_time_ms: 2601.105\n","    load_throughput: 9143395.28\n","    load_time_ms: 0.437\n","    sample_throughput: 470.423\n","    sample_time_ms: 8502.99\n","    update_time_ms: 2.937\n","  timestamp: 1649863190\n","  timesteps_since_restore: 48000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 48000\n","  training_iteration: 12\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 56000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-19-52\n","  done: false\n","  episode_len_mean: 84.29\n","  episode_media: {}\n","  episode_reward_max: 17.451168927429634\n","  episode_reward_mean: -178.53598104758188\n","  episode_reward_min: -498.97267075574985\n","  episodes_this_iter: 49\n","  episodes_total: 626\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 25.949268341064453\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.6015673279762268\n","          entropy_coeff: 0.0\n","          kl: 0.10581710934638977\n","          model: {}\n","          policy_loss: 0.009991886094212532\n","          total_loss: 1145.583251953125\n","          vf_explained_var: 0.4120899438858032\n","          vf_loss: 1142.8272705078125\n","    num_agent_steps_sampled: 56000\n","    num_agent_steps_trained: 56000\n","    num_steps_sampled: 56000\n","    num_steps_trained: 56000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 14\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.370000000000001\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07022303591479197\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.21823983812510903\n","    mean_inference_ms: 0.7205458033159968\n","    mean_raw_obs_processing_ms: 0.11327690584336086\n","  time_since_restore: 100.45919013023376\n","  time_this_iter_s: 7.1867451667785645\n","  time_total_s: 100.45919013023376\n","  timers:\n","    learn_throughput: 1548.214\n","    learn_time_ms: 2583.623\n","    load_throughput: 9152872.886\n","    load_time_ms: 0.437\n","    sample_throughput: 553.772\n","    sample_time_ms: 7223.188\n","    update_time_ms: 2.901\n","  timestamp: 1649863192\n","  timesteps_since_restore: 56000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 56000\n","  training_iteration: 14\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:19:54 (running for 00:02:04.98)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">        100.459 </td><td style=\"text-align: right;\">56000</td><td style=\"text-align: right;\">-178.536 </td><td style=\"text-align: right;\">             17.4512</td><td style=\"text-align: right;\">            -498.973</td><td style=\"text-align: right;\">             84.29</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         98.5133</td><td style=\"text-align: right;\">48000</td><td style=\"text-align: right;\"> -13.597 </td><td style=\"text-align: right;\">             96.6777</td><td style=\"text-align: right;\">            -319.154</td><td style=\"text-align: right;\">            179.72</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         88.4835</td><td style=\"text-align: right;\">44000</td><td style=\"text-align: right;\"> -14.4657</td><td style=\"text-align: right;\">            179.054 </td><td style=\"text-align: right;\">            -160.412</td><td style=\"text-align: right;\">            171.63</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 48000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-19-56\n","  done: false\n","  episode_len_mean: 151.54\n","  episode_media: {}\n","  episode_reward_max: 141.32777018542663\n","  episode_reward_mean: -16.41585178119742\n","  episode_reward_min: -175.08364409703088\n","  episodes_this_iter: 24\n","  episodes_total: 401\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.20000000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 1.1009031534194946\n","          entropy_coeff: 0.0\n","          kl: 0.009169855155050755\n","          model: {}\n","          policy_loss: -0.010270553641021252\n","          total_loss: 1712.543701171875\n","          vf_explained_var: 0.02841540053486824\n","          vf_loss: 1712.5521240234375\n","    num_agent_steps_sampled: 48000\n","    num_agent_steps_trained: 48000\n","    num_steps_sampled: 48000\n","    num_steps_trained: 48000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 12\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.433333333333335\n","    ram_util_percent: 16.5\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07485498866572929\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.3941408728571939\n","    mean_inference_ms: 0.7436009446964672\n","    mean_raw_obs_processing_ms: 0.1160705387988631\n","  time_since_restore: 96.89966154098511\n","  time_this_iter_s: 8.416162014007568\n","  time_total_s: 96.89966154098511\n","  timers:\n","    learn_throughput: 1555.611\n","    learn_time_ms: 2571.337\n","    load_throughput: 8528474.99\n","    load_time_ms: 0.469\n","    sample_throughput: 486.582\n","    sample_time_ms: 8220.612\n","    update_time_ms: 2.693\n","  timestamp: 1649863196\n","  timesteps_since_restore: 48000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 48000\n","  training_iteration: 12\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 60000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-20-00\n","  done: false\n","  episode_len_mean: 86.37\n","  episode_media: {}\n","  episode_reward_max: 17.451168927429634\n","  episode_reward_mean: -173.04801585939404\n","  episode_reward_min: -430.91674144471517\n","  episodes_this_iter: 38\n","  episodes_total: 664\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 38.92390060424805\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.6816824674606323\n","          entropy_coeff: 0.0\n","          kl: 0.06201207637786865\n","          model: {}\n","          policy_loss: 0.016652636229991913\n","          total_loss: 2281.22265625\n","          vf_explained_var: 0.3117233216762543\n","          vf_loss: 2278.7919921875\n","    num_agent_steps_sampled: 60000\n","    num_agent_steps_trained: 60000\n","    num_steps_sampled: 60000\n","    num_steps_trained: 60000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 15\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.154545454545454\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07032389153758857\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2193329185825567\n","    mean_inference_ms: 0.7217629345982803\n","    mean_raw_obs_processing_ms: 0.11340685946778276\n","  time_since_restore: 107.78080487251282\n","  time_this_iter_s: 7.321614742279053\n","  time_total_s: 107.78080487251282\n","  timers:\n","    learn_throughput: 1558.297\n","    learn_time_ms: 2566.905\n","    load_throughput: 9372746.369\n","    load_time_ms: 0.427\n","    sample_throughput: 552.252\n","    sample_time_ms: 7243.066\n","    update_time_ms: 2.869\n","  timestamp: 1649863200\n","  timesteps_since_restore: 60000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 60000\n","  training_iteration: 15\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:20:00 (running for 00:02:10.26)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">        107.781 </td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\">-173.048 </td><td style=\"text-align: right;\">             17.4512</td><td style=\"text-align: right;\">            -430.917</td><td style=\"text-align: right;\">             86.37</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         98.5133</td><td style=\"text-align: right;\">48000</td><td style=\"text-align: right;\"> -13.597 </td><td style=\"text-align: right;\">             96.6777</td><td style=\"text-align: right;\">            -319.154</td><td style=\"text-align: right;\">            179.72</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         96.8997</td><td style=\"text-align: right;\">48000</td><td style=\"text-align: right;\"> -16.4159</td><td style=\"text-align: right;\">            141.328 </td><td style=\"text-align: right;\">            -175.084</td><td style=\"text-align: right;\">            151.54</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 52000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-20-01\n","  done: false\n","  episode_len_mean: 198.78\n","  episode_media: {}\n","  episode_reward_max: 105.19805195995905\n","  episode_reward_mean: -12.842132492403517\n","  episode_reward_min: -319.1541031602992\n","  episodes_this_iter: 12\n","  episodes_total: 407\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.675000011920929\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.1304057836532593\n","          entropy_coeff: 0.0\n","          kl: 0.014202860184013844\n","          model: {}\n","          policy_loss: -0.04208642244338989\n","          total_loss: 270.5760803222656\n","          vf_explained_var: 0.6399173140525818\n","          vf_loss: 270.60858154296875\n","    num_agent_steps_sampled: 52000\n","    num_agent_steps_trained: 52000\n","    num_steps_sampled: 52000\n","    num_steps_trained: 52000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 13\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.613333333333335\n","    ram_util_percent: 16.5\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07094969946453811\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.40497344835936033\n","    mean_inference_ms: 0.7131809125127748\n","    mean_raw_obs_processing_ms: 0.11122191503278607\n","  time_since_restore: 108.93550515174866\n","  time_this_iter_s: 10.422247171401978\n","  time_total_s: 108.93550515174866\n","  timers:\n","    learn_throughput: 1546.14\n","    learn_time_ms: 2587.088\n","    load_throughput: 9078580.087\n","    load_time_ms: 0.441\n","    sample_throughput: 453.616\n","    sample_time_ms: 8818.033\n","    update_time_ms: 2.952\n","  timestamp: 1649863201\n","  timesteps_since_restore: 52000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 52000\n","  training_iteration: 13\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:20:05 (running for 00:02:15.58)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">        107.781 </td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\">-173.048 </td><td style=\"text-align: right;\">             17.4512</td><td style=\"text-align: right;\">            -430.917</td><td style=\"text-align: right;\">             86.37</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">        108.936 </td><td style=\"text-align: right;\">52000</td><td style=\"text-align: right;\"> -12.8421</td><td style=\"text-align: right;\">            105.198 </td><td style=\"text-align: right;\">            -319.154</td><td style=\"text-align: right;\">            198.78</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         96.8997</td><td style=\"text-align: right;\">48000</td><td style=\"text-align: right;\"> -16.4159</td><td style=\"text-align: right;\">            141.328 </td><td style=\"text-align: right;\">            -175.084</td><td style=\"text-align: right;\">            151.54</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 52000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-20-06\n","  done: false\n","  episode_len_mean: 182.39\n","  episode_media: {}\n","  episode_reward_max: 141.32777018542663\n","  episode_reward_mean: -13.1911397031236\n","  episode_reward_min: -175.08364409703088\n","  episodes_this_iter: 12\n","  episodes_total: 413\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.20000000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 1.1015199422836304\n","          entropy_coeff: 0.0\n","          kl: 0.006901863496750593\n","          model: {}\n","          policy_loss: -0.006197907961905003\n","          total_loss: 903.013427734375\n","          vf_explained_var: 0.06771096587181091\n","          vf_loss: 903.0182495117188\n","    num_agent_steps_sampled: 52000\n","    num_agent_steps_trained: 52000\n","    num_steps_sampled: 52000\n","    num_steps_trained: 52000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 13\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.840000000000002\n","    ram_util_percent: 16.5\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07483812991675404\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.40567432840752504\n","    mean_inference_ms: 0.7437654016637621\n","    mean_raw_obs_processing_ms: 0.11599130769180575\n","  time_since_restore: 107.45869946479797\n","  time_this_iter_s: 10.559037923812866\n","  time_total_s: 107.45869946479797\n","  timers:\n","    learn_throughput: 1560.865\n","    learn_time_ms: 2562.682\n","    load_throughput: 8547157.777\n","    load_time_ms: 0.468\n","    sample_throughput: 469.87\n","    sample_time_ms: 8513.002\n","    update_time_ms: 2.724\n","  timestamp: 1649863206\n","  timesteps_since_restore: 52000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 52000\n","  training_iteration: 13\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 64000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-20-07\n","  done: false\n","  episode_len_mean: 98.09\n","  episode_media: {}\n","  episode_reward_max: -25.82250176657861\n","  episode_reward_mean: -195.64934701911778\n","  episode_reward_min: -567.709745695408\n","  episodes_this_iter: 39\n","  episodes_total: 703\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 58.3858528137207\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7493496537208557\n","          entropy_coeff: 0.0\n","          kl: 0.03622022271156311\n","          model: {}\n","          policy_loss: 0.008893823251128197\n","          total_loss: 2624.87158203125\n","          vf_explained_var: 0.47191566228866577\n","          vf_loss: 2622.747802734375\n","    num_agent_steps_sampled: 64000\n","    num_agent_steps_trained: 64000\n","    num_steps_sampled: 64000\n","    num_steps_trained: 64000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 16\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.054545454545455\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07030421241481935\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.22618356016522143\n","    mean_inference_ms: 0.721700679965523\n","    mean_raw_obs_processing_ms: 0.11333656596372421\n","  time_since_restore: 115.68289566040039\n","  time_this_iter_s: 7.902090787887573\n","  time_total_s: 115.68289566040039\n","  timers:\n","    learn_throughput: 1578.21\n","    learn_time_ms: 2534.516\n","    load_throughput: 9516288.145\n","    load_time_ms: 0.42\n","    sample_throughput: 547.012\n","    sample_time_ms: 7312.451\n","    update_time_ms: 2.834\n","  timestamp: 1649863207\n","  timesteps_since_restore: 64000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 64000\n","  training_iteration: 16\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:20:11 (running for 00:02:21.20)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         115.683</td><td style=\"text-align: right;\">64000</td><td style=\"text-align: right;\">-195.649 </td><td style=\"text-align: right;\">            -25.8225</td><td style=\"text-align: right;\">            -567.71 </td><td style=\"text-align: right;\">             98.09</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         108.936</td><td style=\"text-align: right;\">52000</td><td style=\"text-align: right;\"> -12.8421</td><td style=\"text-align: right;\">            105.198 </td><td style=\"text-align: right;\">            -319.154</td><td style=\"text-align: right;\">            198.78</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         107.459</td><td style=\"text-align: right;\">52000</td><td style=\"text-align: right;\"> -13.1911</td><td style=\"text-align: right;\">            141.328 </td><td style=\"text-align: right;\">            -175.084</td><td style=\"text-align: right;\">            182.39</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 56000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-20-13\n","  done: false\n","  episode_len_mean: 225.77\n","  episode_media: {}\n","  episode_reward_max: 122.99051101058673\n","  episode_reward_mean: -12.303705833899112\n","  episode_reward_min: -319.1541031602992\n","  episodes_this_iter: 8\n","  episodes_total: 415\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.675000011920929\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.1367783546447754\n","          entropy_coeff: 0.0\n","          kl: 0.016975976526737213\n","          model: {}\n","          policy_loss: -0.043161820620298386\n","          total_loss: 450.4811096191406\n","          vf_explained_var: 0.5800098776817322\n","          vf_loss: 450.5128479003906\n","    num_agent_steps_sampled: 56000\n","    num_agent_steps_trained: 56000\n","    num_steps_sampled: 56000\n","    num_steps_trained: 56000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 14\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.158823529411768\n","    ram_util_percent: 16.5\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07106087192409358\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.42609066800740764\n","    mean_inference_ms: 0.7149617840863017\n","    mean_raw_obs_processing_ms: 0.11126981202386338\n","  time_since_restore: 121.24352669715881\n","  time_this_iter_s: 12.308021545410156\n","  time_total_s: 121.24352669715881\n","  timers:\n","    learn_throughput: 1552.595\n","    learn_time_ms: 2576.332\n","    load_throughput: 8478908.374\n","    load_time_ms: 0.472\n","    sample_throughput: 429.001\n","    sample_time_ms: 9323.99\n","    update_time_ms: 2.918\n","  timestamp: 1649863213\n","  timesteps_since_restore: 56000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 56000\n","  training_iteration: 14\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 68000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-20-15\n","  done: false\n","  episode_len_mean: 101.75\n","  episode_media: {}\n","  episode_reward_max: -25.82250176657861\n","  episode_reward_mean: -217.6187208872945\n","  episode_reward_min: -567.709745695408\n","  episodes_this_iter: 42\n","  episodes_total: 745\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 87.57878112792969\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.718002438545227\n","          entropy_coeff: 0.0\n","          kl: 0.04864859580993652\n","          model: {}\n","          policy_loss: 0.011078755371272564\n","          total_loss: 847.1707153320312\n","          vf_explained_var: 0.5658464431762695\n","          vf_loss: 842.8990478515625\n","    num_agent_steps_sampled: 68000\n","    num_agent_steps_trained: 68000\n","    num_steps_sampled: 68000\n","    num_steps_trained: 68000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 17\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.05\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07021940401209613\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.23284572318871224\n","    mean_inference_ms: 0.7206902454968875\n","    mean_raw_obs_processing_ms: 0.11317939056574118\n","  time_since_restore: 122.79205846786499\n","  time_this_iter_s: 7.1091628074646\n","  time_total_s: 122.79205846786499\n","  timers:\n","    learn_throughput: 1575.726\n","    learn_time_ms: 2538.512\n","    load_throughput: 9493671.344\n","    load_time_ms: 0.421\n","    sample_throughput: 548.835\n","    sample_time_ms: 7288.159\n","    update_time_ms: 2.856\n","  timestamp: 1649863215\n","  timesteps_since_restore: 68000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 68000\n","  training_iteration: 17\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:20:16 (running for 00:02:26.35)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         122.792</td><td style=\"text-align: right;\">68000</td><td style=\"text-align: right;\">-217.619 </td><td style=\"text-align: right;\">            -25.8225</td><td style=\"text-align: right;\">            -567.71 </td><td style=\"text-align: right;\">            101.75</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         121.244</td><td style=\"text-align: right;\">56000</td><td style=\"text-align: right;\"> -12.3037</td><td style=\"text-align: right;\">            122.991 </td><td style=\"text-align: right;\">            -319.154</td><td style=\"text-align: right;\">            225.77</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         107.459</td><td style=\"text-align: right;\">52000</td><td style=\"text-align: right;\"> -13.1911</td><td style=\"text-align: right;\">            141.328 </td><td style=\"text-align: right;\">            -175.084</td><td style=\"text-align: right;\">            182.39</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 56000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-20-16\n","  done: false\n","  episode_len_mean: 191.01\n","  episode_media: {}\n","  episode_reward_max: 141.32777018542663\n","  episode_reward_mean: -6.543524264580665\n","  episode_reward_min: -175.08364409703088\n","  episodes_this_iter: 11\n","  episodes_total: 424\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.20000000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 1.056753158569336\n","          entropy_coeff: 0.0\n","          kl: 0.009415198117494583\n","          model: {}\n","          policy_loss: -0.0130577078089118\n","          total_loss: 725.9435424804688\n","          vf_explained_var: 0.1367492973804474\n","          vf_loss: 725.9547119140625\n","    num_agent_steps_sampled: 56000\n","    num_agent_steps_trained: 56000\n","    num_steps_sampled: 56000\n","    num_steps_trained: 56000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 14\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.071428571428573\n","    ram_util_percent: 16.5\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07482690191637936\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.4192318670764521\n","    mean_inference_ms: 0.7440822316136275\n","    mean_raw_obs_processing_ms: 0.11589004429381893\n","  time_since_restore: 117.19744491577148\n","  time_this_iter_s: 9.73874545097351\n","  time_total_s: 117.19744491577148\n","  timers:\n","    learn_throughput: 1564.055\n","    learn_time_ms: 2557.456\n","    load_throughput: 8279320.963\n","    load_time_ms: 0.483\n","    sample_throughput: 457.074\n","    sample_time_ms: 8751.313\n","    update_time_ms: 2.765\n","  timestamp: 1649863216\n","  timesteps_since_restore: 56000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 56000\n","  training_iteration: 14\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:20:21 (running for 00:02:31.75)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         122.792</td><td style=\"text-align: right;\">68000</td><td style=\"text-align: right;\">-217.619  </td><td style=\"text-align: right;\">            -25.8225</td><td style=\"text-align: right;\">            -567.71 </td><td style=\"text-align: right;\">            101.75</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         121.244</td><td style=\"text-align: right;\">56000</td><td style=\"text-align: right;\"> -12.3037 </td><td style=\"text-align: right;\">            122.991 </td><td style=\"text-align: right;\">            -319.154</td><td style=\"text-align: right;\">            225.77</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         117.197</td><td style=\"text-align: right;\">56000</td><td style=\"text-align: right;\">  -6.54352</td><td style=\"text-align: right;\">            141.328 </td><td style=\"text-align: right;\">            -175.084</td><td style=\"text-align: right;\">            191.01</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 72000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-20-22\n","  done: false\n","  episode_len_mean: 95.01\n","  episode_media: {}\n","  episode_reward_max: -0.7206942599442954\n","  episode_reward_mean: -217.49281350959617\n","  episode_reward_min: -567.709745695408\n","  episodes_this_iter: 41\n","  episodes_total: 786\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 131.3681640625\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7314426302909851\n","          entropy_coeff: 0.0\n","          kl: 0.032245974987745285\n","          model: {}\n","          policy_loss: 0.008174940012395382\n","          total_loss: 1395.957763671875\n","          vf_explained_var: 0.5807404518127441\n","          vf_loss: 1391.7135009765625\n","    num_agent_steps_sampled: 72000\n","    num_agent_steps_trained: 72000\n","    num_steps_sampled: 72000\n","    num_steps_trained: 72000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 18\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.03\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0701251434187915\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.23543142632782696\n","    mean_inference_ms: 0.7193195211605246\n","    mean_raw_obs_processing_ms: 0.11303278912021884\n","  time_since_restore: 129.75331711769104\n","  time_this_iter_s: 6.96125864982605\n","  time_total_s: 129.75331711769104\n","  timers:\n","    learn_throughput: 1582.096\n","    learn_time_ms: 2528.291\n","    load_throughput: 9508198.356\n","    load_time_ms: 0.421\n","    sample_throughput: 550.2\n","    sample_time_ms: 7270.077\n","    update_time_ms: 2.819\n","  timestamp: 1649863222\n","  timesteps_since_restore: 72000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 72000\n","  training_iteration: 18\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 60000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-20-24\n","  done: false\n","  episode_len_mean: 250.43\n","  episode_media: {}\n","  episode_reward_max: 122.99051101058673\n","  episode_reward_mean: -17.369241478062396\n","  episode_reward_min: -371.03975481381383\n","  episodes_this_iter: 7\n","  episodes_total: 422\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.675000011920929\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.10901939868927\n","          entropy_coeff: 0.0\n","          kl: 0.021594399586319923\n","          model: {}\n","          policy_loss: -0.020850885659456253\n","          total_loss: 1697.0718994140625\n","          vf_explained_var: 0.5121858716011047\n","          vf_loss: 1697.0782470703125\n","    num_agent_steps_sampled: 60000\n","    num_agent_steps_trained: 60000\n","    num_steps_sampled: 60000\n","    num_steps_trained: 60000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 15\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.66875\n","    ram_util_percent: 16.5\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07115894961625496\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.44587282040448284\n","    mean_inference_ms: 0.7165609181910164\n","    mean_raw_obs_processing_ms: 0.11130334889720508\n","  time_since_restore: 132.34025502204895\n","  time_this_iter_s: 11.096728324890137\n","  time_total_s: 132.34025502204895\n","  timers:\n","    learn_throughput: 1562.855\n","    learn_time_ms: 2559.418\n","    load_throughput: 8690156.428\n","    load_time_ms: 0.46\n","    sample_throughput: 411.538\n","    sample_time_ms: 9719.639\n","    update_time_ms: 2.883\n","  timestamp: 1649863224\n","  timesteps_since_restore: 60000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 60000\n","  training_iteration: 15\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 60000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-20-26\n","  done: false\n","  episode_len_mean: 210.48\n","  episode_media: {}\n","  episode_reward_max: 161.85633183021088\n","  episode_reward_mean: -4.260876943440587\n","  episode_reward_min: -175.08364409703088\n","  episodes_this_iter: 10\n","  episodes_total: 434\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.20000000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 1.0351524353027344\n","          entropy_coeff: 0.0\n","          kl: 0.008505474776029587\n","          model: {}\n","          policy_loss: -0.0142973642796278\n","          total_loss: 804.1475219726562\n","          vf_explained_var: 0.12294957786798477\n","          vf_loss: 804.1600952148438\n","    num_agent_steps_sampled: 60000\n","    num_agent_steps_trained: 60000\n","    num_steps_sampled: 60000\n","    num_steps_trained: 60000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 15\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.921428571428567\n","    ram_util_percent: 16.5\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07483962028638735\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.4315883419569458\n","    mean_inference_ms: 0.7446492711490706\n","    mean_raw_obs_processing_ms: 0.11581116831129747\n","  time_since_restore: 126.74533081054688\n","  time_this_iter_s: 9.54788589477539\n","  time_total_s: 126.74533081054688\n","  timers:\n","    learn_throughput: 1572.328\n","    learn_time_ms: 2543.998\n","    load_throughput: 8143488.982\n","    load_time_ms: 0.491\n","    sample_throughput: 446.038\n","    sample_time_ms: 8967.847\n","    update_time_ms: 2.757\n","  timestamp: 1649863226\n","  timesteps_since_restore: 60000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 60000\n","  training_iteration: 15\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:20:27 (running for 00:02:37.34)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         129.753</td><td style=\"text-align: right;\">72000</td><td style=\"text-align: right;\">-217.493  </td><td style=\"text-align: right;\">           -0.720694</td><td style=\"text-align: right;\">            -567.71 </td><td style=\"text-align: right;\">             95.01</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         132.34 </td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\"> -17.3692 </td><td style=\"text-align: right;\">          122.991   </td><td style=\"text-align: right;\">            -371.04 </td><td style=\"text-align: right;\">            250.43</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         126.745</td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\">  -4.26088</td><td style=\"text-align: right;\">          161.856   </td><td style=\"text-align: right;\">            -175.084</td><td style=\"text-align: right;\">            210.48</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 76000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-20-29\n","  done: false\n","  episode_len_mean: 98.02\n","  episode_media: {}\n","  episode_reward_max: 29.586403317785084\n","  episode_reward_mean: -205.02862804433806\n","  episode_reward_min: -510.6060785775333\n","  episodes_this_iter: 42\n","  episodes_total: 828\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 197.05224609375\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7138475775718689\n","          entropy_coeff: 0.0\n","          kl: 0.015255429781973362\n","          model: {}\n","          policy_loss: 0.0027051810175180435\n","          total_loss: 766.5704345703125\n","          vf_explained_var: 0.6992394924163818\n","          vf_loss: 763.5615844726562\n","    num_agent_steps_sampled: 76000\n","    num_agent_steps_trained: 76000\n","    num_steps_sampled: 76000\n","    num_steps_trained: 76000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 19\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.3\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07013542279798346\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.23537767001402096\n","    mean_inference_ms: 0.7195225391873166\n","    mean_raw_obs_processing_ms: 0.11305803814003154\n","  time_since_restore: 137.05935382843018\n","  time_this_iter_s: 7.306036710739136\n","  time_total_s: 137.05935382843018\n","  timers:\n","    learn_throughput: 1582.861\n","    learn_time_ms: 2527.07\n","    load_throughput: 9510893.424\n","    load_time_ms: 0.421\n","    sample_throughput: 550.444\n","    sample_time_ms: 7266.867\n","    update_time_ms: 2.787\n","  timestamp: 1649863229\n","  timesteps_since_restore: 76000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 76000\n","  training_iteration: 19\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:20:32 (running for 00:02:42.69)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         137.059</td><td style=\"text-align: right;\">76000</td><td style=\"text-align: right;\">-205.029  </td><td style=\"text-align: right;\">             29.5864</td><td style=\"text-align: right;\">            -510.606</td><td style=\"text-align: right;\">             98.02</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         132.34 </td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\"> -17.3692 </td><td style=\"text-align: right;\">            122.991 </td><td style=\"text-align: right;\">            -371.04 </td><td style=\"text-align: right;\">            250.43</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         126.745</td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\">  -4.26088</td><td style=\"text-align: right;\">            161.856 </td><td style=\"text-align: right;\">            -175.084</td><td style=\"text-align: right;\">            210.48</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 64000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-20-36\n","  done: false\n","  episode_len_mean: 241.85\n","  episode_media: {}\n","  episode_reward_max: 179.38384512746038\n","  episode_reward_mean: 0.7413106932907997\n","  episode_reward_min: -175.08364409703088\n","  episodes_this_iter: 9\n","  episodes_total: 443\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.20000000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 1.1047905683517456\n","          entropy_coeff: 0.0\n","          kl: 0.0069788601249456406\n","          model: {}\n","          policy_loss: -0.011321406811475754\n","          total_loss: 703.3260498046875\n","          vf_explained_var: 0.2682678997516632\n","          vf_loss: 703.3358764648438\n","    num_agent_steps_sampled: 64000\n","    num_agent_steps_trained: 64000\n","    num_steps_sampled: 64000\n","    num_steps_trained: 64000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 16\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.807142857142859\n","    ram_util_percent: 16.5\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07484244254022458\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.44482786283861825\n","    mean_inference_ms: 0.7451724642528619\n","    mean_raw_obs_processing_ms: 0.11570694444019898\n","  time_since_restore: 136.66654634475708\n","  time_this_iter_s: 9.921215534210205\n","  time_total_s: 136.66654634475708\n","  timers:\n","    learn_throughput: 1587.301\n","    learn_time_ms: 2520.0\n","    load_throughput: 8280546.863\n","    load_time_ms: 0.483\n","    sample_throughput: 434.634\n","    sample_time_ms: 9203.153\n","    update_time_ms: 2.747\n","  timestamp: 1649863236\n","  timesteps_since_restore: 64000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 64000\n","  training_iteration: 16\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 80000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-20-36\n","  done: false\n","  episode_len_mean: 100.01\n","  episode_media: {}\n","  episode_reward_max: 29.586403317785084\n","  episode_reward_mean: -223.60983100663114\n","  episode_reward_min: -511.9762990981078\n","  episodes_this_iter: 39\n","  episodes_total: 867\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 197.05224609375\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7420744895935059\n","          entropy_coeff: 0.0\n","          kl: 0.022440986707806587\n","          model: {}\n","          policy_loss: 0.006849512457847595\n","          total_loss: 774.24462890625\n","          vf_explained_var: 0.7230453491210938\n","          vf_loss: 769.8157958984375\n","    num_agent_steps_sampled: 80000\n","    num_agent_steps_trained: 80000\n","    num_steps_sampled: 80000\n","    num_steps_trained: 80000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 20\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.05\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07014086764303873\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.23550053726455838\n","    mean_inference_ms: 0.7194466577410392\n","    mean_raw_obs_processing_ms: 0.11306943862930138\n","  time_since_restore: 144.18065309524536\n","  time_this_iter_s: 7.1212992668151855\n","  time_total_s: 144.18065309524536\n","  timers:\n","    learn_throughput: 1573.19\n","    learn_time_ms: 2542.604\n","    load_throughput: 9401107.251\n","    load_time_ms: 0.425\n","    sample_throughput: 552.545\n","    sample_time_ms: 7239.223\n","    update_time_ms: 2.834\n","  timestamp: 1649863236\n","  timesteps_since_restore: 80000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 80000\n","  training_iteration: 20\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 64000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-20-37\n","  done: false\n","  episode_len_mean: 285.4\n","  episode_media: {}\n","  episode_reward_max: 122.99051101058673\n","  episode_reward_mean: -15.91596737411591\n","  episode_reward_min: -371.03975481381383\n","  episodes_this_iter: 4\n","  episodes_total: 426\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.1271361112594604\n","          entropy_coeff: 0.0\n","          kl: 0.009646975435316563\n","          model: {}\n","          policy_loss: -0.04110938683152199\n","          total_loss: 74.7809829711914\n","          vf_explained_var: 0.7751122117042542\n","          vf_loss: 74.81231689453125\n","    num_agent_steps_sampled: 64000\n","    num_agent_steps_trained: 64000\n","    num_steps_sampled: 64000\n","    num_steps_trained: 64000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 16\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.055555555555557\n","    ram_util_percent: 16.5\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07121763377048604\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.4593000555437969\n","    mean_inference_ms: 0.717572139946347\n","    mean_raw_obs_processing_ms: 0.11132047088639045\n","  time_since_restore: 144.6960289478302\n","  time_this_iter_s: 12.35577392578125\n","  time_total_s: 144.6960289478302\n","  timers:\n","    learn_throughput: 1578.204\n","    learn_time_ms: 2534.527\n","    load_throughput: 8643594.024\n","    load_time_ms: 0.463\n","    sample_throughput: 392.183\n","    sample_time_ms: 10199.328\n","    update_time_ms: 2.84\n","  timestamp: 1649863237\n","  timesteps_since_restore: 64000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 64000\n","  training_iteration: 16\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:20:38 (running for 00:02:48.38)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         144.181</td><td style=\"text-align: right;\">80000</td><td style=\"text-align: right;\">-223.61    </td><td style=\"text-align: right;\">             29.5864</td><td style=\"text-align: right;\">            -511.976</td><td style=\"text-align: right;\">            100.01</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         144.696</td><td style=\"text-align: right;\">64000</td><td style=\"text-align: right;\"> -15.916   </td><td style=\"text-align: right;\">            122.991 </td><td style=\"text-align: right;\">            -371.04 </td><td style=\"text-align: right;\">            285.4 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         136.667</td><td style=\"text-align: right;\">64000</td><td style=\"text-align: right;\">   0.741311</td><td style=\"text-align: right;\">            179.384 </td><td style=\"text-align: right;\">            -175.084</td><td style=\"text-align: right;\">            241.85</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:20:43 (running for 00:02:53.38)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         144.181</td><td style=\"text-align: right;\">80000</td><td style=\"text-align: right;\">-223.61    </td><td style=\"text-align: right;\">             29.5864</td><td style=\"text-align: right;\">            -511.976</td><td style=\"text-align: right;\">            100.01</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         144.696</td><td style=\"text-align: right;\">64000</td><td style=\"text-align: right;\"> -15.916   </td><td style=\"text-align: right;\">            122.991 </td><td style=\"text-align: right;\">            -371.04 </td><td style=\"text-align: right;\">            285.4 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         136.667</td><td style=\"text-align: right;\">64000</td><td style=\"text-align: right;\">   0.741311</td><td style=\"text-align: right;\">            179.384 </td><td style=\"text-align: right;\">            -175.084</td><td style=\"text-align: right;\">            241.85</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 84000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-20-43\n","  done: false\n","  episode_len_mean: 98.48\n","  episode_media: {}\n","  episode_reward_max: -8.837998185297565\n","  episode_reward_mean: -240.15928396358652\n","  episode_reward_min: -511.9762990981078\n","  episodes_this_iter: 43\n","  episodes_total: 910\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 295.578369140625\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7217049598693848\n","          entropy_coeff: 0.0\n","          kl: 0.030555885285139084\n","          model: {}\n","          policy_loss: 0.0012927305651828647\n","          total_loss: 1004.2734985351562\n","          vf_explained_var: 0.6852661371231079\n","          vf_loss: 995.2405395507812\n","    num_agent_steps_sampled: 84000\n","    num_agent_steps_trained: 84000\n","    num_steps_sampled: 84000\n","    num_steps_trained: 84000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 21\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 10.999999999999998\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07014096942018049\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.23547740404950432\n","    mean_inference_ms: 0.7191177390193613\n","    mean_raw_obs_processing_ms: 0.11308252753587342\n","  time_since_restore: 151.2865092754364\n","  time_this_iter_s: 7.10585618019104\n","  time_total_s: 151.2865092754364\n","  timers:\n","    learn_throughput: 1582.252\n","    learn_time_ms: 2528.043\n","    load_throughput: 9596302.694\n","    load_time_ms: 0.417\n","    sample_throughput: 550.355\n","    sample_time_ms: 7268.03\n","    update_time_ms: 2.871\n","  timestamp: 1649863243\n","  timesteps_since_restore: 84000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 84000\n","  training_iteration: 21\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 68000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-20-45\n","  done: false\n","  episode_len_mean: 269.03\n","  episode_media: {}\n","  episode_reward_max: 179.38384512746038\n","  episode_reward_mean: 6.457330644193147\n","  episode_reward_min: -175.08364409703088\n","  episodes_this_iter: 14\n","  episodes_total: 457\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.20000000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 1.1165062189102173\n","          entropy_coeff: 0.0\n","          kl: 0.006960214581340551\n","          model: {}\n","          policy_loss: -0.013604742474853992\n","          total_loss: 630.0531616210938\n","          vf_explained_var: 0.35058334469795227\n","          vf_loss: 630.0653686523438\n","    num_agent_steps_sampled: 68000\n","    num_agent_steps_trained: 68000\n","    num_steps_sampled: 68000\n","    num_steps_trained: 68000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 17\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.85\n","    ram_util_percent: 16.5\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07484107363486064\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.4667452775108747\n","    mean_inference_ms: 0.7460631083813806\n","    mean_raw_obs_processing_ms: 0.11552337349933983\n","  time_since_restore: 146.25138545036316\n","  time_this_iter_s: 9.584839105606079\n","  time_total_s: 146.25138545036316\n","  timers:\n","    learn_throughput: 1594.171\n","    learn_time_ms: 2509.14\n","    load_throughput: 8097111.969\n","    load_time_ms: 0.494\n","    sample_throughput: 428.354\n","    sample_time_ms: 9338.063\n","    update_time_ms: 2.779\n","  timestamp: 1649863245\n","  timesteps_since_restore: 68000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 68000\n","  training_iteration: 17\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:20:48 (running for 00:02:59.00)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         151.287</td><td style=\"text-align: right;\">84000</td><td style=\"text-align: right;\">-240.159  </td><td style=\"text-align: right;\">              -8.838</td><td style=\"text-align: right;\">            -511.976</td><td style=\"text-align: right;\">             98.48</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         144.696</td><td style=\"text-align: right;\">64000</td><td style=\"text-align: right;\"> -15.916  </td><td style=\"text-align: right;\">             122.991</td><td style=\"text-align: right;\">            -371.04 </td><td style=\"text-align: right;\">            285.4 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         146.251</td><td style=\"text-align: right;\">68000</td><td style=\"text-align: right;\">   6.45733</td><td style=\"text-align: right;\">             179.384</td><td style=\"text-align: right;\">            -175.084</td><td style=\"text-align: right;\">            269.03</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 68000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-20-49\n","  done: false\n","  episode_len_mean: 317.23\n","  episode_media: {}\n","  episode_reward_max: 126.97406923704018\n","  episode_reward_mean: -13.986634632354653\n","  episode_reward_min: -371.03975481381383\n","  episodes_this_iter: 6\n","  episodes_total: 432\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.1190871000289917\n","          entropy_coeff: 0.0\n","          kl: 0.01069123949855566\n","          model: {}\n","          policy_loss: -0.04535705968737602\n","          total_loss: 373.1618347167969\n","          vf_explained_var: 0.7155182957649231\n","          vf_loss: 373.1963806152344\n","    num_agent_steps_sampled: 68000\n","    num_agent_steps_trained: 68000\n","    num_steps_sampled: 68000\n","    num_steps_trained: 68000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 17\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.133333333333333\n","    ram_util_percent: 16.5\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07132032551656427\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.48235112644120237\n","    mean_inference_ms: 0.7193527396696565\n","    mean_raw_obs_processing_ms: 0.11135130910948461\n","  time_since_restore: 157.2615339756012\n","  time_this_iter_s: 12.565505027770996\n","  time_total_s: 157.2615339756012\n","  timers:\n","    learn_throughput: 1585.439\n","    learn_time_ms: 2522.96\n","    load_throughput: 8670395.866\n","    load_time_ms: 0.461\n","    sample_throughput: 378.261\n","    sample_time_ms: 10574.711\n","    update_time_ms: 2.768\n","  timestamp: 1649863249\n","  timesteps_since_restore: 68000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 68000\n","  training_iteration: 17\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 88000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-20-51\n","  done: false\n","  episode_len_mean: 101.83\n","  episode_media: {}\n","  episode_reward_max: -8.837998185297565\n","  episode_reward_mean: -242.86059386341222\n","  episode_reward_min: -525.860736645655\n","  episodes_this_iter: 35\n","  episodes_total: 945\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 443.3675537109375\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7247079610824585\n","          entropy_coeff: 0.0\n","          kl: 0.021649202331900597\n","          model: {}\n","          policy_loss: 0.0018900057766586542\n","          total_loss: 1053.334716796875\n","          vf_explained_var: 0.6558229923248291\n","          vf_loss: 1043.7342529296875\n","    num_agent_steps_sampled: 88000\n","    num_agent_steps_trained: 88000\n","    num_steps_sampled: 88000\n","    num_steps_trained: 88000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 22\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.02\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07013984068327306\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.23583784631709898\n","    mean_inference_ms: 0.7189704226413187\n","    mean_raw_obs_processing_ms: 0.11306381185615727\n","  time_since_restore: 158.58274674415588\n","  time_this_iter_s: 7.296237468719482\n","  time_total_s: 158.58274674415588\n","  timers:\n","    learn_throughput: 1586.875\n","    learn_time_ms: 2520.678\n","    load_throughput: 9679907.685\n","    load_time_ms: 0.413\n","    sample_throughput: 547.855\n","    sample_time_ms: 7301.196\n","    update_time_ms: 2.778\n","  timestamp: 1649863251\n","  timesteps_since_restore: 88000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 88000\n","  training_iteration: 22\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:20:54 (running for 00:03:04.33)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         158.583</td><td style=\"text-align: right;\">88000</td><td style=\"text-align: right;\">-242.861  </td><td style=\"text-align: right;\">              -8.838</td><td style=\"text-align: right;\">            -525.861</td><td style=\"text-align: right;\">            101.83</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         157.262</td><td style=\"text-align: right;\">68000</td><td style=\"text-align: right;\"> -13.9866 </td><td style=\"text-align: right;\">             126.974</td><td style=\"text-align: right;\">            -371.04 </td><td style=\"text-align: right;\">            317.23</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         146.251</td><td style=\"text-align: right;\">68000</td><td style=\"text-align: right;\">   6.45733</td><td style=\"text-align: right;\">             179.384</td><td style=\"text-align: right;\">            -175.084</td><td style=\"text-align: right;\">            269.03</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 72000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-20-57\n","  done: false\n","  episode_len_mean: 304.9\n","  episode_media: {}\n","  episode_reward_max: 179.38384512746038\n","  episode_reward_mean: 12.550104604913217\n","  episode_reward_min: -175.08364409703088\n","  episodes_this_iter: 4\n","  episodes_total: 461\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.20000000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 1.0741782188415527\n","          entropy_coeff: 0.0\n","          kl: 0.007864660583436489\n","          model: {}\n","          policy_loss: -0.012834984809160233\n","          total_loss: 210.90574645996094\n","          vf_explained_var: 0.5944383144378662\n","          vf_loss: 210.91700744628906\n","    num_agent_steps_sampled: 72000\n","    num_agent_steps_trained: 72000\n","    num_steps_sampled: 72000\n","    num_steps_trained: 72000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 18\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.41875\n","    ram_util_percent: 16.5\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07484418530209323\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.4742364334190863\n","    mean_inference_ms: 0.7463966627910359\n","    mean_raw_obs_processing_ms: 0.11546315975109049\n","  time_since_restore: 157.79264760017395\n","  time_this_iter_s: 11.541262149810791\n","  time_total_s: 157.79264760017395\n","  timers:\n","    learn_throughput: 1598.351\n","    learn_time_ms: 2502.579\n","    load_throughput: 8054739.066\n","    load_time_ms: 0.497\n","    sample_throughput: 417.836\n","    sample_time_ms: 9573.14\n","    update_time_ms: 2.799\n","  timestamp: 1649863257\n","  timesteps_since_restore: 72000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 72000\n","  training_iteration: 18\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 92000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-20-58\n","  done: false\n","  episode_len_mean: 103.03\n","  episode_media: {}\n","  episode_reward_max: 31.659274341099916\n","  episode_reward_mean: -260.0768269792955\n","  episode_reward_min: -525.860736645655\n","  episodes_this_iter: 42\n","  episodes_total: 987\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 665.0513305664062\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7146875262260437\n","          entropy_coeff: 0.0\n","          kl: 0.022832058370113373\n","          model: {}\n","          policy_loss: 0.006291177589446306\n","          total_loss: 1055.89599609375\n","          vf_explained_var: 0.7667471170425415\n","          vf_loss: 1040.7052001953125\n","    num_agent_steps_sampled: 92000\n","    num_agent_steps_trained: 92000\n","    num_steps_sampled: 92000\n","    num_steps_trained: 92000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 23\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.5\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0701396497782833\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.23631881478709643\n","    mean_inference_ms: 0.7188352672111695\n","    mean_raw_obs_processing_ms: 0.11304329285889377\n","  time_since_restore: 165.66400480270386\n","  time_this_iter_s: 7.081258058547974\n","  time_total_s: 165.66400480270386\n","  timers:\n","    learn_throughput: 1585.585\n","    learn_time_ms: 2522.728\n","    load_throughput: 9558577.94\n","    load_time_ms: 0.418\n","    sample_throughput: 549.841\n","    sample_time_ms: 7274.835\n","    update_time_ms: 2.717\n","  timestamp: 1649863258\n","  timesteps_since_restore: 92000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 92000\n","  training_iteration: 23\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:20:59 (running for 00:03:09.44)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         165.664</td><td style=\"text-align: right;\">92000</td><td style=\"text-align: right;\">-260.077 </td><td style=\"text-align: right;\">             31.6593</td><td style=\"text-align: right;\">            -525.861</td><td style=\"text-align: right;\">            103.03</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         157.262</td><td style=\"text-align: right;\">68000</td><td style=\"text-align: right;\"> -13.9866</td><td style=\"text-align: right;\">            126.974 </td><td style=\"text-align: right;\">            -371.04 </td><td style=\"text-align: right;\">            317.23</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         157.793</td><td style=\"text-align: right;\">72000</td><td style=\"text-align: right;\">  12.5501</td><td style=\"text-align: right;\">            179.384 </td><td style=\"text-align: right;\">            -175.084</td><td style=\"text-align: right;\">            304.9 </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 72000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-21-02\n","  done: false\n","  episode_len_mean: 349.28\n","  episode_media: {}\n","  episode_reward_max: 126.97406923704018\n","  episode_reward_mean: -15.769717168669747\n","  episode_reward_min: -429.8267536061066\n","  episodes_this_iter: 7\n","  episodes_total: 439\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.0956226587295532\n","          entropy_coeff: 0.0\n","          kl: 0.011277950368821621\n","          model: {}\n","          policy_loss: -0.021486006677150726\n","          total_loss: 531.090087890625\n","          vf_explained_var: 0.798680305480957\n","          vf_loss: 531.1001586914062\n","    num_agent_steps_sampled: 72000\n","    num_agent_steps_trained: 72000\n","    num_steps_sampled: 72000\n","    num_steps_trained: 72000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 18\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.535294117647059\n","    ram_util_percent: 16.5\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07143549652117728\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5109552954141308\n","    mean_inference_ms: 0.7214072168581498\n","    mean_raw_obs_processing_ms: 0.11137935211873602\n","  time_since_restore: 169.49878931045532\n","  time_this_iter_s: 12.237255334854126\n","  time_total_s: 169.49878931045532\n","  timers:\n","    learn_throughput: 1598.253\n","    learn_time_ms: 2502.733\n","    load_throughput: 8423988.753\n","    load_time_ms: 0.475\n","    sample_throughput: 362.093\n","    sample_time_ms: 11046.888\n","    update_time_ms: 2.736\n","  timestamp: 1649863262\n","  timesteps_since_restore: 72000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 72000\n","  training_iteration: 18\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:21:05 (running for 00:03:15.26)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         165.664</td><td style=\"text-align: right;\">92000</td><td style=\"text-align: right;\">-260.077 </td><td style=\"text-align: right;\">             31.6593</td><td style=\"text-align: right;\">            -525.861</td><td style=\"text-align: right;\">            103.03</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         169.499</td><td style=\"text-align: right;\">72000</td><td style=\"text-align: right;\"> -15.7697</td><td style=\"text-align: right;\">            126.974 </td><td style=\"text-align: right;\">            -429.827</td><td style=\"text-align: right;\">            349.28</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         157.793</td><td style=\"text-align: right;\">72000</td><td style=\"text-align: right;\">  12.5501</td><td style=\"text-align: right;\">            179.384 </td><td style=\"text-align: right;\">            -175.084</td><td style=\"text-align: right;\">            304.9 </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 96000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-21-05\n","  done: false\n","  episode_len_mean: 97.05\n","  episode_media: {}\n","  episode_reward_max: 31.659274341099916\n","  episode_reward_mean: -232.9695432955772\n","  episode_reward_min: -525.860736645655\n","  episodes_this_iter: 43\n","  episodes_total: 1030\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 997.5770263671875\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7281901240348816\n","          entropy_coeff: 0.0\n","          kl: 0.02363746426999569\n","          model: {}\n","          policy_loss: 0.009038780815899372\n","          total_loss: 1554.4735107421875\n","          vf_explained_var: 0.6994299292564392\n","          vf_loss: 1530.88427734375\n","    num_agent_steps_sampled: 96000\n","    num_agent_steps_trained: 96000\n","    num_steps_sampled: 96000\n","    num_steps_trained: 96000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 24\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.569999999999999\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07012309607289362\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.23648123014303768\n","    mean_inference_ms: 0.718437650794804\n","    mean_raw_obs_processing_ms: 0.11301030823524574\n","  time_since_restore: 172.72811102867126\n","  time_this_iter_s: 7.064106225967407\n","  time_total_s: 172.72811102867126\n","  timers:\n","    learn_throughput: 1584.919\n","    learn_time_ms: 2523.788\n","    load_throughput: 9373270.015\n","    load_time_ms: 0.427\n","    sample_throughput: 550.722\n","    sample_time_ms: 7263.198\n","    update_time_ms: 2.754\n","  timestamp: 1649863265\n","  timesteps_since_restore: 96000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 96000\n","  training_iteration: 24\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 76000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-21-06\n","  done: false\n","  episode_len_mean: 333.36\n","  episode_media: {}\n","  episode_reward_max: 188.6009068125303\n","  episode_reward_mean: 18.13298707097062\n","  episode_reward_min: -175.08364409703088\n","  episodes_this_iter: 7\n","  episodes_total: 468\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.20000000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 1.0450395345687866\n","          entropy_coeff: 0.0\n","          kl: 0.0031133266165852547\n","          model: {}\n","          policy_loss: -0.00940656941384077\n","          total_loss: 468.28546142578125\n","          vf_explained_var: 0.6140123605728149\n","          vf_loss: 468.2942199707031\n","    num_agent_steps_sampled: 76000\n","    num_agent_steps_trained: 76000\n","    num_steps_sampled: 76000\n","    num_steps_trained: 76000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 19\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.246153846153845\n","    ram_util_percent: 16.5\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07484093676678018\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.4876945642188726\n","    mean_inference_ms: 0.7469523508552592\n","    mean_raw_obs_processing_ms: 0.11533411572639903\n","  time_since_restore: 166.7787208557129\n","  time_this_iter_s: 8.98607325553894\n","  time_total_s: 166.7787208557129\n","  timers:\n","    learn_throughput: 1608.013\n","    learn_time_ms: 2487.542\n","    load_throughput: 8190400.312\n","    load_time_ms: 0.488\n","    sample_throughput: 416.696\n","    sample_time_ms: 9599.336\n","    update_time_ms: 2.765\n","  timestamp: 1649863266\n","  timesteps_since_restore: 76000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 76000\n","  training_iteration: 19\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:21:10 (running for 00:03:20.64)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         172.728</td><td style=\"text-align: right;\">96000</td><td style=\"text-align: right;\">-232.97  </td><td style=\"text-align: right;\">             31.6593</td><td style=\"text-align: right;\">            -525.861</td><td style=\"text-align: right;\">             97.05</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         169.499</td><td style=\"text-align: right;\">72000</td><td style=\"text-align: right;\"> -15.7697</td><td style=\"text-align: right;\">            126.974 </td><td style=\"text-align: right;\">            -429.827</td><td style=\"text-align: right;\">            349.28</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         166.779</td><td style=\"text-align: right;\">76000</td><td style=\"text-align: right;\">  18.133 </td><td style=\"text-align: right;\">            188.601 </td><td style=\"text-align: right;\">            -175.084</td><td style=\"text-align: right;\">            333.36</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 100000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-21-12\n","  done: false\n","  episode_len_mean: 105.25\n","  episode_media: {}\n","  episode_reward_max: 71.80276221119057\n","  episode_reward_mean: -216.026466719274\n","  episode_reward_min: -528.7401030246672\n","  episodes_this_iter: 32\n","  episodes_total: 1062\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1496.365478515625\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7230757474899292\n","          entropy_coeff: 0.0\n","          kl: 0.025240829214453697\n","          model: {}\n","          policy_loss: 0.006735054310411215\n","          total_loss: 1973.1326904296875\n","          vf_explained_var: 0.5454610586166382\n","          vf_loss: 1935.3564453125\n","    num_agent_steps_sampled: 100000\n","    num_agent_steps_trained: 100000\n","    num_steps_sampled: 100000\n","    num_steps_trained: 100000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 25\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 11.72\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0700784768957424\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2375887840604296\n","    mean_inference_ms: 0.717936951640464\n","    mean_raw_obs_processing_ms: 0.11291875509564563\n","  time_since_restore: 180.13505792617798\n","  time_this_iter_s: 7.406946897506714\n","  time_total_s: 180.13505792617798\n","  timers:\n","    learn_throughput: 1584.379\n","    learn_time_ms: 2524.648\n","    load_throughput: 9356020.522\n","    load_time_ms: 0.428\n","    sample_throughput: 550.046\n","    sample_time_ms: 7272.116\n","    update_time_ms: 2.833\n","  timestamp: 1649863272\n","  timesteps_since_restore: 100000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 100000\n","  training_iteration: 25\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 76000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-21-13\n","  done: false\n","  episode_len_mean: 385.83\n","  episode_media: {}\n","  episode_reward_max: 126.97406923704018\n","  episode_reward_mean: -9.860978662035325\n","  episode_reward_min: -429.8267536061066\n","  episodes_this_iter: 7\n","  episodes_total: 446\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.117150902748108\n","          entropy_coeff: 0.0\n","          kl: 0.00892125628888607\n","          model: {}\n","          policy_loss: -0.02944573014974594\n","          total_loss: 131.32398986816406\n","          vf_explained_var: 0.8525330424308777\n","          vf_loss: 131.3444061279297\n","    num_agent_steps_sampled: 76000\n","    num_agent_steps_trained: 76000\n","    num_steps_sampled: 76000\n","    num_steps_trained: 76000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 19\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.282352941176471\n","    ram_util_percent: 16.5\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07154385420607014\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5412674388418681\n","    mean_inference_ms: 0.7234471930326556\n","    mean_raw_obs_processing_ms: 0.11139546810598842\n","  time_since_restore: 181.2336301803589\n","  time_this_iter_s: 11.734840869903564\n","  time_total_s: 181.2336301803589\n","  timers:\n","    learn_throughput: 1603.494\n","    learn_time_ms: 2494.553\n","    load_throughput: 8447742.195\n","    load_time_ms: 0.473\n","    sample_throughput: 354.024\n","    sample_time_ms: 11298.672\n","    update_time_ms: 2.729\n","  timestamp: 1649863273\n","  timesteps_since_restore: 76000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 76000\n","  training_iteration: 19\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:21:15 (running for 00:03:26.03)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         180.135</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\">-216.026  </td><td style=\"text-align: right;\">             71.8028</td><td style=\"text-align: right;\">            -528.74 </td><td style=\"text-align: right;\">            105.25</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         181.234</td><td style=\"text-align: right;\"> 76000</td><td style=\"text-align: right;\">  -9.86098</td><td style=\"text-align: right;\">            126.974 </td><td style=\"text-align: right;\">            -429.827</td><td style=\"text-align: right;\">            385.83</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         166.779</td><td style=\"text-align: right;\"> 76000</td><td style=\"text-align: right;\">  18.133  </td><td style=\"text-align: right;\">            188.601 </td><td style=\"text-align: right;\">            -175.084</td><td style=\"text-align: right;\">            333.36</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 80000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-21-17\n","  done: false\n","  episode_len_mean: 360.86\n","  episode_media: {}\n","  episode_reward_max: 188.6009068125303\n","  episode_reward_mean: 22.952340270094037\n","  episode_reward_min: -175.08364409703088\n","  episodes_this_iter: 5\n","  episodes_total: 473\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.10000000149011612\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 1.0600032806396484\n","          entropy_coeff: 0.0\n","          kl: 0.007385503966361284\n","          model: {}\n","          policy_loss: -0.009741081856191158\n","          total_loss: 251.8072509765625\n","          vf_explained_var: 0.6885642409324646\n","          vf_loss: 251.81626892089844\n","    num_agent_steps_sampled: 80000\n","    num_agent_steps_trained: 80000\n","    num_steps_sampled: 80000\n","    num_steps_trained: 80000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 20\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.105882352941176\n","    ram_util_percent: 16.5\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07484244854828546\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.49909141284994873\n","    mean_inference_ms: 0.7474391991273446\n","    mean_raw_obs_processing_ms: 0.11524215957452279\n","  time_since_restore: 178.4054398536682\n","  time_this_iter_s: 11.626718997955322\n","  time_total_s: 178.4054398536682\n","  timers:\n","    learn_throughput: 1622.715\n","    learn_time_ms: 2465.005\n","    load_throughput: 8237046.347\n","    load_time_ms: 0.486\n","    sample_throughput: 403.727\n","    sample_time_ms: 9907.68\n","    update_time_ms: 2.744\n","  timestamp: 1649863277\n","  timesteps_since_restore: 80000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 80000\n","  training_iteration: 20\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 104000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-21-19\n","  done: false\n","  episode_len_mean: 111.58\n","  episode_media: {}\n","  episode_reward_max: 71.80276221119057\n","  episode_reward_mean: -240.12519477058385\n","  episode_reward_min: -551.6406485899753\n","  episodes_this_iter: 35\n","  episodes_total: 1097\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 2244.54833984375\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7081154584884644\n","          entropy_coeff: 0.0\n","          kl: 0.01901697739958763\n","          model: {}\n","          policy_loss: 0.01088946033269167\n","          total_loss: 1187.3680419921875\n","          vf_explained_var: 0.8209132552146912\n","          vf_loss: 1144.672607421875\n","    num_agent_steps_sampled: 104000\n","    num_agent_steps_trained: 104000\n","    num_steps_sampled: 104000\n","    num_steps_trained: 104000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 26\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.609090909090908\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07003806729417766\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.23914448520827292\n","    mean_inference_ms: 0.7175965823871615\n","    mean_raw_obs_processing_ms: 0.1128122937232985\n","  time_since_restore: 187.29246830940247\n","  time_this_iter_s: 7.157410383224487\n","  time_total_s: 187.29246830940247\n","  timers:\n","    learn_throughput: 1590.571\n","    learn_time_ms: 2514.82\n","    load_throughput: 9656507.425\n","    load_time_ms: 0.414\n","    sample_throughput: 554.918\n","    sample_time_ms: 7208.278\n","    update_time_ms: 2.822\n","  timestamp: 1649863279\n","  timesteps_since_restore: 104000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 104000\n","  training_iteration: 26\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:21:20 (running for 00:03:31.19)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         187.292</td><td style=\"text-align: right;\">104000</td><td style=\"text-align: right;\">-240.125  </td><td style=\"text-align: right;\">             71.8028</td><td style=\"text-align: right;\">            -551.641</td><td style=\"text-align: right;\">            111.58</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         181.234</td><td style=\"text-align: right;\"> 76000</td><td style=\"text-align: right;\">  -9.86098</td><td style=\"text-align: right;\">            126.974 </td><td style=\"text-align: right;\">            -429.827</td><td style=\"text-align: right;\">            385.83</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         178.405</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\">  22.9523 </td><td style=\"text-align: right;\">            188.601 </td><td style=\"text-align: right;\">            -175.084</td><td style=\"text-align: right;\">            360.86</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 80000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-21-25\n","  done: false\n","  episode_len_mean: 412.29\n","  episode_media: {}\n","  episode_reward_max: 126.97406923704018\n","  episode_reward_mean: -6.792014910295753\n","  episode_reward_min: -429.8267536061066\n","  episodes_this_iter: 4\n","  episodes_total: 450\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.1098979711532593\n","          entropy_coeff: 0.0\n","          kl: 0.010168490000069141\n","          model: {}\n","          policy_loss: -0.028851263225078583\n","          total_loss: 47.360504150390625\n","          vf_explained_var: 0.8516513705253601\n","          vf_loss: 47.379058837890625\n","    num_agent_steps_sampled: 80000\n","    num_agent_steps_trained: 80000\n","    num_steps_sampled: 80000\n","    num_steps_trained: 80000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 20\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.200000000000001\n","    ram_util_percent: 16.5\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07160915674551721\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.559826028758736\n","    mean_inference_ms: 0.7246913070739899\n","    mean_raw_obs_processing_ms: 0.11140455383340628\n","  time_since_restore: 193.32215881347656\n","  time_this_iter_s: 12.088528633117676\n","  time_total_s: 193.32215881347656\n","  timers:\n","    learn_throughput: 1610.281\n","    learn_time_ms: 2484.038\n","    load_throughput: 8479765.479\n","    load_time_ms: 0.472\n","    sample_throughput: 343.667\n","    sample_time_ms: 11639.181\n","    update_time_ms: 2.76\n","  timestamp: 1649863285\n","  timesteps_since_restore: 80000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 80000\n","  training_iteration: 20\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:21:27 (running for 00:03:37.27)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         187.292</td><td style=\"text-align: right;\">104000</td><td style=\"text-align: right;\">-240.125  </td><td style=\"text-align: right;\">             71.8028</td><td style=\"text-align: right;\">            -551.641</td><td style=\"text-align: right;\">            111.58</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         193.322</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\">  -6.79201</td><td style=\"text-align: right;\">            126.974 </td><td style=\"text-align: right;\">            -429.827</td><td style=\"text-align: right;\">            412.29</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         178.405</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\">  22.9523 </td><td style=\"text-align: right;\">            188.601 </td><td style=\"text-align: right;\">            -175.084</td><td style=\"text-align: right;\">            360.86</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 108000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-21-27\n","  done: false\n","  episode_len_mean: 117.7\n","  episode_media: {}\n","  episode_reward_max: 71.80276221119057\n","  episode_reward_mean: -275.9582139211112\n","  episode_reward_min: -551.6406485899753\n","  episodes_this_iter: 35\n","  episodes_total: 1132\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 2244.54833984375\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.6945492029190063\n","          entropy_coeff: 0.0\n","          kl: 0.022893615067005157\n","          model: {}\n","          policy_loss: 0.018376365303993225\n","          total_loss: 816.5823974609375\n","          vf_explained_var: 0.8141921162605286\n","          vf_loss: 765.17822265625\n","    num_agent_steps_sampled: 108000\n","    num_agent_steps_trained: 108000\n","    num_steps_sampled: 108000\n","    num_steps_trained: 108000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 27\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.1\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06997899916461126\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.24096383497676932\n","    mean_inference_ms: 0.7170148225116587\n","    mean_raw_obs_processing_ms: 0.11267409843315435\n","  time_since_restore: 194.40134859085083\n","  time_this_iter_s: 7.108880281448364\n","  time_total_s: 194.40134859085083\n","  timers:\n","    learn_throughput: 1595.077\n","    learn_time_ms: 2507.716\n","    load_throughput: 9647622.772\n","    load_time_ms: 0.415\n","    sample_throughput: 555.139\n","    sample_time_ms: 7205.405\n","    update_time_ms: 2.818\n","  timestamp: 1649863287\n","  timesteps_since_restore: 108000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 108000\n","  training_iteration: 27\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 84000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-21-28\n","  done: false\n","  episode_len_mean: 396.96\n","  episode_media: {}\n","  episode_reward_max: 188.6009068125303\n","  episode_reward_mean: 29.270267904350817\n","  episode_reward_min: -175.08364409703088\n","  episodes_this_iter: 6\n","  episodes_total: 479\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.10000000149011612\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 1.0304720401763916\n","          entropy_coeff: 0.0\n","          kl: 0.0072893560864031315\n","          model: {}\n","          policy_loss: -0.0124666728079319\n","          total_loss: 218.75762939453125\n","          vf_explained_var: 0.6102700233459473\n","          vf_loss: 218.76934814453125\n","    num_agent_steps_sampled: 84000\n","    num_agent_steps_trained: 84000\n","    num_steps_sampled: 84000\n","    num_steps_trained: 84000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 21\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.806666666666667\n","    ram_util_percent: 16.5\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07483586252727838\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5138408901576557\n","    mean_inference_ms: 0.7479997738674777\n","    mean_raw_obs_processing_ms: 0.11511760780723673\n","  time_since_restore: 188.9450876712799\n","  time_this_iter_s: 10.539647817611694\n","  time_total_s: 188.9450876712799\n","  timers:\n","    learn_throughput: 1627.219\n","    learn_time_ms: 2458.182\n","    load_throughput: 8290776.833\n","    load_time_ms: 0.482\n","    sample_throughput: 396.322\n","    sample_time_ms: 10092.81\n","    update_time_ms: 2.731\n","  timestamp: 1649863288\n","  timesteps_since_restore: 84000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 84000\n","  training_iteration: 21\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:21:32 (running for 00:03:42.79)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         194.401</td><td style=\"text-align: right;\">108000</td><td style=\"text-align: right;\">-275.958  </td><td style=\"text-align: right;\">             71.8028</td><td style=\"text-align: right;\">            -551.641</td><td style=\"text-align: right;\">            117.7 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         193.322</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\">  -6.79201</td><td style=\"text-align: right;\">            126.974 </td><td style=\"text-align: right;\">            -429.827</td><td style=\"text-align: right;\">            412.29</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         188.945</td><td style=\"text-align: right;\"> 84000</td><td style=\"text-align: right;\">  29.2703 </td><td style=\"text-align: right;\">            188.601 </td><td style=\"text-align: right;\">            -175.084</td><td style=\"text-align: right;\">            396.96</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 112000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-21-34\n","  done: false\n","  episode_len_mean: 111.92\n","  episode_media: {}\n","  episode_reward_max: 10.039442413002135\n","  episode_reward_mean: -316.71590135932917\n","  episode_reward_min: -742.9108777736687\n","  episodes_this_iter: 36\n","  episodes_total: 1168\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 3366.822509765625\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7206965684890747\n","          entropy_coeff: 0.0\n","          kl: 0.021072518080472946\n","          model: {}\n","          policy_loss: 0.005114832427352667\n","          total_loss: 1229.606689453125\n","          vf_explained_var: 0.7880390882492065\n","          vf_loss: 1158.6541748046875\n","    num_agent_steps_sampled: 112000\n","    num_agent_steps_trained: 112000\n","    num_steps_sampled: 112000\n","    num_steps_trained: 112000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 28\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 11.809999999999999\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06993924901811525\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2416244023028806\n","    mean_inference_ms: 0.7163018605229992\n","    mean_raw_obs_processing_ms: 0.11258315989266171\n","  time_since_restore: 201.35655522346497\n","  time_this_iter_s: 6.955206632614136\n","  time_total_s: 201.35655522346497\n","  timers:\n","    learn_throughput: 1597.18\n","    learn_time_ms: 2504.414\n","    load_throughput: 9522769.894\n","    load_time_ms: 0.42\n","    sample_throughput: 555.475\n","    sample_time_ms: 7201.046\n","    update_time_ms: 2.787\n","  timestamp: 1649863294\n","  timesteps_since_restore: 112000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 112000\n","  training_iteration: 28\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 84000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-21-37\n","  done: false\n","  episode_len_mean: 450.1\n","  episode_media: {}\n","  episode_reward_max: 126.97406923704018\n","  episode_reward_mean: -7.086311094727539\n","  episode_reward_min: -489.4459984118832\n","  episodes_this_iter: 8\n","  episodes_total: 458\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.0549215078353882\n","          entropy_coeff: 0.0\n","          kl: 0.015065611340105534\n","          model: {}\n","          policy_loss: -0.01997355744242668\n","          total_loss: 3064.830078125\n","          vf_explained_var: 0.6957331299781799\n","          vf_loss: 3064.83447265625\n","    num_agent_steps_sampled: 84000\n","    num_agent_steps_trained: 84000\n","    num_steps_sampled: 84000\n","    num_steps_trained: 84000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 21\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.770588235294117\n","    ram_util_percent: 16.5\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.071747270547651\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5987137542716547\n","    mean_inference_ms: 0.7272772450332812\n","    mean_raw_obs_processing_ms: 0.11142859747374124\n","  time_since_restore: 204.85683965682983\n","  time_this_iter_s: 11.534680843353271\n","  time_total_s: 204.85683965682983\n","  timers:\n","    learn_throughput: 1625.034\n","    learn_time_ms: 2461.487\n","    load_throughput: 8671292.123\n","    load_time_ms: 0.461\n","    sample_throughput: 338.238\n","    sample_time_ms: 11825.987\n","    update_time_ms: 2.787\n","  timestamp: 1649863297\n","  timesteps_since_restore: 84000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 84000\n","  training_iteration: 21\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 88000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-21-38\n","  done: false\n","  episode_len_mean: 423.63\n","  episode_media: {}\n","  episode_reward_max: 279.66324056492\n","  episode_reward_mean: 38.10604307829527\n","  episode_reward_min: -175.08364409703088\n","  episodes_this_iter: 6\n","  episodes_total: 485\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.10000000149011612\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.9507880806922913\n","          entropy_coeff: 0.0\n","          kl: 0.017906304448843002\n","          model: {}\n","          policy_loss: -0.014753168448805809\n","          total_loss: 321.432373046875\n","          vf_explained_var: 0.5914372205734253\n","          vf_loss: 321.4452819824219\n","    num_agent_steps_sampled: 88000\n","    num_agent_steps_trained: 88000\n","    num_steps_sampled: 88000\n","    num_steps_trained: 88000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 22\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.814285714285715\n","    ram_util_percent: 16.5\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07482032701179124\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5288121091314982\n","    mean_inference_ms: 0.7484799921091522\n","    mean_raw_obs_processing_ms: 0.11497749425016034\n","  time_since_restore: 198.7394723892212\n","  time_this_iter_s: 9.794384717941284\n","  time_total_s: 198.7394723892212\n","  timers:\n","    learn_throughput: 1623.63\n","    learn_time_ms: 2463.616\n","    load_throughput: 8346873.632\n","    load_time_ms: 0.479\n","    sample_throughput: 391.449\n","    sample_time_ms: 10218.434\n","    update_time_ms: 2.718\n","  timestamp: 1649863298\n","  timesteps_since_restore: 88000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 88000\n","  training_iteration: 22\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:21:38 (running for 00:03:48.61)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         201.357</td><td style=\"text-align: right;\">112000</td><td style=\"text-align: right;\">-316.716  </td><td style=\"text-align: right;\">             10.0394</td><td style=\"text-align: right;\">            -742.911</td><td style=\"text-align: right;\">            111.92</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         204.857</td><td style=\"text-align: right;\"> 84000</td><td style=\"text-align: right;\">  -7.08631</td><td style=\"text-align: right;\">            126.974 </td><td style=\"text-align: right;\">            -489.446</td><td style=\"text-align: right;\">            450.1 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         198.739</td><td style=\"text-align: right;\"> 88000</td><td style=\"text-align: right;\">  38.106  </td><td style=\"text-align: right;\">            279.663 </td><td style=\"text-align: right;\">            -175.084</td><td style=\"text-align: right;\">            423.63</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 116000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-21-41\n","  done: false\n","  episode_len_mean: 111.01\n","  episode_media: {}\n","  episode_reward_max: 10.039442413002135\n","  episode_reward_mean: -312.52151144519274\n","  episode_reward_min: -742.9108777736687\n","  episodes_this_iter: 38\n","  episodes_total: 1206\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 5050.23388671875\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.6840978860855103\n","          entropy_coeff: 0.0\n","          kl: 0.03914109990000725\n","          model: {}\n","          policy_loss: 0.004642219748347998\n","          total_loss: 831.7339477539062\n","          vf_explained_var: 0.8335789442062378\n","          vf_loss: 634.0576782226562\n","    num_agent_steps_sampled: 116000\n","    num_agent_steps_trained: 116000\n","    num_steps_sampled: 116000\n","    num_steps_trained: 116000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 29\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.290000000000001\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06993055050120241\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.24241432850468173\n","    mean_inference_ms: 0.7159025485151805\n","    mean_raw_obs_processing_ms: 0.11255670130609381\n","  time_since_restore: 208.6699731349945\n","  time_this_iter_s: 7.313417911529541\n","  time_total_s: 208.6699731349945\n","  timers:\n","    learn_throughput: 1599.807\n","    learn_time_ms: 2500.301\n","    load_throughput: 9438127.813\n","    load_time_ms: 0.424\n","    sample_throughput: 555.338\n","    sample_time_ms: 7202.825\n","    update_time_ms: 2.788\n","  timestamp: 1649863301\n","  timesteps_since_restore: 116000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 116000\n","  training_iteration: 29\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:21:43 (running for 00:03:53.67)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         208.67 </td><td style=\"text-align: right;\">116000</td><td style=\"text-align: right;\">-312.522  </td><td style=\"text-align: right;\">             10.0394</td><td style=\"text-align: right;\">            -742.911</td><td style=\"text-align: right;\">            111.01</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         204.857</td><td style=\"text-align: right;\"> 84000</td><td style=\"text-align: right;\">  -7.08631</td><td style=\"text-align: right;\">            126.974 </td><td style=\"text-align: right;\">            -489.446</td><td style=\"text-align: right;\">            450.1 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         198.739</td><td style=\"text-align: right;\"> 88000</td><td style=\"text-align: right;\">  38.106  </td><td style=\"text-align: right;\">            279.663 </td><td style=\"text-align: right;\">            -175.084</td><td style=\"text-align: right;\">            423.63</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 88000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-21-47\n","  done: false\n","  episode_len_mean: 453.99\n","  episode_media: {}\n","  episode_reward_max: 126.97406923704018\n","  episode_reward_mean: -19.511748826323892\n","  episode_reward_min: -489.4459984118832\n","  episodes_this_iter: 12\n","  episodes_total: 470\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.0350240468978882\n","          entropy_coeff: 0.0\n","          kl: 0.013923507183790207\n","          model: {}\n","          policy_loss: -0.042911894619464874\n","          total_loss: 5536.76416015625\n","          vf_explained_var: 0.640606701374054\n","          vf_loss: 5536.79296875\n","    num_agent_steps_sampled: 88000\n","    num_agent_steps_trained: 88000\n","    num_steps_sampled: 88000\n","    num_steps_trained: 88000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 22\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.042857142857143\n","    ram_util_percent: 16.5\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07192963682842257\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6533118887042596\n","    mean_inference_ms: 0.7307572075540463\n","    mean_raw_obs_processing_ms: 0.11143476691647031\n","  time_since_restore: 214.84153604507446\n","  time_this_iter_s: 9.984696388244629\n","  time_total_s: 214.84153604507446\n","  timers:\n","    learn_throughput: 1619.29\n","    learn_time_ms: 2470.219\n","    load_throughput: 8669947.806\n","    load_time_ms: 0.461\n","    sample_throughput: 342.942\n","    sample_time_ms: 11663.767\n","    update_time_ms: 2.781\n","  timestamp: 1649863307\n","  timesteps_since_restore: 88000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 88000\n","  training_iteration: 22\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 120000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-21-48\n","  done: false\n","  episode_len_mean: 109.82\n","  episode_media: {}\n","  episode_reward_max: 21.85759505582311\n","  episode_reward_mean: -303.39659163684144\n","  episode_reward_min: -593.5827439907073\n","  episodes_this_iter: 34\n","  episodes_total: 1240\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 7575.3505859375\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7069668173789978\n","          entropy_coeff: 0.0\n","          kl: 0.03128712251782417\n","          model: {}\n","          policy_loss: 0.0002457593218423426\n","          total_loss: 2237.150146484375\n","          vf_explained_var: 0.6630692481994629\n","          vf_loss: 2000.1390380859375\n","    num_agent_steps_sampled: 120000\n","    num_agent_steps_trained: 120000\n","    num_steps_sampled: 120000\n","    num_steps_trained: 120000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 30\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.080000000000002\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06990674947520986\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.24299888968997557\n","    mean_inference_ms: 0.7153756469556717\n","    mean_raw_obs_processing_ms: 0.11250137338057833\n","  time_since_restore: 215.7767186164856\n","  time_this_iter_s: 7.106745481491089\n","  time_total_s: 215.7767186164856\n","  timers:\n","    learn_throughput: 1599.261\n","    learn_time_ms: 2501.155\n","    load_throughput: 9440783.299\n","    load_time_ms: 0.424\n","    sample_throughput: 555.85\n","    sample_time_ms: 7196.182\n","    update_time_ms: 2.771\n","  timestamp: 1649863308\n","  timesteps_since_restore: 120000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 120000\n","  training_iteration: 30\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:21:48 (running for 00:03:58.82)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         215.777</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-303.397 </td><td style=\"text-align: right;\">             21.8576</td><td style=\"text-align: right;\">            -593.583</td><td style=\"text-align: right;\">            109.82</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         214.842</td><td style=\"text-align: right;\"> 88000</td><td style=\"text-align: right;\"> -19.5117</td><td style=\"text-align: right;\">            126.974 </td><td style=\"text-align: right;\">            -489.446</td><td style=\"text-align: right;\">            453.99</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         198.739</td><td style=\"text-align: right;\"> 88000</td><td style=\"text-align: right;\">  38.106 </td><td style=\"text-align: right;\">            279.663 </td><td style=\"text-align: right;\">            -175.084</td><td style=\"text-align: right;\">            423.63</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 92000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-21-48\n","  done: false\n","  episode_len_mean: 455.84\n","  episode_media: {}\n","  episode_reward_max: 279.66324056492\n","  episode_reward_mean: 46.61867898653568\n","  episode_reward_min: -63.29630937622002\n","  episodes_this_iter: 4\n","  episodes_total: 489\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.10000000149011612\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.8834804892539978\n","          entropy_coeff: 0.0\n","          kl: 0.005055407993495464\n","          model: {}\n","          policy_loss: -0.009097415022552013\n","          total_loss: 67.97640228271484\n","          vf_explained_var: 0.661073625087738\n","          vf_loss: 67.98499298095703\n","    num_agent_steps_sampled: 92000\n","    num_agent_steps_trained: 92000\n","    num_steps_sampled: 92000\n","    num_steps_trained: 92000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 23\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.046666666666665\n","    ram_util_percent: 16.5\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07480991341782893\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5392592764251006\n","    mean_inference_ms: 0.748846208130542\n","    mean_raw_obs_processing_ms: 0.11487822466852939\n","  time_since_restore: 208.9851815700531\n","  time_this_iter_s: 10.24570918083191\n","  time_total_s: 208.9851815700531\n","  timers:\n","    learn_throughput: 1614.507\n","    learn_time_ms: 2477.537\n","    load_throughput: 7950156.85\n","    load_time_ms: 0.503\n","    sample_throughput: 392.985\n","    sample_time_ms: 10178.514\n","    update_time_ms: 2.717\n","  timestamp: 1649863308\n","  timesteps_since_restore: 92000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 92000\n","  training_iteration: 23\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:21:53 (running for 00:04:03.90)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         215.777</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-303.397 </td><td style=\"text-align: right;\">             21.8576</td><td style=\"text-align: right;\">           -593.583 </td><td style=\"text-align: right;\">            109.82</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         214.842</td><td style=\"text-align: right;\"> 88000</td><td style=\"text-align: right;\"> -19.5117</td><td style=\"text-align: right;\">            126.974 </td><td style=\"text-align: right;\">           -489.446 </td><td style=\"text-align: right;\">            453.99</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         208.985</td><td style=\"text-align: right;\"> 92000</td><td style=\"text-align: right;\">  46.6187</td><td style=\"text-align: right;\">            279.663 </td><td style=\"text-align: right;\">            -63.2963</td><td style=\"text-align: right;\">            455.84</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 124000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-21-55\n","  done: false\n","  episode_len_mean: 113.31\n","  episode_media: {}\n","  episode_reward_max: 45.234525392325935\n","  episode_reward_mean: -301.31450240401966\n","  episode_reward_min: -593.5827439907073\n","  episodes_this_iter: 35\n","  episodes_total: 1275\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 11363.025390625\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7113984227180481\n","          entropy_coeff: 0.0\n","          kl: 0.020962044596672058\n","          model: {}\n","          policy_loss: 0.008802869357168674\n","          total_loss: 2029.119384765625\n","          vf_explained_var: 0.6076819896697998\n","          vf_loss: 1790.9183349609375\n","    num_agent_steps_sampled: 124000\n","    num_agent_steps_trained: 124000\n","    num_steps_sampled: 124000\n","    num_steps_trained: 124000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 31\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 11.030000000000001\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06985498714578903\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.24354628040833926\n","    mean_inference_ms: 0.714617964976657\n","    mean_raw_obs_processing_ms: 0.11239926398298782\n","  time_since_restore: 222.71260929107666\n","  time_this_iter_s: 6.9358906745910645\n","  time_total_s: 222.71260929107666\n","  timers:\n","    learn_throughput: 1601.652\n","    learn_time_ms: 2497.421\n","    load_throughput: 9346117.765\n","    load_time_ms: 0.428\n","    sample_throughput: 556.829\n","    sample_time_ms: 7183.531\n","    update_time_ms: 2.743\n","  timestamp: 1649863315\n","  timesteps_since_restore: 124000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 124000\n","  training_iteration: 31\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 92000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-21-58\n","  done: false\n","  episode_len_mean: 486.38\n","  episode_media: {}\n","  episode_reward_max: 126.97406923704018\n","  episode_reward_mean: -28.5072161667683\n","  episode_reward_min: -489.4459984118832\n","  episodes_this_iter: 7\n","  episodes_total: 477\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.0333904027938843\n","          entropy_coeff: 0.0\n","          kl: 0.012419282458722591\n","          model: {}\n","          policy_loss: -0.030010206624865532\n","          total_loss: 1796.8057861328125\n","          vf_explained_var: 0.48659080266952515\n","          vf_loss: 1796.8232421875\n","    num_agent_steps_sampled: 92000\n","    num_agent_steps_trained: 92000\n","    num_steps_sampled: 92000\n","    num_steps_trained: 92000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 23\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.54375\n","    ram_util_percent: 16.5\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07203541383786008\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.685510301821903\n","    mean_inference_ms: 0.732808342177064\n","    mean_raw_obs_processing_ms: 0.11143409980175673\n","  time_since_restore: 225.69343876838684\n","  time_this_iter_s: 10.851902723312378\n","  time_total_s: 225.69343876838684\n","  timers:\n","    learn_throughput: 1618.714\n","    learn_time_ms: 2471.097\n","    load_throughput: 8736768.213\n","    load_time_ms: 0.458\n","    sample_throughput: 341.367\n","    sample_time_ms: 11717.608\n","    update_time_ms: 2.758\n","  timestamp: 1649863318\n","  timesteps_since_restore: 92000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 92000\n","  training_iteration: 23\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 96000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-21-59\n","  done: false\n","  episode_len_mean: 491.43\n","  episode_media: {}\n","  episode_reward_max: 279.66324056492\n","  episode_reward_mean: 52.21588320428222\n","  episode_reward_min: -63.29630937622002\n","  episodes_this_iter: 4\n","  episodes_total: 493\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.10000000149011612\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.898938000202179\n","          entropy_coeff: 0.0\n","          kl: 0.004081046208739281\n","          model: {}\n","          policy_loss: -0.009730453602969646\n","          total_loss: 41.91750717163086\n","          vf_explained_var: 0.7371152639389038\n","          vf_loss: 41.92682647705078\n","    num_agent_steps_sampled: 96000\n","    num_agent_steps_trained: 96000\n","    num_steps_sampled: 96000\n","    num_steps_trained: 96000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 24\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.5\n","    ram_util_percent: 16.5\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07479716988968961\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5503256790455486\n","    mean_inference_ms: 0.7492309145301848\n","    mean_raw_obs_processing_ms: 0.11477060460312848\n","  time_since_restore: 219.47778010368347\n","  time_this_iter_s: 10.492598533630371\n","  time_total_s: 219.47778010368347\n","  timers:\n","    learn_throughput: 1616.163\n","    learn_time_ms: 2474.998\n","    load_throughput: 8260162.474\n","    load_time_ms: 0.484\n","    sample_throughput: 389.479\n","    sample_time_ms: 10270.139\n","    update_time_ms: 2.701\n","  timestamp: 1649863319\n","  timesteps_since_restore: 96000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 96000\n","  training_iteration: 24\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:21:59 (running for 00:04:09.43)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         222.713</td><td style=\"text-align: right;\">124000</td><td style=\"text-align: right;\">-301.315 </td><td style=\"text-align: right;\">             45.2345</td><td style=\"text-align: right;\">           -593.583 </td><td style=\"text-align: right;\">            113.31</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         225.693</td><td style=\"text-align: right;\"> 92000</td><td style=\"text-align: right;\"> -28.5072</td><td style=\"text-align: right;\">            126.974 </td><td style=\"text-align: right;\">           -489.446 </td><td style=\"text-align: right;\">            486.38</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         219.478</td><td style=\"text-align: right;\"> 96000</td><td style=\"text-align: right;\">  52.2159</td><td style=\"text-align: right;\">            279.663 </td><td style=\"text-align: right;\">            -63.2963</td><td style=\"text-align: right;\">            491.43</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 128000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-22-02\n","  done: false\n","  episode_len_mean: 112.02\n","  episode_media: {}\n","  episode_reward_max: 45.234525392325935\n","  episode_reward_mean: -307.4173767793783\n","  episode_reward_min: -590.4304656268653\n","  episodes_this_iter: 37\n","  episodes_total: 1312\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 17044.5390625\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.6662383675575256\n","          entropy_coeff: 0.0\n","          kl: 0.015473749488592148\n","          model: {}\n","          policy_loss: -0.005482450593262911\n","          total_loss: 1024.7100830078125\n","          vf_explained_var: 0.8142613768577576\n","          vf_loss: 760.9725952148438\n","    num_agent_steps_sampled: 128000\n","    num_agent_steps_trained: 128000\n","    num_steps_sampled: 128000\n","    num_steps_trained: 128000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 32\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.263636363636367\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06980207268365474\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.24423281662348245\n","    mean_inference_ms: 0.7138988805323314\n","    mean_raw_obs_processing_ms: 0.11228911892875892\n","  time_since_restore: 230.0554735660553\n","  time_this_iter_s: 7.342864274978638\n","  time_total_s: 230.0554735660553\n","  timers:\n","    learn_throughput: 1606.507\n","    learn_time_ms: 2489.874\n","    load_throughput: 8586088.025\n","    load_time_ms: 0.466\n","    sample_throughput: 556.211\n","    sample_time_ms: 7191.519\n","    update_time_ms: 2.769\n","  timestamp: 1649863322\n","  timesteps_since_restore: 128000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 128000\n","  training_iteration: 32\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:22:04 (running for 00:04:15.18)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         230.055</td><td style=\"text-align: right;\">128000</td><td style=\"text-align: right;\">-307.417 </td><td style=\"text-align: right;\">             45.2345</td><td style=\"text-align: right;\">           -590.43  </td><td style=\"text-align: right;\">            112.02</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         225.693</td><td style=\"text-align: right;\"> 92000</td><td style=\"text-align: right;\"> -28.5072</td><td style=\"text-align: right;\">            126.974 </td><td style=\"text-align: right;\">           -489.446 </td><td style=\"text-align: right;\">            486.38</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         219.478</td><td style=\"text-align: right;\"> 96000</td><td style=\"text-align: right;\">  52.2159</td><td style=\"text-align: right;\">            279.663 </td><td style=\"text-align: right;\">            -63.2963</td><td style=\"text-align: right;\">            491.43</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 96000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-22-08\n","  done: false\n","  episode_len_mean: 484.82\n","  episode_media: {}\n","  episode_reward_max: 126.97406923704018\n","  episode_reward_mean: -37.942349925473856\n","  episode_reward_min: -489.4459984118832\n","  episodes_this_iter: 11\n","  episodes_total: 488\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.033813238143921\n","          entropy_coeff: 0.0\n","          kl: 0.014272556640207767\n","          model: {}\n","          policy_loss: -0.04133886843919754\n","          total_loss: 2387.650634765625\n","          vf_explained_var: 0.45269015431404114\n","          vf_loss: 2387.677490234375\n","    num_agent_steps_sampled: 96000\n","    num_agent_steps_trained: 96000\n","    num_steps_sampled: 96000\n","    num_steps_trained: 96000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 24\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.892857142857142\n","    ram_util_percent: 16.5\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07217797944931262\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.730902719031314\n","    mean_inference_ms: 0.7356253787208706\n","    mean_raw_obs_processing_ms: 0.11140529495569322\n","  time_since_restore: 235.70717120170593\n","  time_this_iter_s: 10.013732433319092\n","  time_total_s: 235.70717120170593\n","  timers:\n","    learn_throughput: 1615.395\n","    learn_time_ms: 2476.174\n","    load_throughput: 9475976.278\n","    load_time_ms: 0.422\n","    sample_throughput: 348.304\n","    sample_time_ms: 11484.221\n","    update_time_ms: 2.784\n","  timestamp: 1649863328\n","  timesteps_since_restore: 96000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 96000\n","  training_iteration: 24\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 100000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-22-09\n","  done: false\n","  episode_len_mean: 527.25\n","  episode_media: {}\n","  episode_reward_max: 279.66324056492\n","  episode_reward_mean: 58.45051118878225\n","  episode_reward_min: -63.29630937622002\n","  episodes_this_iter: 4\n","  episodes_total: 497\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.05000000074505806\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.8611923456192017\n","          entropy_coeff: 0.0\n","          kl: 0.006311884615570307\n","          model: {}\n","          policy_loss: -0.018454520031809807\n","          total_loss: 71.62135314941406\n","          vf_explained_var: 0.7610250115394592\n","          vf_loss: 71.63949584960938\n","    num_agent_steps_sampled: 100000\n","    num_agent_steps_trained: 100000\n","    num_steps_sampled: 100000\n","    num_steps_trained: 100000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 25\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.450000000000001\n","    ram_util_percent: 16.5\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07478420273817812\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5616655708583175\n","    mean_inference_ms: 0.7496375008374123\n","    mean_raw_obs_processing_ms: 0.11465442852904069\n","  time_since_restore: 229.357976436615\n","  time_this_iter_s: 9.880196332931519\n","  time_total_s: 229.357976436615\n","  timers:\n","    learn_throughput: 1611.109\n","    learn_time_ms: 2482.762\n","    load_throughput: 8174039.464\n","    load_time_ms: 0.489\n","    sample_throughput: 388.623\n","    sample_time_ms: 10292.742\n","    update_time_ms: 2.731\n","  timestamp: 1649863329\n","  timesteps_since_restore: 100000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 100000\n","  training_iteration: 25\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:22:10 (running for 00:04:20.35)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         230.055</td><td style=\"text-align: right;\">128000</td><td style=\"text-align: right;\">-307.417 </td><td style=\"text-align: right;\">             45.2345</td><td style=\"text-align: right;\">           -590.43  </td><td style=\"text-align: right;\">            112.02</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         235.707</td><td style=\"text-align: right;\"> 96000</td><td style=\"text-align: right;\"> -37.9423</td><td style=\"text-align: right;\">            126.974 </td><td style=\"text-align: right;\">           -489.446 </td><td style=\"text-align: right;\">            484.82</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         229.358</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\">  58.4505</td><td style=\"text-align: right;\">            279.663 </td><td style=\"text-align: right;\">            -63.2963</td><td style=\"text-align: right;\">            527.25</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 132000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-22-10\n","  done: false\n","  episode_len_mean: 112.62\n","  episode_media: {}\n","  episode_reward_max: 45.234525392325935\n","  episode_reward_mean: -310.6902662289869\n","  episode_reward_min: -632.1103296812937\n","  episodes_this_iter: 35\n","  episodes_total: 1347\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 17044.5390625\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.698074460029602\n","          entropy_coeff: 0.0\n","          kl: 0.02246011048555374\n","          model: {}\n","          policy_loss: 0.005697550252079964\n","          total_loss: 2180.279541015625\n","          vf_explained_var: 0.7128488421440125\n","          vf_loss: 1797.4517822265625\n","    num_agent_steps_sampled: 132000\n","    num_agent_steps_trained: 132000\n","    num_steps_sampled: 132000\n","    num_steps_trained: 132000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 33\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.510000000000002\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06978615754566873\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.24501925035967242\n","    mean_inference_ms: 0.7136166485795625\n","    mean_raw_obs_processing_ms: 0.11224716750535603\n","  time_since_restore: 237.26982235908508\n","  time_this_iter_s: 7.214348793029785\n","  time_total_s: 237.26982235908508\n","  timers:\n","    learn_throughput: 1605.661\n","    learn_time_ms: 2491.186\n","    load_throughput: 8673533.578\n","    load_time_ms: 0.461\n","    sample_throughput: 555.79\n","    sample_time_ms: 7196.958\n","    update_time_ms: 2.792\n","  timestamp: 1649863330\n","  timesteps_since_restore: 132000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 132000\n","  training_iteration: 33\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:22:15 (running for 00:04:25.43)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         237.27 </td><td style=\"text-align: right;\">132000</td><td style=\"text-align: right;\">-310.69  </td><td style=\"text-align: right;\">             45.2345</td><td style=\"text-align: right;\">           -632.11  </td><td style=\"text-align: right;\">            112.62</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         235.707</td><td style=\"text-align: right;\"> 96000</td><td style=\"text-align: right;\"> -37.9423</td><td style=\"text-align: right;\">            126.974 </td><td style=\"text-align: right;\">           -489.446 </td><td style=\"text-align: right;\">            484.82</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         229.358</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\">  58.4505</td><td style=\"text-align: right;\">            279.663 </td><td style=\"text-align: right;\">            -63.2963</td><td style=\"text-align: right;\">            527.25</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 136000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-22-17\n","  done: false\n","  episode_len_mean: 108.43\n","  episode_media: {}\n","  episode_reward_max: -8.490372409732643\n","  episode_reward_mean: -290.303583998324\n","  episode_reward_min: -632.1103296812937\n","  episodes_this_iter: 39\n","  episodes_total: 1386\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 25566.80859375\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.6665524840354919\n","          entropy_coeff: 0.0\n","          kl: 0.03816235437989235\n","          model: {}\n","          policy_loss: 0.011141966097056866\n","          total_loss: 1438.8369140625\n","          vf_explained_var: 0.8143941164016724\n","          vf_loss: 463.13629150390625\n","    num_agent_steps_sampled: 136000\n","    num_agent_steps_trained: 136000\n","    num_steps_sampled: 136000\n","    num_steps_trained: 136000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 34\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 10.41\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0697550471183862\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.24554442181704683\n","    mean_inference_ms: 0.7132753787020869\n","    mean_raw_obs_processing_ms: 0.11219977623897925\n","  time_since_restore: 244.1885232925415\n","  time_this_iter_s: 6.918700933456421\n","  time_total_s: 244.1885232925415\n","  timers:\n","    learn_throughput: 1607.785\n","    learn_time_ms: 2487.895\n","    load_throughput: 8856216.216\n","    load_time_ms: 0.452\n","    sample_throughput: 556.53\n","    sample_time_ms: 7187.397\n","    update_time_ms: 2.775\n","  timestamp: 1649863337\n","  timesteps_since_restore: 136000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 136000\n","  training_iteration: 34\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 104000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-22-19\n","  done: false\n","  episode_len_mean: 555.11\n","  episode_media: {}\n","  episode_reward_max: 279.66324056492\n","  episode_reward_mean: 63.91931010091463\n","  episode_reward_min: -63.29630937622002\n","  episodes_this_iter: 5\n","  episodes_total: 502\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.05000000074505806\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7497613430023193\n","          entropy_coeff: 0.0\n","          kl: 0.00936315581202507\n","          model: {}\n","          policy_loss: -0.01055958028882742\n","          total_loss: 174.26087951660156\n","          vf_explained_var: 0.5061485767364502\n","          vf_loss: 174.27096557617188\n","    num_agent_steps_sampled: 104000\n","    num_agent_steps_trained: 104000\n","    num_steps_sampled: 104000\n","    num_steps_trained: 104000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 26\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.492857142857142\n","    ram_util_percent: 16.5\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07476668203674496\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5758128033403659\n","    mean_inference_ms: 0.7501509277699268\n","    mean_raw_obs_processing_ms: 0.11450622958589018\n","  time_since_restore: 239.52395725250244\n","  time_this_iter_s: 10.165980815887451\n","  time_total_s: 239.52395725250244\n","  timers:\n","    learn_throughput: 1612.931\n","    learn_time_ms: 2479.958\n","    load_throughput: 8183608.604\n","    load_time_ms: 0.489\n","    sample_throughput: 387.298\n","    sample_time_ms: 10327.963\n","    update_time_ms: 2.743\n","  timestamp: 1649863339\n","  timesteps_since_restore: 104000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 104000\n","  training_iteration: 26\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 100000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-22-20\n","  done: false\n","  episode_len_mean: 516.06\n","  episode_media: {}\n","  episode_reward_max: 126.97406923704018\n","  episode_reward_mean: -37.90067826964878\n","  episode_reward_min: -489.4459984118832\n","  episodes_this_iter: 6\n","  episodes_total: 494\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.093955159187317\n","          entropy_coeff: 0.0\n","          kl: 0.01111979316920042\n","          model: {}\n","          policy_loss: -0.04142090678215027\n","          total_loss: 736.2808227539062\n","          vf_explained_var: 0.6727161407470703\n","          vf_loss: 736.31103515625\n","    num_agent_steps_sampled: 100000\n","    num_agent_steps_trained: 100000\n","    num_steps_sampled: 100000\n","    num_steps_trained: 100000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 25\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.711764705882354\n","    ram_util_percent: 16.5\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07225509885901403\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.7555805149857204\n","    mean_inference_ms: 0.7371423779595853\n","    mean_raw_obs_processing_ms: 0.11138713506568398\n","  time_since_restore: 247.32162976264954\n","  time_this_iter_s: 11.614458560943604\n","  time_total_s: 247.32162976264954\n","  timers:\n","    learn_throughput: 1611.349\n","    learn_time_ms: 2482.392\n","    load_throughput: 9341954.452\n","    load_time_ms: 0.428\n","    sample_throughput: 346.749\n","    sample_time_ms: 11535.717\n","    update_time_ms: 2.762\n","  timestamp: 1649863340\n","  timesteps_since_restore: 100000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 100000\n","  training_iteration: 25\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:22:21 (running for 00:04:31.40)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         244.189</td><td style=\"text-align: right;\">136000</td><td style=\"text-align: right;\">-290.304 </td><td style=\"text-align: right;\">            -8.49037</td><td style=\"text-align: right;\">           -632.11  </td><td style=\"text-align: right;\">            108.43</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         247.322</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -37.9007</td><td style=\"text-align: right;\">           126.974  </td><td style=\"text-align: right;\">           -489.446 </td><td style=\"text-align: right;\">            516.06</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         239.524</td><td style=\"text-align: right;\">104000</td><td style=\"text-align: right;\">  63.9193</td><td style=\"text-align: right;\">           279.663  </td><td style=\"text-align: right;\">            -63.2963</td><td style=\"text-align: right;\">            555.11</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 140000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-22-24\n","  done: false\n","  episode_len_mean: 106.55\n","  episode_media: {}\n","  episode_reward_max: 2.8329110525500028\n","  episode_reward_mean: -279.2806857456856\n","  episode_reward_min: -632.1103296812937\n","  episodes_this_iter: 37\n","  episodes_total: 1423\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 38350.2109375\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.6851057410240173\n","          entropy_coeff: 0.0\n","          kl: 0.05568366125226021\n","          model: {}\n","          policy_loss: 0.0027798519004136324\n","          total_loss: 3925.884521484375\n","          vf_explained_var: 0.749204158782959\n","          vf_loss: 1790.401611328125\n","    num_agent_steps_sampled: 140000\n","    num_agent_steps_trained: 140000\n","    num_steps_sampled: 140000\n","    num_steps_trained: 140000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 35\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.281818181818181\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06973093973586382\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.24595021495818792\n","    mean_inference_ms: 0.7130893786712287\n","    mean_raw_obs_processing_ms: 0.11216151417127246\n","  time_since_restore: 251.49639582633972\n","  time_this_iter_s: 7.307872533798218\n","  time_total_s: 251.49639582633972\n","  timers:\n","    learn_throughput: 1613.259\n","    learn_time_ms: 2479.453\n","    load_throughput: 8776071.559\n","    load_time_ms: 0.456\n","    sample_throughput: 556.891\n","    sample_time_ms: 7182.737\n","    update_time_ms: 2.703\n","  timestamp: 1649863344\n","  timesteps_since_restore: 140000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 140000\n","  training_iteration: 35\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:22:26 (running for 00:04:36.74)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         251.496</td><td style=\"text-align: right;\">140000</td><td style=\"text-align: right;\">-279.281 </td><td style=\"text-align: right;\">             2.83291</td><td style=\"text-align: right;\">           -632.11  </td><td style=\"text-align: right;\">            106.55</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         247.322</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -37.9007</td><td style=\"text-align: right;\">           126.974  </td><td style=\"text-align: right;\">           -489.446 </td><td style=\"text-align: right;\">            516.06</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         239.524</td><td style=\"text-align: right;\">104000</td><td style=\"text-align: right;\">  63.9193</td><td style=\"text-align: right;\">           279.663  </td><td style=\"text-align: right;\">            -63.2963</td><td style=\"text-align: right;\">            555.11</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 108000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-22-29\n","  done: false\n","  episode_len_mean: 576.38\n","  episode_media: {}\n","  episode_reward_max: 286.62593647483067\n","  episode_reward_mean: 72.0660112450487\n","  episode_reward_min: -63.29630937622002\n","  episodes_this_iter: 4\n","  episodes_total: 506\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.05000000074505806\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6621793508529663\n","          entropy_coeff: 0.0\n","          kl: 0.01087987795472145\n","          model: {}\n","          policy_loss: -0.008253880776464939\n","          total_loss: 294.2948913574219\n","          vf_explained_var: 0.22827033698558807\n","          vf_loss: 294.3026123046875\n","    num_agent_steps_sampled: 108000\n","    num_agent_steps_trained: 108000\n","    num_steps_sampled: 108000\n","    num_steps_trained: 108000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 27\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.59375\n","    ram_util_percent: 16.53125\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07475108710562604\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5860450983311458\n","    mean_inference_ms: 0.7505310863618755\n","    mean_raw_obs_processing_ms: 0.11438832792100805\n","  time_since_restore: 250.05826878547668\n","  time_this_iter_s: 10.534311532974243\n","  time_total_s: 250.05826878547668\n","  timers:\n","    learn_throughput: 1612.06\n","    learn_time_ms: 2481.297\n","    load_throughput: 8357684.567\n","    load_time_ms: 0.479\n","    sample_throughput: 383.939\n","    sample_time_ms: 10418.315\n","    update_time_ms: 2.769\n","  timestamp: 1649863349\n","  timesteps_since_restore: 108000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 108000\n","  training_iteration: 27\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 104000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-22-31\n","  done: false\n","  episode_len_mean: 530.16\n","  episode_media: {}\n","  episode_reward_max: 126.97406923704018\n","  episode_reward_mean: -36.66175303386807\n","  episode_reward_min: -489.4459984118832\n","  episodes_this_iter: 7\n","  episodes_total: 501\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.0799005031585693\n","          entropy_coeff: 0.0\n","          kl: 0.014411752112209797\n","          model: {}\n","          policy_loss: -0.03928299620747566\n","          total_loss: 348.9510803222656\n","          vf_explained_var: 0.7114775776863098\n","          vf_loss: 348.9757995605469\n","    num_agent_steps_sampled: 104000\n","    num_agent_steps_trained: 104000\n","    num_steps_sampled: 104000\n","    num_steps_trained: 104000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 26\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.90625\n","    ram_util_percent: 16.54375\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07232477819665123\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.782973555593494\n","    mean_inference_ms: 0.7387554577551206\n","    mean_raw_obs_processing_ms: 0.11136899572625274\n","  time_since_restore: 259.0136966705322\n","  time_this_iter_s: 11.69206690788269\n","  time_total_s: 259.0136966705322\n","  timers:\n","    learn_throughput: 1607.639\n","    learn_time_ms: 2488.12\n","    load_throughput: 9452485.21\n","    load_time_ms: 0.423\n","    sample_throughput: 348.757\n","    sample_time_ms: 11469.292\n","    update_time_ms: 2.814\n","  timestamp: 1649863351\n","  timesteps_since_restore: 104000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 104000\n","  training_iteration: 26\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:22:31 (running for 00:04:42.13)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         251.496</td><td style=\"text-align: right;\">140000</td><td style=\"text-align: right;\">-279.281 </td><td style=\"text-align: right;\">             2.83291</td><td style=\"text-align: right;\">           -632.11  </td><td style=\"text-align: right;\">            106.55</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         259.014</td><td style=\"text-align: right;\">104000</td><td style=\"text-align: right;\"> -36.6618</td><td style=\"text-align: right;\">           126.974  </td><td style=\"text-align: right;\">           -489.446 </td><td style=\"text-align: right;\">            530.16</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         250.058</td><td style=\"text-align: right;\">108000</td><td style=\"text-align: right;\">  72.066 </td><td style=\"text-align: right;\">           286.626  </td><td style=\"text-align: right;\">            -63.2963</td><td style=\"text-align: right;\">            576.38</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 144000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-22-31\n","  done: false\n","  episode_len_mean: 109.95\n","  episode_media: {}\n","  episode_reward_max: 4.361988402511983\n","  episode_reward_mean: -288.2943229406953\n","  episode_reward_min: -615.4919495915624\n","  episodes_this_iter: 34\n","  episodes_total: 1457\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 57525.31640625\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.699516773223877\n","          entropy_coeff: 0.0\n","          kl: 0.017985301092267036\n","          model: {}\n","          policy_loss: 0.0033518236596137285\n","          total_loss: 2335.869140625\n","          vf_explained_var: 0.6858658790588379\n","          vf_loss: 1301.255615234375\n","    num_agent_steps_sampled: 144000\n","    num_agent_steps_trained: 144000\n","    num_steps_sampled: 144000\n","    num_steps_trained: 144000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 36\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.88\n","    ram_util_percent: 16.57\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06971465009762409\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.24646970746381583\n","    mean_inference_ms: 0.713094396634216\n","    mean_raw_obs_processing_ms: 0.11213146329790546\n","  time_since_restore: 258.89046120643616\n","  time_this_iter_s: 7.3940653800964355\n","  time_total_s: 258.89046120643616\n","  timers:\n","    learn_throughput: 1598.766\n","    learn_time_ms: 2501.93\n","    load_throughput: 8770107.684\n","    load_time_ms: 0.456\n","    sample_throughput: 557.444\n","    sample_time_ms: 7175.613\n","    update_time_ms: 2.744\n","  timestamp: 1649863351\n","  timesteps_since_restore: 144000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 144000\n","  training_iteration: 36\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:22:36 (running for 00:04:47.17)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         258.89 </td><td style=\"text-align: right;\">144000</td><td style=\"text-align: right;\">-288.294 </td><td style=\"text-align: right;\">             4.36199</td><td style=\"text-align: right;\">           -615.492 </td><td style=\"text-align: right;\">            109.95</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         259.014</td><td style=\"text-align: right;\">104000</td><td style=\"text-align: right;\"> -36.6618</td><td style=\"text-align: right;\">           126.974  </td><td style=\"text-align: right;\">           -489.446 </td><td style=\"text-align: right;\">            530.16</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         250.058</td><td style=\"text-align: right;\">108000</td><td style=\"text-align: right;\">  72.066 </td><td style=\"text-align: right;\">           286.626  </td><td style=\"text-align: right;\">            -63.2963</td><td style=\"text-align: right;\">            576.38</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 148000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-22-39\n","  done: false\n","  episode_len_mean: 111.39\n","  episode_media: {}\n","  episode_reward_max: 4.361988402511983\n","  episode_reward_mean: -284.9444833683922\n","  episode_reward_min: -627.7536558439525\n","  episodes_this_iter: 37\n","  episodes_total: 1494\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 57525.31640625\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7129180431365967\n","          entropy_coeff: 0.0\n","          kl: 0.01177253294736147\n","          model: {}\n","          policy_loss: 0.005475605838000774\n","          total_loss: 2822.129150390625\n","          vf_explained_var: 0.6663057208061218\n","          vf_loss: 2144.90478515625\n","    num_agent_steps_sampled: 148000\n","    num_agent_steps_trained: 148000\n","    num_steps_sampled: 148000\n","    num_steps_trained: 148000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 37\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.881818181818181\n","    ram_util_percent: 16.59090909090909\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06970405084925035\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.24702274497337778\n","    mean_inference_ms: 0.7131104856706948\n","    mean_raw_obs_processing_ms: 0.11209951891875733\n","  time_since_restore: 266.04143166542053\n","  time_this_iter_s: 7.150970458984375\n","  time_total_s: 266.04143166542053\n","  timers:\n","    learn_throughput: 1593.73\n","    learn_time_ms: 2509.836\n","    load_throughput: 8777448.99\n","    load_time_ms: 0.456\n","    sample_throughput: 555.987\n","    sample_time_ms: 7194.419\n","    update_time_ms: 2.757\n","  timestamp: 1649863359\n","  timesteps_since_restore: 148000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 148000\n","  training_iteration: 37\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 112000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-22-39\n","  done: false\n","  episode_len_mean: 585.73\n","  episode_media: {}\n","  episode_reward_max: 297.8473191240466\n","  episode_reward_mean: 93.4786318422859\n","  episode_reward_min: -63.29630937622002\n","  episodes_this_iter: 9\n","  episodes_total: 515\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.05000000074505806\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6749650835990906\n","          entropy_coeff: 0.0\n","          kl: 0.026677098125219345\n","          model: {}\n","          policy_loss: -0.020258404314517975\n","          total_loss: 798.222900390625\n","          vf_explained_var: -0.03322911262512207\n","          vf_loss: 798.241943359375\n","    num_agent_steps_sampled: 112000\n","    num_agent_steps_trained: 112000\n","    num_steps_sampled: 112000\n","    num_steps_trained: 112000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 28\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.930769230769233\n","    ram_util_percent: 16.592307692307692\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07472056897440062\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6085452769724827\n","    mean_inference_ms: 0.7514008019875692\n","    mean_raw_obs_processing_ms: 0.11412915786174828\n","  time_since_restore: 259.4510831832886\n","  time_this_iter_s: 9.39281439781189\n","  time_total_s: 259.4510831832886\n","  timers:\n","    learn_throughput: 1606.756\n","    learn_time_ms: 2489.487\n","    load_throughput: 8364768.41\n","    load_time_ms: 0.478\n","    sample_throughput: 392.244\n","    sample_time_ms: 10197.727\n","    update_time_ms: 2.722\n","  timestamp: 1649863359\n","  timesteps_since_restore: 112000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 112000\n","  training_iteration: 28\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:22:42 (running for 00:04:52.56)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         266.041</td><td style=\"text-align: right;\">148000</td><td style=\"text-align: right;\">-284.944 </td><td style=\"text-align: right;\">             4.36199</td><td style=\"text-align: right;\">           -627.754 </td><td style=\"text-align: right;\">            111.39</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         259.014</td><td style=\"text-align: right;\">104000</td><td style=\"text-align: right;\"> -36.6618</td><td style=\"text-align: right;\">           126.974  </td><td style=\"text-align: right;\">           -489.446 </td><td style=\"text-align: right;\">            530.16</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         259.451</td><td style=\"text-align: right;\">112000</td><td style=\"text-align: right;\">  93.4786</td><td style=\"text-align: right;\">           297.847  </td><td style=\"text-align: right;\">            -63.2963</td><td style=\"text-align: right;\">            585.73</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 108000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-22-45\n","  done: false\n","  episode_len_mean: 556.7\n","  episode_media: {}\n","  episode_reward_max: 126.97406923704018\n","  episode_reward_mean: -33.78922394061674\n","  episode_reward_min: -489.4459984118832\n","  episodes_this_iter: 6\n","  episodes_total: 507\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.085275411605835\n","          entropy_coeff: 0.0\n","          kl: 0.01041535846889019\n","          model: {}\n","          policy_loss: -0.029684465378522873\n","          total_loss: 238.5513153076172\n","          vf_explained_var: 0.7827515602111816\n","          vf_loss: 238.5704345703125\n","    num_agent_steps_sampled: 108000\n","    num_agent_steps_trained: 108000\n","    num_steps_sampled: 108000\n","    num_steps_trained: 108000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 27\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.205263157894738\n","    ram_util_percent: 16.563157894736843\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07238656944481298\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.8078800772205668\n","    mean_inference_ms: 0.7402023176662244\n","    mean_raw_obs_processing_ms: 0.11136260819733489\n","  time_since_restore: 272.278116941452\n","  time_this_iter_s: 13.2644202709198\n","  time_total_s: 272.278116941452\n","  timers:\n","    learn_throughput: 1610.205\n","    learn_time_ms: 2484.156\n","    load_throughput: 9726486.173\n","    load_time_ms: 0.411\n","    sample_throughput: 346.336\n","    sample_time_ms: 11549.48\n","    update_time_ms: 2.808\n","  timestamp: 1649863365\n","  timesteps_since_restore: 108000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 108000\n","  training_iteration: 27\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 152000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-22-46\n","  done: false\n","  episode_len_mean: 118.27\n","  episode_media: {}\n","  episode_reward_max: 4.361988402511983\n","  episode_reward_mean: -317.4376667513476\n","  episode_reward_min: -630.1339067010093\n","  episodes_this_iter: 31\n","  episodes_total: 1525\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 57525.31640625\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.738793671131134\n","          entropy_coeff: 0.0\n","          kl: 0.02010573446750641\n","          model: {}\n","          policy_loss: 8.844585681799799e-05\n","          total_loss: 3474.259765625\n","          vf_explained_var: 0.5790965557098389\n","          vf_loss: 2317.67041015625\n","    num_agent_steps_sampled: 152000\n","    num_agent_steps_trained: 152000\n","    num_steps_sampled: 152000\n","    num_steps_trained: 152000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 38\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.53\n","    ram_util_percent: 16.54\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06969299121278837\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.24759714919997758\n","    mean_inference_ms: 0.7130489125317166\n","    mean_raw_obs_processing_ms: 0.11205682342768875\n","  time_since_restore: 273.4566457271576\n","  time_this_iter_s: 7.4152140617370605\n","  time_total_s: 273.4566457271576\n","  timers:\n","    learn_throughput: 1584.932\n","    learn_time_ms: 2523.768\n","    load_throughput: 8916936.487\n","    load_time_ms: 0.449\n","    sample_throughput: 552.89\n","    sample_time_ms: 7234.716\n","    update_time_ms: 2.798\n","  timestamp: 1649863366\n","  timesteps_since_restore: 152000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 152000\n","  training_iteration: 38\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:22:47 (running for 00:04:57.82)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         273.457</td><td style=\"text-align: right;\">152000</td><td style=\"text-align: right;\">-317.438 </td><td style=\"text-align: right;\">             4.36199</td><td style=\"text-align: right;\">           -630.134 </td><td style=\"text-align: right;\">            118.27</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         272.278</td><td style=\"text-align: right;\">108000</td><td style=\"text-align: right;\"> -33.7892</td><td style=\"text-align: right;\">           126.974  </td><td style=\"text-align: right;\">           -489.446 </td><td style=\"text-align: right;\">            556.7 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         259.451</td><td style=\"text-align: right;\">112000</td><td style=\"text-align: right;\">  93.4786</td><td style=\"text-align: right;\">           297.847  </td><td style=\"text-align: right;\">            -63.2963</td><td style=\"text-align: right;\">            585.73</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 116000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-22-48\n","  done: false\n","  episode_len_mean: 595.56\n","  episode_media: {}\n","  episode_reward_max: 308.50330463860075\n","  episode_reward_mean: 120.54313144048974\n","  episode_reward_min: -63.29630937622002\n","  episodes_this_iter: 11\n","  episodes_total: 526\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.07500000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6865520477294922\n","          entropy_coeff: 0.0\n","          kl: 0.00652255630120635\n","          model: {}\n","          policy_loss: -0.012257486581802368\n","          total_loss: 630.5735473632812\n","          vf_explained_var: -0.010810486041009426\n","          vf_loss: 630.5853271484375\n","    num_agent_steps_sampled: 116000\n","    num_agent_steps_trained: 116000\n","    num_steps_sampled: 116000\n","    num_steps_trained: 116000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 29\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.384615384615385\n","    ram_util_percent: 16.538461538461537\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07468085104217798\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6330218892748067\n","    mean_inference_ms: 0.7523227783604841\n","    mean_raw_obs_processing_ms: 0.11383410710964792\n","  time_since_restore: 268.3485174179077\n","  time_this_iter_s: 8.89743423461914\n","  time_total_s: 268.3485174179077\n","  timers:\n","    learn_throughput: 1606.151\n","    learn_time_ms: 2490.426\n","    load_throughput: 8888591.258\n","    load_time_ms: 0.45\n","    sample_throughput: 392.3\n","    sample_time_ms: 10196.274\n","    update_time_ms: 2.728\n","  timestamp: 1649863368\n","  timesteps_since_restore: 116000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 116000\n","  training_iteration: 29\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:22:53 (running for 00:05:03.58)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         273.457</td><td style=\"text-align: right;\">152000</td><td style=\"text-align: right;\">-317.438 </td><td style=\"text-align: right;\">             4.36199</td><td style=\"text-align: right;\">           -630.134 </td><td style=\"text-align: right;\">            118.27</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         272.278</td><td style=\"text-align: right;\">108000</td><td style=\"text-align: right;\"> -33.7892</td><td style=\"text-align: right;\">           126.974  </td><td style=\"text-align: right;\">           -489.446 </td><td style=\"text-align: right;\">            556.7 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         268.349</td><td style=\"text-align: right;\">116000</td><td style=\"text-align: right;\"> 120.543 </td><td style=\"text-align: right;\">           308.503  </td><td style=\"text-align: right;\">            -63.2963</td><td style=\"text-align: right;\">            595.56</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 156000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-22-53\n","  done: false\n","  episode_len_mean: 118.88\n","  episode_media: {}\n","  episode_reward_max: -6.99743686437651\n","  episode_reward_mean: -345.09011866292116\n","  episode_reward_min: -662.0873431941844\n","  episodes_this_iter: 31\n","  episodes_total: 1556\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 86287.9765625\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7182281613349915\n","          entropy_coeff: 0.0\n","          kl: 0.015173676423728466\n","          model: {}\n","          policy_loss: 0.006376642733812332\n","          total_loss: 3208.94140625\n","          vf_explained_var: 0.7915052771568298\n","          vf_loss: 1899.6290283203125\n","    num_agent_steps_sampled: 156000\n","    num_agent_steps_trained: 156000\n","    num_steps_sampled: 156000\n","    num_steps_trained: 156000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 39\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.254545454545452\n","    ram_util_percent: 16.509090909090908\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06968359578685908\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2483501640532515\n","    mean_inference_ms: 0.7129926720948981\n","    mean_raw_obs_processing_ms: 0.11201258166286693\n","  time_since_restore: 280.7217574119568\n","  time_this_iter_s: 7.265111684799194\n","  time_total_s: 280.7217574119568\n","  timers:\n","    learn_throughput: 1585.694\n","    learn_time_ms: 2522.555\n","    load_throughput: 8873078.062\n","    load_time_ms: 0.451\n","    sample_throughput: 552.057\n","    sample_time_ms: 7245.629\n","    update_time_ms: 2.816\n","  timestamp: 1649863373\n","  timesteps_since_restore: 156000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 156000\n","  training_iteration: 39\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 120000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-22-56\n","  done: false\n","  episode_len_mean: 574.29\n","  episode_media: {}\n","  episode_reward_max: 308.50330463860075\n","  episode_reward_mean: 150.2624304633951\n","  episode_reward_min: -63.29630937622002\n","  episodes_this_iter: 13\n","  episodes_total: 539\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.07500000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.8204476833343506\n","          entropy_coeff: 0.0\n","          kl: 0.00908148754388094\n","          model: {}\n","          policy_loss: -0.008731667883694172\n","          total_loss: 547.5748291015625\n","          vf_explained_var: -0.08071225136518478\n","          vf_loss: 547.5828857421875\n","    num_agent_steps_sampled: 120000\n","    num_agent_steps_trained: 120000\n","    num_steps_sampled: 120000\n","    num_steps_trained: 120000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 30\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 11.975\n","    ram_util_percent: 16.5\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07463684000714947\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6578560420764397\n","    mean_inference_ms: 0.7532947561526291\n","    mean_raw_obs_processing_ms: 0.11352665072757287\n","  time_since_restore: 276.8400766849518\n","  time_this_iter_s: 8.491559267044067\n","  time_total_s: 276.8400766849518\n","  timers:\n","    learn_throughput: 1602.765\n","    learn_time_ms: 2495.687\n","    load_throughput: 8712268.785\n","    load_time_ms: 0.459\n","    sample_throughput: 405.003\n","    sample_time_ms: 9876.476\n","    update_time_ms: 2.734\n","  timestamp: 1649863376\n","  timesteps_since_restore: 120000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 120000\n","  training_iteration: 30\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 112000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-22-58\n","  done: false\n","  episode_len_mean: 565.35\n","  episode_media: {}\n","  episode_reward_max: 130.79490068827636\n","  episode_reward_mean: -31.662086311097315\n","  episode_reward_min: -489.4459984118832\n","  episodes_this_iter: 5\n","  episodes_total: 512\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.097245693206787\n","          entropy_coeff: 0.0\n","          kl: 0.011351066641509533\n","          model: {}\n","          policy_loss: -0.02880772389471531\n","          total_loss: 178.52745056152344\n","          vf_explained_var: 0.6678277850151062\n","          vf_loss: 178.54476928710938\n","    num_agent_steps_sampled: 112000\n","    num_agent_steps_trained: 112000\n","    num_steps_sampled: 112000\n","    num_steps_trained: 112000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 28\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.626315789473683\n","    ram_util_percent: 16.51578947368421\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07243211850960687\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.8266160830096196\n","    mean_inference_ms: 0.7412851070571393\n","    mean_raw_obs_processing_ms: 0.11135612940959333\n","  time_since_restore: 285.5162992477417\n","  time_this_iter_s: 13.238182306289673\n","  time_total_s: 285.5162992477417\n","  timers:\n","    learn_throughput: 1607.795\n","    learn_time_ms: 2487.879\n","    load_throughput: 9727050.093\n","    load_time_ms: 0.411\n","    sample_throughput: 343.574\n","    sample_time_ms: 11642.323\n","    update_time_ms: 2.842\n","  timestamp: 1649863378\n","  timesteps_since_restore: 112000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 112000\n","  training_iteration: 28\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:22:58 (running for 00:05:08.72)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         280.722</td><td style=\"text-align: right;\">156000</td><td style=\"text-align: right;\">-345.09  </td><td style=\"text-align: right;\">            -6.99744</td><td style=\"text-align: right;\">           -662.087 </td><td style=\"text-align: right;\">            118.88</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         285.516</td><td style=\"text-align: right;\">112000</td><td style=\"text-align: right;\"> -31.6621</td><td style=\"text-align: right;\">           130.795  </td><td style=\"text-align: right;\">           -489.446 </td><td style=\"text-align: right;\">            565.35</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         276.84 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> 150.262 </td><td style=\"text-align: right;\">           308.503  </td><td style=\"text-align: right;\">            -63.2963</td><td style=\"text-align: right;\">            574.29</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 160000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-23-01\n","  done: false\n","  episode_len_mean: 121.1\n","  episode_media: {}\n","  episode_reward_max: -11.208292444388249\n","  episode_reward_mean: -371.54402537152004\n","  episode_reward_min: -743.009602899591\n","  episodes_this_iter: 37\n","  episodes_total: 1593\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 86287.9765625\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7543444037437439\n","          entropy_coeff: 0.0\n","          kl: 0.0038064110558480024\n","          model: {}\n","          policy_loss: -0.00016326199693139642\n","          total_loss: 1669.88671875\n","          vf_explained_var: 0.7174264192581177\n","          vf_loss: 1341.4395751953125\n","    num_agent_steps_sampled: 160000\n","    num_agent_steps_trained: 160000\n","    num_steps_sampled: 160000\n","    num_steps_trained: 160000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 40\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.16\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06971557945079158\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.24960952413979\n","    mean_inference_ms: 0.7134385275002555\n","    mean_raw_obs_processing_ms: 0.1120435854507854\n","  time_since_restore: 288.1653175354004\n","  time_this_iter_s: 7.4435601234436035\n","  time_total_s: 288.1653175354004\n","  timers:\n","    learn_throughput: 1598.195\n","    learn_time_ms: 2502.823\n","    load_throughput: 9192995.068\n","    load_time_ms: 0.435\n","    sample_throughput: 548.123\n","    sample_time_ms: 7297.628\n","    update_time_ms: 2.789\n","  timestamp: 1649863381\n","  timesteps_since_restore: 160000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 160000\n","  training_iteration: 40\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:23:04 (running for 00:05:14.59)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         288.165</td><td style=\"text-align: right;\">160000</td><td style=\"text-align: right;\">-371.544 </td><td style=\"text-align: right;\">            -11.2083</td><td style=\"text-align: right;\">           -743.01  </td><td style=\"text-align: right;\">            121.1 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         285.516</td><td style=\"text-align: right;\">112000</td><td style=\"text-align: right;\"> -31.6621</td><td style=\"text-align: right;\">            130.795 </td><td style=\"text-align: right;\">           -489.446 </td><td style=\"text-align: right;\">            565.35</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         276.84 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> 150.262 </td><td style=\"text-align: right;\">            308.503 </td><td style=\"text-align: right;\">            -63.2963</td><td style=\"text-align: right;\">            574.29</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 124000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-23-05\n","  done: false\n","  episode_len_mean: 568.12\n","  episode_media: {}\n","  episode_reward_max: 308.50330463860075\n","  episode_reward_mean: 183.84871156903566\n","  episode_reward_min: -32.52210125515974\n","  episodes_this_iter: 14\n","  episodes_total: 553\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.07500000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7706704139709473\n","          entropy_coeff: 0.0\n","          kl: 0.009784718044102192\n","          model: {}\n","          policy_loss: 0.0011064131977036595\n","          total_loss: 624.7752685546875\n","          vf_explained_var: -0.17589297890663147\n","          vf_loss: 624.7733764648438\n","    num_agent_steps_sampled: 124000\n","    num_agent_steps_trained: 124000\n","    num_steps_sampled: 124000\n","    num_steps_trained: 124000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 31\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.958333333333336\n","    ram_util_percent: 16.5\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07460848301689012\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6805217615303357\n","    mean_inference_ms: 0.7543037596008861\n","    mean_raw_obs_processing_ms: 0.11326030771571263\n","  time_since_restore: 285.61102747917175\n","  time_this_iter_s: 8.77095079421997\n","  time_total_s: 285.61102747917175\n","  timers:\n","    learn_throughput: 1602.587\n","    learn_time_ms: 2495.965\n","    load_throughput: 8566359.969\n","    load_time_ms: 0.467\n","    sample_throughput: 412.178\n","    sample_time_ms: 9704.551\n","    update_time_ms: 2.758\n","  timestamp: 1649863385\n","  timesteps_since_restore: 124000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 124000\n","  training_iteration: 31\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 164000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-23-08\n","  done: false\n","  episode_len_mean: 114.67\n","  episode_media: {}\n","  episode_reward_max: -11.208292444388249\n","  episode_reward_mean: -364.14551273239914\n","  episode_reward_min: -743.009602899591\n","  episodes_this_iter: 36\n","  episodes_total: 1629\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 43143.98828125\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.8146023750305176\n","          entropy_coeff: 0.0\n","          kl: 0.0001294190442422405\n","          model: {}\n","          policy_loss: 0.004492321517318487\n","          total_loss: 932.3386840820312\n","          vf_explained_var: 0.8244624137878418\n","          vf_loss: 926.7505493164062\n","    num_agent_steps_sampled: 164000\n","    num_agent_steps_trained: 164000\n","    num_steps_sampled: 164000\n","    num_steps_trained: 164000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 41\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.899999999999999\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06973389708371218\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.25052197365438567\n","    mean_inference_ms: 0.7137233977308725\n","    mean_raw_obs_processing_ms: 0.11207119659842803\n","  time_since_restore: 295.33842277526855\n","  time_this_iter_s: 7.173105239868164\n","  time_total_s: 295.33842277526855\n","  timers:\n","    learn_throughput: 1596.121\n","    learn_time_ms: 2506.076\n","    load_throughput: 9218250.549\n","    load_time_ms: 0.434\n","    sample_throughput: 548.119\n","    sample_time_ms: 7297.681\n","    update_time_ms: 2.787\n","  timestamp: 1649863388\n","  timesteps_since_restore: 164000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 164000\n","  training_iteration: 41\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:23:09 (running for 00:05:19.80)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         295.338</td><td style=\"text-align: right;\">164000</td><td style=\"text-align: right;\">-364.146 </td><td style=\"text-align: right;\">            -11.2083</td><td style=\"text-align: right;\">           -743.01  </td><td style=\"text-align: right;\">            114.67</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         285.516</td><td style=\"text-align: right;\">112000</td><td style=\"text-align: right;\"> -31.6621</td><td style=\"text-align: right;\">            130.795 </td><td style=\"text-align: right;\">           -489.446 </td><td style=\"text-align: right;\">            565.35</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         285.611</td><td style=\"text-align: right;\">124000</td><td style=\"text-align: right;\"> 183.849 </td><td style=\"text-align: right;\">            308.503 </td><td style=\"text-align: right;\">            -32.5221</td><td style=\"text-align: right;\">            568.12</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 116000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-23-10\n","  done: false\n","  episode_len_mean: 576.48\n","  episode_media: {}\n","  episode_reward_max: 130.79490068827636\n","  episode_reward_mean: -23.957659089614037\n","  episode_reward_min: -489.4459984118832\n","  episodes_this_iter: 7\n","  episodes_total: 519\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.0718692541122437\n","          entropy_coeff: 0.0\n","          kl: 0.013292904943227768\n","          model: {}\n","          policy_loss: -0.035839229822158813\n","          total_loss: 493.49468994140625\n","          vf_explained_var: 0.8143340945243835\n","          vf_loss: 493.51702880859375\n","    num_agent_steps_sampled: 116000\n","    num_agent_steps_trained: 116000\n","    num_steps_sampled: 116000\n","    num_steps_trained: 116000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 29\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.223529411764705\n","    ram_util_percent: 16.5\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07249416721068357\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.8522064442561517\n","    mean_inference_ms: 0.7427766959336484\n","    mean_raw_obs_processing_ms: 0.11135246982296718\n","  time_since_restore: 297.39830493927\n","  time_this_iter_s: 11.88200569152832\n","  time_total_s: 297.39830493927\n","  timers:\n","    learn_throughput: 1608.183\n","    learn_time_ms: 2487.279\n","    load_throughput: 9678790.816\n","    load_time_ms: 0.413\n","    sample_throughput: 343.022\n","    sample_time_ms: 11661.057\n","    update_time_ms: 2.84\n","  timestamp: 1649863390\n","  timesteps_since_restore: 116000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 116000\n","  training_iteration: 29\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 128000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-23-14\n","  done: false\n","  episode_len_mean: 536.86\n","  episode_media: {}\n","  episode_reward_max: 308.50330463860075\n","  episode_reward_mean: 210.25822400209228\n","  episode_reward_min: -9.937221394907311\n","  episodes_this_iter: 13\n","  episodes_total: 566\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.07500000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.812490701675415\n","          entropy_coeff: 0.0\n","          kl: 0.012679293751716614\n","          model: {}\n","          policy_loss: -0.02607027254998684\n","          total_loss: 319.71673583984375\n","          vf_explained_var: 0.01834728755056858\n","          vf_loss: 319.74188232421875\n","    num_agent_steps_sampled: 128000\n","    num_agent_steps_trained: 128000\n","    num_steps_sampled: 128000\n","    num_steps_trained: 128000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 32\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.76923076923077\n","    ram_util_percent: 16.5\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07459244304451056\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6965738367821327\n","    mean_inference_ms: 0.7550995904482288\n","    mean_raw_obs_processing_ms: 0.11306716731299754\n","  time_since_restore: 294.275235414505\n","  time_this_iter_s: 8.664207935333252\n","  time_total_s: 294.275235414505\n","  timers:\n","    learn_throughput: 1603.016\n","    learn_time_ms: 2495.296\n","    load_throughput: 8603259.32\n","    load_time_ms: 0.465\n","    sample_throughput: 416.99\n","    sample_time_ms: 9592.564\n","    update_time_ms: 2.773\n","  timestamp: 1649863394\n","  timesteps_since_restore: 128000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 128000\n","  training_iteration: 32\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:23:15 (running for 00:05:25.54)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         295.338</td><td style=\"text-align: right;\">164000</td><td style=\"text-align: right;\">-364.146 </td><td style=\"text-align: right;\">            -11.2083</td><td style=\"text-align: right;\">          -743.01   </td><td style=\"text-align: right;\">            114.67</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         297.398</td><td style=\"text-align: right;\">116000</td><td style=\"text-align: right;\"> -23.9577</td><td style=\"text-align: right;\">            130.795 </td><td style=\"text-align: right;\">          -489.446  </td><td style=\"text-align: right;\">            576.48</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         294.275</td><td style=\"text-align: right;\">128000</td><td style=\"text-align: right;\"> 210.258 </td><td style=\"text-align: right;\">            308.503 </td><td style=\"text-align: right;\">            -9.93722</td><td style=\"text-align: right;\">            536.86</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 168000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-23-15\n","  done: false\n","  episode_len_mean: 111.39\n","  episode_media: {}\n","  episode_reward_max: 20.65011925595921\n","  episode_reward_mean: -351.7478236980311\n","  episode_reward_min: -743.009602899591\n","  episodes_this_iter: 37\n","  episodes_total: 1666\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 21571.994140625\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.8217635750770569\n","          entropy_coeff: 0.0\n","          kl: 4.256914053257788e-06\n","          model: {}\n","          policy_loss: 0.0030826451256871223\n","          total_loss: 1837.2939453125\n","          vf_explained_var: 0.7375940084457397\n","          vf_loss: 1837.198974609375\n","    num_agent_steps_sampled: 168000\n","    num_agent_steps_trained: 168000\n","    num_steps_sampled: 168000\n","    num_steps_trained: 168000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 42\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.86\n","    ram_util_percent: 16.5\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06975886521284812\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.25109370354285265\n","    mean_inference_ms: 0.7140507665678458\n","    mean_raw_obs_processing_ms: 0.1121152916058252\n","  time_since_restore: 302.6568412780762\n","  time_this_iter_s: 7.318418502807617\n","  time_total_s: 302.6568412780762\n","  timers:\n","    learn_throughput: 1592.898\n","    learn_time_ms: 2511.146\n","    load_throughput: 9448226.615\n","    load_time_ms: 0.423\n","    sample_throughput: 548.444\n","    sample_time_ms: 7293.359\n","    update_time_ms: 2.776\n","  timestamp: 1649863395\n","  timesteps_since_restore: 168000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 168000\n","  training_iteration: 42\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:23:21 (running for 00:05:31.22)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         302.657</td><td style=\"text-align: right;\">168000</td><td style=\"text-align: right;\">-351.748 </td><td style=\"text-align: right;\">             20.6501</td><td style=\"text-align: right;\">          -743.01   </td><td style=\"text-align: right;\">            111.39</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         297.398</td><td style=\"text-align: right;\">116000</td><td style=\"text-align: right;\"> -23.9577</td><td style=\"text-align: right;\">            130.795 </td><td style=\"text-align: right;\">          -489.446  </td><td style=\"text-align: right;\">            576.48</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         294.275</td><td style=\"text-align: right;\">128000</td><td style=\"text-align: right;\"> 210.258 </td><td style=\"text-align: right;\">            308.503 </td><td style=\"text-align: right;\">            -9.93722</td><td style=\"text-align: right;\">            536.86</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 120000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-23-21\n","  done: false\n","  episode_len_mean: 571.15\n","  episode_media: {}\n","  episode_reward_max: 130.79490068827636\n","  episode_reward_mean: -18.443492884201472\n","  episode_reward_min: -489.4459984118832\n","  episodes_this_iter: 6\n","  episodes_total: 525\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.0553804636001587\n","          entropy_coeff: 0.0\n","          kl: 0.011397444643080235\n","          model: {}\n","          policy_loss: -0.03643631562590599\n","          total_loss: 214.66030883789062\n","          vf_explained_var: 0.6947489380836487\n","          vf_loss: 214.6852264404297\n","    num_agent_steps_sampled: 120000\n","    num_agent_steps_trained: 120000\n","    num_steps_sampled: 120000\n","    num_steps_trained: 120000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 30\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.411764705882353\n","    ram_util_percent: 16.55294117647059\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07254023071492081\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.872109633717815\n","    mean_inference_ms: 0.7439231411463503\n","    mean_raw_obs_processing_ms: 0.11134604704778678\n","  time_since_restore: 308.8537621498108\n","  time_this_iter_s: 11.455457210540771\n","  time_total_s: 308.8537621498108\n","  timers:\n","    learn_throughput: 1604.077\n","    learn_time_ms: 2493.646\n","    load_throughput: 10060092.343\n","    load_time_ms: 0.398\n","    sample_throughput: 345.103\n","    sample_time_ms: 11590.742\n","    update_time_ms: 2.852\n","  timestamp: 1649863401\n","  timesteps_since_restore: 120000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 120000\n","  training_iteration: 30\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 132000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-23-23\n","  done: false\n","  episode_len_mean: 479.33\n","  episode_media: {}\n","  episode_reward_max: 308.50330463860075\n","  episode_reward_mean: 233.28393476854563\n","  episode_reward_min: 33.2167087467669\n","  episodes_this_iter: 13\n","  episodes_total: 579\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.07500000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7934451699256897\n","          entropy_coeff: 0.0\n","          kl: 0.006957647856324911\n","          model: {}\n","          policy_loss: -0.014493238180875778\n","          total_loss: 260.2865905761719\n","          vf_explained_var: 0.1177486926317215\n","          vf_loss: 260.3005676269531\n","    num_agent_steps_sampled: 132000\n","    num_agent_steps_trained: 132000\n","    num_steps_sampled: 132000\n","    num_steps_trained: 132000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 33\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.308333333333332\n","    ram_util_percent: 16.583333333333332\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07459079119282698\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.7048802441436781\n","    mean_inference_ms: 0.7557160667837158\n","    mean_raw_obs_processing_ms: 0.11293832168195748\n","  time_since_restore: 303.0510244369507\n","  time_this_iter_s: 8.775789022445679\n","  time_total_s: 303.0510244369507\n","  timers:\n","    learn_throughput: 1604.862\n","    learn_time_ms: 2492.427\n","    load_throughput: 9111614.62\n","    load_time_ms: 0.439\n","    sample_throughput: 423.347\n","    sample_time_ms: 9448.523\n","    update_time_ms: 2.766\n","  timestamp: 1649863403\n","  timesteps_since_restore: 132000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 132000\n","  training_iteration: 33\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 172000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-23-23\n","  done: false\n","  episode_len_mean: 110.9\n","  episode_media: {}\n","  episode_reward_max: 20.65011925595921\n","  episode_reward_mean: -351.1160533557824\n","  episode_reward_min: -659.7589949512728\n","  episodes_this_iter: 35\n","  episodes_total: 1701\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 10785.9970703125\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.8157768249511719\n","          entropy_coeff: 0.0\n","          kl: 0.00036248512333258986\n","          model: {}\n","          policy_loss: -0.0021014618687331676\n","          total_loss: 1142.0362548828125\n","          vf_explained_var: 0.7902626991271973\n","          vf_loss: 1138.1287841796875\n","    num_agent_steps_sampled: 172000\n","    num_agent_steps_trained: 172000\n","    num_steps_sampled: 172000\n","    num_steps_trained: 172000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 43\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.16\n","    ram_util_percent: 16.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06974726209126769\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.25138287369061707\n","    mean_inference_ms: 0.7140224174851957\n","    mean_raw_obs_processing_ms: 0.11209737956267998\n","  time_since_restore: 309.86591386795044\n","  time_this_iter_s: 7.209072589874268\n","  time_total_s: 309.86591386795044\n","  timers:\n","    learn_throughput: 1588.613\n","    learn_time_ms: 2517.919\n","    load_throughput: 9439189.828\n","    load_time_ms: 0.424\n","    sample_throughput: 548.666\n","    sample_time_ms: 7290.408\n","    update_time_ms: 2.781\n","  timestamp: 1649863403\n","  timesteps_since_restore: 172000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 172000\n","  training_iteration: 43\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:23:26 (running for 00:05:36.40)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         309.866</td><td style=\"text-align: right;\">172000</td><td style=\"text-align: right;\">-351.116 </td><td style=\"text-align: right;\">             20.6501</td><td style=\"text-align: right;\">           -659.759 </td><td style=\"text-align: right;\">            110.9 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         308.854</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -18.4435</td><td style=\"text-align: right;\">            130.795 </td><td style=\"text-align: right;\">           -489.446 </td><td style=\"text-align: right;\">            571.15</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         303.051</td><td style=\"text-align: right;\">132000</td><td style=\"text-align: right;\"> 233.284 </td><td style=\"text-align: right;\">            308.503 </td><td style=\"text-align: right;\">             33.2167</td><td style=\"text-align: right;\">            479.33</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 176000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-23-30\n","  done: false\n","  episode_len_mean: 108.28\n","  episode_media: {}\n","  episode_reward_max: 20.65011925595921\n","  episode_reward_mean: -334.6864431593554\n","  episode_reward_min: -659.7589949512728\n","  episodes_this_iter: 39\n","  episodes_total: 1740\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 5392.99853515625\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7900022268295288\n","          entropy_coeff: 0.0\n","          kl: 8.779727522778558e-07\n","          model: {}\n","          policy_loss: -0.0033040158450603485\n","          total_loss: 891.6903686523438\n","          vf_explained_var: 0.8353577256202698\n","          vf_loss: 891.68896484375\n","    num_agent_steps_sampled: 176000\n","    num_agent_steps_trained: 176000\n","    num_steps_sampled: 176000\n","    num_steps_trained: 176000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 44\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 11.5\n","    ram_util_percent: 16.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06971123385068752\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2515208510205556\n","    mean_inference_ms: 0.7136691935369677\n","    mean_raw_obs_processing_ms: 0.11204688866204454\n","  time_since_restore: 316.8616874217987\n","  time_this_iter_s: 6.995773553848267\n","  time_total_s: 316.8616874217987\n","  timers:\n","    learn_throughput: 1585.937\n","    learn_time_ms: 2522.168\n","    load_throughput: 9408488.111\n","    load_time_ms: 0.425\n","    sample_throughput: 547.899\n","    sample_time_ms: 7300.62\n","    update_time_ms: 2.783\n","  timestamp: 1649863410\n","  timesteps_since_restore: 176000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 176000\n","  training_iteration: 44\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:23:31 (running for 00:05:41.51)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         316.862</td><td style=\"text-align: right;\">176000</td><td style=\"text-align: right;\">-334.686 </td><td style=\"text-align: right;\">             20.6501</td><td style=\"text-align: right;\">           -659.759 </td><td style=\"text-align: right;\">            108.28</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         308.854</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -18.4435</td><td style=\"text-align: right;\">            130.795 </td><td style=\"text-align: right;\">           -489.446 </td><td style=\"text-align: right;\">            571.15</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         303.051</td><td style=\"text-align: right;\">132000</td><td style=\"text-align: right;\"> 233.284 </td><td style=\"text-align: right;\">            308.503 </td><td style=\"text-align: right;\">             33.2167</td><td style=\"text-align: right;\">            479.33</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 136000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-23-31\n","  done: false\n","  episode_len_mean: 390.99\n","  episode_media: {}\n","  episode_reward_max: 308.50330463860075\n","  episode_reward_mean: 253.42881506464252\n","  episode_reward_min: 46.15102761335345\n","  episodes_this_iter: 15\n","  episodes_total: 594\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.07500000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.732164740562439\n","          entropy_coeff: 0.0\n","          kl: 0.009292341768741608\n","          model: {}\n","          policy_loss: -0.012612290680408478\n","          total_loss: 161.38766479492188\n","          vf_explained_var: 0.060312364250421524\n","          vf_loss: 161.39959716796875\n","    num_agent_steps_sampled: 136000\n","    num_agent_steps_trained: 136000\n","    num_steps_sampled: 136000\n","    num_steps_trained: 136000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 34\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.491666666666665\n","    ram_util_percent: 16.599999999999998\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07459163422419739\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.7076475590043393\n","    mean_inference_ms: 0.7559888674771379\n","    mean_raw_obs_processing_ms: 0.11282557747932921\n","  time_since_restore: 311.1316604614258\n","  time_this_iter_s: 8.080636024475098\n","  time_total_s: 311.1316604614258\n","  timers:\n","    learn_throughput: 1603.262\n","    learn_time_ms: 2494.913\n","    load_throughput: 8763694.108\n","    load_time_ms: 0.456\n","    sample_throughput: 434.698\n","    sample_time_ms: 9201.788\n","    update_time_ms: 2.793\n","  timestamp: 1649863411\n","  timesteps_since_restore: 136000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 136000\n","  training_iteration: 34\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 124000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-23-34\n","  done: false\n","  episode_len_mean: 564.96\n","  episode_media: {}\n","  episode_reward_max: 130.79490068827636\n","  episode_reward_mean: -16.92647191331815\n","  episode_reward_min: -489.4459984118832\n","  episodes_this_iter: 5\n","  episodes_total: 530\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.066412329673767\n","          entropy_coeff: 0.0\n","          kl: 0.011366491205990314\n","          model: {}\n","          policy_loss: -0.03371354937553406\n","          total_loss: 38.1082649230957\n","          vf_explained_var: 0.8994026184082031\n","          vf_loss: 38.13047790527344\n","    num_agent_steps_sampled: 124000\n","    num_agent_steps_trained: 124000\n","    num_steps_sampled: 124000\n","    num_steps_trained: 124000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 31\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.28235294117647\n","    ram_util_percent: 16.594117647058823\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07257007634598212\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.8861711303626394\n","    mean_inference_ms: 0.7447058559444443\n","    mean_raw_obs_processing_ms: 0.11134128713417672\n","  time_since_restore: 321.0204277038574\n","  time_this_iter_s: 12.16666555404663\n","  time_total_s: 321.0204277038574\n","  timers:\n","    learn_throughput: 1607.581\n","    learn_time_ms: 2488.21\n","    load_throughput: 9907414.669\n","    load_time_ms: 0.404\n","    sample_throughput: 342.86\n","    sample_time_ms: 11666.554\n","    update_time_ms: 2.804\n","  timestamp: 1649863414\n","  timesteps_since_restore: 124000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 124000\n","  training_iteration: 31\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:23:37 (running for 00:05:47.34)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         316.862</td><td style=\"text-align: right;\">176000</td><td style=\"text-align: right;\">-334.686 </td><td style=\"text-align: right;\">             20.6501</td><td style=\"text-align: right;\">            -659.759</td><td style=\"text-align: right;\">            108.28</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         321.02 </td><td style=\"text-align: right;\">124000</td><td style=\"text-align: right;\"> -16.9265</td><td style=\"text-align: right;\">            130.795 </td><td style=\"text-align: right;\">            -489.446</td><td style=\"text-align: right;\">            564.96</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         311.132</td><td style=\"text-align: right;\">136000</td><td style=\"text-align: right;\"> 253.429 </td><td style=\"text-align: right;\">            308.503 </td><td style=\"text-align: right;\">              46.151</td><td style=\"text-align: right;\">            390.99</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 180000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-23-37\n","  done: false\n","  episode_len_mean: 105.58\n","  episode_media: {}\n","  episode_reward_max: -20.95299914662705\n","  episode_reward_mean: -351.85834648886237\n","  episode_reward_min: -635.1461515570954\n","  episodes_this_iter: 38\n","  episodes_total: 1778\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 2696.499267578125\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7998933792114258\n","          entropy_coeff: 0.0\n","          kl: 1.4545578608249343e-07\n","          model: {}\n","          policy_loss: 0.005493081174790859\n","          total_loss: 1009.2251586914062\n","          vf_explained_var: 0.8272095322608948\n","          vf_loss: 1009.21923828125\n","    num_agent_steps_sampled: 180000\n","    num_agent_steps_trained: 180000\n","    num_steps_sampled: 180000\n","    num_steps_trained: 180000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 45\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.754545454545456\n","    ram_util_percent: 16.581818181818182\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06968292003068079\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.25157653574298505\n","    mean_inference_ms: 0.7133608995138592\n","    mean_raw_obs_processing_ms: 0.11199975789642405\n","  time_since_restore: 324.0541613101959\n","  time_this_iter_s: 7.192473888397217\n","  time_total_s: 324.0541613101959\n","  timers:\n","    learn_throughput: 1585.271\n","    learn_time_ms: 2523.228\n","    load_throughput: 9522229.411\n","    load_time_ms: 0.42\n","    sample_throughput: 548.461\n","    sample_time_ms: 7293.138\n","    update_time_ms: 2.775\n","  timestamp: 1649863417\n","  timesteps_since_restore: 180000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 180000\n","  training_iteration: 45\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 140000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-23-40\n","  done: false\n","  episode_len_mean: 324.81\n","  episode_media: {}\n","  episode_reward_max: 308.50330463860075\n","  episode_reward_mean: 262.74815661341637\n","  episode_reward_min: 32.588917623924516\n","  episodes_this_iter: 12\n","  episodes_total: 606\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.07500000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7759218215942383\n","          entropy_coeff: 0.0\n","          kl: 0.027962906286120415\n","          model: {}\n","          policy_loss: -0.02757893316447735\n","          total_loss: 912.4290161132812\n","          vf_explained_var: -0.10768047720193863\n","          vf_loss: 912.45458984375\n","    num_agent_steps_sampled: 140000\n","    num_agent_steps_trained: 140000\n","    num_steps_sampled: 140000\n","    num_steps_trained: 140000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 35\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.984615384615385\n","    ram_util_percent: 16.576923076923077\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07460227469247338\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.7060227166639066\n","    mean_inference_ms: 0.7560567614638094\n","    mean_raw_obs_processing_ms: 0.11280087211061626\n","  time_since_restore: 320.35213589668274\n","  time_this_iter_s: 9.220475435256958\n","  time_total_s: 320.35213589668274\n","  timers:\n","    learn_throughput: 1609.891\n","    learn_time_ms: 2484.64\n","    load_throughput: 9020493.575\n","    load_time_ms: 0.443\n","    sample_throughput: 436.871\n","    sample_time_ms: 9156.014\n","    update_time_ms: 2.776\n","  timestamp: 1649863420\n","  timesteps_since_restore: 140000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 140000\n","  training_iteration: 35\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:23:42 (running for 00:05:52.88)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         324.054</td><td style=\"text-align: right;\">180000</td><td style=\"text-align: right;\">-351.858 </td><td style=\"text-align: right;\">             -20.953</td><td style=\"text-align: right;\">           -635.146 </td><td style=\"text-align: right;\">            105.58</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         321.02 </td><td style=\"text-align: right;\">124000</td><td style=\"text-align: right;\"> -16.9265</td><td style=\"text-align: right;\">             130.795</td><td style=\"text-align: right;\">           -489.446 </td><td style=\"text-align: right;\">            564.96</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         320.352</td><td style=\"text-align: right;\">140000</td><td style=\"text-align: right;\"> 262.748 </td><td style=\"text-align: right;\">             308.503</td><td style=\"text-align: right;\">             32.5889</td><td style=\"text-align: right;\">            324.81</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 184000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-23-44\n","  done: false\n","  episode_len_mean: 102.32\n","  episode_media: {}\n","  episode_reward_max: 12.71938138275425\n","  episode_reward_mean: -333.27479040599945\n","  episode_reward_min: -671.5600515640333\n","  episodes_this_iter: 40\n","  episodes_total: 1818\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1348.2496337890625\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7960420846939087\n","          entropy_coeff: 0.0\n","          kl: 2.285156142534106e-06\n","          model: {}\n","          policy_loss: 0.004246801137924194\n","          total_loss: 944.350830078125\n","          vf_explained_var: 0.7223852276802063\n","          vf_loss: 944.3433837890625\n","    num_agent_steps_sampled: 184000\n","    num_agent_steps_trained: 184000\n","    num_steps_sampled: 184000\n","    num_steps_trained: 184000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 46\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.9\n","    ram_util_percent: 16.59\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06968161453443364\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2517465793517257\n","    mean_inference_ms: 0.713416737253354\n","    mean_raw_obs_processing_ms: 0.11200708821332672\n","  time_since_restore: 331.3965175151825\n","  time_this_iter_s: 7.342356204986572\n","  time_total_s: 331.3965175151825\n","  timers:\n","    learn_throughput: 1591.605\n","    learn_time_ms: 2513.186\n","    load_throughput: 9336755.523\n","    load_time_ms: 0.428\n","    sample_throughput: 548.097\n","    sample_time_ms: 7297.978\n","    update_time_ms: 2.747\n","  timestamp: 1649863424\n","  timesteps_since_restore: 184000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 184000\n","  training_iteration: 46\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 128000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-23-45\n","  done: false\n","  episode_len_mean: 577.99\n","  episode_media: {}\n","  episode_reward_max: 130.79490068827636\n","  episode_reward_mean: -11.210950621830259\n","  episode_reward_min: -489.4459984118832\n","  episodes_this_iter: 6\n","  episodes_total: 536\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.0835922956466675\n","          entropy_coeff: 0.0\n","          kl: 0.008617406710982323\n","          model: {}\n","          policy_loss: -0.0353727713227272\n","          total_loss: 340.1405334472656\n","          vf_explained_var: 0.8219220638275146\n","          vf_loss: 340.16717529296875\n","    num_agent_steps_sampled: 128000\n","    num_agent_steps_trained: 128000\n","    num_steps_sampled: 128000\n","    num_steps_trained: 128000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 32\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.264705882352942\n","    ram_util_percent: 16.594117647058823\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07259848952236096\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.9014717214678702\n","    mean_inference_ms: 0.7455149980915255\n","    mean_raw_obs_processing_ms: 0.11133038505856266\n","  time_since_restore: 332.7699382305145\n","  time_this_iter_s: 11.749510526657104\n","  time_total_s: 332.7699382305145\n","  timers:\n","    learn_throughput: 1611.33\n","    learn_time_ms: 2482.421\n","    load_throughput: 9875340.514\n","    load_time_ms: 0.405\n","    sample_throughput: 337.768\n","    sample_time_ms: 11842.444\n","    update_time_ms: 2.761\n","  timestamp: 1649863425\n","  timesteps_since_restore: 128000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 128000\n","  training_iteration: 32\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:23:47 (running for 00:05:58.13)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         331.397</td><td style=\"text-align: right;\">184000</td><td style=\"text-align: right;\">-333.275</td><td style=\"text-align: right;\">             12.7194</td><td style=\"text-align: right;\">           -671.56  </td><td style=\"text-align: right;\">            102.32</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         332.77 </td><td style=\"text-align: right;\">128000</td><td style=\"text-align: right;\"> -11.211</td><td style=\"text-align: right;\">            130.795 </td><td style=\"text-align: right;\">           -489.446 </td><td style=\"text-align: right;\">            577.99</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         320.352</td><td style=\"text-align: right;\">140000</td><td style=\"text-align: right;\"> 262.748</td><td style=\"text-align: right;\">            308.503 </td><td style=\"text-align: right;\">             32.5889</td><td style=\"text-align: right;\">            324.81</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 144000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-23-49\n","  done: false\n","  episode_len_mean: 311.56\n","  episode_media: {}\n","  episode_reward_max: 308.50330463860075\n","  episode_reward_mean: 257.3815978044624\n","  episode_reward_min: -112.24231407936273\n","  episodes_this_iter: 11\n","  episodes_total: 617\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.11249999701976776\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7519587874412537\n","          entropy_coeff: 0.0\n","          kl: 0.015304546803236008\n","          model: {}\n","          policy_loss: -0.014003259129822254\n","          total_loss: 1217.9749755859375\n","          vf_explained_var: 0.05682701990008354\n","          vf_loss: 1217.987060546875\n","    num_agent_steps_sampled: 144000\n","    num_agent_steps_trained: 144000\n","    num_steps_sampled: 144000\n","    num_steps_trained: 144000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 36\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.03846153846154\n","    ram_util_percent: 16.599999999999998\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07461441265173269\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.7033749980946858\n","    mean_inference_ms: 0.7561089080692167\n","    mean_raw_obs_processing_ms: 0.11279994916538506\n","  time_since_restore: 329.50919675827026\n","  time_this_iter_s: 9.157060861587524\n","  time_total_s: 329.50919675827026\n","  timers:\n","    learn_throughput: 1617.048\n","    learn_time_ms: 2473.643\n","    load_throughput: 8987152.346\n","    load_time_ms: 0.445\n","    sample_throughput: 441.739\n","    sample_time_ms: 9055.113\n","    update_time_ms: 2.817\n","  timestamp: 1649863429\n","  timesteps_since_restore: 144000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 144000\n","  training_iteration: 36\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 188000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-23-52\n","  done: false\n","  episode_len_mean: 106.71\n","  episode_media: {}\n","  episode_reward_max: 12.71938138275425\n","  episode_reward_mean: -349.15210135544015\n","  episode_reward_min: -671.5600515640333\n","  episodes_this_iter: 35\n","  episodes_total: 1853\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 674.1248168945312\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7968626022338867\n","          entropy_coeff: 0.0\n","          kl: 6.798902177251875e-05\n","          model: {}\n","          policy_loss: 0.0028618457727134228\n","          total_loss: 1802.007568359375\n","          vf_explained_var: 0.7604748606681824\n","          vf_loss: 1801.9588623046875\n","    num_agent_steps_sampled: 188000\n","    num_agent_steps_trained: 188000\n","    num_steps_sampled: 188000\n","    num_steps_trained: 188000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 47\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.645454545454545\n","    ram_util_percent: 16.599999999999998\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0696877803858163\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.25193328356950745\n","    mean_inference_ms: 0.7136661611306203\n","    mean_raw_obs_processing_ms: 0.11201292083065736\n","  time_since_restore: 338.590313911438\n","  time_this_iter_s: 7.193796396255493\n","  time_total_s: 338.590313911438\n","  timers:\n","    learn_throughput: 1599.175\n","    learn_time_ms: 2501.289\n","    load_throughput: 9090385.782\n","    load_time_ms: 0.44\n","    sample_throughput: 547.594\n","    sample_time_ms: 7304.681\n","    update_time_ms: 2.722\n","  timestamp: 1649863432\n","  timesteps_since_restore: 188000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 188000\n","  training_iteration: 47\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:23:53 (running for 00:06:03.28)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         338.59 </td><td style=\"text-align: right;\">188000</td><td style=\"text-align: right;\">-349.152</td><td style=\"text-align: right;\">             12.7194</td><td style=\"text-align: right;\">            -671.56 </td><td style=\"text-align: right;\">            106.71</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         332.77 </td><td style=\"text-align: right;\">128000</td><td style=\"text-align: right;\"> -11.211</td><td style=\"text-align: right;\">            130.795 </td><td style=\"text-align: right;\">            -489.446</td><td style=\"text-align: right;\">            577.99</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         329.509</td><td style=\"text-align: right;\">144000</td><td style=\"text-align: right;\"> 257.382</td><td style=\"text-align: right;\">            308.503 </td><td style=\"text-align: right;\">            -112.242</td><td style=\"text-align: right;\">            311.56</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 132000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-23-57\n","  done: false\n","  episode_len_mean: 569.47\n","  episode_media: {}\n","  episode_reward_max: 130.79490068827636\n","  episode_reward_mean: -11.374501064491515\n","  episode_reward_min: -489.4459984118832\n","  episodes_this_iter: 8\n","  episodes_total: 544\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.0624057054519653\n","          entropy_coeff: 0.0\n","          kl: 0.013165092095732689\n","          model: {}\n","          policy_loss: -0.03427549824118614\n","          total_loss: 86.12084197998047\n","          vf_explained_var: 0.8758370280265808\n","          vf_loss: 86.14178466796875\n","    num_agent_steps_sampled: 132000\n","    num_agent_steps_trained: 132000\n","    num_steps_sampled: 132000\n","    num_steps_trained: 132000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 33\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.770588235294117\n","    ram_util_percent: 16.6\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07263429347282967\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.9200628666729176\n","    mean_inference_ms: 0.7465211782477051\n","    mean_raw_obs_processing_ms: 0.11131688755116834\n","  time_since_restore: 344.6585142612457\n","  time_this_iter_s: 11.888576030731201\n","  time_total_s: 344.6585142612457\n","  timers:\n","    learn_throughput: 1604.389\n","    learn_time_ms: 2493.161\n","    load_throughput: 9868950.588\n","    load_time_ms: 0.405\n","    sample_throughput: 335.393\n","    sample_time_ms: 11926.309\n","    update_time_ms: 2.835\n","  timestamp: 1649863437\n","  timesteps_since_restore: 132000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 132000\n","  training_iteration: 33\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:23:58 (running for 00:06:09.06)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         338.59 </td><td style=\"text-align: right;\">188000</td><td style=\"text-align: right;\">-349.152 </td><td style=\"text-align: right;\">             12.7194</td><td style=\"text-align: right;\">            -671.56 </td><td style=\"text-align: right;\">            106.71</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         344.659</td><td style=\"text-align: right;\">132000</td><td style=\"text-align: right;\"> -11.3745</td><td style=\"text-align: right;\">            130.795 </td><td style=\"text-align: right;\">            -489.446</td><td style=\"text-align: right;\">            569.47</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         329.509</td><td style=\"text-align: right;\">144000</td><td style=\"text-align: right;\"> 257.382 </td><td style=\"text-align: right;\">            308.503 </td><td style=\"text-align: right;\">            -112.242</td><td style=\"text-align: right;\">            311.56</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 148000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-23-59\n","  done: false\n","  episode_len_mean: 312.97\n","  episode_media: {}\n","  episode_reward_max: 306.159587730079\n","  episode_reward_mean: 257.8186492883051\n","  episode_reward_min: -112.24231407936273\n","  episodes_this_iter: 12\n","  episodes_total: 629\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.11249999701976776\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7345277070999146\n","          entropy_coeff: 0.0\n","          kl: 0.009420402348041534\n","          model: {}\n","          policy_loss: -0.003637864952906966\n","          total_loss: 335.4365539550781\n","          vf_explained_var: 0.07211165875196457\n","          vf_loss: 335.4391174316406\n","    num_agent_steps_sampled: 148000\n","    num_agent_steps_trained: 148000\n","    num_steps_sampled: 148000\n","    num_steps_trained: 148000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 37\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.42857142857143\n","    ram_util_percent: 16.59285714285714\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07463133766302339\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.7009448020961764\n","    mean_inference_ms: 0.7561947808819149\n","    mean_raw_obs_processing_ms: 0.11280445245047777\n","  time_since_restore: 338.8445928096771\n","  time_this_iter_s: 9.33539605140686\n","  time_total_s: 338.8445928096771\n","  timers:\n","    learn_throughput: 1609.198\n","    learn_time_ms: 2485.71\n","    load_throughput: 8666364.998\n","    load_time_ms: 0.462\n","    sample_throughput: 448.803\n","    sample_time_ms: 8912.6\n","    update_time_ms: 2.794\n","  timestamp: 1649863439\n","  timesteps_since_restore: 148000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 148000\n","  training_iteration: 37\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 192000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-23-59\n","  done: false\n","  episode_len_mean: 108.21\n","  episode_media: {}\n","  episode_reward_max: -6.818192030178423\n","  episode_reward_mean: -360.9825707503927\n","  episode_reward_min: -671.5600515640333\n","  episodes_this_iter: 36\n","  episodes_total: 1889\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 337.0624084472656\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7994536757469177\n","          entropy_coeff: 0.0\n","          kl: 2.7048622541769873e-07\n","          model: {}\n","          policy_loss: 0.0018764170818030834\n","          total_loss: 1065.9259033203125\n","          vf_explained_var: 0.8439128994941711\n","          vf_loss: 1065.9239501953125\n","    num_agent_steps_sampled: 192000\n","    num_agent_steps_trained: 192000\n","    num_steps_sampled: 192000\n","    num_steps_trained: 192000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 48\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.510000000000002\n","    ram_util_percent: 16.59\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06968859888304757\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2521610993087425\n","    mean_inference_ms: 0.7138912688903027\n","    mean_raw_obs_processing_ms: 0.11201521109130531\n","  time_since_restore: 345.990074634552\n","  time_this_iter_s: 7.399760723114014\n","  time_total_s: 345.990074634552\n","  timers:\n","    learn_throughput: 1594.188\n","    learn_time_ms: 2509.114\n","    load_throughput: 8914567.481\n","    load_time_ms: 0.449\n","    sample_throughput: 549.242\n","    sample_time_ms: 7282.768\n","    update_time_ms: 2.699\n","  timestamp: 1649863439\n","  timesteps_since_restore: 192000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 192000\n","  training_iteration: 48\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:24:04 (running for 00:06:14.80)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">         345.99 </td><td style=\"text-align: right;\">192000</td><td style=\"text-align: right;\">-360.983 </td><td style=\"text-align: right;\">            -6.81819</td><td style=\"text-align: right;\">            -671.56 </td><td style=\"text-align: right;\">            108.21</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         344.659</td><td style=\"text-align: right;\">132000</td><td style=\"text-align: right;\"> -11.3745</td><td style=\"text-align: right;\">           130.795  </td><td style=\"text-align: right;\">            -489.446</td><td style=\"text-align: right;\">            569.47</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         338.845</td><td style=\"text-align: right;\">148000</td><td style=\"text-align: right;\"> 257.819 </td><td style=\"text-align: right;\">           306.16   </td><td style=\"text-align: right;\">            -112.242</td><td style=\"text-align: right;\">            312.97</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 196000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-24-07\n","  done: false\n","  episode_len_mean: 109.62\n","  episode_media: {}\n","  episode_reward_max: -6.818192030178423\n","  episode_reward_mean: -381.7065104324748\n","  episode_reward_min: -672.2050238254313\n","  episodes_this_iter: 37\n","  episodes_total: 1926\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 168.5312042236328\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.8085979223251343\n","          entropy_coeff: 0.0\n","          kl: 9.717965667732642e-07\n","          model: {}\n","          policy_loss: 0.0007287534535862505\n","          total_loss: 803.0606689453125\n","          vf_explained_var: 0.8459749817848206\n","          vf_loss: 803.059814453125\n","    num_agent_steps_sampled: 196000\n","    num_agent_steps_trained: 196000\n","    num_steps_sampled: 196000\n","    num_steps_trained: 196000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 49\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 11.518181818181818\n","    ram_util_percent: 16.599999999999998\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06971962626672623\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.25251953487601914\n","    mean_inference_ms: 0.7144278858664996\n","    mean_raw_obs_processing_ms: 0.11206130890009536\n","  time_since_restore: 353.69688868522644\n","  time_this_iter_s: 7.7068140506744385\n","  time_total_s: 353.69688868522644\n","  timers:\n","    learn_throughput: 1579.003\n","    learn_time_ms: 2533.244\n","    load_throughput: 9021463.677\n","    load_time_ms: 0.443\n","    sample_throughput: 547.211\n","    sample_time_ms: 7309.797\n","    update_time_ms: 2.753\n","  timestamp: 1649863447\n","  timesteps_since_restore: 196000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 196000\n","  training_iteration: 49\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 152000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-24-08\n","  done: false\n","  episode_len_mean: 312.05\n","  episode_media: {}\n","  episode_reward_max: 306.159587730079\n","  episode_reward_mean: 255.59558614405546\n","  episode_reward_min: -112.24231407936273\n","  episodes_this_iter: 13\n","  episodes_total: 642\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.11249999701976776\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7163508534431458\n","          entropy_coeff: 0.0\n","          kl: 0.0066492799669504166\n","          model: {}\n","          policy_loss: -0.0057881176471710205\n","          total_loss: 337.2802734375\n","          vf_explained_var: 0.08207091689109802\n","          vf_loss: 337.2853088378906\n","    num_agent_steps_sampled: 152000\n","    num_agent_steps_trained: 152000\n","    num_steps_sampled: 152000\n","    num_steps_trained: 152000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 38\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.600000000000001\n","    ram_util_percent: 16.591666666666665\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07465043339563131\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6984399473062329\n","    mean_inference_ms: 0.7564113227587316\n","    mean_raw_obs_processing_ms: 0.11281143248230982\n","  time_since_restore: 347.6754434108734\n","  time_this_iter_s: 8.830850601196289\n","  time_total_s: 347.6754434108734\n","  timers:\n","    learn_throughput: 1605.59\n","    learn_time_ms: 2491.296\n","    load_throughput: 8531510.806\n","    load_time_ms: 0.469\n","    sample_throughput: 451.35\n","    sample_time_ms: 8862.299\n","    update_time_ms: 2.786\n","  timestamp: 1649863448\n","  timesteps_since_restore: 152000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 152000\n","  training_iteration: 38\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 136000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-24-09\n","  done: false\n","  episode_len_mean: 549.88\n","  episode_media: {}\n","  episode_reward_max: 130.79490068827636\n","  episode_reward_mean: -11.0018907781844\n","  episode_reward_min: -486.5621715216068\n","  episodes_this_iter: 10\n","  episodes_total: 554\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.0734226703643799\n","          entropy_coeff: 0.0\n","          kl: 0.014129667542874813\n","          model: {}\n","          policy_loss: -0.0439985916018486\n","          total_loss: 231.0374755859375\n","          vf_explained_var: 0.8042086958885193\n","          vf_loss: 231.06716918945312\n","    num_agent_steps_sampled: 136000\n","    num_agent_steps_trained: 136000\n","    num_steps_sampled: 136000\n","    num_steps_trained: 136000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 34\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.36875\n","    ram_util_percent: 16.59375\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07267626792214112\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.9392995084982516\n","    mean_inference_ms: 0.747641356503111\n","    mean_raw_obs_processing_ms: 0.1113123255572551\n","  time_since_restore: 355.96497225761414\n","  time_this_iter_s: 11.306457996368408\n","  time_total_s: 355.96497225761414\n","  timers:\n","    learn_throughput: 1605.956\n","    learn_time_ms: 2490.728\n","    load_throughput: 9684377.742\n","    load_time_ms: 0.413\n","    sample_throughput: 331.421\n","    sample_time_ms: 12069.237\n","    update_time_ms: 2.833\n","  timestamp: 1649863449\n","  timesteps_since_restore: 136000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 136000\n","  training_iteration: 34\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:24:10 (running for 00:06:20.41)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         353.697</td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">-381.707 </td><td style=\"text-align: right;\">            -6.81819</td><td style=\"text-align: right;\">            -672.205</td><td style=\"text-align: right;\">            109.62</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         355.965</td><td style=\"text-align: right;\">136000</td><td style=\"text-align: right;\"> -11.0019</td><td style=\"text-align: right;\">           130.795  </td><td style=\"text-align: right;\">            -486.562</td><td style=\"text-align: right;\">            549.88</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         347.675</td><td style=\"text-align: right;\">152000</td><td style=\"text-align: right;\"> 255.596 </td><td style=\"text-align: right;\">           306.16   </td><td style=\"text-align: right;\">            -112.242</td><td style=\"text-align: right;\">            312.05</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 200000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-24-14\n","  done: false\n","  episode_len_mean: 106.8\n","  episode_media: {}\n","  episode_reward_max: 5.8446784405843175\n","  episode_reward_mean: -369.9965895257545\n","  episode_reward_min: -672.2050238254313\n","  episodes_this_iter: 39\n","  episodes_total: 1965\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 84.2656021118164\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7975326180458069\n","          entropy_coeff: 0.0\n","          kl: 3.3268213428527815e-06\n","          model: {}\n","          policy_loss: 0.00041952362516894937\n","          total_loss: 1513.906494140625\n","          vf_explained_var: 0.8009394407272339\n","          vf_loss: 1513.9056396484375\n","    num_agent_steps_sampled: 200000\n","    num_agent_steps_trained: 200000\n","    num_steps_sampled: 200000\n","    num_steps_trained: 200000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 50\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.672727272727274\n","    ram_util_percent: 16.599999999999998\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06975677979644186\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.25288775167068744\n","    mean_inference_ms: 0.7149667594308472\n","    mean_raw_obs_processing_ms: 0.11213856073933158\n","  time_since_restore: 360.9879231452942\n","  time_this_iter_s: 7.291034460067749\n","  time_total_s: 360.9879231452942\n","  timers:\n","    learn_throughput: 1573.443\n","    learn_time_ms: 2542.196\n","    load_throughput: 8996308.649\n","    load_time_ms: 0.445\n","    sample_throughput: 547.128\n","    sample_time_ms: 7310.898\n","    update_time_ms: 2.75\n","  timestamp: 1649863454\n","  timesteps_since_restore: 200000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 200000\n","  training_iteration: 50\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:24:15 (running for 00:06:25.79)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         360.988</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">-369.997 </td><td style=\"text-align: right;\">             5.84468</td><td style=\"text-align: right;\">            -672.205</td><td style=\"text-align: right;\">            106.8 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         355.965</td><td style=\"text-align: right;\">136000</td><td style=\"text-align: right;\"> -11.0019</td><td style=\"text-align: right;\">           130.795  </td><td style=\"text-align: right;\">            -486.562</td><td style=\"text-align: right;\">            549.88</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         347.675</td><td style=\"text-align: right;\">152000</td><td style=\"text-align: right;\"> 255.596 </td><td style=\"text-align: right;\">           306.16   </td><td style=\"text-align: right;\">            -112.242</td><td style=\"text-align: right;\">            312.05</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 156000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-24-16\n","  done: false\n","  episode_len_mean: 309.32\n","  episode_media: {}\n","  episode_reward_max: 305.4398900649365\n","  episode_reward_mean: 256.9371071437334\n","  episode_reward_min: -112.24231407936273\n","  episodes_this_iter: 14\n","  episodes_total: 656\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.11249999701976776\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7722716331481934\n","          entropy_coeff: 0.0\n","          kl: 0.006487699691206217\n","          model: {}\n","          policy_loss: -0.011729542165994644\n","          total_loss: 185.5397491455078\n","          vf_explained_var: 0.12210433930158615\n","          vf_loss: 185.55075073242188\n","    num_agent_steps_sampled: 156000\n","    num_agent_steps_trained: 156000\n","    num_steps_sampled: 156000\n","    num_steps_trained: 156000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 39\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.13846153846154\n","    ram_util_percent: 16.599999999999998\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07466909322374414\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6956950449417977\n","    mean_inference_ms: 0.7566189896579673\n","    mean_raw_obs_processing_ms: 0.11281105153549152\n","  time_since_restore: 356.22935223579407\n","  time_this_iter_s: 8.553908824920654\n","  time_total_s: 356.22935223579407\n","  timers:\n","    learn_throughput: 1606.474\n","    learn_time_ms: 2489.925\n","    load_throughput: 8215668.185\n","    load_time_ms: 0.487\n","    sample_throughput: 452.711\n","    sample_time_ms: 8835.658\n","    update_time_ms: 2.799\n","  timestamp: 1649863456\n","  timesteps_since_restore: 156000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 156000\n","  training_iteration: 39\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 140000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-24-20\n","  done: false\n","  episode_len_mean: 531.79\n","  episode_media: {}\n","  episode_reward_max: 130.79490068827636\n","  episode_reward_mean: -6.157928189558609\n","  episode_reward_min: -486.5621715216068\n","  episodes_this_iter: 8\n","  episodes_total: 562\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.078300952911377\n","          entropy_coeff: 0.0\n","          kl: 0.01570647582411766\n","          model: {}\n","          policy_loss: -0.0371573269367218\n","          total_loss: 285.49114990234375\n","          vf_explained_var: 0.8475601673126221\n","          vf_loss: 285.51239013671875\n","    num_agent_steps_sampled: 140000\n","    num_agent_steps_trained: 140000\n","    num_steps_sampled: 140000\n","    num_steps_trained: 140000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 35\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.425\n","    ram_util_percent: 16.6\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07271444062867463\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.9534202948057705\n","    mean_inference_ms: 0.7485344000417835\n","    mean_raw_obs_processing_ms: 0.11131504923232217\n","  time_since_restore: 367.31502866744995\n","  time_this_iter_s: 11.350056409835815\n","  time_total_s: 367.31502866744995\n","  timers:\n","    learn_throughput: 1604.139\n","    learn_time_ms: 2493.549\n","    load_throughput: 9864888.575\n","    load_time_ms: 0.405\n","    sample_throughput: 332.307\n","    sample_time_ms: 12037.05\n","    update_time_ms: 2.878\n","  timestamp: 1649863460\n","  timesteps_since_restore: 140000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 140000\n","  training_iteration: 35\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:24:20 (running for 00:06:30.80)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         360.988</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">-369.997  </td><td style=\"text-align: right;\">             5.84468</td><td style=\"text-align: right;\">            -672.205</td><td style=\"text-align: right;\">            106.8 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         367.315</td><td style=\"text-align: right;\">140000</td><td style=\"text-align: right;\">  -6.15793</td><td style=\"text-align: right;\">           130.795  </td><td style=\"text-align: right;\">            -486.562</td><td style=\"text-align: right;\">            531.79</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         356.229</td><td style=\"text-align: right;\">156000</td><td style=\"text-align: right;\"> 256.937  </td><td style=\"text-align: right;\">           305.44   </td><td style=\"text-align: right;\">            -112.242</td><td style=\"text-align: right;\">            309.32</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 204000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-24-22\n","  done: false\n","  episode_len_mean: 104.37\n","  episode_media: {}\n","  episode_reward_max: 12.309901736424777\n","  episode_reward_mean: -347.36969222413603\n","  episode_reward_min: -659.7553814914074\n","  episodes_this_iter: 39\n","  episodes_total: 2004\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 42.1328010559082\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7795071601867676\n","          entropy_coeff: 0.0\n","          kl: 1.0969457434839569e-05\n","          model: {}\n","          policy_loss: -0.0037215210031718016\n","          total_loss: 952.0278930664062\n","          vf_explained_var: 0.7573457360267639\n","          vf_loss: 952.0311889648438\n","    num_agent_steps_sampled: 204000\n","    num_agent_steps_trained: 204000\n","    num_steps_sampled: 204000\n","    num_steps_trained: 204000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 51\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.02\n","    ram_util_percent: 16.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06980247544953139\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2531660700525233\n","    mean_inference_ms: 0.7155483957616551\n","    mean_raw_obs_processing_ms: 0.11223431099169272\n","  time_since_restore: 368.42462182044983\n","  time_this_iter_s: 7.43669867515564\n","  time_total_s: 368.42462182044983\n","  timers:\n","    learn_throughput: 1569.51\n","    learn_time_ms: 2548.567\n","    load_throughput: 8779286.238\n","    load_time_ms: 0.456\n","    sample_throughput: 544.942\n","    sample_time_ms: 7340.232\n","    update_time_ms: 2.749\n","  timestamp: 1649863462\n","  timesteps_since_restore: 204000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 204000\n","  training_iteration: 51\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 160000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-24-25\n","  done: false\n","  episode_len_mean: 304.73\n","  episode_media: {}\n","  episode_reward_max: 303.226586714449\n","  episode_reward_mean: 253.04667516824213\n","  episode_reward_min: -112.24231407936273\n","  episodes_this_iter: 15\n","  episodes_total: 671\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.11249999701976776\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7840155363082886\n","          entropy_coeff: 0.0\n","          kl: 0.008732178248465061\n","          model: {}\n","          policy_loss: -0.009289980866014957\n","          total_loss: 496.37841796875\n","          vf_explained_var: 0.26112547516822815\n","          vf_loss: 496.3867492675781\n","    num_agent_steps_sampled: 160000\n","    num_agent_steps_trained: 160000\n","    num_steps_sampled: 160000\n","    num_steps_trained: 160000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 40\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.441666666666668\n","    ram_util_percent: 16.599999999999998\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07468397489629043\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6929118194876789\n","    mean_inference_ms: 0.756838172273899\n","    mean_raw_obs_processing_ms: 0.11280933032198849\n","  time_since_restore: 364.7597188949585\n","  time_this_iter_s: 8.530366659164429\n","  time_total_s: 364.7597188949585\n","  timers:\n","    learn_throughput: 1609.033\n","    learn_time_ms: 2485.966\n","    load_throughput: 8373117.732\n","    load_time_ms: 0.478\n","    sample_throughput: 452.36\n","    sample_time_ms: 8842.513\n","    update_time_ms: 2.785\n","  timestamp: 1649863465\n","  timesteps_since_restore: 160000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 160000\n","  training_iteration: 40\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:24:26 (running for 00:06:36.41)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         368.425</td><td style=\"text-align: right;\">204000</td><td style=\"text-align: right;\">-347.37   </td><td style=\"text-align: right;\">             12.3099</td><td style=\"text-align: right;\">            -659.755</td><td style=\"text-align: right;\">            104.37</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         367.315</td><td style=\"text-align: right;\">140000</td><td style=\"text-align: right;\">  -6.15793</td><td style=\"text-align: right;\">            130.795 </td><td style=\"text-align: right;\">            -486.562</td><td style=\"text-align: right;\">            531.79</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         364.76 </td><td style=\"text-align: right;\">160000</td><td style=\"text-align: right;\"> 253.047  </td><td style=\"text-align: right;\">            303.227 </td><td style=\"text-align: right;\">            -112.242</td><td style=\"text-align: right;\">            304.73</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 208000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-24-29\n","  done: false\n","  episode_len_mean: 102.49\n","  episode_media: {}\n","  episode_reward_max: 15.010166152327656\n","  episode_reward_mean: -372.62413045219955\n","  episode_reward_min: -659.7553814914074\n","  episodes_this_iter: 41\n","  episodes_total: 2045\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 21.0664005279541\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.8022284507751465\n","          entropy_coeff: 0.0\n","          kl: 3.116514199064113e-05\n","          model: {}\n","          policy_loss: 0.009864329360425472\n","          total_loss: 621.15576171875\n","          vf_explained_var: 0.9079254269599915\n","          vf_loss: 621.1453247070312\n","    num_agent_steps_sampled: 208000\n","    num_agent_steps_trained: 208000\n","    num_steps_sampled: 208000\n","    num_steps_trained: 208000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 52\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.70909090909091\n","    ram_util_percent: 16.599999999999998\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06983390948592669\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2533627156197606\n","    mean_inference_ms: 0.7159507448424692\n","    mean_raw_obs_processing_ms: 0.11230617397898221\n","  time_since_restore: 375.75469613075256\n","  time_this_iter_s: 7.330074310302734\n","  time_total_s: 375.75469613075256\n","  timers:\n","    learn_throughput: 1566.893\n","    learn_time_ms: 2552.822\n","    load_throughput: 9258438.276\n","    load_time_ms: 0.432\n","    sample_throughput: 544.603\n","    sample_time_ms: 7344.802\n","    update_time_ms: 2.822\n","  timestamp: 1649863469\n","  timesteps_since_restore: 208000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 208000\n","  training_iteration: 52\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 144000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-24-31\n","  done: false\n","  episode_len_mean: 536.49\n","  episode_media: {}\n","  episode_reward_max: 130.79490068827636\n","  episode_reward_mean: 1.3062939249048282\n","  episode_reward_min: -414.907705035423\n","  episodes_this_iter: 13\n","  episodes_total: 575\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.0776622295379639\n","          entropy_coeff: 0.0\n","          kl: 0.012526621110737324\n","          model: {}\n","          policy_loss: -0.051621757447719574\n","          total_loss: 709.60546875\n","          vf_explained_var: 0.7838258147239685\n","          vf_loss: 709.6443481445312\n","    num_agent_steps_sampled: 144000\n","    num_agent_steps_trained: 144000\n","    num_steps_sampled: 144000\n","    num_steps_trained: 144000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 36\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.64375\n","    ram_util_percent: 16.6\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07278291452380385\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.9756271388763657\n","    mean_inference_ms: 0.7500290385940585\n","    mean_raw_obs_processing_ms: 0.1113399625485042\n","  time_since_restore: 377.945259809494\n","  time_this_iter_s: 10.630231142044067\n","  time_total_s: 377.945259809494\n","  timers:\n","    learn_throughput: 1611.303\n","    learn_time_ms: 2482.463\n","    load_throughput: 9885232.147\n","    load_time_ms: 0.405\n","    sample_throughput: 334.861\n","    sample_time_ms: 11945.269\n","    update_time_ms: 2.841\n","  timestamp: 1649863471\n","  timesteps_since_restore: 144000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 144000\n","  training_iteration: 36\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:24:31 (running for 00:06:41.47)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         375.755</td><td style=\"text-align: right;\">208000</td><td style=\"text-align: right;\">-372.624  </td><td style=\"text-align: right;\">             15.0102</td><td style=\"text-align: right;\">            -659.755</td><td style=\"text-align: right;\">            102.49</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         377.945</td><td style=\"text-align: right;\">144000</td><td style=\"text-align: right;\">   1.30629</td><td style=\"text-align: right;\">            130.795 </td><td style=\"text-align: right;\">            -414.908</td><td style=\"text-align: right;\">            536.49</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         364.76 </td><td style=\"text-align: right;\">160000</td><td style=\"text-align: right;\"> 253.047  </td><td style=\"text-align: right;\">            303.227 </td><td style=\"text-align: right;\">            -112.242</td><td style=\"text-align: right;\">            304.73</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 164000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-24-34\n","  done: false\n","  episode_len_mean: 302.27\n","  episode_media: {}\n","  episode_reward_max: 303.226586714449\n","  episode_reward_mean: 250.2385278287822\n","  episode_reward_min: -112.24231407936273\n","  episodes_this_iter: 13\n","  episodes_total: 684\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.11249999701976776\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7360946536064148\n","          entropy_coeff: 0.0\n","          kl: 0.007715544663369656\n","          model: {}\n","          policy_loss: -0.007017206400632858\n","          total_loss: 667.3316650390625\n","          vf_explained_var: 0.1504843831062317\n","          vf_loss: 667.3377685546875\n","    num_agent_steps_sampled: 164000\n","    num_agent_steps_trained: 164000\n","    num_steps_sampled: 164000\n","    num_steps_trained: 164000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 41\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.369230769230766\n","    ram_util_percent: 16.599999999999998\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07469688170037232\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6909538347294046\n","    mean_inference_ms: 0.7570743147154515\n","    mean_raw_obs_processing_ms: 0.11280993951338335\n","  time_since_restore: 373.5609428882599\n","  time_this_iter_s: 8.801223993301392\n","  time_total_s: 373.5609428882599\n","  timers:\n","    learn_throughput: 1607.093\n","    learn_time_ms: 2488.966\n","    load_throughput: 8338576.541\n","    load_time_ms: 0.48\n","    sample_throughput: 452.577\n","    sample_time_ms: 8838.273\n","    update_time_ms: 2.788\n","  timestamp: 1649863474\n","  timesteps_since_restore: 164000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 164000\n","  training_iteration: 41\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 212000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-24-37\n","  done: false\n","  episode_len_mean: 103.97\n","  episode_media: {}\n","  episode_reward_max: 15.010166152327656\n","  episode_reward_mean: -355.17376119846807\n","  episode_reward_min: -659.7553814914074\n","  episodes_this_iter: 35\n","  episodes_total: 2080\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 10.53320026397705\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7782636284828186\n","          entropy_coeff: 0.0\n","          kl: 0.00012418310507200658\n","          model: {}\n","          policy_loss: -0.008595913648605347\n","          total_loss: 821.682373046875\n","          vf_explained_var: 0.7672138810157776\n","          vf_loss: 821.689697265625\n","    num_agent_steps_sampled: 212000\n","    num_agent_steps_trained: 212000\n","    num_steps_sampled: 212000\n","    num_steps_trained: 212000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 53\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.781818181818183\n","    ram_util_percent: 16.599999999999998\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06987334517770502\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.25375088487861214\n","    mean_inference_ms: 0.7164808776946623\n","    mean_raw_obs_processing_ms: 0.11237210775331764\n","  time_since_restore: 383.31204438209534\n","  time_this_iter_s: 7.557348251342773\n","  time_total_s: 383.31204438209534\n","  timers:\n","    learn_throughput: 1574.699\n","    learn_time_ms: 2540.167\n","    load_throughput: 9116070.419\n","    load_time_ms: 0.439\n","    sample_throughput: 540.716\n","    sample_time_ms: 7397.593\n","    update_time_ms: 2.818\n","  timestamp: 1649863477\n","  timesteps_since_restore: 212000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 212000\n","  training_iteration: 53\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:24:37 (running for 00:06:47.25)<br>Memory usage on this node: 5.8/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         383.312</td><td style=\"text-align: right;\">212000</td><td style=\"text-align: right;\">-355.174  </td><td style=\"text-align: right;\">             15.0102</td><td style=\"text-align: right;\">            -659.755</td><td style=\"text-align: right;\">            103.97</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         377.945</td><td style=\"text-align: right;\">144000</td><td style=\"text-align: right;\">   1.30629</td><td style=\"text-align: right;\">            130.795 </td><td style=\"text-align: right;\">            -414.908</td><td style=\"text-align: right;\">            536.49</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         373.561</td><td style=\"text-align: right;\">164000</td><td style=\"text-align: right;\"> 250.239  </td><td style=\"text-align: right;\">            303.227 </td><td style=\"text-align: right;\">            -112.242</td><td style=\"text-align: right;\">            302.27</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 148000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-24-41\n","  done: false\n","  episode_len_mean: 501.08\n","  episode_media: {}\n","  episode_reward_max: 130.79490068827636\n","  episode_reward_mean: 16.69643110655863\n","  episode_reward_min: -310.67798028815093\n","  episodes_this_iter: 16\n","  episodes_total: 591\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.0409613847732544\n","          entropy_coeff: 0.0\n","          kl: 0.014941520988941193\n","          model: {}\n","          policy_loss: -0.04699446260929108\n","          total_loss: 703.3665161132812\n","          vf_explained_var: 0.6758859753608704\n","          vf_loss: 703.3983764648438\n","    num_agent_steps_sampled: 148000\n","    num_agent_steps_trained: 148000\n","    num_steps_sampled: 148000\n","    num_steps_trained: 148000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 37\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.18\n","    ram_util_percent: 16.43333333333333\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0728850218487072\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.000756409089521\n","    mean_inference_ms: 0.7518988878477637\n","    mean_raw_obs_processing_ms: 0.11141748214610667\n","  time_since_restore: 388.6327555179596\n","  time_this_iter_s: 10.687495708465576\n","  time_total_s: 388.6327555179596\n","  timers:\n","    learn_throughput: 1593.63\n","    learn_time_ms: 2509.994\n","    load_throughput: 9839432.291\n","    load_time_ms: 0.407\n","    sample_throughput: 343.395\n","    sample_time_ms: 11648.389\n","    update_time_ms: 2.842\n","  timestamp: 1649863481\n","  timesteps_since_restore: 148000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 148000\n","  training_iteration: 37\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:24:43 (running for 00:06:53.20)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         383.312</td><td style=\"text-align: right;\">212000</td><td style=\"text-align: right;\">-355.174 </td><td style=\"text-align: right;\">             15.0102</td><td style=\"text-align: right;\">            -659.755</td><td style=\"text-align: right;\">            103.97</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         388.633</td><td style=\"text-align: right;\">148000</td><td style=\"text-align: right;\">  16.6964</td><td style=\"text-align: right;\">            130.795 </td><td style=\"text-align: right;\">            -310.678</td><td style=\"text-align: right;\">            501.08</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         373.561</td><td style=\"text-align: right;\">164000</td><td style=\"text-align: right;\"> 250.239 </td><td style=\"text-align: right;\">            303.227 </td><td style=\"text-align: right;\">            -112.242</td><td style=\"text-align: right;\">            302.27</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 168000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-24-43\n","  done: false\n","  episode_len_mean: 309.46\n","  episode_media: {}\n","  episode_reward_max: 303.226586714449\n","  episode_reward_mean: 245.9007160673647\n","  episode_reward_min: -112.24231407936273\n","  episodes_this_iter: 14\n","  episodes_total: 698\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.11249999701976776\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7571843266487122\n","          entropy_coeff: 0.0\n","          kl: 0.011763266287744045\n","          model: {}\n","          policy_loss: -0.017681019380688667\n","          total_loss: 298.55987548828125\n","          vf_explained_var: 0.16055457293987274\n","          vf_loss: 298.5762023925781\n","    num_agent_steps_sampled: 168000\n","    num_agent_steps_trained: 168000\n","    num_steps_sampled: 168000\n","    num_steps_trained: 168000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 42\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.907692307692306\n","    ram_util_percent: 16.215384615384615\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07472368685312061\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.689392200715735\n","    mean_inference_ms: 0.7576849149961788\n","    mean_raw_obs_processing_ms: 0.11283593118772323\n","  time_since_restore: 383.0847451686859\n","  time_this_iter_s: 9.523802280426025\n","  time_total_s: 383.0847451686859\n","  timers:\n","    learn_throughput: 1601.403\n","    learn_time_ms: 2497.81\n","    load_throughput: 8348119.62\n","    load_time_ms: 0.479\n","    sample_throughput: 448.507\n","    sample_time_ms: 8918.476\n","    update_time_ms: 2.783\n","  timestamp: 1649863483\n","  timesteps_since_restore: 168000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 168000\n","  training_iteration: 42\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 216000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-24-45\n","  done: false\n","  episode_len_mean: 108.9\n","  episode_media: {}\n","  episode_reward_max: 15.010166152327656\n","  episode_reward_mean: -344.6579675198206\n","  episode_reward_min: -629.3038118314695\n","  episodes_this_iter: 35\n","  episodes_total: 2115\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 5.266600131988525\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.8052716851234436\n","          entropy_coeff: 0.0\n","          kl: 0.00031955106533132493\n","          model: {}\n","          policy_loss: -0.005058249458670616\n","          total_loss: 2780.56982421875\n","          vf_explained_var: 0.6347092986106873\n","          vf_loss: 2780.572998046875\n","    num_agent_steps_sampled: 216000\n","    num_agent_steps_trained: 216000\n","    num_steps_sampled: 216000\n","    num_steps_trained: 216000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 54\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.6\n","    ram_util_percent: 15.963636363636363\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06992855119771864\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.25451263204431074\n","    mean_inference_ms: 0.7175377292132233\n","    mean_raw_obs_processing_ms: 0.11245225055536194\n","  time_since_restore: 391.2911276817322\n","  time_this_iter_s: 7.979083299636841\n","  time_total_s: 391.2911276817322\n","  timers:\n","    learn_throughput: 1572.457\n","    learn_time_ms: 2543.791\n","    load_throughput: 9099260.223\n","    load_time_ms: 0.44\n","    sample_throughput: 534.746\n","    sample_time_ms: 7480.187\n","    update_time_ms: 2.785\n","  timestamp: 1649863485\n","  timesteps_since_restore: 216000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 216000\n","  training_iteration: 54\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:24:48 (running for 00:06:58.35)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         391.291</td><td style=\"text-align: right;\">216000</td><td style=\"text-align: right;\">-344.658 </td><td style=\"text-align: right;\">             15.0102</td><td style=\"text-align: right;\">            -629.304</td><td style=\"text-align: right;\">            108.9 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         388.633</td><td style=\"text-align: right;\">148000</td><td style=\"text-align: right;\">  16.6964</td><td style=\"text-align: right;\">            130.795 </td><td style=\"text-align: right;\">            -310.678</td><td style=\"text-align: right;\">            501.08</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         383.085</td><td style=\"text-align: right;\">168000</td><td style=\"text-align: right;\"> 245.901 </td><td style=\"text-align: right;\">            303.227 </td><td style=\"text-align: right;\">            -112.242</td><td style=\"text-align: right;\">            309.46</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 220000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-24-52\n","  done: false\n","  episode_len_mean: 113.93\n","  episode_media: {}\n","  episode_reward_max: 2.358200854018122\n","  episode_reward_mean: -346.40553807718226\n","  episode_reward_min: -651.9356566436918\n","  episodes_this_iter: 36\n","  episodes_total: 2151\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 2.6333000659942627\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.8010458946228027\n","          entropy_coeff: 0.0\n","          kl: 0.0009846467291936278\n","          model: {}\n","          policy_loss: -0.00305699510499835\n","          total_loss: 1145.7840576171875\n","          vf_explained_var: 0.8770015835762024\n","          vf_loss: 1145.784423828125\n","    num_agent_steps_sampled: 220000\n","    num_agent_steps_trained: 220000\n","    num_steps_sampled: 220000\n","    num_steps_trained: 220000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 55\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.390909090909092\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06996798422256868\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2552850192706821\n","    mean_inference_ms: 0.7183850657359931\n","    mean_raw_obs_processing_ms: 0.11250613114863568\n","  time_since_restore: 398.62985706329346\n","  time_this_iter_s: 7.338729381561279\n","  time_total_s: 398.62985706329346\n","  timers:\n","    learn_throughput: 1558.82\n","    learn_time_ms: 2566.044\n","    load_throughput: 9063376.371\n","    load_time_ms: 0.441\n","    sample_throughput: 535.087\n","    sample_time_ms: 7475.419\n","    update_time_ms: 2.799\n","  timestamp: 1649863492\n","  timesteps_since_restore: 220000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 220000\n","  training_iteration: 55\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 172000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-24-52\n","  done: false\n","  episode_len_mean: 308.22\n","  episode_media: {}\n","  episode_reward_max: 303.226586714449\n","  episode_reward_mean: 246.7673278411322\n","  episode_reward_min: -182.10200189807384\n","  episodes_this_iter: 13\n","  episodes_total: 711\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.11249999701976776\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7692151665687561\n","          entropy_coeff: 0.0\n","          kl: 0.010948017239570618\n","          model: {}\n","          policy_loss: -0.018889345228672028\n","          total_loss: 737.0676879882812\n","          vf_explained_var: 0.14392827451229095\n","          vf_loss: 737.0853271484375\n","    num_agent_steps_sampled: 172000\n","    num_agent_steps_trained: 172000\n","    num_steps_sampled: 172000\n","    num_steps_trained: 172000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 43\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.700000000000001\n","    ram_util_percent: 15.599999999999998\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07474077597517581\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6876858669292116\n","    mean_inference_ms: 0.7581722089678613\n","    mean_raw_obs_processing_ms: 0.11284780437721391\n","  time_since_restore: 391.9921684265137\n","  time_this_iter_s: 8.907423257827759\n","  time_total_s: 391.9921684265137\n","  timers:\n","    learn_throughput: 1598.315\n","    learn_time_ms: 2502.636\n","    load_throughput: 8243927.08\n","    load_time_ms: 0.485\n","    sample_throughput: 447.622\n","    sample_time_ms: 8936.105\n","    update_time_ms: 2.807\n","  timestamp: 1649863492\n","  timesteps_since_restore: 172000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 172000\n","  training_iteration: 43\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:24:53 (running for 00:07:03.77)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         398.63 </td><td style=\"text-align: right;\">220000</td><td style=\"text-align: right;\">-346.406 </td><td style=\"text-align: right;\">              2.3582</td><td style=\"text-align: right;\">            -651.936</td><td style=\"text-align: right;\">            113.93</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         388.633</td><td style=\"text-align: right;\">148000</td><td style=\"text-align: right;\">  16.6964</td><td style=\"text-align: right;\">            130.795 </td><td style=\"text-align: right;\">            -310.678</td><td style=\"text-align: right;\">            501.08</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         391.992</td><td style=\"text-align: right;\">172000</td><td style=\"text-align: right;\"> 246.767 </td><td style=\"text-align: right;\">            303.227 </td><td style=\"text-align: right;\">            -182.102</td><td style=\"text-align: right;\">            308.22</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 152000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-24-53\n","  done: false\n","  episode_len_mean: 474.48\n","  episode_media: {}\n","  episode_reward_max: 130.79490068827636\n","  episode_reward_mean: 20.53300625246457\n","  episode_reward_min: -276.85648672758646\n","  episodes_this_iter: 11\n","  episodes_total: 602\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.0651696920394897\n","          entropy_coeff: 0.0\n","          kl: 0.012668628245592117\n","          model: {}\n","          policy_loss: -0.04593062028288841\n","          total_loss: 168.4276885986328\n","          vf_explained_var: 0.849208652973175\n","          vf_loss: 168.46078491210938\n","    num_agent_steps_sampled: 152000\n","    num_agent_steps_trained: 152000\n","    num_steps_sampled: 152000\n","    num_steps_trained: 152000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 38\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.576470588235296\n","    ram_util_percent: 15.6\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07295899949757371\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.0155819455764226\n","    mean_inference_ms: 0.7531271648193684\n","    mean_raw_obs_processing_ms: 0.11148686191564604\n","  time_since_restore: 400.32179832458496\n","  time_this_iter_s: 11.689042806625366\n","  time_total_s: 400.32179832458496\n","  timers:\n","    learn_throughput: 1585.32\n","    learn_time_ms: 2523.149\n","    load_throughput: 10015650.409\n","    load_time_ms: 0.399\n","    sample_throughput: 347.597\n","    sample_time_ms: 11507.578\n","    update_time_ms: 2.852\n","  timestamp: 1649863493\n","  timesteps_since_restore: 152000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 152000\n","  training_iteration: 38\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:24:58 (running for 00:07:09.00)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         398.63 </td><td style=\"text-align: right;\">220000</td><td style=\"text-align: right;\">-346.406</td><td style=\"text-align: right;\">              2.3582</td><td style=\"text-align: right;\">            -651.936</td><td style=\"text-align: right;\">            113.93</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         400.322</td><td style=\"text-align: right;\">152000</td><td style=\"text-align: right;\">  20.533</td><td style=\"text-align: right;\">            130.795 </td><td style=\"text-align: right;\">            -276.856</td><td style=\"text-align: right;\">            474.48</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         391.992</td><td style=\"text-align: right;\">172000</td><td style=\"text-align: right;\"> 246.767</td><td style=\"text-align: right;\">            303.227 </td><td style=\"text-align: right;\">            -182.102</td><td style=\"text-align: right;\">            308.22</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 224000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-24-59\n","  done: false\n","  episode_len_mean: 107.42\n","  episode_media: {}\n","  episode_reward_max: 2.358200854018122\n","  episode_reward_mean: -362.1854163653625\n","  episode_reward_min: -651.9356566436918\n","  episodes_this_iter: 38\n","  episodes_total: 2189\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.3166500329971313\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.780267596244812\n","          entropy_coeff: 0.0\n","          kl: 0.0030358191579580307\n","          model: {}\n","          policy_loss: -0.0057968138717114925\n","          total_loss: 1664.5474853515625\n","          vf_explained_var: 0.7652232646942139\n","          vf_loss: 1664.5491943359375\n","    num_agent_steps_sampled: 224000\n","    num_agent_steps_trained: 224000\n","    num_steps_sampled: 224000\n","    num_steps_trained: 224000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 56\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 11.65\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06997115585979065\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.25573319471714046\n","    mean_inference_ms: 0.7187660794125249\n","    mean_raw_obs_processing_ms: 0.11251134076906029\n","  time_since_restore: 405.8215596675873\n","  time_this_iter_s: 7.191702604293823\n","  time_total_s: 405.8215596675873\n","  timers:\n","    learn_throughput: 1559.406\n","    learn_time_ms: 2565.08\n","    load_throughput: 9106174.555\n","    load_time_ms: 0.439\n","    sample_throughput: 534.385\n","    sample_time_ms: 7485.245\n","    update_time_ms: 2.818\n","  timestamp: 1649863499\n","  timesteps_since_restore: 224000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 224000\n","  training_iteration: 56\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 176000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-25-01\n","  done: false\n","  episode_len_mean: 300.98\n","  episode_media: {}\n","  episode_reward_max: 303.226586714449\n","  episode_reward_mean: 238.96460040473926\n","  episode_reward_min: -182.10200189807384\n","  episodes_this_iter: 11\n","  episodes_total: 722\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.11249999701976776\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7313551306724548\n","          entropy_coeff: 0.0\n","          kl: 0.01277872547507286\n","          model: {}\n","          policy_loss: -0.013570224866271019\n","          total_loss: 2001.281982421875\n","          vf_explained_var: 0.07480412721633911\n","          vf_loss: 2001.2940673828125\n","    num_agent_steps_sampled: 176000\n","    num_agent_steps_trained: 176000\n","    num_steps_sampled: 176000\n","    num_steps_trained: 176000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 44\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.646153846153847\n","    ram_util_percent: 15.599999999999998\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07475258535776325\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6862523939365843\n","    mean_inference_ms: 0.7585645713231298\n","    mean_raw_obs_processing_ms: 0.11286033602741365\n","  time_since_restore: 401.2367613315582\n","  time_this_iter_s: 9.244592905044556\n","  time_total_s: 401.2367613315582\n","  timers:\n","    learn_throughput: 1594.083\n","    learn_time_ms: 2509.279\n","    load_throughput: 8472485.608\n","    load_time_ms: 0.472\n","    sample_throughput: 441.931\n","    sample_time_ms: 9051.189\n","    update_time_ms: 2.819\n","  timestamp: 1649863501\n","  timesteps_since_restore: 176000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 176000\n","  training_iteration: 44\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 156000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-25-03\n","  done: false\n","  episode_len_mean: 411.3\n","  episode_media: {}\n","  episode_reward_max: 116.77492878829075\n","  episode_reward_mean: 11.999363559581504\n","  episode_reward_min: -306.6053059002911\n","  episodes_this_iter: 14\n","  episodes_total: 616\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.0398192405700684\n","          entropy_coeff: 0.0\n","          kl: 0.01563991792500019\n","          model: {}\n","          policy_loss: -0.03369565308094025\n","          total_loss: 1133.0430908203125\n","          vf_explained_var: 0.7374829649925232\n","          vf_loss: 1133.06103515625\n","    num_agent_steps_sampled: 156000\n","    num_agent_steps_trained: 156000\n","    num_steps_sampled: 156000\n","    num_steps_trained: 156000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 39\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.757142857142856\n","    ram_util_percent: 15.599999999999998\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07302423665622068\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.0266853733872296\n","    mean_inference_ms: 0.7542370947448975\n","    mean_raw_obs_processing_ms: 0.11154091845138872\n","  time_since_restore: 410.32740569114685\n","  time_this_iter_s: 10.00560736656189\n","  time_total_s: 410.32740569114685\n","  timers:\n","    learn_throughput: 1584.647\n","    learn_time_ms: 2524.221\n","    load_throughput: 9787769.675\n","    load_time_ms: 0.409\n","    sample_throughput: 352.976\n","    sample_time_ms: 11332.223\n","    update_time_ms: 2.85\n","  timestamp: 1649863503\n","  timesteps_since_restore: 156000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 156000\n","  training_iteration: 39\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:25:04 (running for 00:07:14.97)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         405.822</td><td style=\"text-align: right;\">224000</td><td style=\"text-align: right;\">-362.185 </td><td style=\"text-align: right;\">              2.3582</td><td style=\"text-align: right;\">            -651.936</td><td style=\"text-align: right;\">            107.42</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         410.327</td><td style=\"text-align: right;\">156000</td><td style=\"text-align: right;\">  11.9994</td><td style=\"text-align: right;\">            116.775 </td><td style=\"text-align: right;\">            -306.605</td><td style=\"text-align: right;\">            411.3 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         401.237</td><td style=\"text-align: right;\">176000</td><td style=\"text-align: right;\"> 238.965 </td><td style=\"text-align: right;\">            303.227 </td><td style=\"text-align: right;\">            -182.102</td><td style=\"text-align: right;\">            300.98</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 228000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-25-07\n","  done: false\n","  episode_len_mean: 107.17\n","  episode_media: {}\n","  episode_reward_max: 13.521081726501635\n","  episode_reward_mean: -351.87861543810004\n","  episode_reward_min: -651.9356566436918\n","  episodes_this_iter: 37\n","  episodes_total: 2226\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.6583250164985657\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.793027400970459\n","          entropy_coeff: 0.0\n","          kl: 0.009126927703619003\n","          model: {}\n","          policy_loss: -0.01357594970613718\n","          total_loss: 1725.8829345703125\n","          vf_explained_var: 0.7639666795730591\n","          vf_loss: 1725.890380859375\n","    num_agent_steps_sampled: 228000\n","    num_agent_steps_trained: 228000\n","    num_steps_sampled: 228000\n","    num_steps_trained: 228000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 57\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.20909090909091\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.06998943621822358\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.25588914349350506\n","    mean_inference_ms: 0.7189783982436779\n","    mean_raw_obs_processing_ms: 0.11252623213934725\n","  time_since_restore: 413.31020617485046\n","  time_this_iter_s: 7.488646507263184\n","  time_total_s: 413.31020617485046\n","  timers:\n","    learn_throughput: 1560.61\n","    learn_time_ms: 2563.1\n","    load_throughput: 9334677.572\n","    load_time_ms: 0.429\n","    sample_throughput: 532.203\n","    sample_time_ms: 7515.931\n","    update_time_ms: 2.818\n","  timestamp: 1649863507\n","  timesteps_since_restore: 228000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 228000\n","  training_iteration: 57\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:25:10 (running for 00:07:20.50)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         413.31 </td><td style=\"text-align: right;\">228000</td><td style=\"text-align: right;\">-351.879 </td><td style=\"text-align: right;\">             13.5211</td><td style=\"text-align: right;\">            -651.936</td><td style=\"text-align: right;\">            107.17</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         410.327</td><td style=\"text-align: right;\">156000</td><td style=\"text-align: right;\">  11.9994</td><td style=\"text-align: right;\">            116.775 </td><td style=\"text-align: right;\">            -306.605</td><td style=\"text-align: right;\">            411.3 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         401.237</td><td style=\"text-align: right;\">176000</td><td style=\"text-align: right;\"> 238.965 </td><td style=\"text-align: right;\">            303.227 </td><td style=\"text-align: right;\">            -182.102</td><td style=\"text-align: right;\">            300.98</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 180000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-25-10\n","  done: false\n","  episode_len_mean: 305.57\n","  episode_media: {}\n","  episode_reward_max: 303.226586714449\n","  episode_reward_mean: 236.48506786096016\n","  episode_reward_min: -182.10200189807384\n","  episodes_this_iter: 11\n","  episodes_total: 733\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.11249999701976776\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7097265124320984\n","          entropy_coeff: 0.0\n","          kl: 0.0077610919252038\n","          model: {}\n","          policy_loss: -0.008589335717260838\n","          total_loss: 830.9075317382812\n","          vf_explained_var: -0.0959099531173706\n","          vf_loss: 830.915283203125\n","    num_agent_steps_sampled: 180000\n","    num_agent_steps_trained: 180000\n","    num_steps_sampled: 180000\n","    num_steps_trained: 180000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 45\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.223076923076926\n","    ram_util_percent: 15.599999999999998\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07476729964068381\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6848807287713027\n","    mean_inference_ms: 0.7589632835289716\n","    mean_raw_obs_processing_ms: 0.11287898098379852\n","  time_since_restore: 410.24791169166565\n","  time_this_iter_s: 9.011150360107422\n","  time_total_s: 410.24791169166565\n","  timers:\n","    learn_throughput: 1596.225\n","    learn_time_ms: 2505.912\n","    load_throughput: 8472485.608\n","    load_time_ms: 0.472\n","    sample_throughput: 442.779\n","    sample_time_ms: 9033.843\n","    update_time_ms: 2.82\n","  timestamp: 1649863510\n","  timesteps_since_restore: 180000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 180000\n","  training_iteration: 45\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 160000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-25-13\n","  done: false\n","  episode_len_mean: 367.19\n","  episode_media: {}\n","  episode_reward_max: 110.10328188255576\n","  episode_reward_mean: 7.158674876211432\n","  episode_reward_min: -306.6053059002911\n","  episodes_this_iter: 13\n","  episodes_total: 629\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.0432218313217163\n","          entropy_coeff: 0.0\n","          kl: 0.012601272203028202\n","          model: {}\n","          policy_loss: -0.043053366243839264\n","          total_loss: 287.0272216796875\n","          vf_explained_var: 0.75841224193573\n","          vf_loss: 287.0575256347656\n","    num_agent_steps_sampled: 160000\n","    num_agent_steps_trained: 160000\n","    num_steps_sampled: 160000\n","    num_steps_trained: 160000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 40\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.464285714285712\n","    ram_util_percent: 15.599999999999998\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0730722889566324\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.0322762069613853\n","    mean_inference_ms: 0.7550295261159147\n","    mean_raw_obs_processing_ms: 0.11158724930832896\n","  time_since_restore: 420.0890407562256\n","  time_this_iter_s: 9.761635065078735\n","  time_total_s: 420.0890407562256\n","  timers:\n","    learn_throughput: 1589.007\n","    learn_time_ms: 2517.295\n","    load_throughput: 9670422.503\n","    load_time_ms: 0.414\n","    sample_throughput: 358.077\n","    sample_time_ms: 11170.793\n","    update_time_ms: 2.823\n","  timestamp: 1649863513\n","  timesteps_since_restore: 160000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 160000\n","  training_iteration: 40\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 232000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-25-14\n","  done: false\n","  episode_len_mean: 105.81\n","  episode_media: {}\n","  episode_reward_max: 13.521081726501635\n","  episode_reward_mean: -295.4760961307682\n","  episode_reward_min: -638.3743449141118\n","  episodes_this_iter: 37\n","  episodes_total: 2263\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.6583250164985657\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7819634079933167\n","          entropy_coeff: 0.0\n","          kl: 0.006425774656236172\n","          model: {}\n","          policy_loss: 0.005507256835699081\n","          total_loss: 1757.9827880859375\n","          vf_explained_var: 0.6337240934371948\n","          vf_loss: 1757.9730224609375\n","    num_agent_steps_sampled: 232000\n","    num_agent_steps_trained: 232000\n","    num_steps_sampled: 232000\n","    num_steps_trained: 232000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 58\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.329999999999998\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07004165878878439\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.25601869236311886\n","    mean_inference_ms: 0.7195913309648438\n","    mean_raw_obs_processing_ms: 0.11257375539317001\n","  time_since_restore: 420.7905056476593\n","  time_this_iter_s: 7.480299472808838\n","  time_total_s: 420.7905056476593\n","  timers:\n","    learn_throughput: 1566.669\n","    learn_time_ms: 2553.188\n","    load_throughput: 9164372.098\n","    load_time_ms: 0.436\n","    sample_throughput: 531.068\n","    sample_time_ms: 7531.994\n","    update_time_ms: 2.83\n","  timestamp: 1649863514\n","  timesteps_since_restore: 232000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 232000\n","  training_iteration: 58\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:25:15 (running for 00:07:25.94)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         420.791</td><td style=\"text-align: right;\">232000</td><td style=\"text-align: right;\">-295.476  </td><td style=\"text-align: right;\">             13.5211</td><td style=\"text-align: right;\">            -638.374</td><td style=\"text-align: right;\">            105.81</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         420.089</td><td style=\"text-align: right;\">160000</td><td style=\"text-align: right;\">   7.15867</td><td style=\"text-align: right;\">            110.103 </td><td style=\"text-align: right;\">            -306.605</td><td style=\"text-align: right;\">            367.19</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         410.248</td><td style=\"text-align: right;\">180000</td><td style=\"text-align: right;\"> 236.485  </td><td style=\"text-align: right;\">            303.227 </td><td style=\"text-align: right;\">            -182.102</td><td style=\"text-align: right;\">            305.57</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 184000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-25-19\n","  done: false\n","  episode_len_mean: 310.37\n","  episode_media: {}\n","  episode_reward_max: 303.226586714449\n","  episode_reward_mean: 236.75295305969013\n","  episode_reward_min: -182.10200189807384\n","  episodes_this_iter: 12\n","  episodes_total: 745\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.11249999701976776\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6321465373039246\n","          entropy_coeff: 0.0\n","          kl: 0.0058565507642924786\n","          model: {}\n","          policy_loss: -0.011290316469967365\n","          total_loss: 363.86767578125\n","          vf_explained_var: -0.10331076383590698\n","          vf_loss: 363.87835693359375\n","    num_agent_steps_sampled: 184000\n","    num_agent_steps_trained: 184000\n","    num_steps_sampled: 184000\n","    num_steps_trained: 184000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 46\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.415384615384616\n","    ram_util_percent: 15.599999999999998\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07478788426430728\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6835928079592131\n","    mean_inference_ms: 0.759401295112823\n","    mean_raw_obs_processing_ms: 0.11290733514559861\n","  time_since_restore: 419.1461853981018\n","  time_this_iter_s: 8.898273706436157\n","  time_total_s: 419.1461853981018\n","  timers:\n","    learn_throughput: 1594.289\n","    learn_time_ms: 2508.955\n","    load_throughput: 8452423.8\n","    load_time_ms: 0.473\n","    sample_throughput: 444.348\n","    sample_time_ms: 9001.961\n","    update_time_ms: 2.776\n","  timestamp: 1649863519\n","  timesteps_since_restore: 184000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 184000\n","  training_iteration: 46\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:25:20 (running for 00:07:31.05)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         420.791</td><td style=\"text-align: right;\">232000</td><td style=\"text-align: right;\">-295.476  </td><td style=\"text-align: right;\">             13.5211</td><td style=\"text-align: right;\">            -638.374</td><td style=\"text-align: right;\">            105.81</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         420.089</td><td style=\"text-align: right;\">160000</td><td style=\"text-align: right;\">   7.15867</td><td style=\"text-align: right;\">            110.103 </td><td style=\"text-align: right;\">            -306.605</td><td style=\"text-align: right;\">            367.19</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         419.146</td><td style=\"text-align: right;\">184000</td><td style=\"text-align: right;\"> 236.753  </td><td style=\"text-align: right;\">            303.227 </td><td style=\"text-align: right;\">            -182.102</td><td style=\"text-align: right;\">            310.37</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 236000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-25-22\n","  done: false\n","  episode_len_mean: 107.05\n","  episode_media: {}\n","  episode_reward_max: 9.040767828163297\n","  episode_reward_mean: -256.6032270610198\n","  episode_reward_min: -638.3743449141118\n","  episodes_this_iter: 38\n","  episodes_total: 2301\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.6583250164985657\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7603204250335693\n","          entropy_coeff: 0.0\n","          kl: 0.015450185164809227\n","          model: {}\n","          policy_loss: -0.014690093696117401\n","          total_loss: 775.4898071289062\n","          vf_explained_var: 0.683275043964386\n","          vf_loss: 775.4942016601562\n","    num_agent_steps_sampled: 236000\n","    num_agent_steps_trained: 236000\n","    num_steps_sampled: 236000\n","    num_steps_trained: 236000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 59\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.518181818181818\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07009977532403133\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.25608571535275904\n","    mean_inference_ms: 0.7202647867268951\n","    mean_raw_obs_processing_ms: 0.11263201481924093\n","  time_since_restore: 428.0629003047943\n","  time_this_iter_s: 7.27239465713501\n","  time_total_s: 428.0629003047943\n","  timers:\n","    learn_throughput: 1576.908\n","    learn_time_ms: 2536.61\n","    load_throughput: 9039448.276\n","    load_time_ms: 0.443\n","    sample_throughput: 533.638\n","    sample_time_ms: 7495.721\n","    update_time_ms: 2.78\n","  timestamp: 1649863522\n","  timesteps_since_restore: 236000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 236000\n","  training_iteration: 59\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 164000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-25-25\n","  done: false\n","  episode_len_mean: 357.93\n","  episode_media: {}\n","  episode_reward_max: 148.0397968204181\n","  episode_reward_mean: 5.628586810348627\n","  episode_reward_min: -306.6053059002911\n","  episodes_this_iter: 8\n","  episodes_total: 637\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.04987370967865\n","          entropy_coeff: 0.0\n","          kl: 0.011778576299548149\n","          model: {}\n","          policy_loss: -0.04476076737046242\n","          total_loss: 367.2768249511719\n","          vf_explained_var: 0.7725824117660522\n","          vf_loss: 367.30963134765625\n","    num_agent_steps_sampled: 164000\n","    num_agent_steps_trained: 164000\n","    num_steps_sampled: 164000\n","    num_steps_trained: 164000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 41\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.923529411764704\n","    ram_util_percent: 15.6\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07310217230546219\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.0344826243222585\n","    mean_inference_ms: 0.7554539437423611\n","    mean_raw_obs_processing_ms: 0.11162260549018818\n","  time_since_restore: 431.8818459510803\n","  time_this_iter_s: 11.792805194854736\n","  time_total_s: 431.8818459510803\n","  timers:\n","    learn_throughput: 1588.025\n","    learn_time_ms: 2518.852\n","    load_throughput: 9497971.014\n","    load_time_ms: 0.421\n","    sample_throughput: 359.583\n","    sample_time_ms: 11124.003\n","    update_time_ms: 2.848\n","  timestamp: 1649863525\n","  timesteps_since_restore: 164000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 164000\n","  training_iteration: 41\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:25:26 (running for 00:07:36.60)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         428.063</td><td style=\"text-align: right;\">236000</td><td style=\"text-align: right;\">-256.603  </td><td style=\"text-align: right;\">             9.04077</td><td style=\"text-align: right;\">            -638.374</td><td style=\"text-align: right;\">            107.05</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         431.882</td><td style=\"text-align: right;\">164000</td><td style=\"text-align: right;\">   5.62859</td><td style=\"text-align: right;\">           148.04   </td><td style=\"text-align: right;\">            -306.605</td><td style=\"text-align: right;\">            357.93</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         419.146</td><td style=\"text-align: right;\">184000</td><td style=\"text-align: right;\"> 236.753  </td><td style=\"text-align: right;\">           303.227  </td><td style=\"text-align: right;\">            -182.102</td><td style=\"text-align: right;\">            310.37</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 188000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-25-29\n","  done: false\n","  episode_len_mean: 319.64\n","  episode_media: {}\n","  episode_reward_max: 300.00698366074954\n","  episode_reward_mean: 232.044052037154\n","  episode_reward_min: -182.10200189807384\n","  episodes_this_iter: 11\n","  episodes_total: 756\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.11249999701976776\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6683654189109802\n","          entropy_coeff: 0.0\n","          kl: 0.013733585365116596\n","          model: {}\n","          policy_loss: -0.011280575767159462\n","          total_loss: 552.56689453125\n","          vf_explained_var: -0.10063036531209946\n","          vf_loss: 552.5765991210938\n","    num_agent_steps_sampled: 188000\n","    num_agent_steps_trained: 188000\n","    num_steps_sampled: 188000\n","    num_steps_trained: 188000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 47\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.215384615384616\n","    ram_util_percent: 15.599999999999998\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07480448933238713\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6828516738939738\n","    mean_inference_ms: 0.7597946221075154\n","    mean_raw_obs_processing_ms: 0.11292690928334703\n","  time_since_restore: 428.51051592826843\n","  time_this_iter_s: 9.364330530166626\n","  time_total_s: 428.51051592826843\n","  timers:\n","    learn_throughput: 1599.958\n","    learn_time_ms: 2500.066\n","    load_throughput: 8357268.244\n","    load_time_ms: 0.479\n","    sample_throughput: 443.618\n","    sample_time_ms: 9016.775\n","    update_time_ms: 2.745\n","  timestamp: 1649863529\n","  timesteps_since_restore: 188000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 188000\n","  training_iteration: 47\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 240000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-25-29\n","  done: false\n","  episode_len_mean: 111.73\n","  episode_media: {}\n","  episode_reward_max: 9.040767828163297\n","  episode_reward_mean: -236.99561087223555\n","  episode_reward_min: -583.8145957019158\n","  episodes_this_iter: 34\n","  episodes_total: 2335\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.6583250164985657\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.7125900983810425\n","          entropy_coeff: 0.0\n","          kl: 0.019228186458349228\n","          model: {}\n","          policy_loss: -0.00607497151941061\n","          total_loss: 1517.69189453125\n","          vf_explained_var: 0.5476670861244202\n","          vf_loss: 1517.685302734375\n","    num_agent_steps_sampled: 240000\n","    num_agent_steps_trained: 240000\n","    num_steps_sampled: 240000\n","    num_steps_trained: 240000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 60\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.454545454545455\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07013660691517938\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2561801376566193\n","    mean_inference_ms: 0.7207196848704346\n","    mean_raw_obs_processing_ms: 0.11267233182547692\n","  time_since_restore: 435.55444860458374\n","  time_this_iter_s: 7.491548299789429\n","  time_total_s: 435.55444860458374\n","  timers:\n","    learn_throughput: 1574.749\n","    learn_time_ms: 2540.087\n","    load_throughput: 8832438.01\n","    load_time_ms: 0.453\n","    sample_throughput: 533.681\n","    sample_time_ms: 7495.117\n","    update_time_ms: 2.778\n","  timestamp: 1649863529\n","  timesteps_since_restore: 240000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 240000\n","  training_iteration: 60\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:25:31 (running for 00:07:41.79)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         435.554</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">-236.996  </td><td style=\"text-align: right;\">             9.04077</td><td style=\"text-align: right;\">            -583.815</td><td style=\"text-align: right;\">            111.73</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         431.882</td><td style=\"text-align: right;\">164000</td><td style=\"text-align: right;\">   5.62859</td><td style=\"text-align: right;\">           148.04   </td><td style=\"text-align: right;\">            -306.605</td><td style=\"text-align: right;\">            357.93</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         428.511</td><td style=\"text-align: right;\">188000</td><td style=\"text-align: right;\"> 232.044  </td><td style=\"text-align: right;\">           300.007  </td><td style=\"text-align: right;\">            -182.102</td><td style=\"text-align: right;\">            319.64</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 168000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-25-35\n","  done: false\n","  episode_len_mean: 333.3\n","  episode_media: {}\n","  episode_reward_max: 148.0397968204181\n","  episode_reward_mean: -0.9243647092197462\n","  episode_reward_min: -306.6053059002911\n","  episodes_this_iter: 12\n","  episodes_total: 649\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.024869441986084\n","          entropy_coeff: 0.0\n","          kl: 0.013505254872143269\n","          model: {}\n","          policy_loss: -0.03962022438645363\n","          total_loss: 574.2454223632812\n","          vf_explained_var: 0.7576698660850525\n","          vf_loss: 574.271240234375\n","    num_agent_steps_sampled: 168000\n","    num_agent_steps_trained: 168000\n","    num_steps_sampled: 168000\n","    num_steps_trained: 168000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 42\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.633333333333333\n","    ram_util_percent: 15.599999999999998\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07314459859570378\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.0361024392662386\n","    mean_inference_ms: 0.7559582975221527\n","    mean_raw_obs_processing_ms: 0.11167605473843704\n","  time_since_restore: 442.1969692707062\n","  time_this_iter_s: 10.315123319625854\n","  time_total_s: 442.1969692707062\n","  timers:\n","    learn_throughput: 1582.946\n","    learn_time_ms: 2526.934\n","    load_throughput: 9516288.145\n","    load_time_ms: 0.42\n","    sample_throughput: 364.485\n","    sample_time_ms: 10974.377\n","    update_time_ms: 2.959\n","  timestamp: 1649863535\n","  timesteps_since_restore: 168000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 168000\n","  training_iteration: 42\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:25:36 (running for 00:07:46.97)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         435.554</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">-236.996   </td><td style=\"text-align: right;\">             9.04077</td><td style=\"text-align: right;\">            -583.815</td><td style=\"text-align: right;\">            111.73</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         442.197</td><td style=\"text-align: right;\">168000</td><td style=\"text-align: right;\">  -0.924365</td><td style=\"text-align: right;\">           148.04   </td><td style=\"text-align: right;\">            -306.605</td><td style=\"text-align: right;\">            333.3 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         428.511</td><td style=\"text-align: right;\">188000</td><td style=\"text-align: right;\"> 232.044   </td><td style=\"text-align: right;\">           300.007  </td><td style=\"text-align: right;\">            -182.102</td><td style=\"text-align: right;\">            319.64</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 244000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-25-37\n","  done: false\n","  episode_len_mean: 116.44\n","  episode_media: {}\n","  episode_reward_max: 12.847226906836639\n","  episode_reward_mean: -221.94167076555698\n","  episode_reward_min: -583.8145957019158\n","  episodes_this_iter: 32\n","  episodes_total: 2367\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.6583250164985657\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.707545280456543\n","          entropy_coeff: 0.0\n","          kl: 0.024005785584449768\n","          model: {}\n","          policy_loss: -0.010213693603873253\n","          total_loss: 1734.787353515625\n","          vf_explained_var: 0.6263855695724487\n","          vf_loss: 1734.78173828125\n","    num_agent_steps_sampled: 244000\n","    num_agent_steps_trained: 244000\n","    num_steps_sampled: 244000\n","    num_steps_trained: 244000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 61\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.23\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07016487852241009\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.25630064439143396\n","    mean_inference_ms: 0.7210777462953587\n","    mean_raw_obs_processing_ms: 0.11270782326284108\n","  time_since_restore: 443.1198170185089\n","  time_this_iter_s: 7.565368413925171\n","  time_total_s: 443.1198170185089\n","  timers:\n","    learn_throughput: 1565.589\n","    learn_time_ms: 2554.948\n","    load_throughput: 8984264.753\n","    load_time_ms: 0.445\n","    sample_throughput: 533.512\n","    sample_time_ms: 7497.487\n","    update_time_ms: 2.785\n","  timestamp: 1649863537\n","  timesteps_since_restore: 244000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 244000\n","  training_iteration: 61\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 192000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-25-37\n","  done: false\n","  episode_len_mean: 319.98\n","  episode_media: {}\n","  episode_reward_max: 305.17021650506695\n","  episode_reward_mean: 234.03664842679885\n","  episode_reward_min: -182.10200189807384\n","  episodes_this_iter: 15\n","  episodes_total: 771\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.11249999701976776\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7192524671554565\n","          entropy_coeff: 0.0\n","          kl: 0.0103281419724226\n","          model: {}\n","          policy_loss: -0.01797797530889511\n","          total_loss: 248.42327880859375\n","          vf_explained_var: 0.0151902437210083\n","          vf_loss: 248.4401092529297\n","    num_agent_steps_sampled: 192000\n","    num_agent_steps_trained: 192000\n","    num_steps_sampled: 192000\n","    num_steps_trained: 192000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 48\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.253846153846153\n","    ram_util_percent: 15.599999999999998\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.074823906319104\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6819682062344243\n","    mean_inference_ms: 0.7602909866524514\n","    mean_raw_obs_processing_ms: 0.11294955309237421\n","  time_since_restore: 437.215451002121\n","  time_this_iter_s: 8.704935073852539\n","  time_total_s: 437.215451002121\n","  timers:\n","    learn_throughput: 1602.367\n","    learn_time_ms: 2496.307\n","    load_throughput: 8265452.754\n","    load_time_ms: 0.484\n","    sample_throughput: 444.497\n","    sample_time_ms: 8998.932\n","    update_time_ms: 2.725\n","  timestamp: 1649863537\n","  timesteps_since_restore: 192000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 192000\n","  training_iteration: 48\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:25:42 (running for 00:07:52.28)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         443.12 </td><td style=\"text-align: right;\">244000</td><td style=\"text-align: right;\">-221.942   </td><td style=\"text-align: right;\">             12.8472</td><td style=\"text-align: right;\">            -583.815</td><td style=\"text-align: right;\">            116.44</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         442.197</td><td style=\"text-align: right;\">168000</td><td style=\"text-align: right;\">  -0.924365</td><td style=\"text-align: right;\">            148.04  </td><td style=\"text-align: right;\">            -306.605</td><td style=\"text-align: right;\">            333.3 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">         437.215</td><td style=\"text-align: right;\">192000</td><td style=\"text-align: right;\"> 234.037   </td><td style=\"text-align: right;\">            305.17  </td><td style=\"text-align: right;\">            -182.102</td><td style=\"text-align: right;\">            319.98</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 248000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-25-44\n","  done: false\n","  episode_len_mean: 126.81\n","  episode_media: {}\n","  episode_reward_max: 19.756654213254976\n","  episode_reward_mean: -223.32193114327754\n","  episode_reward_min: -633.6847172775346\n","  episodes_this_iter: 28\n","  episodes_total: 2395\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.9874875545501709\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.6687137484550476\n","          entropy_coeff: 0.0\n","          kl: 0.03596210107207298\n","          model: {}\n","          policy_loss: 0.005114846397191286\n","          total_loss: 2191.51953125\n","          vf_explained_var: 0.5587396025657654\n","          vf_loss: 2191.47900390625\n","    num_agent_steps_sampled: 248000\n","    num_agent_steps_trained: 248000\n","    num_steps_sampled: 248000\n","    num_steps_trained: 248000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 62\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 11.70909090909091\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0701804959329415\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2565839789589775\n","    mean_inference_ms: 0.7212025938550426\n","    mean_raw_obs_processing_ms: 0.11271580081508321\n","  time_since_restore: 450.3238546848297\n","  time_this_iter_s: 7.204037666320801\n","  time_total_s: 450.3238546848297\n","  timers:\n","    learn_throughput: 1570.589\n","    learn_time_ms: 2546.816\n","    load_throughput: 9022919.221\n","    load_time_ms: 0.443\n","    sample_throughput: 532.786\n","    sample_time_ms: 7507.702\n","    update_time_ms: 2.753\n","  timestamp: 1649863544\n","  timesteps_since_restore: 248000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 248000\n","  training_iteration: 62\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:25:47 (running for 00:07:57.64)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         450.324</td><td style=\"text-align: right;\">248000</td><td style=\"text-align: right;\">-223.322   </td><td style=\"text-align: right;\">             19.7567</td><td style=\"text-align: right;\">            -633.685</td><td style=\"text-align: right;\">            126.81</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         442.197</td><td style=\"text-align: right;\">168000</td><td style=\"text-align: right;\">  -0.924365</td><td style=\"text-align: right;\">            148.04  </td><td style=\"text-align: right;\">            -306.605</td><td style=\"text-align: right;\">            333.3 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">         437.215</td><td style=\"text-align: right;\">192000</td><td style=\"text-align: right;\"> 234.037   </td><td style=\"text-align: right;\">            305.17  </td><td style=\"text-align: right;\">            -182.102</td><td style=\"text-align: right;\">            319.98</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 196000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-25-47\n","  done: false\n","  episode_len_mean: 332.58\n","  episode_media: {}\n","  episode_reward_max: 305.17021650506695\n","  episode_reward_mean: 234.94458710486157\n","  episode_reward_min: -182.10200189807384\n","  episodes_this_iter: 10\n","  episodes_total: 781\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.11249999701976776\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7751395106315613\n","          entropy_coeff: 0.0\n","          kl: 0.02486162818968296\n","          model: {}\n","          policy_loss: -0.024482345208525658\n","          total_loss: 273.03961181640625\n","          vf_explained_var: -0.013138038106262684\n","          vf_loss: 273.061279296875\n","    num_agent_steps_sampled: 196000\n","    num_agent_steps_trained: 196000\n","    num_steps_sampled: 196000\n","    num_steps_trained: 196000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 49\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.5\n","    ram_util_percent: 15.599999999999998\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07483492823439147\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6819335022281433\n","    mean_inference_ms: 0.7605806538280604\n","    mean_raw_obs_processing_ms: 0.11295926517158687\n","  time_since_restore: 447.0746748447418\n","  time_this_iter_s: 9.85922384262085\n","  time_total_s: 447.0746748447418\n","  timers:\n","    learn_throughput: 1596.584\n","    learn_time_ms: 2505.348\n","    load_throughput: 8305552.475\n","    load_time_ms: 0.482\n","    sample_throughput: 438.781\n","    sample_time_ms: 9116.166\n","    update_time_ms: 2.755\n","  timestamp: 1649863547\n","  timesteps_since_restore: 196000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 196000\n","  training_iteration: 49\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 172000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-25-48\n","  done: false\n","  episode_len_mean: 350.37\n","  episode_media: {}\n","  episode_reward_max: 148.0397968204181\n","  episode_reward_mean: 2.0058931006055434\n","  episode_reward_min: -306.6053059002911\n","  episodes_this_iter: 7\n","  episodes_total: 656\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.0560892820358276\n","          entropy_coeff: 0.0\n","          kl: 0.009314366616308689\n","          model: {}\n","          policy_loss: -0.031246960163116455\n","          total_loss: 153.54864501953125\n","          vf_explained_var: 0.8262774348258972\n","          vf_loss: 153.57046508789062\n","    num_agent_steps_sampled: 172000\n","    num_agent_steps_trained: 172000\n","    num_steps_sampled: 172000\n","    num_steps_trained: 172000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 43\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.552941176470588\n","    ram_util_percent: 15.6\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07316960615400422\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.0374059778808133\n","    mean_inference_ms: 0.7562627150641862\n","    mean_raw_obs_processing_ms: 0.11171027999483268\n","  time_since_restore: 454.6207857131958\n","  time_this_iter_s: 12.423816442489624\n","  time_total_s: 454.6207857131958\n","  timers:\n","    learn_throughput: 1583.864\n","    learn_time_ms: 2525.47\n","    load_throughput: 9525473.23\n","    load_time_ms: 0.42\n","    sample_throughput: 362.368\n","    sample_time_ms: 11038.514\n","    update_time_ms: 2.903\n","  timestamp: 1649863548\n","  timesteps_since_restore: 172000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 172000\n","  training_iteration: 43\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 252000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-25-52\n","  done: false\n","  episode_len_mean: 137.49\n","  episode_media: {}\n","  episode_reward_max: 19.756654213254976\n","  episode_reward_mean: -258.4919005559466\n","  episode_reward_min: -633.6847172775346\n","  episodes_this_iter: 24\n","  episodes_total: 2419\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.4812313318252563\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.6718884110450745\n","          entropy_coeff: 0.0\n","          kl: 0.07336590439081192\n","          model: {}\n","          policy_loss: 0.01741735078394413\n","          total_loss: 2007.9613037109375\n","          vf_explained_var: 0.45900818705558777\n","          vf_loss: 2007.8353271484375\n","    num_agent_steps_sampled: 252000\n","    num_agent_steps_trained: 252000\n","    num_steps_sampled: 252000\n","    num_steps_trained: 252000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 63\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.93636363636364\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07020356552551522\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2572740794092383\n","    mean_inference_ms: 0.7214186283800109\n","    mean_raw_obs_processing_ms: 0.11272498723492991\n","  time_since_restore: 458.2950909137726\n","  time_this_iter_s: 7.971236228942871\n","  time_total_s: 458.2950909137726\n","  timers:\n","    learn_throughput: 1569.713\n","    learn_time_ms: 2548.236\n","    load_throughput: 9177908.096\n","    load_time_ms: 0.436\n","    sample_throughput: 530.614\n","    sample_time_ms: 7538.437\n","    update_time_ms: 2.785\n","  timestamp: 1649863552\n","  timesteps_since_restore: 252000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 252000\n","  training_iteration: 63\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:25:52 (running for 00:08:02.65)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         458.295</td><td style=\"text-align: right;\">252000</td><td style=\"text-align: right;\">-258.492  </td><td style=\"text-align: right;\">             19.7567</td><td style=\"text-align: right;\">            -633.685</td><td style=\"text-align: right;\">            137.49</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         454.621</td><td style=\"text-align: right;\">172000</td><td style=\"text-align: right;\">   2.00589</td><td style=\"text-align: right;\">            148.04  </td><td style=\"text-align: right;\">            -306.605</td><td style=\"text-align: right;\">            350.37</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         447.075</td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\"> 234.945  </td><td style=\"text-align: right;\">            305.17  </td><td style=\"text-align: right;\">            -182.102</td><td style=\"text-align: right;\">            332.58</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 200000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-25-56\n","  done: false\n","  episode_len_mean: 330.84\n","  episode_media: {}\n","  episode_reward_max: 305.17021650506695\n","  episode_reward_mean: 231.4108489058251\n","  episode_reward_min: -244.49379170565405\n","  episodes_this_iter: 13\n","  episodes_total: 794\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.16875000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7722976803779602\n","          entropy_coeff: 0.0\n","          kl: 0.015717187896370888\n","          model: {}\n","          policy_loss: -0.02065151184797287\n","          total_loss: 1647.0889892578125\n","          vf_explained_var: 0.07865498960018158\n","          vf_loss: 1647.10693359375\n","    num_agent_steps_sampled: 200000\n","    num_agent_steps_trained: 200000\n","    num_steps_sampled: 200000\n","    num_steps_trained: 200000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 50\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 11.825000000000001\n","    ram_util_percent: 15.6\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07484441235801985\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6816551336469269\n","    mean_inference_ms: 0.7607803312487857\n","    mean_raw_obs_processing_ms: 0.11295961814794774\n","  time_since_restore: 455.8516335487366\n","  time_this_iter_s: 8.776958703994751\n","  time_total_s: 455.8516335487366\n","  timers:\n","    learn_throughput: 1592.867\n","    learn_time_ms: 2511.195\n","    load_throughput: 8281773.127\n","    load_time_ms: 0.483\n","    sample_throughput: 437.43\n","    sample_time_ms: 9144.329\n","    update_time_ms: 2.78\n","  timestamp: 1649863556\n","  timesteps_since_restore: 200000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 200000\n","  training_iteration: 50\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:25:57 (running for 00:08:07.92)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         458.295</td><td style=\"text-align: right;\">252000</td><td style=\"text-align: right;\">-258.492  </td><td style=\"text-align: right;\">             19.7567</td><td style=\"text-align: right;\">            -633.685</td><td style=\"text-align: right;\">            137.49</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         454.621</td><td style=\"text-align: right;\">172000</td><td style=\"text-align: right;\">   2.00589</td><td style=\"text-align: right;\">            148.04  </td><td style=\"text-align: right;\">            -306.605</td><td style=\"text-align: right;\">            350.37</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         455.852</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> 231.411  </td><td style=\"text-align: right;\">            305.17  </td><td style=\"text-align: right;\">            -244.494</td><td style=\"text-align: right;\">            330.84</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 176000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-25-59\n","  done: false\n","  episode_len_mean: 367.49\n","  episode_media: {}\n","  episode_reward_max: 148.0397968204181\n","  episode_reward_mean: 4.07200931346027\n","  episode_reward_min: -306.6053059002911\n","  episodes_this_iter: 5\n","  episodes_total: 661\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.0080533027648926\n","          entropy_coeff: 0.0\n","          kl: 0.01058585662394762\n","          model: {}\n","          policy_loss: -0.03932444378733635\n","          total_loss: 226.37069702148438\n","          vf_explained_var: 0.7236596941947937\n","          vf_loss: 226.3992919921875\n","    num_agent_steps_sampled: 176000\n","    num_agent_steps_trained: 176000\n","    num_steps_sampled: 176000\n","    num_steps_trained: 176000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 44\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.88823529411765\n","    ram_util_percent: 15.6\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07318698088686001\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.038390729710323\n","    mean_inference_ms: 0.7564961377521968\n","    mean_raw_obs_processing_ms: 0.1117323733960077\n","  time_since_restore: 466.310307264328\n","  time_this_iter_s: 11.689521551132202\n","  time_total_s: 466.310307264328\n","  timers:\n","    learn_throughput: 1577.33\n","    learn_time_ms: 2535.931\n","    load_throughput: 9621618.398\n","    load_time_ms: 0.416\n","    sample_throughput: 361.519\n","    sample_time_ms: 11064.437\n","    update_time_ms: 2.891\n","  timestamp: 1649863559\n","  timesteps_since_restore: 176000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 176000\n","  training_iteration: 44\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 256000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-26-00\n","  done: false\n","  episode_len_mean: 146.77\n","  episode_media: {}\n","  episode_reward_max: 19.756654213254976\n","  episode_reward_mean: -331.22781849841544\n","  episode_reward_min: -906.5347198843524\n","  episodes_this_iter: 26\n","  episodes_total: 2445\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 2.22184681892395\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5345431566238403\n","          entropy_coeff: 0.0\n","          kl: 0.03367846831679344\n","          model: {}\n","          policy_loss: 0.017501356080174446\n","          total_loss: 6438.74609375\n","          vf_explained_var: 0.4786871671676636\n","          vf_loss: 6438.65380859375\n","    num_agent_steps_sampled: 256000\n","    num_agent_steps_trained: 256000\n","    num_steps_sampled: 256000\n","    num_steps_trained: 256000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 64\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.566666666666668\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07023956217175364\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.258478354552003\n","    mean_inference_ms: 0.7218195096668387\n","    mean_raw_obs_processing_ms: 0.11273721285134516\n","  time_since_restore: 466.4040639400482\n","  time_this_iter_s: 8.108973026275635\n","  time_total_s: 466.4040639400482\n","  timers:\n","    learn_throughput: 1564.615\n","    learn_time_ms: 2556.539\n","    load_throughput: 9219770.292\n","    load_time_ms: 0.434\n","    sample_throughput: 530.178\n","    sample_time_ms: 7544.638\n","    update_time_ms: 2.78\n","  timestamp: 1649863560\n","  timesteps_since_restore: 256000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 256000\n","  training_iteration: 64\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:26:03 (running for 00:08:13.80)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         466.404</td><td style=\"text-align: right;\">256000</td><td style=\"text-align: right;\">-331.228  </td><td style=\"text-align: right;\">             19.7567</td><td style=\"text-align: right;\">            -906.535</td><td style=\"text-align: right;\">            146.77</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         466.31 </td><td style=\"text-align: right;\">176000</td><td style=\"text-align: right;\">   4.07201</td><td style=\"text-align: right;\">            148.04  </td><td style=\"text-align: right;\">            -306.605</td><td style=\"text-align: right;\">            367.49</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         455.852</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> 231.411  </td><td style=\"text-align: right;\">            305.17  </td><td style=\"text-align: right;\">            -244.494</td><td style=\"text-align: right;\">            330.84</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 204000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-26-07\n","  done: false\n","  episode_len_mean: 346.99\n","  episode_media: {}\n","  episode_reward_max: 305.17021650506695\n","  episode_reward_mean: 227.3899712320985\n","  episode_reward_min: -244.49379170565405\n","  episodes_this_iter: 7\n","  episodes_total: 801\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.16875000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7897266149520874\n","          entropy_coeff: 0.0\n","          kl: 0.006623856723308563\n","          model: {}\n","          policy_loss: -0.007659041788429022\n","          total_loss: 692.9191284179688\n","          vf_explained_var: -0.07986321300268173\n","          vf_loss: 692.9256591796875\n","    num_agent_steps_sampled: 204000\n","    num_agent_steps_trained: 204000\n","    num_steps_sampled: 204000\n","    num_steps_trained: 204000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 51\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.0875\n","    ram_util_percent: 15.6\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07485547711746682\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.682130388650506\n","    mean_inference_ms: 0.7609478094015663\n","    mean_raw_obs_processing_ms: 0.11296498992732004\n","  time_since_restore: 467.00227093696594\n","  time_this_iter_s: 11.15063738822937\n","  time_total_s: 467.00227093696594\n","  timers:\n","    learn_throughput: 1584.259\n","    learn_time_ms: 2524.84\n","    load_throughput: 8509442.078\n","    load_time_ms: 0.47\n","    sample_throughput: 426.789\n","    sample_time_ms: 9372.307\n","    update_time_ms: 2.842\n","  timestamp: 1649863567\n","  timesteps_since_restore: 204000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 204000\n","  training_iteration: 51\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 260000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-26-08\n","  done: false\n","  episode_len_mean: 148.82\n","  episode_media: {}\n","  episode_reward_max: -14.313116691861154\n","  episode_reward_mean: -379.9397455130742\n","  episode_reward_min: -906.5347198843524\n","  episodes_this_iter: 28\n","  episodes_total: 2473\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 3.332770347595215\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.6067951917648315\n","          entropy_coeff: 0.0\n","          kl: 0.05846182256937027\n","          model: {}\n","          policy_loss: 0.019414862617850304\n","          total_loss: 2879.062255859375\n","          vf_explained_var: 0.6451241970062256\n","          vf_loss: 2878.847900390625\n","    num_agent_steps_sampled: 260000\n","    num_agent_steps_trained: 260000\n","    num_steps_sampled: 260000\n","    num_steps_trained: 260000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 65\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.272727272727273\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07026904008634136\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.25992908081121546\n","    mean_inference_ms: 0.7221494411860166\n","    mean_raw_obs_processing_ms: 0.11273350663595284\n","  time_since_restore: 473.89703917503357\n","  time_this_iter_s: 7.492975234985352\n","  time_total_s: 473.89703917503357\n","  timers:\n","    learn_throughput: 1567.832\n","    learn_time_ms: 2551.293\n","    load_throughput: 8997273.556\n","    load_time_ms: 0.445\n","    sample_throughput: 528.159\n","    sample_time_ms: 7573.478\n","    update_time_ms: 2.791\n","  timestamp: 1649863568\n","  timesteps_since_restore: 260000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 260000\n","  training_iteration: 65\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:26:09 (running for 00:08:19.33)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         473.897</td><td style=\"text-align: right;\">260000</td><td style=\"text-align: right;\">-379.94   </td><td style=\"text-align: right;\">            -14.3131</td><td style=\"text-align: right;\">            -906.535</td><td style=\"text-align: right;\">            148.82</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         466.31 </td><td style=\"text-align: right;\">176000</td><td style=\"text-align: right;\">   4.07201</td><td style=\"text-align: right;\">            148.04  </td><td style=\"text-align: right;\">            -306.605</td><td style=\"text-align: right;\">            367.49</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         467.002</td><td style=\"text-align: right;\">204000</td><td style=\"text-align: right;\"> 227.39   </td><td style=\"text-align: right;\">            305.17  </td><td style=\"text-align: right;\">            -244.494</td><td style=\"text-align: right;\">            346.99</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 180000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-26-11\n","  done: false\n","  episode_len_mean: 367.61\n","  episode_media: {}\n","  episode_reward_max: 157.08219463702878\n","  episode_reward_mean: 2.9345779064031374\n","  episode_reward_min: -316.64103340249653\n","  episodes_this_iter: 7\n","  episodes_total: 668\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.0065944194793701\n","          entropy_coeff: 0.0\n","          kl: 0.01572408899664879\n","          model: {}\n","          policy_loss: -0.023779472336173058\n","          total_loss: 1018.6900024414062\n","          vf_explained_var: 0.7485705018043518\n","          vf_loss: 1018.69775390625\n","    num_agent_steps_sampled: 180000\n","    num_agent_steps_trained: 180000\n","    num_steps_sampled: 180000\n","    num_steps_trained: 180000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 45\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.741176470588233\n","    ram_util_percent: 15.6\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07321181521005043\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.0400590934895757\n","    mean_inference_ms: 0.7568444676230434\n","    mean_raw_obs_processing_ms: 0.11176381352920035\n","  time_since_restore: 477.7878074645996\n","  time_this_iter_s: 11.477500200271606\n","  time_total_s: 477.7878074645996\n","  timers:\n","    learn_throughput: 1582.996\n","    learn_time_ms: 2526.854\n","    load_throughput: 9633773.184\n","    load_time_ms: 0.415\n","    sample_throughput: 360.453\n","    sample_time_ms: 11097.142\n","    update_time_ms: 2.849\n","  timestamp: 1649863571\n","  timesteps_since_restore: 180000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 180000\n","  training_iteration: 45\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:26:14 (running for 00:08:24.68)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         473.897</td><td style=\"text-align: right;\">260000</td><td style=\"text-align: right;\">-379.94   </td><td style=\"text-align: right;\">            -14.3131</td><td style=\"text-align: right;\">            -906.535</td><td style=\"text-align: right;\">            148.82</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         477.788</td><td style=\"text-align: right;\">180000</td><td style=\"text-align: right;\">   2.93458</td><td style=\"text-align: right;\">            157.082 </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            367.61</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         467.002</td><td style=\"text-align: right;\">204000</td><td style=\"text-align: right;\"> 227.39   </td><td style=\"text-align: right;\">            305.17  </td><td style=\"text-align: right;\">            -244.494</td><td style=\"text-align: right;\">            346.99</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 264000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-26-15\n","  done: false\n","  episode_len_mean: 149.97\n","  episode_media: {}\n","  episode_reward_max: -14.313116691861154\n","  episode_reward_mean: -418.1242763786719\n","  episode_reward_min: -906.5347198843524\n","  episodes_this_iter: 27\n","  episodes_total: 2500\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 4.999155521392822\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5344132781028748\n","          entropy_coeff: 0.0\n","          kl: 0.0439314991235733\n","          model: {}\n","          policy_loss: 0.016729319468140602\n","          total_loss: 2344.742431640625\n","          vf_explained_var: 0.7198818325996399\n","          vf_loss: 2344.505859375\n","    num_agent_steps_sampled: 264000\n","    num_agent_steps_trained: 264000\n","    num_steps_sampled: 264000\n","    num_steps_trained: 264000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 66\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.04\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0702958030795072\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2614335157678848\n","    mean_inference_ms: 0.7225510258386635\n","    mean_raw_obs_processing_ms: 0.11273181244654835\n","  time_since_restore: 481.48796463012695\n","  time_this_iter_s: 7.590925455093384\n","  time_total_s: 481.48796463012695\n","  timers:\n","    learn_throughput: 1570.426\n","    learn_time_ms: 2547.079\n","    load_throughput: 8919780.956\n","    load_time_ms: 0.448\n","    sample_throughput: 525.572\n","    sample_time_ms: 7610.754\n","    update_time_ms: 2.778\n","  timestamp: 1649863575\n","  timesteps_since_restore: 264000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 264000\n","  training_iteration: 66\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 208000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-26-19\n","  done: false\n","  episode_len_mean: 367.06\n","  episode_media: {}\n","  episode_reward_max: 305.17021650506695\n","  episode_reward_mean: 226.9910234275902\n","  episode_reward_min: -244.49379170565405\n","  episodes_this_iter: 7\n","  episodes_total: 808\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.16875000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.8545529842376709\n","          entropy_coeff: 0.0\n","          kl: 0.007211663760244846\n","          model: {}\n","          policy_loss: -0.004709356464445591\n","          total_loss: 394.8967590332031\n","          vf_explained_var: 0.09262042492628098\n","          vf_loss: 394.9002685546875\n","    num_agent_steps_sampled: 208000\n","    num_agent_steps_trained: 208000\n","    num_steps_sampled: 208000\n","    num_steps_trained: 208000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 52\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.71875\n","    ram_util_percent: 15.6\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07486887895261878\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6833261312420901\n","    mean_inference_ms: 0.7611556299330658\n","    mean_raw_obs_processing_ms: 0.11297373567100212\n","  time_since_restore: 478.11646461486816\n","  time_this_iter_s: 11.114193677902222\n","  time_total_s: 478.11646461486816\n","  timers:\n","    learn_throughput: 1593.006\n","    learn_time_ms: 2510.976\n","    load_throughput: 8437970.125\n","    load_time_ms: 0.474\n","    sample_throughput: 418.425\n","    sample_time_ms: 9559.649\n","    update_time_ms: 2.837\n","  timestamp: 1649863579\n","  timesteps_since_restore: 208000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 208000\n","  training_iteration: 52\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:26:20 (running for 00:08:30.27)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">         481.488</td><td style=\"text-align: right;\">264000</td><td style=\"text-align: right;\">-418.124  </td><td style=\"text-align: right;\">            -14.3131</td><td style=\"text-align: right;\">            -906.535</td><td style=\"text-align: right;\">            149.97</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         477.788</td><td style=\"text-align: right;\">180000</td><td style=\"text-align: right;\">   2.93458</td><td style=\"text-align: right;\">            157.082 </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            367.61</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         478.116</td><td style=\"text-align: right;\">208000</td><td style=\"text-align: right;\"> 226.991  </td><td style=\"text-align: right;\">            305.17  </td><td style=\"text-align: right;\">            -244.494</td><td style=\"text-align: right;\">            367.06</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 268000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-26-23\n","  done: false\n","  episode_len_mean: 150.15\n","  episode_media: {}\n","  episode_reward_max: -14.313116691861154\n","  episode_reward_mean: -456.89386773956835\n","  episode_reward_min: -906.5347198843524\n","  episodes_this_iter: 25\n","  episodes_total: 2525\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 7.4987335205078125\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5037316679954529\n","          entropy_coeff: 0.0\n","          kl: 0.04969203472137451\n","          model: {}\n","          policy_loss: 0.016314050182700157\n","          total_loss: 2275.2734375\n","          vf_explained_var: 0.7071346640586853\n","          vf_loss: 2274.884521484375\n","    num_agent_steps_sampled: 268000\n","    num_agent_steps_trained: 268000\n","    num_steps_sampled: 268000\n","    num_steps_trained: 268000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 67\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.766666666666667\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07030553209873018\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.26263523050921916\n","    mean_inference_ms: 0.7227501140150223\n","    mean_raw_obs_processing_ms: 0.11271624591525789\n","  time_since_restore: 489.2817187309265\n","  time_this_iter_s: 7.7937541007995605\n","  time_total_s: 489.2817187309265\n","  timers:\n","    learn_throughput: 1560.454\n","    learn_time_ms: 2563.357\n","    load_throughput: 8934506.337\n","    load_time_ms: 0.448\n","    sample_throughput: 524.94\n","    sample_time_ms: 7619.914\n","    update_time_ms: 2.858\n","  timestamp: 1649863583\n","  timesteps_since_restore: 268000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 268000\n","  training_iteration: 67\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 184000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-26-23\n","  done: false\n","  episode_len_mean: 395.67\n","  episode_media: {}\n","  episode_reward_max: 205.94261229475939\n","  episode_reward_mean: 9.659496036868495\n","  episode_reward_min: -316.64103340249653\n","  episodes_this_iter: 5\n","  episodes_total: 673\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.9846320152282715\n","          entropy_coeff: 0.0\n","          kl: 0.008722842670977116\n","          model: {}\n","          policy_loss: -0.02732381969690323\n","          total_loss: 375.1212463378906\n","          vf_explained_var: 0.6581453084945679\n","          vf_loss: 375.13970947265625\n","    num_agent_steps_sampled: 184000\n","    num_agent_steps_trained: 184000\n","    num_steps_sampled: 184000\n","    num_steps_trained: 184000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 46\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.929411764705883\n","    ram_util_percent: 15.6\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07322957093472518\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.0416988880675158\n","    mean_inference_ms: 0.7571185667568535\n","    mean_raw_obs_processing_ms: 0.1117854281547351\n","  time_since_restore: 490.1992244720459\n","  time_this_iter_s: 12.411417007446289\n","  time_total_s: 490.1992244720459\n","  timers:\n","    learn_throughput: 1579.92\n","    learn_time_ms: 2531.774\n","    load_throughput: 9597400.606\n","    load_time_ms: 0.417\n","    sample_throughput: 355.203\n","    sample_time_ms: 11261.159\n","    update_time_ms: 2.834\n","  timestamp: 1649863583\n","  timesteps_since_restore: 184000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 184000\n","  training_iteration: 46\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:26:25 (running for 00:08:36.13)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         489.282</td><td style=\"text-align: right;\">268000</td><td style=\"text-align: right;\">-456.894 </td><td style=\"text-align: right;\">            -14.3131</td><td style=\"text-align: right;\">            -906.535</td><td style=\"text-align: right;\">            150.15</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         490.199</td><td style=\"text-align: right;\">184000</td><td style=\"text-align: right;\">   9.6595</td><td style=\"text-align: right;\">            205.943 </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            395.67</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         478.116</td><td style=\"text-align: right;\">208000</td><td style=\"text-align: right;\"> 226.991 </td><td style=\"text-align: right;\">            305.17  </td><td style=\"text-align: right;\">            -244.494</td><td style=\"text-align: right;\">            367.06</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 212000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-26-30\n","  done: false\n","  episode_len_mean: 374.46\n","  episode_media: {}\n","  episode_reward_max: 309.24642649555864\n","  episode_reward_mean: 231.1027857116195\n","  episode_reward_min: -244.49379170565405\n","  episodes_this_iter: 9\n","  episodes_total: 817\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.16875000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.8209810256958008\n","          entropy_coeff: 0.0\n","          kl: 0.007933356799185276\n","          model: {}\n","          policy_loss: 0.0018172264099121094\n","          total_loss: 256.4849853515625\n","          vf_explained_var: 0.1511767953634262\n","          vf_loss: 256.4818420410156\n","    num_agent_steps_sampled: 212000\n","    num_agent_steps_trained: 212000\n","    num_steps_sampled: 212000\n","    num_steps_trained: 212000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 53\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.056250000000002\n","    ram_util_percent: 15.6\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07489056785036297\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6855094948137238\n","    mean_inference_ms: 0.7614697985740173\n","    mean_raw_obs_processing_ms: 0.11298968752853422\n","  time_since_restore: 489.0717258453369\n","  time_this_iter_s: 10.95526123046875\n","  time_total_s: 489.0717258453369\n","  timers:\n","    learn_throughput: 1597.608\n","    learn_time_ms: 2503.743\n","    load_throughput: 8275645.44\n","    load_time_ms: 0.483\n","    sample_throughput: 409.972\n","    sample_time_ms: 9756.754\n","    update_time_ms: 2.852\n","  timestamp: 1649863590\n","  timesteps_since_restore: 212000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 212000\n","  training_iteration: 53\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:26:31 (running for 00:08:41.26)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         489.282</td><td style=\"text-align: right;\">268000</td><td style=\"text-align: right;\">-456.894 </td><td style=\"text-align: right;\">            -14.3131</td><td style=\"text-align: right;\">            -906.535</td><td style=\"text-align: right;\">            150.15</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         490.199</td><td style=\"text-align: right;\">184000</td><td style=\"text-align: right;\">   9.6595</td><td style=\"text-align: right;\">            205.943 </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            395.67</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         489.072</td><td style=\"text-align: right;\">212000</td><td style=\"text-align: right;\"> 231.103 </td><td style=\"text-align: right;\">            309.246 </td><td style=\"text-align: right;\">            -244.494</td><td style=\"text-align: right;\">            374.46</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 272000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-26-31\n","  done: false\n","  episode_len_mean: 143.0\n","  episode_media: {}\n","  episode_reward_max: -14.313116691861154\n","  episode_reward_mean: -446.40105602415025\n","  episode_reward_min: -853.1700641341016\n","  episodes_this_iter: 31\n","  episodes_total: 2556\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 11.248100280761719\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5609384775161743\n","          entropy_coeff: 0.0\n","          kl: 0.01672477461397648\n","          model: {}\n","          policy_loss: 0.012954331934452057\n","          total_loss: 1885.99169921875\n","          vf_explained_var: 0.871254563331604\n","          vf_loss: 1885.7906494140625\n","    num_agent_steps_sampled: 272000\n","    num_agent_steps_trained: 272000\n","    num_steps_sampled: 272000\n","    num_steps_trained: 272000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 68\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.39\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07030058074362666\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2639380251900215\n","    mean_inference_ms: 0.7227574980680777\n","    mean_raw_obs_processing_ms: 0.11268496695553103\n","  time_since_restore: 496.8630020618439\n","  time_this_iter_s: 7.581283330917358\n","  time_total_s: 496.8630020618439\n","  timers:\n","    learn_throughput: 1558.066\n","    learn_time_ms: 2567.285\n","    load_throughput: 9193498.822\n","    load_time_ms: 0.435\n","    sample_throughput: 523.371\n","    sample_time_ms: 7642.76\n","    update_time_ms: 2.833\n","  timestamp: 1649863591\n","  timesteps_since_restore: 272000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 272000\n","  training_iteration: 68\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 188000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-26-35\n","  done: false\n","  episode_len_mean: 415.52\n","  episode_media: {}\n","  episode_reward_max: 205.94261229475939\n","  episode_reward_mean: 12.972425683386065\n","  episode_reward_min: -316.64103340249653\n","  episodes_this_iter: 7\n","  episodes_total: 680\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.027145266532898\n","          entropy_coeff: 0.0\n","          kl: 0.010082895867526531\n","          model: {}\n","          policy_loss: -0.04291672259569168\n","          total_loss: 236.70297241210938\n","          vf_explained_var: 0.8840055465698242\n","          vf_loss: 236.73568725585938\n","    num_agent_steps_sampled: 188000\n","    num_agent_steps_trained: 188000\n","    num_steps_sampled: 188000\n","    num_steps_trained: 188000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 47\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.11764705882353\n","    ram_util_percent: 15.6\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07325260237081689\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.044480344115823\n","    mean_inference_ms: 0.7575144937500301\n","    mean_raw_obs_processing_ms: 0.11181191920765104\n","  time_since_restore: 502.1007604598999\n","  time_this_iter_s: 11.901535987854004\n","  time_total_s: 502.1007604598999\n","  timers:\n","    learn_throughput: 1596.555\n","    learn_time_ms: 2505.394\n","    load_throughput: 9583694.733\n","    load_time_ms: 0.417\n","    sample_throughput: 350.452\n","    sample_time_ms: 11413.827\n","    update_time_ms: 2.812\n","  timestamp: 1649863595\n","  timesteps_since_restore: 188000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 188000\n","  training_iteration: 47\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:26:36 (running for 00:08:47.07)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">         496.863</td><td style=\"text-align: right;\">272000</td><td style=\"text-align: right;\">-446.401 </td><td style=\"text-align: right;\">            -14.3131</td><td style=\"text-align: right;\">            -853.17 </td><td style=\"text-align: right;\">            143   </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         502.101</td><td style=\"text-align: right;\">188000</td><td style=\"text-align: right;\">  12.9724</td><td style=\"text-align: right;\">            205.943 </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            415.52</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         489.072</td><td style=\"text-align: right;\">212000</td><td style=\"text-align: right;\"> 231.103 </td><td style=\"text-align: right;\">            309.246 </td><td style=\"text-align: right;\">            -244.494</td><td style=\"text-align: right;\">            374.46</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 276000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-26-38\n","  done: false\n","  episode_len_mean: 145.64\n","  episode_media: {}\n","  episode_reward_max: -31.32782766723055\n","  episode_reward_mean: -459.63515077522106\n","  episode_reward_min: -853.1700641341016\n","  episodes_this_iter: 26\n","  episodes_total: 2582\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 11.248100280761719\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5778924226760864\n","          entropy_coeff: 0.0\n","          kl: 0.03015829436480999\n","          model: {}\n","          policy_loss: 0.0090847322717309\n","          total_loss: 926.7901000976562\n","          vf_explained_var: 0.8640512228012085\n","          vf_loss: 926.4417724609375\n","    num_agent_steps_sampled: 276000\n","    num_agent_steps_trained: 276000\n","    num_steps_sampled: 276000\n","    num_steps_trained: 276000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 69\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.872727272727273\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07030549820648825\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.26501568852668894\n","    mean_inference_ms: 0.7228719685868958\n","    mean_raw_obs_processing_ms: 0.11267207144437358\n","  time_since_restore: 504.51811933517456\n","  time_this_iter_s: 7.6551172733306885\n","  time_total_s: 504.51811933517456\n","  timers:\n","    learn_throughput: 1554.182\n","    learn_time_ms: 2573.702\n","    load_throughput: 9344035.645\n","    load_time_ms: 0.428\n","    sample_throughput: 520.963\n","    sample_time_ms: 7678.083\n","    update_time_ms: 2.854\n","  timestamp: 1649863598\n","  timesteps_since_restore: 276000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 276000\n","  training_iteration: 69\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 216000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-26-39\n","  done: false\n","  episode_len_mean: 379.0\n","  episode_media: {}\n","  episode_reward_max: 309.24642649555864\n","  episode_reward_mean: 231.54445046300054\n","  episode_reward_min: -244.49379170565405\n","  episodes_this_iter: 9\n","  episodes_total: 826\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.16875000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6626666188240051\n","          entropy_coeff: 0.0\n","          kl: 0.006283029913902283\n","          model: {}\n","          policy_loss: -0.016117703169584274\n","          total_loss: 1300.49169921875\n","          vf_explained_var: -0.14198079705238342\n","          vf_loss: 1300.5068359375\n","    num_agent_steps_sampled: 216000\n","    num_agent_steps_trained: 216000\n","    num_steps_sampled: 216000\n","    num_steps_trained: 216000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 54\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.742857142857144\n","    ram_util_percent: 15.599999999999998\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07490922187155225\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6878886397404784\n","    mean_inference_ms: 0.7617594538064151\n","    mean_raw_obs_processing_ms: 0.11300098153700641\n","  time_since_restore: 498.71106696128845\n","  time_this_iter_s: 9.639341115951538\n","  time_total_s: 498.71106696128845\n","  timers:\n","    learn_throughput: 1600.067\n","    learn_time_ms: 2499.895\n","    load_throughput: 8269526.814\n","    load_time_ms: 0.484\n","    sample_throughput: 408.45\n","    sample_time_ms: 9793.119\n","    update_time_ms: 2.796\n","  timestamp: 1649863599\n","  timesteps_since_restore: 216000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 216000\n","  training_iteration: 54\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:26:42 (running for 00:08:53.02)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         504.518</td><td style=\"text-align: right;\">276000</td><td style=\"text-align: right;\">-459.635 </td><td style=\"text-align: right;\">            -31.3278</td><td style=\"text-align: right;\">            -853.17 </td><td style=\"text-align: right;\">            145.64</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         502.101</td><td style=\"text-align: right;\">188000</td><td style=\"text-align: right;\">  12.9724</td><td style=\"text-align: right;\">            205.943 </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            415.52</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         498.711</td><td style=\"text-align: right;\">216000</td><td style=\"text-align: right;\"> 231.544 </td><td style=\"text-align: right;\">            309.246 </td><td style=\"text-align: right;\">            -244.494</td><td style=\"text-align: right;\">            379   </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 280000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-26-46\n","  done: false\n","  episode_len_mean: 143.7\n","  episode_media: {}\n","  episode_reward_max: -31.32782766723055\n","  episode_reward_mean: -456.0728025870095\n","  episode_reward_min: -924.4943676282329\n","  episodes_this_iter: 29\n","  episodes_total: 2611\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 16.872150421142578\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5184475183486938\n","          entropy_coeff: 0.0\n","          kl: 0.050257496535778046\n","          model: {}\n","          policy_loss: 0.019532736390829086\n","          total_loss: 2261.120361328125\n","          vf_explained_var: 0.8421909213066101\n","          vf_loss: 2260.2529296875\n","    num_agent_steps_sampled: 280000\n","    num_agent_steps_trained: 280000\n","    num_steps_sampled: 280000\n","    num_steps_trained: 280000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 70\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.800000000000004\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07030960386390077\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.26612019026672074\n","    mean_inference_ms: 0.7229469058111718\n","    mean_raw_obs_processing_ms: 0.11265364951013492\n","  time_since_restore: 512.1185989379883\n","  time_this_iter_s: 7.600479602813721\n","  time_total_s: 512.1185989379883\n","  timers:\n","    learn_throughput: 1554.387\n","    learn_time_ms: 2573.361\n","    load_throughput: 9448226.615\n","    load_time_ms: 0.423\n","    sample_throughput: 519.751\n","    sample_time_ms: 7695.987\n","    update_time_ms: 2.9\n","  timestamp: 1649863606\n","  timesteps_since_restore: 280000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 280000\n","  training_iteration: 70\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 192000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-26-46\n","  done: false\n","  episode_len_mean: 440.97\n","  episode_media: {}\n","  episode_reward_max: 205.94261229475939\n","  episode_reward_mean: 14.070603688209678\n","  episode_reward_min: -316.64103340249653\n","  episodes_this_iter: 9\n","  episodes_total: 689\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.0291157960891724\n","          entropy_coeff: 0.0\n","          kl: 0.014433828182518482\n","          model: {}\n","          policy_loss: -0.0454103946685791\n","          total_loss: 568.0635375976562\n","          vf_explained_var: 0.8223199844360352\n","          vf_loss: 568.0942993164062\n","    num_agent_steps_sampled: 192000\n","    num_agent_steps_trained: 192000\n","    num_steps_sampled: 192000\n","    num_steps_trained: 192000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 48\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.787500000000001\n","    ram_util_percent: 15.6\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0732825142002501\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.048200235899051\n","    mean_inference_ms: 0.7580275332006968\n","    mean_raw_obs_processing_ms: 0.11184132820026463\n","  time_since_restore: 513.1019947528839\n","  time_this_iter_s: 11.001234292984009\n","  time_total_s: 513.1019947528839\n","  timers:\n","    learn_throughput: 1598.628\n","    learn_time_ms: 2502.145\n","    load_throughput: 9691090.573\n","    load_time_ms: 0.413\n","    sample_throughput: 353.316\n","    sample_time_ms: 11321.298\n","    update_time_ms: 2.81\n","  timestamp: 1649863606\n","  timesteps_since_restore: 192000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 192000\n","  training_iteration: 48\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:26:47 (running for 00:08:58.11)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">         512.119</td><td style=\"text-align: right;\">280000</td><td style=\"text-align: right;\">-456.073 </td><td style=\"text-align: right;\">            -31.3278</td><td style=\"text-align: right;\">            -924.494</td><td style=\"text-align: right;\">            143.7 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">         513.102</td><td style=\"text-align: right;\">192000</td><td style=\"text-align: right;\">  14.0706</td><td style=\"text-align: right;\">            205.943 </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            440.97</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         498.711</td><td style=\"text-align: right;\">216000</td><td style=\"text-align: right;\"> 231.544 </td><td style=\"text-align: right;\">            309.246 </td><td style=\"text-align: right;\">            -244.494</td><td style=\"text-align: right;\">            379   </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 220000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-26-49\n","  done: false\n","  episode_len_mean: 383.67\n","  episode_media: {}\n","  episode_reward_max: 309.24642649555864\n","  episode_reward_mean: 228.40269058376347\n","  episode_reward_min: -244.49379170565405\n","  episodes_this_iter: 12\n","  episodes_total: 838\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.16875000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7948852777481079\n","          entropy_coeff: 0.0\n","          kl: 0.008844097144901752\n","          model: {}\n","          policy_loss: -0.014260224997997284\n","          total_loss: 402.7519226074219\n","          vf_explained_var: -0.0718652606010437\n","          vf_loss: 402.7646484375\n","    num_agent_steps_sampled: 220000\n","    num_agent_steps_trained: 220000\n","    num_steps_sampled: 220000\n","    num_steps_trained: 220000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 55\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.215384615384615\n","    ram_util_percent: 15.599999999999998\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07493306990953905\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6911924096408635\n","    mean_inference_ms: 0.7621348051119571\n","    mean_raw_obs_processing_ms: 0.11301451220612435\n","  time_since_restore: 507.98059010505676\n","  time_this_iter_s: 9.26952314376831\n","  time_total_s: 507.98059010505676\n","  timers:\n","    learn_throughput: 1600.341\n","    learn_time_ms: 2499.467\n","    load_throughput: 8245953.013\n","    load_time_ms: 0.485\n","    sample_throughput: 407.546\n","    sample_time_ms: 9814.845\n","    update_time_ms: 2.808\n","  timestamp: 1649863609\n","  timesteps_since_restore: 220000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 220000\n","  training_iteration: 55\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:26:53 (running for 00:09:03.35)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">         512.119</td><td style=\"text-align: right;\">280000</td><td style=\"text-align: right;\">-456.073 </td><td style=\"text-align: right;\">            -31.3278</td><td style=\"text-align: right;\">            -924.494</td><td style=\"text-align: right;\">            143.7 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">         513.102</td><td style=\"text-align: right;\">192000</td><td style=\"text-align: right;\">  14.0706</td><td style=\"text-align: right;\">            205.943 </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            440.97</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         507.981</td><td style=\"text-align: right;\">220000</td><td style=\"text-align: right;\"> 228.403 </td><td style=\"text-align: right;\">            309.246 </td><td style=\"text-align: right;\">            -244.494</td><td style=\"text-align: right;\">            383.67</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 284000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-26-53\n","  done: false\n","  episode_len_mean: 140.21\n","  episode_media: {}\n","  episode_reward_max: -31.32782766723055\n","  episode_reward_mean: -428.84401943062824\n","  episode_reward_min: -924.4943676282329\n","  episodes_this_iter: 28\n","  episodes_total: 2639\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 25.308225631713867\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5594396591186523\n","          entropy_coeff: 0.0\n","          kl: 0.056790582835674286\n","          model: {}\n","          policy_loss: 0.015765227377414703\n","          total_loss: 1355.188720703125\n","          vf_explained_var: 0.7656949758529663\n","          vf_loss: 1353.7357177734375\n","    num_agent_steps_sampled: 284000\n","    num_agent_steps_trained: 284000\n","    num_steps_sampled: 284000\n","    num_steps_trained: 284000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 71\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.163636363636364\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0703132121469316\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.26694917042452493\n","    mean_inference_ms: 0.7230228997976081\n","    mean_raw_obs_processing_ms: 0.11263852362107887\n","  time_since_restore: 519.5106406211853\n","  time_this_iter_s: 7.3920416831970215\n","  time_total_s: 519.5106406211853\n","  timers:\n","    learn_throughput: 1569.1\n","    learn_time_ms: 2549.232\n","    load_throughput: 9531425.974\n","    load_time_ms: 0.42\n","    sample_throughput: 519.387\n","    sample_time_ms: 7701.38\n","    update_time_ms: 2.91\n","  timestamp: 1649863613\n","  timesteps_since_restore: 284000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 284000\n","  training_iteration: 71\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 224000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-26-58\n","  done: false\n","  episode_len_mean: 380.48\n","  episode_media: {}\n","  episode_reward_max: 309.24642649555864\n","  episode_reward_mean: 229.4675622111975\n","  episode_reward_min: -244.49379170565405\n","  episodes_this_iter: 12\n","  episodes_total: 850\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.16875000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6429086923599243\n","          entropy_coeff: 0.0\n","          kl: 0.007251409813761711\n","          model: {}\n","          policy_loss: -0.00825049914419651\n","          total_loss: 489.7157287597656\n","          vf_explained_var: -0.00044704112224280834\n","          vf_loss: 489.7227478027344\n","    num_agent_steps_sampled: 224000\n","    num_agent_steps_trained: 224000\n","    num_steps_sampled: 224000\n","    num_steps_trained: 224000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 56\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.438461538461537\n","    ram_util_percent: 15.599999999999998\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07495351810521114\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6943539781715186\n","    mean_inference_ms: 0.7624670959214345\n","    mean_raw_obs_processing_ms: 0.11302448806668779\n","  time_since_restore: 516.9319448471069\n","  time_this_iter_s: 8.951354742050171\n","  time_total_s: 516.9319448471069\n","  timers:\n","    learn_throughput: 1592.36\n","    learn_time_ms: 2511.994\n","    load_throughput: 8002487.956\n","    load_time_ms: 0.5\n","    sample_throughput: 407.85\n","    sample_time_ms: 9807.523\n","    update_time_ms: 2.839\n","  timestamp: 1649863618\n","  timesteps_since_restore: 224000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 224000\n","  training_iteration: 56\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:26:59 (running for 00:09:09.25)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         519.511</td><td style=\"text-align: right;\">284000</td><td style=\"text-align: right;\">-428.844 </td><td style=\"text-align: right;\">            -31.3278</td><td style=\"text-align: right;\">            -924.494</td><td style=\"text-align: right;\">            140.21</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">         513.102</td><td style=\"text-align: right;\">192000</td><td style=\"text-align: right;\">  14.0706</td><td style=\"text-align: right;\">            205.943 </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            440.97</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         516.932</td><td style=\"text-align: right;\">224000</td><td style=\"text-align: right;\"> 229.468 </td><td style=\"text-align: right;\">            309.246 </td><td style=\"text-align: right;\">            -244.494</td><td style=\"text-align: right;\">            380.48</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 196000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-26-59\n","  done: false\n","  episode_len_mean: 467.24\n","  episode_media: {}\n","  episode_reward_max: 205.94261229475939\n","  episode_reward_mean: 17.7195718151198\n","  episode_reward_min: -316.64103340249653\n","  episodes_this_iter: 5\n","  episodes_total: 694\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.02131187915802\n","          entropy_coeff: 0.0\n","          kl: 0.01025683619081974\n","          model: {}\n","          policy_loss: -0.03665884584188461\n","          total_loss: 136.6216278076172\n","          vf_explained_var: 0.8543617129325867\n","          vf_loss: 136.64791870117188\n","    num_agent_steps_sampled: 196000\n","    num_agent_steps_trained: 196000\n","    num_steps_sampled: 196000\n","    num_steps_trained: 196000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 49\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.261111111111111\n","    ram_util_percent: 15.600000000000001\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0733004709213388\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.0503921098723932\n","    mean_inference_ms: 0.7583238146087029\n","    mean_raw_obs_processing_ms: 0.11185735831281991\n","  time_since_restore: 525.2360682487488\n","  time_this_iter_s: 12.134073495864868\n","  time_total_s: 525.2360682487488\n","  timers:\n","    learn_throughput: 1593.457\n","    learn_time_ms: 2510.265\n","    load_throughput: 9941464.802\n","    load_time_ms: 0.402\n","    sample_throughput: 347.122\n","    sample_time_ms: 11523.326\n","    update_time_ms: 2.826\n","  timestamp: 1649863619\n","  timesteps_since_restore: 196000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 196000\n","  training_iteration: 49\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 288000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-27-01\n","  done: false\n","  episode_len_mean: 145.81\n","  episode_media: {}\n","  episode_reward_max: -4.419918560596486\n","  episode_reward_mean: -411.4113991514752\n","  episode_reward_min: -924.4943676282329\n","  episodes_this_iter: 26\n","  episodes_total: 2665\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 37.962337493896484\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5792430639266968\n","          entropy_coeff: 0.0\n","          kl: 0.03547770902514458\n","          model: {}\n","          policy_loss: 0.00851154513657093\n","          total_loss: 2392.66552734375\n","          vf_explained_var: 0.6891007423400879\n","          vf_loss: 2391.310791015625\n","    num_agent_steps_sampled: 288000\n","    num_agent_steps_trained: 288000\n","    num_steps_sampled: 288000\n","    num_steps_trained: 288000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 72\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.936363636363637\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07032787794765366\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2677884395300671\n","    mean_inference_ms: 0.7232681800741907\n","    mean_raw_obs_processing_ms: 0.11264250019038403\n","  time_since_restore: 527.3683762550354\n","  time_this_iter_s: 7.857735633850098\n","  time_total_s: 527.3683762550354\n","  timers:\n","    learn_throughput: 1565.075\n","    learn_time_ms: 2555.788\n","    load_throughput: 9177908.096\n","    load_time_ms: 0.436\n","    sample_throughput: 517.123\n","    sample_time_ms: 7735.109\n","    update_time_ms: 2.907\n","  timestamp: 1649863621\n","  timesteps_since_restore: 288000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 288000\n","  training_iteration: 72\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:27:04 (running for 00:09:15.13)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         527.368</td><td style=\"text-align: right;\">288000</td><td style=\"text-align: right;\">-411.411 </td><td style=\"text-align: right;\">            -4.41992</td><td style=\"text-align: right;\">            -924.494</td><td style=\"text-align: right;\">            145.81</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         525.236</td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  17.7196</td><td style=\"text-align: right;\">           205.943  </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            467.24</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         516.932</td><td style=\"text-align: right;\">224000</td><td style=\"text-align: right;\"> 229.468 </td><td style=\"text-align: right;\">           309.246  </td><td style=\"text-align: right;\">            -244.494</td><td style=\"text-align: right;\">            380.48</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 228000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-27-06\n","  done: false\n","  episode_len_mean: 380.41\n","  episode_media: {}\n","  episode_reward_max: 309.24642649555864\n","  episode_reward_mean: 228.9561436190155\n","  episode_reward_min: -244.49379170565405\n","  episodes_this_iter: 13\n","  episodes_total: 863\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.16875000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7312355637550354\n","          entropy_coeff: 0.0\n","          kl: 0.008765064179897308\n","          model: {}\n","          policy_loss: -0.014271587133407593\n","          total_loss: 514.4527587890625\n","          vf_explained_var: 0.19911734759807587\n","          vf_loss: 514.465576171875\n","    num_agent_steps_sampled: 228000\n","    num_agent_steps_trained: 228000\n","    num_steps_sampled: 228000\n","    num_steps_trained: 228000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 57\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.608333333333334\n","    ram_util_percent: 15.6\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07497897458518377\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6975121381899649\n","    mean_inference_ms: 0.7628349894373437\n","    mean_raw_obs_processing_ms: 0.11304183240465449\n","  time_since_restore: 525.4761188030243\n","  time_this_iter_s: 8.544173955917358\n","  time_total_s: 525.4761188030243\n","  timers:\n","    learn_throughput: 1599.971\n","    learn_time_ms: 2500.046\n","    load_throughput: 8382321.259\n","    load_time_ms: 0.477\n","    sample_throughput: 410.256\n","    sample_time_ms: 9750.0\n","    update_time_ms: 2.861\n","  timestamp: 1649863626\n","  timesteps_since_restore: 228000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 228000\n","  training_iteration: 57\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 292000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-27-09\n","  done: false\n","  episode_len_mean: 146.03\n","  episode_media: {}\n","  episode_reward_max: -4.419918560596486\n","  episode_reward_mean: -384.91774273780226\n","  episode_reward_min: -924.4943676282329\n","  episodes_this_iter: 26\n","  episodes_total: 2691\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 56.94350814819336\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.587181806564331\n","          entropy_coeff: 0.0\n","          kl: 0.058018092066049576\n","          model: {}\n","          policy_loss: 0.016118718311190605\n","          total_loss: 2058.520751953125\n","          vf_explained_var: 0.5846209526062012\n","          vf_loss: 2055.20068359375\n","    num_agent_steps_sampled: 292000\n","    num_agent_steps_trained: 292000\n","    num_steps_sampled: 292000\n","    num_steps_trained: 292000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 73\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.799999999999999\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07033920840173621\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2689112041438564\n","    mean_inference_ms: 0.7235130722288966\n","    mean_raw_obs_processing_ms: 0.11264531872609343\n","  time_since_restore: 535.3637347221375\n","  time_this_iter_s: 7.995358467102051\n","  time_total_s: 535.3637347221375\n","  timers:\n","    learn_throughput: 1560.214\n","    learn_time_ms: 2563.751\n","    load_throughput: 9214706.432\n","    load_time_ms: 0.434\n","    sample_throughput: 517.066\n","    sample_time_ms: 7735.95\n","    update_time_ms: 2.897\n","  timestamp: 1649863629\n","  timesteps_since_restore: 292000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 292000\n","  training_iteration: 73\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:27:10 (running for 00:09:21.08)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         535.364</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">-384.918 </td><td style=\"text-align: right;\">            -4.41992</td><td style=\"text-align: right;\">            -924.494</td><td style=\"text-align: right;\">            146.03</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         525.236</td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  17.7196</td><td style=\"text-align: right;\">           205.943  </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            467.24</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         525.476</td><td style=\"text-align: right;\">228000</td><td style=\"text-align: right;\"> 228.956 </td><td style=\"text-align: right;\">           309.246  </td><td style=\"text-align: right;\">            -244.494</td><td style=\"text-align: right;\">            380.41</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 200000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-27-11\n","  done: false\n","  episode_len_mean: 476.96\n","  episode_media: {}\n","  episode_reward_max: 205.94261229475939\n","  episode_reward_mean: 18.72686231840242\n","  episode_reward_min: -316.64103340249653\n","  episodes_this_iter: 8\n","  episodes_total: 702\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.0425441265106201\n","          entropy_coeff: 0.0\n","          kl: 0.012467495165765285\n","          model: {}\n","          policy_loss: -0.04735926166176796\n","          total_loss: 295.1573791503906\n","          vf_explained_var: 0.8476161360740662\n","          vf_loss: 295.192138671875\n","    num_agent_steps_sampled: 200000\n","    num_agent_steps_trained: 200000\n","    num_steps_sampled: 200000\n","    num_steps_trained: 200000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 50\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.15294117647059\n","    ram_util_percent: 15.6\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07332916097848993\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.0542252602591975\n","    mean_inference_ms: 0.7588121072052357\n","    mean_raw_obs_processing_ms: 0.11188294629017044\n","  time_since_restore: 537.3588273525238\n","  time_this_iter_s: 12.122759103775024\n","  time_total_s: 537.3588273525238\n","  timers:\n","    learn_throughput: 1592.418\n","    learn_time_ms: 2511.903\n","    load_throughput: 9679349.218\n","    load_time_ms: 0.413\n","    sample_throughput: 339.963\n","    sample_time_ms: 11765.989\n","    update_time_ms: 2.822\n","  timestamp: 1649863631\n","  timesteps_since_restore: 200000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 200000\n","  training_iteration: 50\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 232000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-27-15\n","  done: false\n","  episode_len_mean: 387.13\n","  episode_media: {}\n","  episode_reward_max: 309.24642649555864\n","  episode_reward_mean: 227.0834071060646\n","  episode_reward_min: -244.49379170565405\n","  episodes_this_iter: 12\n","  episodes_total: 875\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.16875000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7161182761192322\n","          entropy_coeff: 0.0\n","          kl: 0.007206383626908064\n","          model: {}\n","          policy_loss: -0.006680687423795462\n","          total_loss: 380.4615783691406\n","          vf_explained_var: -0.030309773981571198\n","          vf_loss: 380.467041015625\n","    num_agent_steps_sampled: 232000\n","    num_agent_steps_trained: 232000\n","    num_steps_sampled: 232000\n","    num_steps_trained: 232000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 58\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.423076923076925\n","    ram_util_percent: 15.599999999999998\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07500397732850911\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.700351013323901\n","    mean_inference_ms: 0.7632026884690916\n","    mean_raw_obs_processing_ms: 0.11305918419642591\n","  time_since_restore: 534.568103313446\n","  time_this_iter_s: 9.091984510421753\n","  time_total_s: 534.568103313446\n","  timers:\n","    learn_throughput: 1608.488\n","    learn_time_ms: 2486.807\n","    load_throughput: 8640922.95\n","    load_time_ms: 0.463\n","    sample_throughput: 408.583\n","    sample_time_ms: 9789.944\n","    update_time_ms: 2.943\n","  timestamp: 1649863635\n","  timesteps_since_restore: 232000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 232000\n","  training_iteration: 58\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:27:16 (running for 00:09:26.97)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         535.364</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">-384.918 </td><td style=\"text-align: right;\">            -4.41992</td><td style=\"text-align: right;\">            -924.494</td><td style=\"text-align: right;\">            146.03</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         537.359</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  18.7269</td><td style=\"text-align: right;\">           205.943  </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            476.96</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         534.568</td><td style=\"text-align: right;\">232000</td><td style=\"text-align: right;\"> 227.083 </td><td style=\"text-align: right;\">           309.246  </td><td style=\"text-align: right;\">            -244.494</td><td style=\"text-align: right;\">            387.13</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 296000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-27-17\n","  done: false\n","  episode_len_mean: 144.14\n","  episode_media: {}\n","  episode_reward_max: -4.419918560596486\n","  episode_reward_mean: -358.8827187035308\n","  episode_reward_min: -826.2080302769549\n","  episodes_this_iter: 31\n","  episodes_total: 2722\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 85.4152603149414\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5628148913383484\n","          entropy_coeff: 0.0\n","          kl: 0.034843068569898605\n","          model: {}\n","          policy_loss: 0.00855397991836071\n","          total_loss: 933.7427368164062\n","          vf_explained_var: 0.6496551036834717\n","          vf_loss: 930.758056640625\n","    num_agent_steps_sampled: 296000\n","    num_agent_steps_trained: 296000\n","    num_steps_sampled: 296000\n","    num_steps_trained: 296000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 74\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.3\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07034704126242865\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.27020586341395825\n","    mean_inference_ms: 0.7238197065105684\n","    mean_raw_obs_processing_ms: 0.1126466194664318\n","  time_since_restore: 542.8731637001038\n","  time_this_iter_s: 7.509428977966309\n","  time_total_s: 542.8731637001038\n","  timers:\n","    learn_throughput: 1567.468\n","    learn_time_ms: 2551.887\n","    load_throughput: 9172388.606\n","    load_time_ms: 0.436\n","    sample_throughput: 519.827\n","    sample_time_ms: 7694.87\n","    update_time_ms: 2.919\n","  timestamp: 1649863637\n","  timesteps_since_restore: 296000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 296000\n","  training_iteration: 74\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 204000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-27-22\n","  done: false\n","  episode_len_mean: 485.53\n","  episode_media: {}\n","  episode_reward_max: 226.52336192616522\n","  episode_reward_mean: 24.473499729099004\n","  episode_reward_min: -316.64103340249653\n","  episodes_this_iter: 10\n","  episodes_total: 712\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.005226492881775\n","          entropy_coeff: 0.0\n","          kl: 0.014425057917833328\n","          model: {}\n","          policy_loss: -0.0392540842294693\n","          total_loss: 280.7060546875\n","          vf_explained_var: 0.758820116519928\n","          vf_loss: 280.730712890625\n","    num_agent_steps_sampled: 204000\n","    num_agent_steps_trained: 204000\n","    num_steps_sampled: 204000\n","    num_steps_trained: 204000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 51\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.381250000000001\n","    ram_util_percent: 15.6\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07336704600401989\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.0594598370782682\n","    mean_inference_ms: 0.759440536435751\n","    mean_raw_obs_processing_ms: 0.11191792799745535\n","  time_since_restore: 548.4186887741089\n","  time_this_iter_s: 11.059861421585083\n","  time_total_s: 548.4186887741089\n","  timers:\n","    learn_throughput: 1587.074\n","    learn_time_ms: 2520.361\n","    load_throughput: 9531967.502\n","    load_time_ms: 0.42\n","    sample_throughput: 342.308\n","    sample_time_ms: 11685.373\n","    update_time_ms: 2.846\n","  timestamp: 1649863642\n","  timesteps_since_restore: 204000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 204000\n","  training_iteration: 51\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:27:22 (running for 00:09:32.54)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         542.873</td><td style=\"text-align: right;\">296000</td><td style=\"text-align: right;\">-358.883 </td><td style=\"text-align: right;\">            -4.41992</td><td style=\"text-align: right;\">            -826.208</td><td style=\"text-align: right;\">            144.14</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         548.419</td><td style=\"text-align: right;\">204000</td><td style=\"text-align: right;\">  24.4735</td><td style=\"text-align: right;\">           226.523  </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            485.53</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         534.568</td><td style=\"text-align: right;\">232000</td><td style=\"text-align: right;\"> 227.083 </td><td style=\"text-align: right;\">           309.246  </td><td style=\"text-align: right;\">            -244.494</td><td style=\"text-align: right;\">            387.13</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 300000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-27-25\n","  done: false\n","  episode_len_mean: 134.99\n","  episode_media: {}\n","  episode_reward_max: 12.62497930848302\n","  episode_reward_mean: -295.37313628282834\n","  episode_reward_min: -642.9417824093928\n","  episodes_this_iter: 35\n","  episodes_total: 2757\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 128.12289428710938\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.6264594793319702\n","          entropy_coeff: 0.0\n","          kl: 0.01360322441905737\n","          model: {}\n","          policy_loss: -0.0055753933265805244\n","          total_loss: 1629.40234375\n","          vf_explained_var: 0.5009399056434631\n","          vf_loss: 1627.6649169921875\n","    num_agent_steps_sampled: 300000\n","    num_agent_steps_trained: 300000\n","    num_steps_sampled: 300000\n","    num_steps_trained: 300000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 75\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.472727272727274\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07035402436831979\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2713001957030544\n","    mean_inference_ms: 0.7242092025663386\n","    mean_raw_obs_processing_ms: 0.11264763257842453\n","  time_since_restore: 550.4556310176849\n","  time_this_iter_s: 7.582467317581177\n","  time_total_s: 550.4556310176849\n","  timers:\n","    learn_throughput: 1565.414\n","    learn_time_ms: 2555.235\n","    load_throughput: 9397421.162\n","    load_time_ms: 0.426\n","    sample_throughput: 520.266\n","    sample_time_ms: 7688.38\n","    update_time_ms: 2.939\n","  timestamp: 1649863645\n","  timesteps_since_restore: 300000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 300000\n","  training_iteration: 75\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 236000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-27-25\n","  done: false\n","  episode_len_mean: 387.95\n","  episode_media: {}\n","  episode_reward_max: 309.24642649555864\n","  episode_reward_mean: 230.42502707806705\n","  episode_reward_min: -142.86982516535215\n","  episodes_this_iter: 10\n","  episodes_total: 885\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.16875000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7688747644424438\n","          entropy_coeff: 0.0\n","          kl: 0.005546923261135817\n","          model: {}\n","          policy_loss: -0.009050454013049603\n","          total_loss: 589.5602416992188\n","          vf_explained_var: 0.03414539992809296\n","          vf_loss: 589.568359375\n","    num_agent_steps_sampled: 236000\n","    num_agent_steps_trained: 236000\n","    num_steps_sampled: 236000\n","    num_steps_trained: 236000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 59\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.133333333333333\n","    ram_util_percent: 15.599999999999998\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07503377707527875\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.7027387858034924\n","    mean_inference_ms: 0.763584531103058\n","    mean_raw_obs_processing_ms: 0.11308558481235899\n","  time_since_restore: 544.6344194412231\n","  time_this_iter_s: 10.0663161277771\n","  time_total_s: 544.6344194412231\n","  timers:\n","    learn_throughput: 1602.349\n","    learn_time_ms: 2496.336\n","    load_throughput: 8934982.159\n","    load_time_ms: 0.448\n","    sample_throughput: 408.638\n","    sample_time_ms: 9788.613\n","    update_time_ms: 2.918\n","  timestamp: 1649863645\n","  timesteps_since_restore: 236000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 236000\n","  training_iteration: 59\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:27:27 (running for 00:09:38.08)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         550.456</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">-295.373 </td><td style=\"text-align: right;\">              12.625</td><td style=\"text-align: right;\">            -642.942</td><td style=\"text-align: right;\">            134.99</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         548.419</td><td style=\"text-align: right;\">204000</td><td style=\"text-align: right;\">  24.4735</td><td style=\"text-align: right;\">             226.523</td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            485.53</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         544.634</td><td style=\"text-align: right;\">236000</td><td style=\"text-align: right;\"> 230.425 </td><td style=\"text-align: right;\">             309.246</td><td style=\"text-align: right;\">            -142.87 </td><td style=\"text-align: right;\">            387.95</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 304000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-27-32\n","  done: false\n","  episode_len_mean: 112.54\n","  episode_media: {}\n","  episode_reward_max: 73.14765203479669\n","  episode_reward_mean: -250.48088428835524\n","  episode_reward_min: -599.3536846617175\n","  episodes_this_iter: 39\n","  episodes_total: 2796\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 128.12289428710938\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.6250656247138977\n","          entropy_coeff: 0.0\n","          kl: 0.005807908251881599\n","          model: {}\n","          policy_loss: 0.0008002737304195762\n","          total_loss: 2183.120849609375\n","          vf_explained_var: 0.7519524097442627\n","          vf_loss: 2182.375732421875\n","    num_agent_steps_sampled: 304000\n","    num_agent_steps_trained: 304000\n","    num_steps_sampled: 304000\n","    num_steps_trained: 304000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 76\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 11.681818181818182\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07034119697981424\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2715566345292025\n","    mean_inference_ms: 0.7243613154862159\n","    mean_raw_obs_processing_ms: 0.11262984089360362\n","  time_since_restore: 557.6082437038422\n","  time_this_iter_s: 7.152612686157227\n","  time_total_s: 557.6082437038422\n","  timers:\n","    learn_throughput: 1563.7\n","    learn_time_ms: 2558.035\n","    load_throughput: 9429640.288\n","    load_time_ms: 0.424\n","    sample_throughput: 523.18\n","    sample_time_ms: 7645.559\n","    update_time_ms: 2.973\n","  timestamp: 1649863652\n","  timesteps_since_restore: 304000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 304000\n","  training_iteration: 76\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:27:33 (running for 00:09:43.45)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         557.608</td><td style=\"text-align: right;\">304000</td><td style=\"text-align: right;\">-250.481 </td><td style=\"text-align: right;\">             73.1477</td><td style=\"text-align: right;\">            -599.354</td><td style=\"text-align: right;\">            112.54</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         548.419</td><td style=\"text-align: right;\">204000</td><td style=\"text-align: right;\">  24.4735</td><td style=\"text-align: right;\">            226.523 </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            485.53</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         544.634</td><td style=\"text-align: right;\">236000</td><td style=\"text-align: right;\"> 230.425 </td><td style=\"text-align: right;\">            309.246 </td><td style=\"text-align: right;\">            -142.87 </td><td style=\"text-align: right;\">            387.95</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 240000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-27-34\n","  done: false\n","  episode_len_mean: 383.73\n","  episode_media: {}\n","  episode_reward_max: 309.24642649555864\n","  episode_reward_mean: 231.75834256877755\n","  episode_reward_min: -142.86982516535215\n","  episodes_this_iter: 13\n","  episodes_total: 898\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.16875000298023224\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6713573932647705\n","          entropy_coeff: 0.0\n","          kl: 0.0040675015188753605\n","          model: {}\n","          policy_loss: -0.011936478316783905\n","          total_loss: 638.3372192382812\n","          vf_explained_var: -0.052118826657533646\n","          vf_loss: 638.3485107421875\n","    num_agent_steps_sampled: 240000\n","    num_agent_steps_trained: 240000\n","    num_steps_sampled: 240000\n","    num_steps_trained: 240000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 60\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.675000000000002\n","    ram_util_percent: 15.6\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0750675679138481\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.705342010718596\n","    mean_inference_ms: 0.7640076766800544\n","    mean_raw_obs_processing_ms: 0.1131158074602304\n","  time_since_restore: 553.3665995597839\n","  time_this_iter_s: 8.732180118560791\n","  time_total_s: 553.3665995597839\n","  timers:\n","    learn_throughput: 1595.015\n","    learn_time_ms: 2507.814\n","    load_throughput: 8952145.563\n","    load_time_ms: 0.447\n","    sample_throughput: 408.944\n","    sample_time_ms: 9781.302\n","    update_time_ms: 3.305\n","  timestamp: 1649863654\n","  timesteps_since_restore: 240000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 240000\n","  training_iteration: 60\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 208000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-27-35\n","  done: false\n","  episode_len_mean: 503.71\n","  episode_media: {}\n","  episode_reward_max: 226.52336192616522\n","  episode_reward_mean: 29.113075868317548\n","  episode_reward_min: -316.64103340249653\n","  episodes_this_iter: 6\n","  episodes_total: 718\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.0416548252105713\n","          entropy_coeff: 0.0\n","          kl: 0.008886847645044327\n","          model: {}\n","          policy_loss: -0.03214544057846069\n","          total_loss: 164.59280395507812\n","          vf_explained_var: 0.8805651664733887\n","          vf_loss: 164.615966796875\n","    num_agent_steps_sampled: 208000\n","    num_agent_steps_trained: 208000\n","    num_steps_sampled: 208000\n","    num_steps_trained: 208000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 52\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.18888888888889\n","    ram_util_percent: 15.600000000000001\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07339636767203903\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.0632136593498616\n","    mean_inference_ms: 0.7598949689124679\n","    mean_raw_obs_processing_ms: 0.11195003021032855\n","  time_since_restore: 561.3824872970581\n","  time_this_iter_s: 12.963798522949219\n","  time_total_s: 561.3824872970581\n","  timers:\n","    learn_throughput: 1586.178\n","    learn_time_ms: 2521.785\n","    load_throughput: 9506582.049\n","    load_time_ms: 0.421\n","    sample_throughput: 334.519\n","    sample_time_ms: 11957.469\n","    update_time_ms: 2.749\n","  timestamp: 1649863655\n","  timesteps_since_restore: 208000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 208000\n","  training_iteration: 52\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:27:38 (running for 00:09:48.55)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         557.608</td><td style=\"text-align: right;\">304000</td><td style=\"text-align: right;\">-250.481 </td><td style=\"text-align: right;\">             73.1477</td><td style=\"text-align: right;\">            -599.354</td><td style=\"text-align: right;\">            112.54</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         561.382</td><td style=\"text-align: right;\">208000</td><td style=\"text-align: right;\">  29.1131</td><td style=\"text-align: right;\">            226.523 </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            503.71</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         553.367</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> 231.758 </td><td style=\"text-align: right;\">            309.246 </td><td style=\"text-align: right;\">            -142.87 </td><td style=\"text-align: right;\">            383.73</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 308000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-27-39\n","  done: false\n","  episode_len_mean: 114.85\n","  episode_media: {}\n","  episode_reward_max: 73.14765203479669\n","  episode_reward_mean: -221.7368046217479\n","  episode_reward_min: -548.0436262363197\n","  episodes_this_iter: 31\n","  episodes_total: 2827\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 128.12289428710938\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5952939987182617\n","          entropy_coeff: 0.0\n","          kl: 0.04139188677072525\n","          model: {}\n","          policy_loss: 0.012357122264802456\n","          total_loss: 720.1080932617188\n","          vf_explained_var: 0.7267812490463257\n","          vf_loss: 714.79248046875\n","    num_agent_steps_sampled: 308000\n","    num_agent_steps_trained: 308000\n","    num_steps_sampled: 308000\n","    num_steps_trained: 308000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 77\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.2\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07034906160676938\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2716241919419429\n","    mean_inference_ms: 0.7245787424503244\n","    mean_raw_obs_processing_ms: 0.11264018417435441\n","  time_since_restore: 565.2268803119659\n","  time_this_iter_s: 7.618636608123779\n","  time_total_s: 565.2268803119659\n","  timers:\n","    learn_throughput: 1572.61\n","    learn_time_ms: 2543.542\n","    load_throughput: 9502274.581\n","    load_time_ms: 0.421\n","    sample_throughput: 523.112\n","    sample_time_ms: 7646.546\n","    update_time_ms: 2.904\n","  timestamp: 1649863659\n","  timesteps_since_restore: 308000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 308000\n","  training_iteration: 77\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 244000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-27-43\n","  done: false\n","  episode_len_mean: 348.23\n","  episode_media: {}\n","  episode_reward_max: 302.87137554651747\n","  episode_reward_mean: 240.90243506341344\n","  episode_reward_min: -142.86982516535215\n","  episodes_this_iter: 13\n","  episodes_total: 911\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.08437500149011612\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6871737837791443\n","          entropy_coeff: 0.0\n","          kl: 0.006316880229860544\n","          model: {}\n","          policy_loss: -0.010672823525965214\n","          total_loss: 257.2535095214844\n","          vf_explained_var: 0.04198930412530899\n","          vf_loss: 257.2636413574219\n","    num_agent_steps_sampled: 244000\n","    num_agent_steps_trained: 244000\n","    num_steps_sampled: 244000\n","    num_steps_trained: 244000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 61\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.484615384615383\n","    ram_util_percent: 15.599999999999998\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07508896890226567\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.7058643703763733\n","    mean_inference_ms: 0.7642403275546263\n","    mean_raw_obs_processing_ms: 0.11313487701382428\n","  time_since_restore: 562.1398236751556\n","  time_this_iter_s: 8.773224115371704\n","  time_total_s: 562.1398236751556\n","  timers:\n","    learn_throughput: 1605.629\n","    learn_time_ms: 2491.236\n","    load_throughput: 8411740.286\n","    load_time_ms: 0.476\n","    sample_throughput: 417.882\n","    sample_time_ms: 9572.085\n","    update_time_ms: 3.261\n","  timestamp: 1649863663\n","  timesteps_since_restore: 244000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 244000\n","  training_iteration: 61\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:27:43 (running for 00:09:53.66)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">         565.227</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">-221.737 </td><td style=\"text-align: right;\">             73.1477</td><td style=\"text-align: right;\">            -548.044</td><td style=\"text-align: right;\">            114.85</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         561.382</td><td style=\"text-align: right;\">208000</td><td style=\"text-align: right;\">  29.1131</td><td style=\"text-align: right;\">            226.523 </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            503.71</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         562.14 </td><td style=\"text-align: right;\">244000</td><td style=\"text-align: right;\"> 240.902 </td><td style=\"text-align: right;\">            302.871 </td><td style=\"text-align: right;\">            -142.87 </td><td style=\"text-align: right;\">            348.23</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 212000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-27-47\n","  done: false\n","  episode_len_mean: 528.8\n","  episode_media: {}\n","  episode_reward_max: 226.52336192616522\n","  episode_reward_mean: 31.88834900219547\n","  episode_reward_min: -316.64103340249653\n","  episodes_this_iter: 6\n","  episodes_total: 724\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.0134074687957764\n","          entropy_coeff: 0.0\n","          kl: 0.014833656139671803\n","          model: {}\n","          policy_loss: -0.04699864238500595\n","          total_loss: 267.412841796875\n","          vf_explained_var: 0.7309482097625732\n","          vf_loss: 267.44482421875\n","    num_agent_steps_sampled: 212000\n","    num_agent_steps_trained: 212000\n","    num_steps_sampled: 212000\n","    num_steps_trained: 212000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 53\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.041176470588237\n","    ram_util_percent: 15.6\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07342453723436987\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.0674197211143284\n","    mean_inference_ms: 0.760333639949953\n","    mean_raw_obs_processing_ms: 0.11197925705193945\n","  time_since_restore: 573.130945444107\n","  time_this_iter_s: 11.74845814704895\n","  time_total_s: 573.130945444107\n","  timers:\n","    learn_throughput: 1585.635\n","    learn_time_ms: 2522.649\n","    load_throughput: 8934030.566\n","    load_time_ms: 0.448\n","    sample_throughput: 336.432\n","    sample_time_ms: 11889.472\n","    update_time_ms: 2.773\n","  timestamp: 1649863667\n","  timesteps_since_restore: 212000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 212000\n","  training_iteration: 53\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 312000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-27-47\n","  done: false\n","  episode_len_mean: 116.15\n","  episode_media: {}\n","  episode_reward_max: 73.14765203479669\n","  episode_reward_mean: -244.56003808558538\n","  episode_reward_min: -579.3887820102541\n","  episodes_this_iter: 34\n","  episodes_total: 2861\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 192.18434143066406\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.601697564125061\n","          entropy_coeff: 0.0\n","          kl: 0.017448237165808678\n","          model: {}\n","          policy_loss: 0.01039840467274189\n","          total_loss: 1125.9317626953125\n","          vf_explained_var: 0.8137500286102295\n","          vf_loss: 1122.5682373046875\n","    num_agent_steps_sampled: 312000\n","    num_agent_steps_trained: 312000\n","    num_steps_sampled: 312000\n","    num_steps_trained: 312000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 78\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.07272727272727\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07036425248726612\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2718436649022112\n","    mean_inference_ms: 0.7247879851401444\n","    mean_raw_obs_processing_ms: 0.11265814381047874\n","  time_since_restore: 572.8095593452454\n","  time_this_iter_s: 7.582679033279419\n","  time_total_s: 572.8095593452454\n","  timers:\n","    learn_throughput: 1573.144\n","    learn_time_ms: 2542.68\n","    load_throughput: 8998721.304\n","    load_time_ms: 0.445\n","    sample_throughput: 524.062\n","    sample_time_ms: 7632.685\n","    update_time_ms: 2.89\n","  timestamp: 1649863667\n","  timesteps_since_restore: 312000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 312000\n","  training_iteration: 78\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:27:48 (running for 00:09:58.72)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         572.81 </td><td style=\"text-align: right;\">312000</td><td style=\"text-align: right;\">-244.56  </td><td style=\"text-align: right;\">             73.1477</td><td style=\"text-align: right;\">            -579.389</td><td style=\"text-align: right;\">            116.15</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         573.131</td><td style=\"text-align: right;\">212000</td><td style=\"text-align: right;\">  31.8883</td><td style=\"text-align: right;\">            226.523 </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            528.8 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         562.14 </td><td style=\"text-align: right;\">244000</td><td style=\"text-align: right;\"> 240.902 </td><td style=\"text-align: right;\">            302.871 </td><td style=\"text-align: right;\">            -142.87 </td><td style=\"text-align: right;\">            348.23</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 248000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-27-51\n","  done: false\n","  episode_len_mean: 325.06\n","  episode_media: {}\n","  episode_reward_max: 302.87137554651747\n","  episode_reward_mean: 243.80508344105922\n","  episode_reward_min: -106.62117211778029\n","  episodes_this_iter: 14\n","  episodes_total: 925\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.08437500149011612\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7476730346679688\n","          entropy_coeff: 0.0\n","          kl: 0.013486352749168873\n","          model: {}\n","          policy_loss: -0.019548814743757248\n","          total_loss: 561.4811401367188\n","          vf_explained_var: 0.1588766723871231\n","          vf_loss: 561.49951171875\n","    num_agent_steps_sampled: 248000\n","    num_agent_steps_trained: 248000\n","    num_steps_sampled: 248000\n","    num_steps_trained: 248000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 62\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.608333333333334\n","    ram_util_percent: 15.6\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07510987639268887\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.7047224896974339\n","    mean_inference_ms: 0.7644384853553006\n","    mean_raw_obs_processing_ms: 0.11315210382571557\n","  time_since_restore: 570.5631580352783\n","  time_this_iter_s: 8.42333436012268\n","  time_total_s: 570.5631580352783\n","  timers:\n","    learn_throughput: 1604.696\n","    learn_time_ms: 2492.684\n","    load_throughput: 8469919.225\n","    load_time_ms: 0.472\n","    sample_throughput: 430.843\n","    sample_time_ms: 9284.129\n","    update_time_ms: 3.237\n","  timestamp: 1649863671\n","  timesteps_since_restore: 248000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 248000\n","  training_iteration: 62\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:27:53 (running for 00:10:04.12)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         572.81 </td><td style=\"text-align: right;\">312000</td><td style=\"text-align: right;\">-244.56  </td><td style=\"text-align: right;\">             73.1477</td><td style=\"text-align: right;\">            -579.389</td><td style=\"text-align: right;\">            116.15</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         573.131</td><td style=\"text-align: right;\">212000</td><td style=\"text-align: right;\">  31.8883</td><td style=\"text-align: right;\">            226.523 </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            528.8 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         570.563</td><td style=\"text-align: right;\">248000</td><td style=\"text-align: right;\"> 243.805 </td><td style=\"text-align: right;\">            302.871 </td><td style=\"text-align: right;\">            -106.621</td><td style=\"text-align: right;\">            325.06</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 316000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-27-55\n","  done: false\n","  episode_len_mean: 123.83\n","  episode_media: {}\n","  episode_reward_max: 13.698157065629871\n","  episode_reward_mean: -252.85811099682607\n","  episode_reward_min: -579.3887820102541\n","  episodes_this_iter: 32\n","  episodes_total: 2893\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 192.18434143066406\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5956446528434753\n","          entropy_coeff: 0.0\n","          kl: 0.020946534350514412\n","          model: {}\n","          policy_loss: 0.006584010552614927\n","          total_loss: 1020.8880615234375\n","          vf_explained_var: 0.6911259293556213\n","          vf_loss: 1016.8558959960938\n","    num_agent_steps_sampled: 316000\n","    num_agent_steps_trained: 316000\n","    num_steps_sampled: 316000\n","    num_steps_trained: 316000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 79\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.29090909090909\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07039660152250753\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.27229406759024277\n","    mean_inference_ms: 0.725095422099824\n","    mean_raw_obs_processing_ms: 0.11270132853116904\n","  time_since_restore: 580.3162281513214\n","  time_this_iter_s: 7.50666880607605\n","  time_total_s: 580.3162281513214\n","  timers:\n","    learn_throughput: 1579.146\n","    learn_time_ms: 2533.015\n","    load_throughput: 9048711.504\n","    load_time_ms: 0.442\n","    sample_throughput: 524.452\n","    sample_time_ms: 7627.013\n","    update_time_ms: 2.886\n","  timestamp: 1649863675\n","  timesteps_since_restore: 316000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 316000\n","  training_iteration: 79\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 216000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-27-58\n","  done: false\n","  episode_len_mean: 544.68\n","  episode_media: {}\n","  episode_reward_max: 226.52336192616522\n","  episode_reward_mean: 31.0290902959385\n","  episode_reward_min: -316.64103340249653\n","  episodes_this_iter: 8\n","  episodes_total: 732\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.964478075504303\n","          entropy_coeff: 0.0\n","          kl: 0.013835558667778969\n","          model: {}\n","          policy_loss: -0.041140470653772354\n","          total_loss: 220.49838256835938\n","          vf_explained_var: 0.7241665124893188\n","          vf_loss: 220.52549743652344\n","    num_agent_steps_sampled: 216000\n","    num_agent_steps_trained: 216000\n","    num_steps_sampled: 216000\n","    num_steps_trained: 216000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 54\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.40625\n","    ram_util_percent: 15.6\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07345826686019702\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.0730867534463513\n","    mean_inference_ms: 0.7608838012505598\n","    mean_raw_obs_processing_ms: 0.11201293313727606\n","  time_since_restore: 584.6044793128967\n","  time_this_iter_s: 11.473533868789673\n","  time_total_s: 584.6044793128967\n","  timers:\n","    learn_throughput: 1596.352\n","    learn_time_ms: 2505.713\n","    load_throughput: 8715436.883\n","    load_time_ms: 0.459\n","    sample_throughput: 336.527\n","    sample_time_ms: 11886.124\n","    update_time_ms: 2.737\n","  timestamp: 1649863678\n","  timesteps_since_restore: 216000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 216000\n","  training_iteration: 54\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:27:59 (running for 00:10:09.85)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         580.316</td><td style=\"text-align: right;\">316000</td><td style=\"text-align: right;\">-252.858 </td><td style=\"text-align: right;\">             13.6982</td><td style=\"text-align: right;\">            -579.389</td><td style=\"text-align: right;\">            123.83</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         584.604</td><td style=\"text-align: right;\">216000</td><td style=\"text-align: right;\">  31.0291</td><td style=\"text-align: right;\">            226.523 </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            544.68</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         570.563</td><td style=\"text-align: right;\">248000</td><td style=\"text-align: right;\"> 243.805 </td><td style=\"text-align: right;\">            302.871 </td><td style=\"text-align: right;\">            -106.621</td><td style=\"text-align: right;\">            325.06</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 252000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-28-00\n","  done: false\n","  episode_len_mean: 318.71\n","  episode_media: {}\n","  episode_reward_max: 305.7607637040405\n","  episode_reward_mean: 245.57560425193316\n","  episode_reward_min: -106.62117211778029\n","  episodes_this_iter: 14\n","  episodes_total: 939\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.08437500149011612\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6899255514144897\n","          entropy_coeff: 0.0\n","          kl: 0.006811574567109346\n","          model: {}\n","          policy_loss: -0.005255486350506544\n","          total_loss: 599.9716186523438\n","          vf_explained_var: 0.08626671135425568\n","          vf_loss: 599.9761962890625\n","    num_agent_steps_sampled: 252000\n","    num_agent_steps_trained: 252000\n","    num_steps_sampled: 252000\n","    num_steps_trained: 252000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 63\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.35\n","    ram_util_percent: 15.6\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07512493622897491\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.7031809641789863\n","    mean_inference_ms: 0.764579804084701\n","    mean_raw_obs_processing_ms: 0.11316449619899208\n","  time_since_restore: 579.163932800293\n","  time_this_iter_s: 8.600774765014648\n","  time_total_s: 579.163932800293\n","  timers:\n","    learn_throughput: 1612.18\n","    learn_time_ms: 2481.113\n","    load_throughput: 8671292.123\n","    load_time_ms: 0.461\n","    sample_throughput: 441.427\n","    sample_time_ms: 9061.516\n","    update_time_ms: 3.244\n","  timestamp: 1649863680\n","  timesteps_since_restore: 252000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 252000\n","  training_iteration: 63\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 320000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-28-02\n","  done: false\n","  episode_len_mean: 120.88\n","  episode_media: {}\n","  episode_reward_max: 13.698157065629871\n","  episode_reward_mean: -273.97510122343317\n","  episode_reward_min: -596.8922103850064\n","  episodes_this_iter: 32\n","  episodes_total: 2925\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 288.2764892578125\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.586280345916748\n","          entropy_coeff: 0.0\n","          kl: 0.020912960171699524\n","          model: {}\n","          policy_loss: 0.013560865074396133\n","          total_loss: 609.01611328125\n","          vf_explained_var: 0.7609451413154602\n","          vf_loss: 602.973876953125\n","    num_agent_steps_sampled: 320000\n","    num_agent_steps_trained: 320000\n","    num_steps_sampled: 320000\n","    num_steps_trained: 320000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 80\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.118181818181817\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0704279140207622\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2726693267541209\n","    mean_inference_ms: 0.7253849986139406\n","    mean_raw_obs_processing_ms: 0.11274908389833477\n","  time_since_restore: 587.8421688079834\n","  time_this_iter_s: 7.525940656661987\n","  time_total_s: 587.8421688079834\n","  timers:\n","    learn_throughput: 1584.881\n","    learn_time_ms: 2523.849\n","    load_throughput: 8838952.637\n","    load_time_ms: 0.453\n","    sample_throughput: 524.98\n","    sample_time_ms: 7619.345\n","    update_time_ms: 2.861\n","  timestamp: 1649863682\n","  timesteps_since_restore: 320000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 320000\n","  training_iteration: 80\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:28:05 (running for 00:10:15.91)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         587.842</td><td style=\"text-align: right;\">320000</td><td style=\"text-align: right;\">-273.975 </td><td style=\"text-align: right;\">             13.6982</td><td style=\"text-align: right;\">            -596.892</td><td style=\"text-align: right;\">            120.88</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         584.604</td><td style=\"text-align: right;\">216000</td><td style=\"text-align: right;\">  31.0291</td><td style=\"text-align: right;\">            226.523 </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            544.68</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         579.164</td><td style=\"text-align: right;\">252000</td><td style=\"text-align: right;\"> 245.576 </td><td style=\"text-align: right;\">            305.761 </td><td style=\"text-align: right;\">            -106.621</td><td style=\"text-align: right;\">            318.71</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 256000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-28-08\n","  done: false\n","  episode_len_mean: 311.75\n","  episode_media: {}\n","  episode_reward_max: 305.7607637040405\n","  episode_reward_mean: 246.13279734858332\n","  episode_reward_min: -106.62117211778029\n","  episodes_this_iter: 13\n","  episodes_total: 952\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.08437500149011612\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6699208617210388\n","          entropy_coeff: 0.0\n","          kl: 0.010061414912343025\n","          model: {}\n","          policy_loss: -0.008798344992101192\n","          total_loss: 166.10699462890625\n","          vf_explained_var: 0.08715666830539703\n","          vf_loss: 166.11492919921875\n","    num_agent_steps_sampled: 256000\n","    num_agent_steps_trained: 256000\n","    num_steps_sampled: 256000\n","    num_steps_trained: 256000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 64\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.808333333333332\n","    ram_util_percent: 15.6\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0751349716132366\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.7015914304937664\n","    mean_inference_ms: 0.7646673305205599\n","    mean_raw_obs_processing_ms: 0.11316945384127884\n","  time_since_restore: 587.4419286251068\n","  time_this_iter_s: 8.277995824813843\n","  time_total_s: 587.4419286251068\n","  timers:\n","    learn_throughput: 1613.831\n","    learn_time_ms: 2478.574\n","    load_throughput: 8700521.703\n","    load_time_ms: 0.46\n","    sample_throughput: 448.629\n","    sample_time_ms: 8916.056\n","    update_time_ms: 3.309\n","  timestamp: 1649863688\n","  timesteps_since_restore: 256000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 256000\n","  training_iteration: 64\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 220000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-28-10\n","  done: false\n","  episode_len_mean: 551.45\n","  episode_media: {}\n","  episode_reward_max: 226.52336192616522\n","  episode_reward_mean: 32.52187883805107\n","  episode_reward_min: -316.64103340249653\n","  episodes_this_iter: 7\n","  episodes_total: 739\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.9785606265068054\n","          entropy_coeff: 0.0\n","          kl: 0.015430116094648838\n","          model: {}\n","          policy_loss: -0.034016191959381104\n","          total_loss: 57.809207916259766\n","          vf_explained_var: 0.9169095158576965\n","          vf_loss: 57.82760238647461\n","    num_agent_steps_sampled: 220000\n","    num_agent_steps_trained: 220000\n","    num_steps_sampled: 220000\n","    num_steps_trained: 220000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 55\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.31764705882353\n","    ram_util_percent: 15.6\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07349095991959337\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.0779833712986127\n","    mean_inference_ms: 0.7613663975188242\n","    mean_raw_obs_processing_ms: 0.11203839105595308\n","  time_since_restore: 596.3829674720764\n","  time_this_iter_s: 11.778488159179688\n","  time_total_s: 596.3829674720764\n","  timers:\n","    learn_throughput: 1587.155\n","    learn_time_ms: 2520.233\n","    load_throughput: 8165287.39\n","    load_time_ms: 0.49\n","    sample_throughput: 336.584\n","    sample_time_ms: 11884.089\n","    update_time_ms: 2.741\n","  timestamp: 1649863690\n","  timesteps_since_restore: 220000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 220000\n","  training_iteration: 55\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 324000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-28-10\n","  done: false\n","  episode_len_mean: 126.65\n","  episode_media: {}\n","  episode_reward_max: 35.11157675038308\n","  episode_reward_mean: -276.0992627175719\n","  episode_reward_min: -657.4378101527757\n","  episodes_this_iter: 30\n","  episodes_total: 2955\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 432.4147644042969\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5898340344429016\n","          entropy_coeff: 0.0\n","          kl: 0.030367493629455566\n","          model: {}\n","          policy_loss: 0.009642285294830799\n","          total_loss: 1574.457763671875\n","          vf_explained_var: 0.6372987627983093\n","          vf_loss: 1561.316650390625\n","    num_agent_steps_sampled: 324000\n","    num_agent_steps_trained: 324000\n","    num_steps_sampled: 324000\n","    num_steps_trained: 324000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 81\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.79090909090909\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0704455795785171\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2733016075930085\n","    mean_inference_ms: 0.7255181174082708\n","    mean_raw_obs_processing_ms: 0.11277833122745634\n","  time_since_restore: 595.6378519535065\n","  time_this_iter_s: 7.795683145523071\n","  time_total_s: 595.6378519535065\n","  timers:\n","    learn_throughput: 1574.16\n","    learn_time_ms: 2541.038\n","    load_throughput: 8875894.614\n","    load_time_ms: 0.451\n","    sample_throughput: 524.007\n","    sample_time_ms: 7633.486\n","    update_time_ms: 2.855\n","  timestamp: 1649863690\n","  timesteps_since_restore: 324000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 324000\n","  training_iteration: 81\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:28:11 (running for 00:10:21.69)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         595.638</td><td style=\"text-align: right;\">324000</td><td style=\"text-align: right;\">-276.099 </td><td style=\"text-align: right;\">             35.1116</td><td style=\"text-align: right;\">            -657.438</td><td style=\"text-align: right;\">            126.65</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         596.383</td><td style=\"text-align: right;\">220000</td><td style=\"text-align: right;\">  32.5219</td><td style=\"text-align: right;\">            226.523 </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            551.45</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         587.442</td><td style=\"text-align: right;\">256000</td><td style=\"text-align: right;\"> 246.133 </td><td style=\"text-align: right;\">            305.761 </td><td style=\"text-align: right;\">            -106.621</td><td style=\"text-align: right;\">            311.75</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:28:16 (running for 00:10:26.79)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         595.638</td><td style=\"text-align: right;\">324000</td><td style=\"text-align: right;\">-276.099 </td><td style=\"text-align: right;\">             35.1116</td><td style=\"text-align: right;\">            -657.438</td><td style=\"text-align: right;\">            126.65</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         596.383</td><td style=\"text-align: right;\">220000</td><td style=\"text-align: right;\">  32.5219</td><td style=\"text-align: right;\">            226.523 </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            551.45</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         587.442</td><td style=\"text-align: right;\">256000</td><td style=\"text-align: right;\"> 246.133 </td><td style=\"text-align: right;\">            305.761 </td><td style=\"text-align: right;\">            -106.621</td><td style=\"text-align: right;\">            311.75</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 328000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-28-17\n","  done: false\n","  episode_len_mean: 128.71\n","  episode_media: {}\n","  episode_reward_max: 35.11157675038308\n","  episode_reward_mean: -289.76577410192385\n","  episode_reward_min: -657.4378101527757\n","  episodes_this_iter: 30\n","  episodes_total: 2985\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 648.6221313476562\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5469083189964294\n","          entropy_coeff: 0.0\n","          kl: 0.06287165731191635\n","          model: {}\n","          policy_loss: 0.01617056131362915\n","          total_loss: 928.0872802734375\n","          vf_explained_var: 0.6742607951164246\n","          vf_loss: 887.2911987304688\n","    num_agent_steps_sampled: 328000\n","    num_agent_steps_trained: 328000\n","    num_steps_sampled: 328000\n","    num_steps_trained: 328000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 82\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.47272727272727\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07044703091570755\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.27394984821267654\n","    mean_inference_ms: 0.7254553854720746\n","    mean_raw_obs_processing_ms: 0.11278064780239358\n","  time_since_restore: 603.0266735553741\n","  time_this_iter_s: 7.388821601867676\n","  time_total_s: 603.0266735553741\n","  timers:\n","    learn_throughput: 1569.492\n","    learn_time_ms: 2548.596\n","    load_throughput: 9204090.41\n","    load_time_ms: 0.435\n","    sample_throughput: 526.403\n","    sample_time_ms: 7598.748\n","    update_time_ms: 2.869\n","  timestamp: 1649863697\n","  timesteps_since_restore: 328000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 328000\n","  training_iteration: 82\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 260000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-28-18\n","  done: false\n","  episode_len_mean: 317.52\n","  episode_media: {}\n","  episode_reward_max: 311.30423527970953\n","  episode_reward_mean: 244.22541622921918\n","  episode_reward_min: -106.62117211778029\n","  episodes_this_iter: 12\n","  episodes_total: 964\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.08437500149011612\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.645204484462738\n","          entropy_coeff: 0.0\n","          kl: 0.010916435159742832\n","          model: {}\n","          policy_loss: -0.011834174394607544\n","          total_loss: 662.0587768554688\n","          vf_explained_var: 0.1557389199733734\n","          vf_loss: 662.0697631835938\n","    num_agent_steps_sampled: 260000\n","    num_agent_steps_trained: 260000\n","    num_steps_sampled: 260000\n","    num_steps_trained: 260000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 65\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.861538461538458\n","    ram_util_percent: 15.599999999999998\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07514236804084758\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.7004146179472643\n","    mean_inference_ms: 0.76475630449738\n","    mean_raw_obs_processing_ms: 0.11317248285321943\n","  time_since_restore: 596.7370820045471\n","  time_this_iter_s: 9.295153379440308\n","  time_total_s: 596.7370820045471\n","  timers:\n","    learn_throughput: 1604.827\n","    learn_time_ms: 2492.481\n","    load_throughput: 8641368.014\n","    load_time_ms: 0.463\n","    sample_throughput: 449.295\n","    sample_time_ms: 8902.839\n","    update_time_ms: 3.296\n","  timestamp: 1649863698\n","  timesteps_since_restore: 260000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 260000\n","  training_iteration: 65\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:28:22 (running for 00:10:32.42)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">         603.027</td><td style=\"text-align: right;\">328000</td><td style=\"text-align: right;\">-289.766 </td><td style=\"text-align: right;\">             35.1116</td><td style=\"text-align: right;\">            -657.438</td><td style=\"text-align: right;\">            128.71</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         596.383</td><td style=\"text-align: right;\">220000</td><td style=\"text-align: right;\">  32.5219</td><td style=\"text-align: right;\">            226.523 </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            551.45</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         596.737</td><td style=\"text-align: right;\">260000</td><td style=\"text-align: right;\"> 244.225 </td><td style=\"text-align: right;\">            311.304 </td><td style=\"text-align: right;\">            -106.621</td><td style=\"text-align: right;\">            317.52</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 224000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-28-23\n","  done: false\n","  episode_len_mean: 576.46\n","  episode_media: {}\n","  episode_reward_max: 226.52336192616522\n","  episode_reward_mean: 36.73146208802231\n","  episode_reward_min: -316.64103340249653\n","  episodes_this_iter: 6\n","  episodes_total: 745\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.9660242199897766\n","          entropy_coeff: 0.0\n","          kl: 0.01071405690163374\n","          model: {}\n","          policy_loss: -0.03237609192728996\n","          total_loss: 216.06881713867188\n","          vf_explained_var: 0.6860013008117676\n","          vf_loss: 216.09036254882812\n","    num_agent_steps_sampled: 224000\n","    num_agent_steps_trained: 224000\n","    num_steps_sampled: 224000\n","    num_steps_trained: 224000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 56\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.194444444444443\n","    ram_util_percent: 15.600000000000001\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07352129751073401\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.0826895219718065\n","    mean_inference_ms: 0.7618192434961588\n","    mean_raw_obs_processing_ms: 0.11206378909986073\n","  time_since_restore: 608.994624376297\n","  time_this_iter_s: 12.611656904220581\n","  time_total_s: 608.994624376297\n","  timers:\n","    learn_throughput: 1592.658\n","    learn_time_ms: 2511.525\n","    load_throughput: 8134802.172\n","    load_time_ms: 0.492\n","    sample_throughput: 335.37\n","    sample_time_ms: 11927.108\n","    update_time_ms: 2.783\n","  timestamp: 1649863703\n","  timesteps_since_restore: 224000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 224000\n","  training_iteration: 56\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 332000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-28-25\n","  done: false\n","  episode_len_mean: 130.33\n","  episode_media: {}\n","  episode_reward_max: 35.11157675038308\n","  episode_reward_mean: -293.4866883522857\n","  episode_reward_min: -657.4378101527757\n","  episodes_this_iter: 32\n","  episodes_total: 3017\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 972.9332275390625\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5130624175071716\n","          entropy_coeff: 0.0\n","          kl: 0.02625104784965515\n","          model: {}\n","          policy_loss: 0.0044427430257201195\n","          total_loss: 1023.6572875976562\n","          vf_explained_var: 0.6544057130813599\n","          vf_loss: 998.1123046875\n","    num_agent_steps_sampled: 332000\n","    num_agent_steps_trained: 332000\n","    num_steps_sampled: 332000\n","    num_steps_trained: 332000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 83\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.9\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0704335712631279\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.27466201448891536\n","    mean_inference_ms: 0.7252768545041142\n","    mean_raw_obs_processing_ms: 0.11275815257015825\n","  time_since_restore: 610.4458637237549\n","  time_this_iter_s: 7.419190168380737\n","  time_total_s: 610.4458637237549\n","  timers:\n","    learn_throughput: 1573.696\n","    learn_time_ms: 2541.787\n","    load_throughput: 9184942.516\n","    load_time_ms: 0.435\n","    sample_throughput: 529.362\n","    sample_time_ms: 7556.267\n","    update_time_ms: 2.89\n","  timestamp: 1649863705\n","  timesteps_since_restore: 332000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 332000\n","  training_iteration: 83\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 264000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-28-26\n","  done: false\n","  episode_len_mean: 301.04\n","  episode_media: {}\n","  episode_reward_max: 311.30423527970953\n","  episode_reward_mean: 245.59198287213124\n","  episode_reward_min: -106.62117211778029\n","  episodes_this_iter: 15\n","  episodes_total: 979\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.08437500149011612\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7321339845657349\n","          entropy_coeff: 0.0\n","          kl: 0.00950116291642189\n","          model: {}\n","          policy_loss: -0.014760822057723999\n","          total_loss: 499.3940124511719\n","          vf_explained_var: 0.16513049602508545\n","          vf_loss: 499.4079895019531\n","    num_agent_steps_sampled: 264000\n","    num_agent_steps_trained: 264000\n","    num_steps_sampled: 264000\n","    num_steps_trained: 264000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 66\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.615384615384617\n","    ram_util_percent: 15.599999999999998\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07514535629489526\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6986370429363989\n","    mean_inference_ms: 0.7647757845168088\n","    mean_raw_obs_processing_ms: 0.11316924270389535\n","  time_since_restore: 605.2831838130951\n","  time_this_iter_s: 8.546101808547974\n","  time_total_s: 605.2831838130951\n","  timers:\n","    learn_throughput: 1611.728\n","    learn_time_ms: 2481.808\n","    load_throughput: 9000652.361\n","    load_time_ms: 0.444\n","    sample_throughput: 450.121\n","    sample_time_ms: 8886.504\n","    update_time_ms: 3.285\n","  timestamp: 1649863706\n","  timesteps_since_restore: 264000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 264000\n","  training_iteration: 66\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:28:27 (running for 00:10:38.08)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">         610.446</td><td style=\"text-align: right;\">332000</td><td style=\"text-align: right;\">-293.487 </td><td style=\"text-align: right;\">             35.1116</td><td style=\"text-align: right;\">            -657.438</td><td style=\"text-align: right;\">            130.33</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         608.995</td><td style=\"text-align: right;\">224000</td><td style=\"text-align: right;\">  36.7315</td><td style=\"text-align: right;\">            226.523 </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            576.46</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">         605.283</td><td style=\"text-align: right;\">264000</td><td style=\"text-align: right;\"> 245.592 </td><td style=\"text-align: right;\">            311.304 </td><td style=\"text-align: right;\">            -106.621</td><td style=\"text-align: right;\">            301.04</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 336000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-28-32\n","  done: false\n","  episode_len_mean: 131.1\n","  episode_media: {}\n","  episode_reward_max: 35.11157675038308\n","  episode_reward_mean: -287.2759620357126\n","  episode_reward_min: -693.0252379846446\n","  episodes_this_iter: 30\n","  episodes_total: 3047\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1459.3997802734375\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5264681577682495\n","          entropy_coeff: 0.0\n","          kl: 0.040327779948711395\n","          model: {}\n","          policy_loss: 0.009932165034115314\n","          total_loss: 930.94921875\n","          vf_explained_var: 0.6814413070678711\n","          vf_loss: 872.0849609375\n","    num_agent_steps_sampled: 336000\n","    num_agent_steps_trained: 336000\n","    num_steps_sampled: 336000\n","    num_steps_trained: 336000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 84\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 11.92727272727273\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07041412960158043\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.275233812572933\n","    mean_inference_ms: 0.7250630315733904\n","    mean_raw_obs_processing_ms: 0.11272515303215325\n","  time_since_restore: 617.8877239227295\n","  time_this_iter_s: 7.441860198974609\n","  time_total_s: 617.8877239227295\n","  timers:\n","    learn_throughput: 1576.495\n","    learn_time_ms: 2537.274\n","    load_throughput: 9274304.035\n","    load_time_ms: 0.431\n","    sample_throughput: 529.954\n","    sample_time_ms: 7547.832\n","    update_time_ms: 2.926\n","  timestamp: 1649863712\n","  timesteps_since_restore: 336000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 336000\n","  training_iteration: 84\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:28:33 (running for 00:10:44.07)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         617.888</td><td style=\"text-align: right;\">336000</td><td style=\"text-align: right;\">-287.276 </td><td style=\"text-align: right;\">             35.1116</td><td style=\"text-align: right;\">            -693.025</td><td style=\"text-align: right;\">            131.1 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         608.995</td><td style=\"text-align: right;\">224000</td><td style=\"text-align: right;\">  36.7315</td><td style=\"text-align: right;\">            226.523 </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            576.46</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">         605.283</td><td style=\"text-align: right;\">264000</td><td style=\"text-align: right;\"> 245.592 </td><td style=\"text-align: right;\">            311.304 </td><td style=\"text-align: right;\">            -106.621</td><td style=\"text-align: right;\">            301.04</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 228000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-28-34\n","  done: false\n","  episode_len_mean: 581.03\n","  episode_media: {}\n","  episode_reward_max: 226.52336192616522\n","  episode_reward_mean: 35.986299566728874\n","  episode_reward_min: -316.64103340249653\n","  episodes_this_iter: 7\n","  episodes_total: 752\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.9996743202209473\n","          entropy_coeff: 0.0\n","          kl: 0.014220251701772213\n","          model: {}\n","          policy_loss: -0.04129960015416145\n","          total_loss: 539.5943603515625\n","          vf_explained_var: 0.8001739978790283\n","          vf_loss: 539.6212768554688\n","    num_agent_steps_sampled: 228000\n","    num_agent_steps_trained: 228000\n","    num_steps_sampled: 228000\n","    num_steps_trained: 228000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 57\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.194117647058825\n","    ram_util_percent: 15.6\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07355319089570472\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.0881862051496018\n","    mean_inference_ms: 0.7623112749038792\n","    mean_raw_obs_processing_ms: 0.11208853769615958\n","  time_since_restore: 620.831060886383\n","  time_this_iter_s: 11.83643651008606\n","  time_total_s: 620.831060886383\n","  timers:\n","    learn_throughput: 1586.411\n","    learn_time_ms: 2521.414\n","    load_throughput: 8034295.566\n","    load_time_ms: 0.498\n","    sample_throughput: 336.069\n","    sample_time_ms: 11902.32\n","    update_time_ms: 2.841\n","  timestamp: 1649863714\n","  timesteps_since_restore: 228000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 228000\n","  training_iteration: 57\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 268000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-28-35\n","  done: false\n","  episode_len_mean: 296.04\n","  episode_media: {}\n","  episode_reward_max: 311.30423527970953\n","  episode_reward_mean: 243.11216534525977\n","  episode_reward_min: -106.62117211778029\n","  episodes_this_iter: 16\n","  episodes_total: 995\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.08437500149011612\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7002349495887756\n","          entropy_coeff: 0.0\n","          kl: 0.01154037844389677\n","          model: {}\n","          policy_loss: -0.013706691563129425\n","          total_loss: 346.7245178222656\n","          vf_explained_var: 0.19626875221729279\n","          vf_loss: 346.73724365234375\n","    num_agent_steps_sampled: 268000\n","    num_agent_steps_trained: 268000\n","    num_steps_sampled: 268000\n","    num_steps_trained: 268000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 67\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.281818181818183\n","    ram_util_percent: 15.6\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07513421368184316\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6962643817070965\n","    mean_inference_ms: 0.7646492905389439\n","    mean_raw_obs_processing_ms: 0.11315209590953686\n","  time_since_restore: 613.6132788658142\n","  time_this_iter_s: 8.330095052719116\n","  time_total_s: 613.6132788658142\n","  timers:\n","    learn_throughput: 1601.028\n","    learn_time_ms: 2498.395\n","    load_throughput: 8978495.13\n","    load_time_ms: 0.446\n","    sample_throughput: 452.625\n","    sample_time_ms: 8837.329\n","    update_time_ms: 3.307\n","  timestamp: 1649863715\n","  timesteps_since_restore: 268000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 268000\n","  training_iteration: 67\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:28:39 (running for 00:10:49.44)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         617.888</td><td style=\"text-align: right;\">336000</td><td style=\"text-align: right;\">-287.276 </td><td style=\"text-align: right;\">             35.1116</td><td style=\"text-align: right;\">            -693.025</td><td style=\"text-align: right;\">            131.1 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         620.831</td><td style=\"text-align: right;\">228000</td><td style=\"text-align: right;\">  35.9863</td><td style=\"text-align: right;\">            226.523 </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            581.03</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         613.613</td><td style=\"text-align: right;\">268000</td><td style=\"text-align: right;\"> 243.112 </td><td style=\"text-align: right;\">            311.304 </td><td style=\"text-align: right;\">            -106.621</td><td style=\"text-align: right;\">            296.04</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 340000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-28-40\n","  done: false\n","  episode_len_mean: 126.59\n","  episode_media: {}\n","  episode_reward_max: 36.434505641294066\n","  episode_reward_mean: -252.1505158161253\n","  episode_reward_min: -693.0252379846446\n","  episodes_this_iter: 33\n","  episodes_total: 3080\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 2189.099609375\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.549392580986023\n","          entropy_coeff: 0.0\n","          kl: 0.023873118683695793\n","          model: {}\n","          policy_loss: 0.008381075225770473\n","          total_loss: 1005.069091796875\n","          vf_explained_var: 0.5999234914779663\n","          vf_loss: 952.8001098632812\n","    num_agent_steps_sampled: 340000\n","    num_agent_steps_trained: 340000\n","    num_steps_sampled: 340000\n","    num_steps_trained: 340000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 85\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.218181818181819\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07040936586960553\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2756174369551054\n","    mean_inference_ms: 0.7250645061517548\n","    mean_raw_obs_processing_ms: 0.1127141521461326\n","  time_since_restore: 625.27405834198\n","  time_this_iter_s: 7.386334419250488\n","  time_total_s: 625.27405834198\n","  timers:\n","    learn_throughput: 1588.946\n","    learn_time_ms: 2517.391\n","    load_throughput: 8852010.763\n","    load_time_ms: 0.452\n","    sample_throughput: 530.165\n","    sample_time_ms: 7544.821\n","    update_time_ms: 2.903\n","  timestamp: 1649863720\n","  timesteps_since_restore: 340000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 340000\n","  training_iteration: 85\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 272000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-28-43\n","  done: false\n","  episode_len_mean: 287.17\n","  episode_media: {}\n","  episode_reward_max: 311.30423527970953\n","  episode_reward_mean: 245.46382345371418\n","  episode_reward_min: -106.62117211778029\n","  episodes_this_iter: 12\n","  episodes_total: 1007\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.08437500149011612\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5811670422554016\n","          entropy_coeff: 0.0\n","          kl: 0.005766548682004213\n","          model: {}\n","          policy_loss: -0.011146549135446548\n","          total_loss: 528.3341064453125\n","          vf_explained_var: 0.17976687848567963\n","          vf_loss: 528.3447875976562\n","    num_agent_steps_sampled: 272000\n","    num_agent_steps_trained: 272000\n","    num_steps_sampled: 272000\n","    num_steps_trained: 272000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 68\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 11.991666666666667\n","    ram_util_percent: 15.6\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07512684185979754\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6944572385534141\n","    mean_inference_ms: 0.7645283843577018\n","    mean_raw_obs_processing_ms: 0.1131341539525016\n","  time_since_restore: 622.0045778751373\n","  time_this_iter_s: 8.39129900932312\n","  time_total_s: 622.0045778751373\n","  timers:\n","    learn_throughput: 1605.162\n","    learn_time_ms: 2491.96\n","    load_throughput: 8974172.773\n","    load_time_ms: 0.446\n","    sample_throughput: 455.058\n","    sample_time_ms: 8790.097\n","    update_time_ms: 3.28\n","  timestamp: 1649863723\n","  timesteps_since_restore: 272000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 272000\n","  training_iteration: 68\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:28:44 (running for 00:10:54.80)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         625.274</td><td style=\"text-align: right;\">340000</td><td style=\"text-align: right;\">-252.151 </td><td style=\"text-align: right;\">             36.4345</td><td style=\"text-align: right;\">            -693.025</td><td style=\"text-align: right;\">            126.59</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         620.831</td><td style=\"text-align: right;\">228000</td><td style=\"text-align: right;\">  35.9863</td><td style=\"text-align: right;\">            226.523 </td><td style=\"text-align: right;\">            -316.641</td><td style=\"text-align: right;\">            581.03</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">         622.005</td><td style=\"text-align: right;\">272000</td><td style=\"text-align: right;\"> 245.464 </td><td style=\"text-align: right;\">            311.304 </td><td style=\"text-align: right;\">            -106.621</td><td style=\"text-align: right;\">            287.17</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 232000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-28-45\n","  done: false\n","  episode_len_mean: 537.35\n","  episode_media: {}\n","  episode_reward_max: 226.52336192616522\n","  episode_reward_mean: 24.50292930849394\n","  episode_reward_min: -342.70656154965684\n","  episodes_this_iter: 13\n","  episodes_total: 765\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.0119422674179077\n","          entropy_coeff: 0.0\n","          kl: 0.017954887822270393\n","          model: {}\n","          policy_loss: -0.04463637247681618\n","          total_loss: 2371.5712890625\n","          vf_explained_var: 0.6947697997093201\n","          vf_loss: 2371.59765625\n","    num_agent_steps_sampled: 232000\n","    num_agent_steps_trained: 232000\n","    num_steps_sampled: 232000\n","    num_steps_trained: 232000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 58\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.88125\n","    ram_util_percent: 15.6\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.073607071063758\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.0970275268031302\n","    mean_inference_ms: 0.7630701241304262\n","    mean_raw_obs_processing_ms: 0.11212836478610257\n","  time_since_restore: 631.6662509441376\n","  time_this_iter_s: 10.835190057754517\n","  time_total_s: 631.6662509441376\n","  timers:\n","    learn_throughput: 1592.586\n","    learn_time_ms: 2511.639\n","    load_throughput: 8007835.426\n","    load_time_ms: 0.5\n","    sample_throughput: 335.963\n","    sample_time_ms: 11906.07\n","    update_time_ms: 2.867\n","  timestamp: 1649863725\n","  timesteps_since_restore: 232000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 232000\n","  training_iteration: 58\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 344000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-28-47\n","  done: false\n","  episode_len_mean: 121.12\n","  episode_media: {}\n","  episode_reward_max: 36.434505641294066\n","  episode_reward_mean: -245.08305187371244\n","  episode_reward_min: -693.0252379846446\n","  episodes_this_iter: 36\n","  episodes_total: 3116\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 3283.649658203125\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5354980230331421\n","          entropy_coeff: 0.0\n","          kl: 0.029385782778263092\n","          model: {}\n","          policy_loss: 0.007365953642874956\n","          total_loss: 845.3006591796875\n","          vf_explained_var: 0.7062342762947083\n","          vf_loss: 748.8006591796875\n","    num_agent_steps_sampled: 344000\n","    num_agent_steps_trained: 344000\n","    num_steps_sampled: 344000\n","    num_steps_trained: 344000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 86\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.1\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0704195303965235\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2759034606614048\n","    mean_inference_ms: 0.7252228161655053\n","    mean_raw_obs_processing_ms: 0.11272928823477248\n","  time_since_restore: 632.6988008022308\n","  time_this_iter_s: 7.4247424602508545\n","  time_total_s: 632.6988008022308\n","  timers:\n","    learn_throughput: 1592.607\n","    learn_time_ms: 2511.605\n","    load_throughput: 9012256.124\n","    load_time_ms: 0.444\n","    sample_throughput: 529.257\n","    sample_time_ms: 7557.765\n","    update_time_ms: 2.873\n","  timestamp: 1649863727\n","  timesteps_since_restore: 344000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 344000\n","  training_iteration: 86\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:28:49 (running for 00:11:00.03)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         632.699</td><td style=\"text-align: right;\">344000</td><td style=\"text-align: right;\">-245.083 </td><td style=\"text-align: right;\">             36.4345</td><td style=\"text-align: right;\">            -693.025</td><td style=\"text-align: right;\">            121.12</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         631.666</td><td style=\"text-align: right;\">232000</td><td style=\"text-align: right;\">  24.5029</td><td style=\"text-align: right;\">            226.523 </td><td style=\"text-align: right;\">            -342.707</td><td style=\"text-align: right;\">            537.35</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">         622.005</td><td style=\"text-align: right;\">272000</td><td style=\"text-align: right;\"> 245.464 </td><td style=\"text-align: right;\">            311.304 </td><td style=\"text-align: right;\">            -106.621</td><td style=\"text-align: right;\">            287.17</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 276000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-28-52\n","  done: false\n","  episode_len_mean: 294.27\n","  episode_media: {}\n","  episode_reward_max: 311.7699589355473\n","  episode_reward_mean: 244.4118805043305\n","  episode_reward_min: -140.33819224187178\n","  episodes_this_iter: 13\n","  episodes_total: 1020\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.08437500149011612\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7091432213783264\n","          entropy_coeff: 0.0\n","          kl: 0.04053459316492081\n","          model: {}\n","          policy_loss: -0.029162144288420677\n","          total_loss: 404.3692626953125\n","          vf_explained_var: 0.2628331780433655\n","          vf_loss: 404.39495849609375\n","    num_agent_steps_sampled: 276000\n","    num_agent_steps_trained: 276000\n","    num_steps_sampled: 276000\n","    num_steps_trained: 276000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 69\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.346153846153847\n","    ram_util_percent: 15.599999999999998\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07511692921576275\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6926090825637553\n","    mean_inference_ms: 0.7643703193474244\n","    mean_raw_obs_processing_ms: 0.1131092735099925\n","  time_since_restore: 630.5552830696106\n","  time_this_iter_s: 8.550705194473267\n","  time_total_s: 630.5552830696106\n","  timers:\n","    learn_throughput: 1621.866\n","    learn_time_ms: 2466.296\n","    load_throughput: 8401209.815\n","    load_time_ms: 0.476\n","    sample_throughput: 462.044\n","    sample_time_ms: 8657.193\n","    update_time_ms: 3.258\n","  timestamp: 1649863732\n","  timesteps_since_restore: 276000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 276000\n","  training_iteration: 69\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 348000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-28-54\n","  done: false\n","  episode_len_mean: 118.08\n","  episode_media: {}\n","  episode_reward_max: 36.434505641294066\n","  episode_reward_mean: -230.8827817878218\n","  episode_reward_min: -547.0627069974596\n","  episodes_this_iter: 33\n","  episodes_total: 3149\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 4925.47412109375\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.55536949634552\n","          entropy_coeff: 0.0\n","          kl: 0.025967534631490707\n","          model: {}\n","          policy_loss: 0.007213003467768431\n","          total_loss: 1215.368408203125\n","          vf_explained_var: 0.538192868232727\n","          vf_loss: 1087.4588623046875\n","    num_agent_steps_sampled: 348000\n","    num_agent_steps_trained: 348000\n","    num_steps_sampled: 348000\n","    num_steps_trained: 348000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 87\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.27\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07043126449003281\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.27584271400868904\n","    mean_inference_ms: 0.725343001189396\n","    mean_raw_obs_processing_ms: 0.11274814870565984\n","  time_since_restore: 639.7716665267944\n","  time_this_iter_s: 7.072865724563599\n","  time_total_s: 639.7716665267944\n","  timers:\n","    learn_throughput: 1595.404\n","    learn_time_ms: 2507.202\n","    load_throughput: 8988596.839\n","    load_time_ms: 0.445\n","    sample_throughput: 533.282\n","    sample_time_ms: 7500.715\n","    update_time_ms: 2.871\n","  timestamp: 1649863734\n","  timesteps_since_restore: 348000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 348000\n","  training_iteration: 87\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:28:54 (running for 00:11:05.07)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">         639.772</td><td style=\"text-align: right;\">348000</td><td style=\"text-align: right;\">-230.883 </td><td style=\"text-align: right;\">             36.4345</td><td style=\"text-align: right;\">            -547.063</td><td style=\"text-align: right;\">            118.08</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         631.666</td><td style=\"text-align: right;\">232000</td><td style=\"text-align: right;\">  24.5029</td><td style=\"text-align: right;\">            226.523 </td><td style=\"text-align: right;\">            -342.707</td><td style=\"text-align: right;\">            537.35</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         630.555</td><td style=\"text-align: right;\">276000</td><td style=\"text-align: right;\"> 244.412 </td><td style=\"text-align: right;\">            311.77  </td><td style=\"text-align: right;\">            -140.338</td><td style=\"text-align: right;\">            294.27</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 236000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-28-57\n","  done: false\n","  episode_len_mean: 498.28\n","  episode_media: {}\n","  episode_reward_max: 226.52336192616522\n","  episode_reward_mean: 18.41045193085759\n","  episode_reward_min: -342.70656154965684\n","  episodes_this_iter: 10\n","  episodes_total: 775\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.003845453262329\n","          entropy_coeff: 0.0\n","          kl: 0.014023702591657639\n","          model: {}\n","          policy_loss: -0.045579247176647186\n","          total_loss: 181.99485778808594\n","          vf_explained_var: 0.8571452498435974\n","          vf_loss: 182.0262451171875\n","    num_agent_steps_sampled: 236000\n","    num_agent_steps_trained: 236000\n","    num_steps_sampled: 236000\n","    num_steps_trained: 236000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 59\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.01764705882353\n","    ram_util_percent: 15.6\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07364394028595664\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1029603215974018\n","    mean_inference_ms: 0.7635583222934993\n","    mean_raw_obs_processing_ms: 0.11215596963516729\n","  time_since_restore: 643.4181799888611\n","  time_this_iter_s: 11.75192904472351\n","  time_total_s: 643.4181799888611\n","  timers:\n","    learn_throughput: 1598.669\n","    learn_time_ms: 2502.081\n","    load_throughput: 8025072.228\n","    load_time_ms: 0.498\n","    sample_throughput: 337.053\n","    sample_time_ms: 11867.565\n","    update_time_ms: 2.864\n","  timestamp: 1649863737\n","  timesteps_since_restore: 236000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 236000\n","  training_iteration: 59\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:29:00 (running for 00:11:10.94)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">         639.772</td><td style=\"text-align: right;\">348000</td><td style=\"text-align: right;\">-230.883 </td><td style=\"text-align: right;\">             36.4345</td><td style=\"text-align: right;\">            -547.063</td><td style=\"text-align: right;\">            118.08</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         643.418</td><td style=\"text-align: right;\">236000</td><td style=\"text-align: right;\">  18.4105</td><td style=\"text-align: right;\">            226.523 </td><td style=\"text-align: right;\">            -342.707</td><td style=\"text-align: right;\">            498.28</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         630.555</td><td style=\"text-align: right;\">276000</td><td style=\"text-align: right;\"> 244.412 </td><td style=\"text-align: right;\">            311.77  </td><td style=\"text-align: right;\">            -140.338</td><td style=\"text-align: right;\">            294.27</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 280000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-29-00\n","  done: false\n","  episode_len_mean: 290.43\n","  episode_media: {}\n","  episode_reward_max: 311.7699589355473\n","  episode_reward_mean: 245.784306035197\n","  episode_reward_min: -140.33819224187178\n","  episodes_this_iter: 14\n","  episodes_total: 1034\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6081445813179016\n","          entropy_coeff: 0.0\n","          kl: 0.008162551559507847\n","          model: {}\n","          policy_loss: -0.014095361344516277\n","          total_loss: 549.232421875\n","          vf_explained_var: 0.23434828221797943\n","          vf_loss: 549.2454223632812\n","    num_agent_steps_sampled: 280000\n","    num_agent_steps_trained: 280000\n","    num_steps_sampled: 280000\n","    num_steps_trained: 280000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 70\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.633333333333333\n","    ram_util_percent: 15.6\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07511233772608089\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6906484866804454\n","    mean_inference_ms: 0.7642630852456793\n","    mean_raw_obs_processing_ms: 0.1130926449192025\n","  time_since_restore: 639.3118722438812\n","  time_this_iter_s: 8.75658917427063\n","  time_total_s: 639.3118722438812\n","  timers:\n","    learn_throughput: 1627.008\n","    learn_time_ms: 2458.501\n","    load_throughput: 8399527.386\n","    load_time_ms: 0.476\n","    sample_throughput: 462.864\n","    sample_time_ms: 8641.838\n","    update_time_ms: 2.891\n","  timestamp: 1649863740\n","  timesteps_since_restore: 280000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 280000\n","  training_iteration: 70\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 352000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-29-02\n","  done: false\n","  episode_len_mean: 122.86\n","  episode_media: {}\n","  episode_reward_max: 29.476083536228856\n","  episode_reward_mean: -267.94025775348234\n","  episode_reward_min: -667.9194983816868\n","  episodes_this_iter: 29\n","  episodes_total: 3178\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 7388.21142578125\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.524929404258728\n","          entropy_coeff: 0.0\n","          kl: 0.023460352793335915\n","          model: {}\n","          policy_loss: 0.004548833705484867\n","          total_loss: 1985.820068359375\n","          vf_explained_var: 0.7152194380760193\n","          vf_loss: 1812.4854736328125\n","    num_agent_steps_sampled: 352000\n","    num_agent_steps_trained: 352000\n","    num_steps_sampled: 352000\n","    num_steps_trained: 352000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 88\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.200000000000001\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0704424904061178\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.27584167608501636\n","    mean_inference_ms: 0.7254830358078153\n","    mean_raw_obs_processing_ms: 0.11276151811497542\n","  time_since_restore: 647.3660397529602\n","  time_this_iter_s: 7.5943732261657715\n","  time_total_s: 647.3660397529602\n","  timers:\n","    learn_throughput: 1596.093\n","    learn_time_ms: 2506.119\n","    load_throughput: 9616654.821\n","    load_time_ms: 0.416\n","    sample_throughput: 533.415\n","    sample_time_ms: 7498.849\n","    update_time_ms: 2.894\n","  timestamp: 1649863742\n","  timesteps_since_restore: 352000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 352000\n","  training_iteration: 88\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:29:06 (running for 00:11:16.70)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         647.366</td><td style=\"text-align: right;\">352000</td><td style=\"text-align: right;\">-267.94  </td><td style=\"text-align: right;\">             29.4761</td><td style=\"text-align: right;\">            -667.919</td><td style=\"text-align: right;\">            122.86</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         643.418</td><td style=\"text-align: right;\">236000</td><td style=\"text-align: right;\">  18.4105</td><td style=\"text-align: right;\">            226.523 </td><td style=\"text-align: right;\">            -342.707</td><td style=\"text-align: right;\">            498.28</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">         639.312</td><td style=\"text-align: right;\">280000</td><td style=\"text-align: right;\"> 245.784 </td><td style=\"text-align: right;\">            311.77  </td><td style=\"text-align: right;\">            -140.338</td><td style=\"text-align: right;\">            290.43</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 240000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-29-08\n","  done: false\n","  episode_len_mean: 496.05\n","  episode_media: {}\n","  episode_reward_max: 226.52336192616522\n","  episode_reward_mean: 18.667107467534098\n","  episode_reward_min: -342.70656154965684\n","  episodes_this_iter: 10\n","  episodes_total: 785\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.9679450988769531\n","          entropy_coeff: 0.0\n","          kl: 0.01094615925103426\n","          model: {}\n","          policy_loss: -0.03708590567111969\n","          total_loss: 377.57427978515625\n","          vf_explained_var: 0.7967149019241333\n","          vf_loss: 377.60028076171875\n","    num_agent_steps_sampled: 240000\n","    num_agent_steps_trained: 240000\n","    num_steps_sampled: 240000\n","    num_steps_trained: 240000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 60\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.413333333333332\n","    ram_util_percent: 15.599999999999998\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07367984591525553\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1080608494274506\n","    mean_inference_ms: 0.7639981265758163\n","    mean_raw_obs_processing_ms: 0.11218389048648554\n","  time_since_restore: 654.493893623352\n","  time_this_iter_s: 11.075713634490967\n","  time_total_s: 654.493893623352\n","  timers:\n","    learn_throughput: 1592.818\n","    learn_time_ms: 2511.273\n","    load_throughput: 8200408.622\n","    load_time_ms: 0.488\n","    sample_throughput: 340.594\n","    sample_time_ms: 11744.204\n","    update_time_ms: 2.882\n","  timestamp: 1649863748\n","  timesteps_since_restore: 240000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 240000\n","  training_iteration: 60\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 284000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-29-09\n","  done: false\n","  episode_len_mean: 286.99\n","  episode_media: {}\n","  episode_reward_max: 311.7699589355473\n","  episode_reward_mean: 244.546238824732\n","  episode_reward_min: -140.33819224187178\n","  episodes_this_iter: 16\n","  episodes_total: 1050\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6849274635314941\n","          entropy_coeff: 0.0\n","          kl: 0.00817675981670618\n","          model: {}\n","          policy_loss: -0.013416663743555546\n","          total_loss: 526.2178955078125\n","          vf_explained_var: 0.3176431655883789\n","          vf_loss: 526.230224609375\n","    num_agent_steps_sampled: 284000\n","    num_agent_steps_trained: 284000\n","    num_steps_sampled: 284000\n","    num_steps_trained: 284000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 71\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.83846153846154\n","    ram_util_percent: 15.599999999999998\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07511148338854645\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6884359799877318\n","    mean_inference_ms: 0.7641918125162954\n","    mean_raw_obs_processing_ms: 0.1130807823294764\n","  time_since_restore: 647.857253074646\n","  time_this_iter_s: 8.54538083076477\n","  time_total_s: 647.857253074646\n","  timers:\n","    learn_throughput: 1611.907\n","    learn_time_ms: 2481.533\n","    load_throughput: 8496083.456\n","    load_time_ms: 0.471\n","    sample_throughput: 465.8\n","    sample_time_ms: 8587.383\n","    update_time_ms: 2.88\n","  timestamp: 1649863749\n","  timesteps_since_restore: 284000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 284000\n","  training_iteration: 71\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 356000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-29-09\n","  done: false\n","  episode_len_mean: 121.98\n","  episode_media: {}\n","  episode_reward_max: 29.476083536228856\n","  episode_reward_mean: -238.83321159471842\n","  episode_reward_min: -667.9194983816868\n","  episodes_this_iter: 35\n","  episodes_total: 3213\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 11082.3173828125\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5302408337593079\n","          entropy_coeff: 0.0\n","          kl: 0.03222735971212387\n","          model: {}\n","          policy_loss: 0.01592780463397503\n","          total_loss: 1085.2822265625\n","          vf_explained_var: 0.5236365795135498\n","          vf_loss: 728.1124877929688\n","    num_agent_steps_sampled: 356000\n","    num_agent_steps_trained: 356000\n","    num_steps_sampled: 356000\n","    num_steps_trained: 356000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 89\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.563636363636363\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07044291778018671\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.27575163465739594\n","    mean_inference_ms: 0.725524203986034\n","    mean_raw_obs_processing_ms: 0.11275293671945633\n","  time_since_restore: 654.7033095359802\n","  time_this_iter_s: 7.3372697830200195\n","  time_total_s: 654.7033095359802\n","  timers:\n","    learn_throughput: 1584.869\n","    learn_time_ms: 2523.868\n","    load_throughput: 9504427.827\n","    load_time_ms: 0.421\n","    sample_throughput: 535.96\n","    sample_time_ms: 7463.246\n","    update_time_ms: 2.901\n","  timestamp: 1649863749\n","  timesteps_since_restore: 356000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 356000\n","  training_iteration: 89\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:29:11 (running for 00:11:22.08)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         654.703</td><td style=\"text-align: right;\">356000</td><td style=\"text-align: right;\">-238.833 </td><td style=\"text-align: right;\">             29.4761</td><td style=\"text-align: right;\">            -667.919</td><td style=\"text-align: right;\">            121.98</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         654.494</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  18.6671</td><td style=\"text-align: right;\">            226.523 </td><td style=\"text-align: right;\">            -342.707</td><td style=\"text-align: right;\">            496.05</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         647.857</td><td style=\"text-align: right;\">284000</td><td style=\"text-align: right;\"> 244.546 </td><td style=\"text-align: right;\">            311.77  </td><td style=\"text-align: right;\">            -140.338</td><td style=\"text-align: right;\">            286.99</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:29:16 (running for 00:11:27.08)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         654.703</td><td style=\"text-align: right;\">356000</td><td style=\"text-align: right;\">-238.833 </td><td style=\"text-align: right;\">             29.4761</td><td style=\"text-align: right;\">            -667.919</td><td style=\"text-align: right;\">            121.98</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         654.494</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  18.6671</td><td style=\"text-align: right;\">            226.523 </td><td style=\"text-align: right;\">            -342.707</td><td style=\"text-align: right;\">            496.05</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         647.857</td><td style=\"text-align: right;\">284000</td><td style=\"text-align: right;\"> 244.546 </td><td style=\"text-align: right;\">            311.77  </td><td style=\"text-align: right;\">            -140.338</td><td style=\"text-align: right;\">            286.99</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 360000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-29-17\n","  done: false\n","  episode_len_mean: 126.6\n","  episode_media: {}\n","  episode_reward_max: 29.476083536228856\n","  episode_reward_mean: -241.65714224911937\n","  episode_reward_min: -667.9194983816868\n","  episodes_this_iter: 31\n","  episodes_total: 3244\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 16623.4765625\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5303845405578613\n","          entropy_coeff: 0.0\n","          kl: 0.031394798308610916\n","          model: {}\n","          policy_loss: 0.002196543151512742\n","          total_loss: 1551.8306884765625\n","          vf_explained_var: 0.6548646092414856\n","          vf_loss: 1029.937744140625\n","    num_agent_steps_sampled: 360000\n","    num_agent_steps_trained: 360000\n","    num_steps_sampled: 360000\n","    num_steps_trained: 360000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 90\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 10.979999999999999\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07043731592636839\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2758709502023551\n","    mean_inference_ms: 0.7254780241728054\n","    mean_raw_obs_processing_ms: 0.11273317194196913\n","  time_since_restore: 662.0388071537018\n","  time_this_iter_s: 7.335497617721558\n","  time_total_s: 662.0388071537018\n","  timers:\n","    learn_throughput: 1579.896\n","    learn_time_ms: 2531.812\n","    load_throughput: 9523851.045\n","    load_time_ms: 0.42\n","    sample_throughput: 536.682\n","    sample_time_ms: 7453.207\n","    update_time_ms: 2.916\n","  timestamp: 1649863757\n","  timesteps_since_restore: 360000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 360000\n","  training_iteration: 90\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 288000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-29-18\n","  done: false\n","  episode_len_mean: 277.21\n","  episode_media: {}\n","  episode_reward_max: 311.7699589355473\n","  episode_reward_mean: 249.42410126593597\n","  episode_reward_min: -140.33819224187178\n","  episodes_this_iter: 13\n","  episodes_total: 1063\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6315964460372925\n","          entropy_coeff: 0.0\n","          kl: 0.0093690762296319\n","          model: {}\n","          policy_loss: -0.01624474860727787\n","          total_loss: 204.8961181640625\n","          vf_explained_var: 0.2563305199146271\n","          vf_loss: 204.9111785888672\n","    num_agent_steps_sampled: 288000\n","    num_agent_steps_trained: 288000\n","    num_steps_sampled: 288000\n","    num_steps_trained: 288000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 72\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.674999999999999\n","    ram_util_percent: 15.6\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07510687246856391\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6865657503203813\n","    mean_inference_ms: 0.7640682806882801\n","    mean_raw_obs_processing_ms: 0.1130641421307832\n","  time_since_restore: 656.4325459003448\n","  time_this_iter_s: 8.575292825698853\n","  time_total_s: 656.4325459003448\n","  timers:\n","    learn_throughput: 1604.937\n","    learn_time_ms: 2492.31\n","    load_throughput: 8108068.819\n","    load_time_ms: 0.493\n","    sample_throughput: 464.271\n","    sample_time_ms: 8615.654\n","    update_time_ms: 2.942\n","  timestamp: 1649863758\n","  timesteps_since_restore: 288000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 288000\n","  training_iteration: 72\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 244000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-29-19\n","  done: false\n","  episode_len_mean: 495.96\n","  episode_media: {}\n","  episode_reward_max: 226.52336192616522\n","  episode_reward_mean: 20.49590893977532\n","  episode_reward_min: -342.70656154965684\n","  episodes_this_iter: 7\n","  episodes_total: 792\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 1.0032637119293213\n","          entropy_coeff: 0.0\n","          kl: 0.015812668949365616\n","          model: {}\n","          policy_loss: -0.04391951858997345\n","          total_loss: 338.3273620605469\n","          vf_explained_var: 0.8353220224380493\n","          vf_loss: 338.35528564453125\n","    num_agent_steps_sampled: 244000\n","    num_agent_steps_trained: 244000\n","    num_steps_sampled: 244000\n","    num_steps_trained: 244000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 61\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.34375\n","    ram_util_percent: 15.6125\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07370275856749478\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.11128445840348\n","    mean_inference_ms: 0.7642763504554319\n","    mean_raw_obs_processing_ms: 0.11220162064443745\n","  time_since_restore: 665.023291349411\n","  time_this_iter_s: 10.52939772605896\n","  time_total_s: 665.023291349411\n","  timers:\n","    learn_throughput: 1590.905\n","    learn_time_ms: 2514.292\n","    load_throughput: 8299389.562\n","    load_time_ms: 0.482\n","    sample_throughput: 341.929\n","    sample_time_ms: 11698.34\n","    update_time_ms: 2.837\n","  timestamp: 1649863759\n","  timesteps_since_restore: 244000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 244000\n","  training_iteration: 61\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:29:22 (running for 00:11:32.56)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         662.039</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">-241.657 </td><td style=\"text-align: right;\">             29.4761</td><td style=\"text-align: right;\">            -667.919</td><td style=\"text-align: right;\">            126.6 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         665.023</td><td style=\"text-align: right;\">244000</td><td style=\"text-align: right;\">  20.4959</td><td style=\"text-align: right;\">            226.523 </td><td style=\"text-align: right;\">            -342.707</td><td style=\"text-align: right;\">            495.96</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         656.433</td><td style=\"text-align: right;\">288000</td><td style=\"text-align: right;\"> 249.424 </td><td style=\"text-align: right;\">            311.77  </td><td style=\"text-align: right;\">            -140.338</td><td style=\"text-align: right;\">            277.21</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 364000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-29-24\n","  done: false\n","  episode_len_mean: 127.09\n","  episode_media: {}\n","  episode_reward_max: 27.471263183769864\n","  episode_reward_mean: -228.1188234791808\n","  episode_reward_min: -667.9194983816868\n","  episodes_this_iter: 29\n","  episodes_total: 3273\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 24935.212890625\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5305682420730591\n","          entropy_coeff: 0.0\n","          kl: 0.03052971139550209\n","          model: {}\n","          policy_loss: 0.01006818376481533\n","          total_loss: 2313.202392578125\n","          vf_explained_var: 0.4469655156135559\n","          vf_loss: 1551.9273681640625\n","    num_agent_steps_sampled: 364000\n","    num_agent_steps_trained: 364000\n","    num_steps_sampled: 364000\n","    num_steps_trained: 364000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 91\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.327272727272726\n","    ram_util_percent: 15.67272727272727\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07042804860155572\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.27617287230815607\n","    mean_inference_ms: 0.7254118178667762\n","    mean_raw_obs_processing_ms: 0.11271023845303983\n","  time_since_restore: 669.71604347229\n","  time_this_iter_s: 7.677236318588257\n","  time_total_s: 669.71604347229\n","  timers:\n","    learn_throughput: 1588.537\n","    learn_time_ms: 2518.041\n","    load_throughput: 9470092.572\n","    load_time_ms: 0.422\n","    sample_throughput: 535.938\n","    sample_time_ms: 7463.55\n","    update_time_ms: 2.969\n","  timestamp: 1649863764\n","  timesteps_since_restore: 364000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 364000\n","  training_iteration: 91\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 292000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-29-26\n","  done: false\n","  episode_len_mean: 292.89\n","  episode_media: {}\n","  episode_reward_max: 311.7699589355473\n","  episode_reward_mean: 246.27239612543013\n","  episode_reward_min: -140.33819224187178\n","  episodes_this_iter: 11\n","  episodes_total: 1074\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6494218111038208\n","          entropy_coeff: 0.0\n","          kl: 0.008572941645979881\n","          model: {}\n","          policy_loss: -0.013363868929445744\n","          total_loss: 248.65867614746094\n","          vf_explained_var: 0.272052139043808\n","          vf_loss: 248.67092895507812\n","    num_agent_steps_sampled: 292000\n","    num_agent_steps_trained: 292000\n","    num_steps_sampled: 292000\n","    num_steps_trained: 292000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 73\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.608333333333334\n","    ram_util_percent: 15.666666666666664\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07509848228041155\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6850980702078817\n","    mean_inference_ms: 0.7639258133217374\n","    mean_raw_obs_processing_ms: 0.11304276762939586\n","  time_since_restore: 665.0739979743958\n","  time_this_iter_s: 8.641452074050903\n","  time_total_s: 665.0739979743958\n","  timers:\n","    learn_throughput: 1603.063\n","    learn_time_ms: 2495.224\n","    load_throughput: 8140722.985\n","    load_time_ms: 0.491\n","    sample_throughput: 463.585\n","    sample_time_ms: 8628.406\n","    update_time_ms: 2.9\n","  timestamp: 1649863766\n","  timesteps_since_restore: 292000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 292000\n","  training_iteration: 73\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:29:27 (running for 00:11:38.07)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         669.716</td><td style=\"text-align: right;\">364000</td><td style=\"text-align: right;\">-228.119 </td><td style=\"text-align: right;\">             27.4713</td><td style=\"text-align: right;\">            -667.919</td><td style=\"text-align: right;\">            127.09</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         665.023</td><td style=\"text-align: right;\">244000</td><td style=\"text-align: right;\">  20.4959</td><td style=\"text-align: right;\">            226.523 </td><td style=\"text-align: right;\">            -342.707</td><td style=\"text-align: right;\">            495.96</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         665.074</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\"> 246.272 </td><td style=\"text-align: right;\">            311.77  </td><td style=\"text-align: right;\">            -140.338</td><td style=\"text-align: right;\">            292.89</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 248000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-29-30\n","  done: false\n","  episode_len_mean: 461.29\n","  episode_media: {}\n","  episode_reward_max: 226.52336192616522\n","  episode_reward_mean: 19.207230480689176\n","  episode_reward_min: -342.70656154965684\n","  episodes_this_iter: 13\n","  episodes_total: 805\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.9777032136917114\n","          entropy_coeff: 0.0\n","          kl: 0.013641769997775555\n","          model: {}\n","          policy_loss: -0.048163652420043945\n","          total_loss: 619.1876831054688\n","          vf_explained_var: 0.7735724449157715\n","          vf_loss: 619.2221069335938\n","    num_agent_steps_sampled: 248000\n","    num_agent_steps_trained: 248000\n","    num_steps_sampled: 248000\n","    num_steps_trained: 248000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 62\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.386666666666667\n","    ram_util_percent: 15.639999999999997\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07374148204837405\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1159623291203973\n","    mean_inference_ms: 0.7646842239827477\n","    mean_raw_obs_processing_ms: 0.11222908867954821\n","  time_since_restore: 675.7480845451355\n","  time_this_iter_s: 10.724793195724487\n","  time_total_s: 675.7480845451355\n","  timers:\n","    learn_throughput: 1601.003\n","    learn_time_ms: 2498.434\n","    load_throughput: 8257723.089\n","    load_time_ms: 0.484\n","    sample_throughput: 348.02\n","    sample_time_ms: 11493.576\n","    update_time_ms: 2.855\n","  timestamp: 1649863770\n","  timesteps_since_restore: 248000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 248000\n","  training_iteration: 62\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 368000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-29-32\n","  done: false\n","  episode_len_mean: 126.74\n","  episode_media: {}\n","  episode_reward_max: 27.471263183769864\n","  episode_reward_mean: -218.45480238494267\n","  episode_reward_min: -602.6031102313016\n","  episodes_this_iter: 33\n","  episodes_total: 3306\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 37402.8203125\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5109177231788635\n","          entropy_coeff: 0.0\n","          kl: 0.031077852472662926\n","          model: {}\n","          policy_loss: 0.008443694561719894\n","          total_loss: 3319.595703125\n","          vf_explained_var: 0.37611839175224304\n","          vf_loss: 2157.188232421875\n","    num_agent_steps_sampled: 368000\n","    num_agent_steps_trained: 368000\n","    num_steps_sampled: 368000\n","    num_steps_trained: 368000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 92\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.20909090909091\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07042325675737446\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.276651551181807\n","    mean_inference_ms: 0.7253689249611895\n","    mean_raw_obs_processing_ms: 0.11269746818397428\n","  time_since_restore: 677.1130566596985\n","  time_this_iter_s: 7.397013187408447\n","  time_total_s: 677.1130566596985\n","  timers:\n","    learn_throughput: 1599.646\n","    learn_time_ms: 2500.553\n","    load_throughput: 9306199.246\n","    load_time_ms: 0.43\n","    sample_throughput: 535.739\n","    sample_time_ms: 7466.318\n","    update_time_ms: 2.924\n","  timestamp: 1649863772\n","  timesteps_since_restore: 368000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 368000\n","  training_iteration: 92\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:29:33 (running for 00:11:43.61)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         677.113</td><td style=\"text-align: right;\">368000</td><td style=\"text-align: right;\">-218.455 </td><td style=\"text-align: right;\">             27.4713</td><td style=\"text-align: right;\">            -602.603</td><td style=\"text-align: right;\">            126.74</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         675.748</td><td style=\"text-align: right;\">248000</td><td style=\"text-align: right;\">  19.2072</td><td style=\"text-align: right;\">            226.523 </td><td style=\"text-align: right;\">            -342.707</td><td style=\"text-align: right;\">            461.29</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         665.074</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\"> 246.272 </td><td style=\"text-align: right;\">            311.77  </td><td style=\"text-align: right;\">            -140.338</td><td style=\"text-align: right;\">            292.89</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 296000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-29-35\n","  done: false\n","  episode_len_mean: 301.93\n","  episode_media: {}\n","  episode_reward_max: 311.7699589355473\n","  episode_reward_mean: 246.17944597315892\n","  episode_reward_min: -140.33819224187178\n","  episodes_this_iter: 13\n","  episodes_total: 1087\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6851886510848999\n","          entropy_coeff: 0.0\n","          kl: 0.008149287663400173\n","          model: {}\n","          policy_loss: -0.013356138952076435\n","          total_loss: 478.810546875\n","          vf_explained_var: 0.14371703565120697\n","          vf_loss: 478.8228454589844\n","    num_agent_steps_sampled: 296000\n","    num_agent_steps_trained: 296000\n","    num_steps_sampled: 296000\n","    num_steps_trained: 296000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 74\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.107692307692306\n","    ram_util_percent: 15.599999999999998\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07508923593888076\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6836973469961655\n","    mean_inference_ms: 0.7637664757335721\n","    mean_raw_obs_processing_ms: 0.11301790275870921\n","  time_since_restore: 674.190052986145\n","  time_this_iter_s: 9.116055011749268\n","  time_total_s: 674.190052986145\n","  timers:\n","    learn_throughput: 1607.329\n","    learn_time_ms: 2488.601\n","    load_throughput: 8094377.382\n","    load_time_ms: 0.494\n","    sample_throughput: 458.651\n","    sample_time_ms: 8721.223\n","    update_time_ms: 2.843\n","  timestamp: 1649863775\n","  timesteps_since_restore: 296000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 296000\n","  training_iteration: 74\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:29:39 (running for 00:11:49.22)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         677.113</td><td style=\"text-align: right;\">368000</td><td style=\"text-align: right;\">-218.455 </td><td style=\"text-align: right;\">             27.4713</td><td style=\"text-align: right;\">            -602.603</td><td style=\"text-align: right;\">            126.74</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         675.748</td><td style=\"text-align: right;\">248000</td><td style=\"text-align: right;\">  19.2072</td><td style=\"text-align: right;\">            226.523 </td><td style=\"text-align: right;\">            -342.707</td><td style=\"text-align: right;\">            461.29</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         674.19 </td><td style=\"text-align: right;\">296000</td><td style=\"text-align: right;\"> 246.179 </td><td style=\"text-align: right;\">            311.77  </td><td style=\"text-align: right;\">            -140.338</td><td style=\"text-align: right;\">            301.93</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 372000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-29-39\n","  done: false\n","  episode_len_mean: 120.57\n","  episode_media: {}\n","  episode_reward_max: 49.394559693606425\n","  episode_reward_mean: -196.75480226951694\n","  episode_reward_min: -602.6031102313016\n","  episodes_this_iter: 36\n","  episodes_total: 3342\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 56104.23046875\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.4667724370956421\n","          entropy_coeff: 0.0\n","          kl: 0.021019840613007545\n","          model: {}\n","          policy_loss: 0.003034672001376748\n","          total_loss: 3348.11181640625\n","          vf_explained_var: 0.40938782691955566\n","          vf_loss: 2168.806396484375\n","    num_agent_steps_sampled: 372000\n","    num_agent_steps_trained: 372000\n","    num_steps_sampled: 372000\n","    num_steps_trained: 372000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 93\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.88\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07041975442272223\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2769070243291982\n","    mean_inference_ms: 0.7253951546966977\n","    mean_raw_obs_processing_ms: 0.11269085961032875\n","  time_since_restore: 684.2649121284485\n","  time_this_iter_s: 7.15185546875\n","  time_total_s: 684.2649121284485\n","  timers:\n","    learn_throughput: 1595.376\n","    learn_time_ms: 2507.246\n","    load_throughput: 9275329.5\n","    load_time_ms: 0.431\n","    sample_throughput: 539.476\n","    sample_time_ms: 7414.599\n","    update_time_ms: 2.913\n","  timestamp: 1649863779\n","  timesteps_since_restore: 372000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 372000\n","  training_iteration: 93\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 252000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-29-41\n","  done: false\n","  episode_len_mean: 468.68\n","  episode_media: {}\n","  episode_reward_max: 146.86110663304385\n","  episode_reward_mean: 19.323046008778498\n","  episode_reward_min: -342.70656154965684\n","  episodes_this_iter: 8\n","  episodes_total: 813\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8643680810928345\n","          entropy_coeff: 0.0\n","          kl: 0.01413015928119421\n","          model: {}\n","          policy_loss: -0.037059422582387924\n","          total_loss: 318.5375061035156\n","          vf_explained_var: 0.85824054479599\n","          vf_loss: 318.56024169921875\n","    num_agent_steps_sampled: 252000\n","    num_agent_steps_trained: 252000\n","    num_steps_sampled: 252000\n","    num_steps_trained: 252000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 63\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.725\n","    ram_util_percent: 15.6\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0737632393474709\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1185969762463963\n","    mean_inference_ms: 0.7648977132204081\n","    mean_raw_obs_processing_ms: 0.11224246598455734\n","  time_since_restore: 686.6973009109497\n","  time_this_iter_s: 10.949216365814209\n","  time_total_s: 686.6973009109497\n","  timers:\n","    learn_throughput: 1602.499\n","    learn_time_ms: 2496.102\n","    load_throughput: 8531944.67\n","    load_time_ms: 0.469\n","    sample_throughput: 350.86\n","    sample_time_ms: 11400.57\n","    update_time_ms: 2.823\n","  timestamp: 1649863781\n","  timesteps_since_restore: 252000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 252000\n","  training_iteration: 63\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:29:44 (running for 00:11:54.32)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         684.265</td><td style=\"text-align: right;\">372000</td><td style=\"text-align: right;\">-196.755</td><td style=\"text-align: right;\">             49.3946</td><td style=\"text-align: right;\">            -602.603</td><td style=\"text-align: right;\">            120.57</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         686.697</td><td style=\"text-align: right;\">252000</td><td style=\"text-align: right;\">  19.323</td><td style=\"text-align: right;\">            146.861 </td><td style=\"text-align: right;\">            -342.707</td><td style=\"text-align: right;\">            468.68</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         674.19 </td><td style=\"text-align: right;\">296000</td><td style=\"text-align: right;\"> 246.179</td><td style=\"text-align: right;\">            311.77  </td><td style=\"text-align: right;\">            -140.338</td><td style=\"text-align: right;\">            301.93</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 300000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-29-44\n","  done: false\n","  episode_len_mean: 292.47\n","  episode_media: {}\n","  episode_reward_max: 311.7699589355473\n","  episode_reward_mean: 247.23278748787845\n","  episode_reward_min: -140.33819224187178\n","  episodes_this_iter: 16\n","  episodes_total: 1103\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6516996622085571\n","          entropy_coeff: 0.0\n","          kl: 0.007133607752621174\n","          model: {}\n","          policy_loss: -0.013395261950790882\n","          total_loss: 280.62518310546875\n","          vf_explained_var: 0.3602171540260315\n","          vf_loss: 280.63763427734375\n","    num_agent_steps_sampled: 300000\n","    num_agent_steps_trained: 300000\n","    num_steps_sampled: 300000\n","    num_steps_trained: 300000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 75\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.633333333333331\n","    ram_util_percent: 15.6\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07508824758781175\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6818692429040223\n","    mean_inference_ms: 0.7637055314804333\n","    mean_raw_obs_processing_ms: 0.11300543062879768\n","  time_since_restore: 682.5916209220886\n","  time_this_iter_s: 8.401567935943604\n","  time_total_s: 682.5916209220886\n","  timers:\n","    learn_throughput: 1615.135\n","    learn_time_ms: 2476.573\n","    load_throughput: 8165287.39\n","    load_time_ms: 0.49\n","    sample_throughput: 463.16\n","    sample_time_ms: 8636.315\n","    update_time_ms: 2.846\n","  timestamp: 1649863784\n","  timesteps_since_restore: 300000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 300000\n","  training_iteration: 75\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 376000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-29-47\n","  done: false\n","  episode_len_mean: 119.22\n","  episode_media: {}\n","  episode_reward_max: 49.394559693606425\n","  episode_reward_mean: -188.97762804160914\n","  episode_reward_min: -676.1092610776417\n","  episodes_this_iter: 30\n","  episodes_total: 3372\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 84156.34375\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5290607213973999\n","          entropy_coeff: 0.0\n","          kl: 0.035659488290548325\n","          model: {}\n","          policy_loss: 0.005787213798612356\n","          total_loss: 4543.57470703125\n","          vf_explained_var: 0.724528431892395\n","          vf_loss: 1542.5970458984375\n","    num_agent_steps_sampled: 376000\n","    num_agent_steps_trained: 376000\n","    num_steps_sampled: 376000\n","    num_steps_trained: 376000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 94\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.672727272727274\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07042512018432752\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2769704251337713\n","    mean_inference_ms: 0.7254826962849384\n","    mean_raw_obs_processing_ms: 0.11269352559943947\n","  time_since_restore: 691.9018180370331\n","  time_this_iter_s: 7.636905908584595\n","  time_total_s: 691.9018180370331\n","  timers:\n","    learn_throughput: 1590.196\n","    learn_time_ms: 2515.414\n","    load_throughput: 9083987.222\n","    load_time_ms: 0.44\n","    sample_throughput: 538.054\n","    sample_time_ms: 7434.195\n","    update_time_ms: 2.866\n","  timestamp: 1649863787\n","  timesteps_since_restore: 376000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 376000\n","  training_iteration: 94\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:29:49 (running for 00:11:59.49)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         691.902</td><td style=\"text-align: right;\">376000</td><td style=\"text-align: right;\">-188.978</td><td style=\"text-align: right;\">             49.3946</td><td style=\"text-align: right;\">            -676.109</td><td style=\"text-align: right;\">            119.22</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         686.697</td><td style=\"text-align: right;\">252000</td><td style=\"text-align: right;\">  19.323</td><td style=\"text-align: right;\">            146.861 </td><td style=\"text-align: right;\">            -342.707</td><td style=\"text-align: right;\">            468.68</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         682.592</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\"> 247.233</td><td style=\"text-align: right;\">            311.77  </td><td style=\"text-align: right;\">            -140.338</td><td style=\"text-align: right;\">            292.47</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 256000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-29-52\n","  done: false\n","  episode_len_mean: 436.81\n","  episode_media: {}\n","  episode_reward_max: 225.16093699222873\n","  episode_reward_mean: 10.716606692211096\n","  episode_reward_min: -715.0805705716425\n","  episodes_this_iter: 11\n","  episodes_total: 824\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.9554376602172852\n","          entropy_coeff: 0.0\n","          kl: 0.01740828901529312\n","          model: {}\n","          policy_loss: -0.03329306095838547\n","          total_loss: 3137.3623046875\n","          vf_explained_var: 0.731012225151062\n","          vf_loss: 3137.3779296875\n","    num_agent_steps_sampled: 256000\n","    num_agent_steps_trained: 256000\n","    num_steps_sampled: 256000\n","    num_steps_trained: 256000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 64\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.026666666666666\n","    ram_util_percent: 15.599999999999998\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07378429758971337\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1210961885795194\n","    mean_inference_ms: 0.7651019568134759\n","    mean_raw_obs_processing_ms: 0.11224760978151682\n","  time_since_restore: 697.644779920578\n","  time_this_iter_s: 10.947479009628296\n","  time_total_s: 697.644779920578\n","  timers:\n","    learn_throughput: 1597.928\n","    learn_time_ms: 2503.241\n","    load_throughput: 8716795.345\n","    load_time_ms: 0.459\n","    sample_throughput: 352.794\n","    sample_time_ms: 11338.07\n","    update_time_ms: 2.866\n","  timestamp: 1649863792\n","  timesteps_since_restore: 256000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 256000\n","  training_iteration: 64\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 304000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-29-52\n","  done: false\n","  episode_len_mean: 280.73\n","  episode_media: {}\n","  episode_reward_max: 306.35164539821346\n","  episode_reward_mean: 249.92042328326585\n","  episode_reward_min: 12.161192947143249\n","  episodes_this_iter: 17\n","  episodes_total: 1120\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6696630716323853\n","          entropy_coeff: 0.0\n","          kl: 0.008004427887499332\n","          model: {}\n","          policy_loss: -0.04228682816028595\n","          total_loss: 180.577392578125\n","          vf_explained_var: 0.32300421595573425\n","          vf_loss: 180.61866760253906\n","    num_agent_steps_sampled: 304000\n","    num_agent_steps_trained: 304000\n","    num_steps_sampled: 304000\n","    num_steps_trained: 304000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 76\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.866666666666667\n","    ram_util_percent: 15.608333333333333\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07508625697306685\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6798900466634137\n","    mean_inference_ms: 0.7636667975216608\n","    mean_raw_obs_processing_ms: 0.11300224070760127\n","  time_since_restore: 690.9174408912659\n","  time_this_iter_s: 8.325819969177246\n","  time_total_s: 690.9174408912659\n","  timers:\n","    learn_throughput: 1613.244\n","    learn_time_ms: 2479.476\n","    load_throughput: 8143093.724\n","    load_time_ms: 0.491\n","    sample_throughput: 465.139\n","    sample_time_ms: 8599.582\n","    update_time_ms: 2.834\n","  timestamp: 1649863792\n","  timesteps_since_restore: 304000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 304000\n","  training_iteration: 76\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 380000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-29-54\n","  done: false\n","  episode_len_mean: 113.61\n","  episode_media: {}\n","  episode_reward_max: 19.024986403019213\n","  episode_reward_mean: -192.0243105287334\n","  episode_reward_min: -676.1092610776417\n","  episodes_this_iter: 40\n","  episodes_total: 3412\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 126234.515625\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.4796772301197052\n","          entropy_coeff: 0.0\n","          kl: 0.030388833954930305\n","          model: {}\n","          policy_loss: 0.006886380258947611\n","          total_loss: 4673.9375\n","          vf_explained_var: 0.6242870092391968\n","          vf_loss: 837.811279296875\n","    num_agent_steps_sampled: 380000\n","    num_agent_steps_trained: 380000\n","    num_steps_sampled: 380000\n","    num_steps_trained: 380000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 95\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.48181818181818\n","    ram_util_percent: 15.636363636363633\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0704393512220126\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.27680747589506843\n","    mean_inference_ms: 0.7257092291265036\n","    mean_raw_obs_processing_ms: 0.11271008555900977\n","  time_since_restore: 699.2059276103973\n","  time_this_iter_s: 7.304109573364258\n","  time_total_s: 699.2059276103973\n","  timers:\n","    learn_throughput: 1590.031\n","    learn_time_ms: 2515.675\n","    load_throughput: 9539012.963\n","    load_time_ms: 0.419\n","    sample_throughput: 538.158\n","    sample_time_ms: 7432.756\n","    update_time_ms: 2.857\n","  timestamp: 1649863794\n","  timesteps_since_restore: 380000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 380000\n","  training_iteration: 95\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:29:54 (running for 00:12:04.83)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         699.206</td><td style=\"text-align: right;\">380000</td><td style=\"text-align: right;\">-192.024 </td><td style=\"text-align: right;\">              19.025</td><td style=\"text-align: right;\">           -676.109 </td><td style=\"text-align: right;\">            113.61</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         697.645</td><td style=\"text-align: right;\">256000</td><td style=\"text-align: right;\">  10.7166</td><td style=\"text-align: right;\">             225.161</td><td style=\"text-align: right;\">           -715.081 </td><td style=\"text-align: right;\">            436.81</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         690.917</td><td style=\"text-align: right;\">304000</td><td style=\"text-align: right;\"> 249.92  </td><td style=\"text-align: right;\">             306.352</td><td style=\"text-align: right;\">             12.1612</td><td style=\"text-align: right;\">            280.73</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:29:59 (running for 00:12:09.83)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         699.206</td><td style=\"text-align: right;\">380000</td><td style=\"text-align: right;\">-192.024 </td><td style=\"text-align: right;\">              19.025</td><td style=\"text-align: right;\">           -676.109 </td><td style=\"text-align: right;\">            113.61</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         697.645</td><td style=\"text-align: right;\">256000</td><td style=\"text-align: right;\">  10.7166</td><td style=\"text-align: right;\">             225.161</td><td style=\"text-align: right;\">           -715.081 </td><td style=\"text-align: right;\">            436.81</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         690.917</td><td style=\"text-align: right;\">304000</td><td style=\"text-align: right;\"> 249.92  </td><td style=\"text-align: right;\">             306.352</td><td style=\"text-align: right;\">             12.1612</td><td style=\"text-align: right;\">            280.73</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 308000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-30-00\n","  done: false\n","  episode_len_mean: 276.49\n","  episode_media: {}\n","  episode_reward_max: 306.35164539821346\n","  episode_reward_mean: 254.10316838027552\n","  episode_reward_min: 12.161192947143249\n","  episodes_this_iter: 16\n","  episodes_total: 1136\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7026565670967102\n","          entropy_coeff: 0.0\n","          kl: 0.010067733004689217\n","          model: {}\n","          policy_loss: -0.021733621135354042\n","          total_loss: 92.03800201416016\n","          vf_explained_var: 0.49184513092041016\n","          vf_loss: 92.05846405029297\n","    num_agent_steps_sampled: 308000\n","    num_agent_steps_trained: 308000\n","    num_steps_sampled: 308000\n","    num_steps_trained: 308000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 77\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.033333333333333\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07507135037001315\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6779845268158472\n","    mean_inference_ms: 0.763491994364478\n","    mean_raw_obs_processing_ms: 0.11298189471601507\n","  time_since_restore: 699.0128746032715\n","  time_this_iter_s: 8.095433712005615\n","  time_total_s: 699.0128746032715\n","  timers:\n","    learn_throughput: 1613.767\n","    learn_time_ms: 2478.673\n","    load_throughput: 8166479.751\n","    load_time_ms: 0.49\n","    sample_throughput: 466.215\n","    sample_time_ms: 8579.733\n","    update_time_ms: 2.852\n","  timestamp: 1649863800\n","  timesteps_since_restore: 308000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 308000\n","  training_iteration: 77\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 384000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-30-01\n","  done: false\n","  episode_len_mean: 111.21\n","  episode_media: {}\n","  episode_reward_max: 19.024986403019213\n","  episode_reward_mean: -193.20261492548318\n","  episode_reward_min: -676.1092610776417\n","  episodes_this_iter: 38\n","  episodes_total: 3450\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 189351.78125\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.4154771566390991\n","          entropy_coeff: 0.0\n","          kl: 0.03967677429318428\n","          model: {}\n","          policy_loss: 0.015819935128092766\n","          total_loss: 8234.845703125\n","          vf_explained_var: 0.755416750907898\n","          vf_loss: 721.962158203125\n","    num_agent_steps_sampled: 384000\n","    num_agent_steps_trained: 384000\n","    num_steps_sampled: 384000\n","    num_steps_trained: 384000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 96\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.05\n","    ram_util_percent: 15.699999999999998\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07044577115190888\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2765516139129026\n","    mean_inference_ms: 0.7258166732423393\n","    mean_raw_obs_processing_ms: 0.11271394633855394\n","  time_since_restore: 706.2810983657837\n","  time_this_iter_s: 7.0751707553863525\n","  time_total_s: 706.2810983657837\n","  timers:\n","    learn_throughput: 1578.935\n","    learn_time_ms: 2533.354\n","    load_throughput: 9282000.553\n","    load_time_ms: 0.431\n","    sample_throughput: 541.97\n","    sample_time_ms: 7380.479\n","    update_time_ms: 2.867\n","  timestamp: 1649863801\n","  timesteps_since_restore: 384000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 384000\n","  training_iteration: 96\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 260000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-30-03\n","  done: false\n","  episode_len_mean: 438.4\n","  episode_media: {}\n","  episode_reward_max: 225.16093699222873\n","  episode_reward_mean: 13.914082777674238\n","  episode_reward_min: -715.0805705716425\n","  episodes_this_iter: 8\n","  episodes_total: 832\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.9645800590515137\n","          entropy_coeff: 0.0\n","          kl: 0.013050730340182781\n","          model: {}\n","          policy_loss: -0.06049012765288353\n","          total_loss: 299.9790954589844\n","          vf_explained_var: 0.8758804798126221\n","          vf_loss: 300.0263671875\n","    num_agent_steps_sampled: 260000\n","    num_agent_steps_trained: 260000\n","    num_steps_sampled: 260000\n","    num_steps_trained: 260000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 65\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.225\n","    ram_util_percent: 15.69375\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07380362329876305\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1225545378846453\n","    mean_inference_ms: 0.7652908303834013\n","    mean_raw_obs_processing_ms: 0.11225907029806152\n","  time_since_restore: 708.9191308021545\n","  time_this_iter_s: 11.274350881576538\n","  time_total_s: 708.9191308021545\n","  timers:\n","    learn_throughput: 1603.652\n","    learn_time_ms: 2494.306\n","    load_throughput: 9165874.126\n","    load_time_ms: 0.436\n","    sample_throughput: 353.849\n","    sample_time_ms: 11304.267\n","    update_time_ms: 2.858\n","  timestamp: 1649863803\n","  timesteps_since_restore: 260000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 260000\n","  training_iteration: 65\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:30:05 (running for 00:12:15.62)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         706.281</td><td style=\"text-align: right;\">384000</td><td style=\"text-align: right;\">-193.203 </td><td style=\"text-align: right;\">              19.025</td><td style=\"text-align: right;\">           -676.109 </td><td style=\"text-align: right;\">            111.21</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         708.919</td><td style=\"text-align: right;\">260000</td><td style=\"text-align: right;\">  13.9141</td><td style=\"text-align: right;\">             225.161</td><td style=\"text-align: right;\">           -715.081 </td><td style=\"text-align: right;\">            438.4 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">         699.013</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\"> 254.103 </td><td style=\"text-align: right;\">             306.352</td><td style=\"text-align: right;\">             12.1612</td><td style=\"text-align: right;\">            276.49</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 388000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-30-08\n","  done: false\n","  episode_len_mean: 99.26\n","  episode_media: {}\n","  episode_reward_max: 19.024986403019213\n","  episode_reward_mean: -168.98985486380593\n","  episode_reward_min: -617.9348940878355\n","  episodes_this_iter: 42\n","  episodes_total: 3492\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 284027.65625\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.45415782928466797\n","          entropy_coeff: 0.0\n","          kl: 0.010822335258126259\n","          model: {}\n","          policy_loss: 0.004951906856149435\n","          total_loss: 3855.486572265625\n","          vf_explained_var: 0.4943500757217407\n","          vf_loss: 781.6389770507812\n","    num_agent_steps_sampled: 388000\n","    num_agent_steps_trained: 388000\n","    num_steps_sampled: 388000\n","    num_steps_trained: 388000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 97\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.570000000000002\n","    ram_util_percent: 15.699999999999998\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0704290909912406\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.27594801259185675\n","    mean_inference_ms: 0.7256610296514314\n","    mean_raw_obs_processing_ms: 0.11269205545363516\n","  time_since_restore: 713.3350949287415\n","  time_this_iter_s: 7.053996562957764\n","  time_total_s: 713.3350949287415\n","  timers:\n","    learn_throughput: 1568.417\n","    learn_time_ms: 2550.342\n","    load_throughput: 9256905.76\n","    load_time_ms: 0.432\n","    sample_throughput: 542.034\n","    sample_time_ms: 7379.608\n","    update_time_ms: 2.911\n","  timestamp: 1649863808\n","  timesteps_since_restore: 388000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 388000\n","  training_iteration: 97\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 312000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-30-09\n","  done: false\n","  episode_len_mean: 275.95\n","  episode_media: {}\n","  episode_reward_max: 306.35164539821346\n","  episode_reward_mean: 255.56695862391445\n","  episode_reward_min: 45.840111157691354\n","  episodes_this_iter: 16\n","  episodes_total: 1152\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6869760751724243\n","          entropy_coeff: 0.0\n","          kl: 0.013068344444036484\n","          model: {}\n","          policy_loss: -0.013411459513008595\n","          total_loss: 307.1467590332031\n","          vf_explained_var: 0.38018104434013367\n","          vf_loss: 307.1585388183594\n","    num_agent_steps_sampled: 312000\n","    num_agent_steps_trained: 312000\n","    num_steps_sampled: 312000\n","    num_steps_trained: 312000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 78\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.408333333333331\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07505951239076725\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6760473289820351\n","    mean_inference_ms: 0.7633306638941731\n","    mean_raw_obs_processing_ms: 0.11296524116932209\n","  time_since_restore: 707.3795809745789\n","  time_this_iter_s: 8.366706371307373\n","  time_total_s: 707.3795809745789\n","  timers:\n","    learn_throughput: 1602.454\n","    learn_time_ms: 2496.172\n","    load_throughput: 7967145.978\n","    load_time_ms: 0.502\n","    sample_throughput: 467.33\n","    sample_time_ms: 8559.256\n","    update_time_ms: 2.841\n","  timestamp: 1649863809\n","  timesteps_since_restore: 312000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 312000\n","  training_iteration: 78\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:30:11 (running for 00:12:21.57)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         713.335</td><td style=\"text-align: right;\">388000</td><td style=\"text-align: right;\">-168.99  </td><td style=\"text-align: right;\">              19.025</td><td style=\"text-align: right;\">           -617.935 </td><td style=\"text-align: right;\">             99.26</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         708.919</td><td style=\"text-align: right;\">260000</td><td style=\"text-align: right;\">  13.9141</td><td style=\"text-align: right;\">             225.161</td><td style=\"text-align: right;\">           -715.081 </td><td style=\"text-align: right;\">            438.4 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         707.38 </td><td style=\"text-align: right;\">312000</td><td style=\"text-align: right;\"> 255.567 </td><td style=\"text-align: right;\">             306.352</td><td style=\"text-align: right;\">             45.8401</td><td style=\"text-align: right;\">            275.95</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 264000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-30-13\n","  done: false\n","  episode_len_mean: 421.05\n","  episode_media: {}\n","  episode_reward_max: 225.16093699222873\n","  episode_reward_mean: 12.319450929654938\n","  episode_reward_min: -715.0805705716425\n","  episodes_this_iter: 10\n","  episodes_total: 842\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8652942180633545\n","          entropy_coeff: 0.0\n","          kl: 0.016029031947255135\n","          model: {}\n","          policy_loss: -0.04864842817187309\n","          total_loss: 506.3440856933594\n","          vf_explained_var: 0.6985295414924622\n","          vf_loss: 506.37646484375\n","    num_agent_steps_sampled: 264000\n","    num_agent_steps_trained: 264000\n","    num_steps_sampled: 264000\n","    num_steps_trained: 264000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 66\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.933333333333335\n","    ram_util_percent: 15.659999999999997\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07382136556732619\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1234693046257818\n","    mean_inference_ms: 0.7655092160834616\n","    mean_raw_obs_processing_ms: 0.11227484689269403\n","  time_since_restore: 719.0145037174225\n","  time_this_iter_s: 10.095372915267944\n","  time_total_s: 719.0145037174225\n","  timers:\n","    learn_throughput: 1605.04\n","    learn_time_ms: 2492.15\n","    load_throughput: 8966978.087\n","    load_time_ms: 0.446\n","    sample_throughput: 362.116\n","    sample_time_ms: 11046.197\n","    update_time_ms: 2.863\n","  timestamp: 1649863813\n","  timesteps_since_restore: 264000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 264000\n","  training_iteration: 66\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 392000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-30-16\n","  done: false\n","  episode_len_mean: 97.88\n","  episode_media: {}\n","  episode_reward_max: 16.842169044609264\n","  episode_reward_mean: -175.12737329218086\n","  episode_reward_min: -617.9348940878355\n","  episodes_this_iter: 43\n","  episodes_total: 3535\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 284027.65625\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.441787987947464\n","          entropy_coeff: 0.0\n","          kl: 0.006511283107101917\n","          model: {}\n","          policy_loss: -0.00012548187805805355\n","          total_loss: 2484.1923828125\n","          vf_explained_var: 0.6811801791191101\n","          vf_loss: 634.8079833984375\n","    num_agent_steps_sampled: 392000\n","    num_agent_steps_trained: 392000\n","    num_steps_sampled: 392000\n","    num_steps_trained: 392000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 98\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.36\n","    ram_util_percent: 15.61\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07042397910516622\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.27529550549123455\n","    mean_inference_ms: 0.7256319677296402\n","    mean_raw_obs_processing_ms: 0.11269036675360666\n","  time_since_restore: 720.5906834602356\n","  time_this_iter_s: 7.255588531494141\n","  time_total_s: 720.5906834602356\n","  timers:\n","    learn_throughput: 1570.997\n","    learn_time_ms: 2546.153\n","    load_throughput: 9246192.339\n","    load_time_ms: 0.433\n","    sample_throughput: 542.938\n","    sample_time_ms: 7367.318\n","    update_time_ms: 2.948\n","  timestamp: 1649863816\n","  timesteps_since_restore: 392000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 392000\n","  training_iteration: 98\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:30:17 (running for 00:12:27.34)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         720.591</td><td style=\"text-align: right;\">392000</td><td style=\"text-align: right;\">-175.127 </td><td style=\"text-align: right;\">             16.8422</td><td style=\"text-align: right;\">           -617.935 </td><td style=\"text-align: right;\">             97.88</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">         719.015</td><td style=\"text-align: right;\">264000</td><td style=\"text-align: right;\">  12.3195</td><td style=\"text-align: right;\">            225.161 </td><td style=\"text-align: right;\">           -715.081 </td><td style=\"text-align: right;\">            421.05</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         707.38 </td><td style=\"text-align: right;\">312000</td><td style=\"text-align: right;\"> 255.567 </td><td style=\"text-align: right;\">            306.352 </td><td style=\"text-align: right;\">             45.8401</td><td style=\"text-align: right;\">            275.95</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 316000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-30-17\n","  done: false\n","  episode_len_mean: 255.79\n","  episode_media: {}\n","  episode_reward_max: 319.59771310114866\n","  episode_reward_mean: 257.67554523389373\n","  episode_reward_min: 45.840111157691354\n","  episodes_this_iter: 16\n","  episodes_total: 1168\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6556799411773682\n","          entropy_coeff: 0.0\n","          kl: 0.010236131958663464\n","          model: {}\n","          policy_loss: -0.020321980118751526\n","          total_loss: 289.04534912109375\n","          vf_explained_var: 0.32362452149391174\n","          vf_loss: 289.064453125\n","    num_agent_steps_sampled: 316000\n","    num_agent_steps_trained: 316000\n","    num_steps_sampled: 316000\n","    num_steps_trained: 316000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 79\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.658333333333333\n","    ram_util_percent: 15.6\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07505613586170239\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6739659628163455\n","    mean_inference_ms: 0.763259312900226\n","    mean_raw_obs_processing_ms: 0.11296289288090533\n","  time_since_restore: 715.6780207157135\n","  time_this_iter_s: 8.298439741134644\n","  time_total_s: 715.6780207157135\n","  timers:\n","    learn_throughput: 1596.294\n","    learn_time_ms: 2505.804\n","    load_throughput: 8217680.251\n","    load_time_ms: 0.487\n","    sample_throughput: 468.294\n","    sample_time_ms: 8541.649\n","    update_time_ms: 2.848\n","  timestamp: 1649863817\n","  timesteps_since_restore: 316000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 316000\n","  training_iteration: 79\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:30:22 (running for 00:12:33.00)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         720.591</td><td style=\"text-align: right;\">392000</td><td style=\"text-align: right;\">-175.127 </td><td style=\"text-align: right;\">             16.8422</td><td style=\"text-align: right;\">           -617.935 </td><td style=\"text-align: right;\">             97.88</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">         719.015</td><td style=\"text-align: right;\">264000</td><td style=\"text-align: right;\">  12.3195</td><td style=\"text-align: right;\">            225.161 </td><td style=\"text-align: right;\">           -715.081 </td><td style=\"text-align: right;\">            421.05</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         715.678</td><td style=\"text-align: right;\">316000</td><td style=\"text-align: right;\"> 257.676 </td><td style=\"text-align: right;\">            319.598 </td><td style=\"text-align: right;\">             45.8401</td><td style=\"text-align: right;\">            255.79</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 396000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-30-23\n","  done: false\n","  episode_len_mean: 97.26\n","  episode_media: {}\n","  episode_reward_max: -20.584094895823355\n","  episode_reward_mean: -174.32096555798068\n","  episode_reward_min: -517.0474666649536\n","  episodes_this_iter: 39\n","  episodes_total: 3574\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 284027.65625\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.4972057640552521\n","          entropy_coeff: 0.0\n","          kl: 0.012801282107830048\n","          model: {}\n","          policy_loss: 0.004832238890230656\n","          total_loss: 4232.7001953125\n","          vf_explained_var: 0.6751941442489624\n","          vf_loss: 596.7767333984375\n","    num_agent_steps_sampled: 396000\n","    num_agent_steps_trained: 396000\n","    num_steps_sampled: 396000\n","    num_steps_trained: 396000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 99\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.381818181818181\n","    ram_util_percent: 15.6\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07042572267906645\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2747786309567632\n","    mean_inference_ms: 0.7256555650165063\n","    mean_raw_obs_processing_ms: 0.11269999888739876\n","  time_since_restore: 727.7567007541656\n","  time_this_iter_s: 7.166017293930054\n","  time_total_s: 727.7567007541656\n","  timers:\n","    learn_throughput: 1571.837\n","    learn_time_ms: 2544.793\n","    load_throughput: 9300524.419\n","    load_time_ms: 0.43\n","    sample_throughput: 544.385\n","    sample_time_ms: 7347.743\n","    update_time_ms: 2.953\n","  timestamp: 1649863823\n","  timesteps_since_restore: 396000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 396000\n","  training_iteration: 99\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 268000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-30-24\n","  done: false\n","  episode_len_mean: 390.42\n","  episode_media: {}\n","  episode_reward_max: 225.16093699222873\n","  episode_reward_mean: 8.886872465934871\n","  episode_reward_min: -715.0805705716425\n","  episodes_this_iter: 12\n","  episodes_total: 854\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.9649916887283325\n","          entropy_coeff: 0.0\n","          kl: 0.01757112331688404\n","          model: {}\n","          policy_loss: -0.05042250081896782\n","          total_loss: 609.0030517578125\n","          vf_explained_var: 0.7913398742675781\n","          vf_loss: 609.03564453125\n","    num_agent_steps_sampled: 268000\n","    num_agent_steps_trained: 268000\n","    num_steps_sampled: 268000\n","    num_steps_trained: 268000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 67\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.979999999999999\n","    ram_util_percent: 15.599999999999998\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07384465621699883\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1234512934338086\n","    mean_inference_ms: 0.7657688025020205\n","    mean_raw_obs_processing_ms: 0.11229373063493506\n","  time_since_restore: 729.9134850502014\n","  time_this_iter_s: 10.89898133277893\n","  time_total_s: 729.9134850502014\n","  timers:\n","    learn_throughput: 1598.307\n","    learn_time_ms: 2502.649\n","    load_throughput: 8628923.52\n","    load_time_ms: 0.464\n","    sample_throughput: 365.641\n","    sample_time_ms: 10939.678\n","    update_time_ms: 2.855\n","  timestamp: 1649863824\n","  timesteps_since_restore: 268000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 268000\n","  training_iteration: 67\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 320000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-30-26\n","  done: false\n","  episode_len_mean: 241.37\n","  episode_media: {}\n","  episode_reward_max: 319.59771310114866\n","  episode_reward_mean: 262.97481271760984\n","  episode_reward_min: 45.840111157691354\n","  episodes_this_iter: 18\n","  episodes_total: 1186\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6570283770561218\n","          entropy_coeff: 0.0\n","          kl: 0.007500636391341686\n","          model: {}\n","          policy_loss: -0.010591983795166016\n","          total_loss: 69.8883285522461\n","          vf_explained_var: 0.4318631589412689\n","          vf_loss: 69.8979721069336\n","    num_agent_steps_sampled: 320000\n","    num_agent_steps_trained: 320000\n","    num_steps_sampled: 320000\n","    num_steps_trained: 320000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 80\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.808333333333335\n","    ram_util_percent: 15.608333333333333\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07506429680699644\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6711706955298464\n","    mean_inference_ms: 0.763299084727835\n","    mean_raw_obs_processing_ms: 0.11297864150569893\n","  time_since_restore: 724.0380947589874\n","  time_this_iter_s: 8.360074043273926\n","  time_total_s: 724.0380947589874\n","  timers:\n","    learn_throughput: 1592.084\n","    learn_time_ms: 2512.43\n","    load_throughput: 8248385.447\n","    load_time_ms: 0.485\n","    sample_throughput: 470.317\n","    sample_time_ms: 8504.905\n","    update_time_ms: 2.872\n","  timestamp: 1649863826\n","  timesteps_since_restore: 320000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 320000\n","  training_iteration: 80\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:30:28 (running for 00:12:38.29)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         727.757</td><td style=\"text-align: right;\">396000</td><td style=\"text-align: right;\">-174.321  </td><td style=\"text-align: right;\">            -20.5841</td><td style=\"text-align: right;\">           -517.047 </td><td style=\"text-align: right;\">             97.26</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         729.913</td><td style=\"text-align: right;\">268000</td><td style=\"text-align: right;\">   8.88687</td><td style=\"text-align: right;\">            225.161 </td><td style=\"text-align: right;\">           -715.081 </td><td style=\"text-align: right;\">            390.42</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         724.038</td><td style=\"text-align: right;\">320000</td><td style=\"text-align: right;\"> 262.975  </td><td style=\"text-align: right;\">            319.598 </td><td style=\"text-align: right;\">             45.8401</td><td style=\"text-align: right;\">            241.37</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 400000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-30-30\n","  done: false\n","  episode_len_mean: 99.89\n","  episode_media: {}\n","  episode_reward_max: -17.023185171318246\n","  episode_reward_mean: -173.97737971570106\n","  episode_reward_min: -517.0474666649536\n","  episodes_this_iter: 41\n","  episodes_total: 3615\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 284027.65625\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.4997241497039795\n","          entropy_coeff: 0.0\n","          kl: 0.009305707179009914\n","          model: {}\n","          policy_loss: 0.0042200833559036255\n","          total_loss: 3133.878173828125\n","          vf_explained_var: 0.7909882068634033\n","          vf_loss: 490.7959289550781\n","    num_agent_steps_sampled: 400000\n","    num_agent_steps_trained: 400000\n","    num_steps_sampled: 400000\n","    num_steps_trained: 400000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 100\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.39\n","    ram_util_percent: 15.669999999999998\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07043493878739954\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.27430897517471114\n","    mean_inference_ms: 0.7257320743421743\n","    mean_raw_obs_processing_ms: 0.11271931728816614\n","  time_since_restore: 734.9974534511566\n","  time_this_iter_s: 7.240752696990967\n","  time_total_s: 734.9974534511566\n","  timers:\n","    learn_throughput: 1577.023\n","    learn_time_ms: 2536.425\n","    load_throughput: 9553679.175\n","    load_time_ms: 0.419\n","    sample_throughput: 544.529\n","    sample_time_ms: 7345.795\n","    update_time_ms: 2.941\n","  timestamp: 1649863830\n","  timesteps_since_restore: 400000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 400000\n","  training_iteration: 100\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:30:33 (running for 00:12:43.90)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         734.997</td><td style=\"text-align: right;\">400000</td><td style=\"text-align: right;\">-173.977  </td><td style=\"text-align: right;\">            -17.0232</td><td style=\"text-align: right;\">           -517.047 </td><td style=\"text-align: right;\">             99.89</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         729.913</td><td style=\"text-align: right;\">268000</td><td style=\"text-align: right;\">   8.88687</td><td style=\"text-align: right;\">            225.161 </td><td style=\"text-align: right;\">           -715.081 </td><td style=\"text-align: right;\">            390.42</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         724.038</td><td style=\"text-align: right;\">320000</td><td style=\"text-align: right;\"> 262.975  </td><td style=\"text-align: right;\">            319.598 </td><td style=\"text-align: right;\">             45.8401</td><td style=\"text-align: right;\">            241.37</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 324000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-30-34\n","  done: false\n","  episode_len_mean: 236.7\n","  episode_media: {}\n","  episode_reward_max: 319.59771310114866\n","  episode_reward_mean: 259.8565768224225\n","  episode_reward_min: 49.26539251093757\n","  episodes_this_iter: 18\n","  episodes_total: 1204\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6744042038917542\n","          entropy_coeff: 0.0\n","          kl: 0.005467365030199289\n","          model: {}\n","          policy_loss: -0.01243529375642538\n","          total_loss: 199.5067901611328\n","          vf_explained_var: 0.48242735862731934\n","          vf_loss: 199.5185089111328\n","    num_agent_steps_sampled: 324000\n","    num_agent_steps_trained: 324000\n","    num_steps_sampled: 324000\n","    num_steps_trained: 324000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 81\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.272727272727273\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07506137792804658\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6683144075043944\n","    mean_inference_ms: 0.7632029134892122\n","    mean_raw_obs_processing_ms: 0.11297873080769139\n","  time_since_restore: 731.9815857410431\n","  time_this_iter_s: 7.943490982055664\n","  time_total_s: 731.9815857410431\n","  timers:\n","    learn_throughput: 1602.933\n","    learn_time_ms: 2495.426\n","    load_throughput: 8627592.307\n","    load_time_ms: 0.464\n","    sample_throughput: 472.376\n","    sample_time_ms: 8467.826\n","    update_time_ms: 2.894\n","  timestamp: 1649863834\n","  timesteps_since_restore: 324000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 324000\n","  training_iteration: 81\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 272000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-30-35\n","  done: false\n","  episode_len_mean: 406.87\n","  episode_media: {}\n","  episode_reward_max: 225.16093699222873\n","  episode_reward_mean: 20.04690153282815\n","  episode_reward_min: -715.0805705716425\n","  episodes_this_iter: 9\n","  episodes_total: 863\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.930763840675354\n","          entropy_coeff: 0.0\n","          kl: 0.011488893069326878\n","          model: {}\n","          policy_loss: -0.04319683462381363\n","          total_loss: 251.2504425048828\n","          vf_explained_var: 0.7360432744026184\n","          vf_loss: 251.2820281982422\n","    num_agent_steps_sampled: 272000\n","    num_agent_steps_trained: 272000\n","    num_steps_sampled: 272000\n","    num_steps_trained: 272000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 68\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.635294117647058\n","    ram_util_percent: 15.688235294117646\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07386180353386138\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1234347153126634\n","    mean_inference_ms: 0.7659953758484441\n","    mean_raw_obs_processing_ms: 0.1123109191985431\n","  time_since_restore: 741.1383800506592\n","  time_this_iter_s: 11.224895000457764\n","  time_total_s: 741.1383800506592\n","  timers:\n","    learn_throughput: 1597.563\n","    learn_time_ms: 2503.814\n","    load_throughput: 8409210.566\n","    load_time_ms: 0.476\n","    sample_throughput: 364.023\n","    sample_time_ms: 10988.305\n","    update_time_ms: 2.812\n","  timestamp: 1649863835\n","  timesteps_since_restore: 272000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 272000\n","  training_iteration: 68\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 404000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-30-37\n","  done: false\n","  episode_len_mean: 103.11\n","  episode_media: {}\n","  episode_reward_max: -3.50908246331133\n","  episode_reward_mean: -159.6924609764163\n","  episode_reward_min: -539.3863467128543\n","  episodes_this_iter: 37\n","  episodes_total: 3652\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 284027.65625\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5038701295852661\n","          entropy_coeff: 0.0\n","          kl: 0.011196845211088657\n","          model: {}\n","          policy_loss: 0.004104869440197945\n","          total_loss: 5580.1005859375\n","          vf_explained_var: 0.49662578105926514\n","          vf_loss: 2399.8828125\n","    num_agent_steps_sampled: 404000\n","    num_agent_steps_trained: 404000\n","    num_steps_sampled: 404000\n","    num_steps_trained: 404000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 101\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.4\n","    ram_util_percent: 15.699999999999998\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07044738982370741\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.27393617764598843\n","    mean_inference_ms: 0.7258732093868158\n","    mean_raw_obs_processing_ms: 0.11273825065507252\n","  time_since_restore: 742.3157987594604\n","  time_this_iter_s: 7.318345308303833\n","  time_total_s: 742.3157987594604\n","  timers:\n","    learn_throughput: 1574.524\n","    learn_time_ms: 2540.45\n","    load_throughput: 9550416.121\n","    load_time_ms: 0.419\n","    sample_throughput: 548.161\n","    sample_time_ms: 7297.122\n","    update_time_ms: 2.885\n","  timestamp: 1649863837\n","  timesteps_since_restore: 404000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 404000\n","  training_iteration: 101\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:30:38 (running for 00:12:49.18)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         742.316</td><td style=\"text-align: right;\">404000</td><td style=\"text-align: right;\">-159.692 </td><td style=\"text-align: right;\">            -3.50908</td><td style=\"text-align: right;\">           -539.386 </td><td style=\"text-align: right;\">            103.11</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">         741.138</td><td style=\"text-align: right;\">272000</td><td style=\"text-align: right;\">  20.0469</td><td style=\"text-align: right;\">           225.161  </td><td style=\"text-align: right;\">           -715.081 </td><td style=\"text-align: right;\">            406.87</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         731.982</td><td style=\"text-align: right;\">324000</td><td style=\"text-align: right;\"> 259.857 </td><td style=\"text-align: right;\">           319.598  </td><td style=\"text-align: right;\">             49.2654</td><td style=\"text-align: right;\">            236.7 </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 328000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-30-42\n","  done: false\n","  episode_len_mean: 236.08\n","  episode_media: {}\n","  episode_reward_max: 319.59771310114866\n","  episode_reward_mean: 264.2846921361077\n","  episode_reward_min: 49.26539251093757\n","  episodes_this_iter: 17\n","  episodes_total: 1221\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.7332620620727539\n","          entropy_coeff: 0.0\n","          kl: 0.017774762585759163\n","          model: {}\n","          policy_loss: -0.019433222711086273\n","          total_loss: 63.543235778808594\n","          vf_explained_var: 0.5608886480331421\n","          vf_loss: 63.5604248046875\n","    num_agent_steps_sampled: 328000\n","    num_agent_steps_trained: 328000\n","    num_steps_sampled: 328000\n","    num_steps_trained: 328000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 82\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.433333333333332\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07506062433340141\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6656883897374912\n","    mean_inference_ms: 0.7631219359996448\n","    mean_raw_obs_processing_ms: 0.11297868391362349\n","  time_since_restore: 740.2318918704987\n","  time_this_iter_s: 8.250306129455566\n","  time_total_s: 740.2318918704987\n","  timers:\n","    learn_throughput: 1608.249\n","    learn_time_ms: 2487.178\n","    load_throughput: 8805088.695\n","    load_time_ms: 0.454\n","    sample_throughput: 474.711\n","    sample_time_ms: 8426.174\n","    update_time_ms: 2.885\n","  timestamp: 1649863842\n","  timesteps_since_restore: 328000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 328000\n","  training_iteration: 82\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:30:44 (running for 00:12:54.64)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         742.316</td><td style=\"text-align: right;\">404000</td><td style=\"text-align: right;\">-159.692 </td><td style=\"text-align: right;\">            -3.50908</td><td style=\"text-align: right;\">           -539.386 </td><td style=\"text-align: right;\">            103.11</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">         741.138</td><td style=\"text-align: right;\">272000</td><td style=\"text-align: right;\">  20.0469</td><td style=\"text-align: right;\">           225.161  </td><td style=\"text-align: right;\">           -715.081 </td><td style=\"text-align: right;\">            406.87</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">         740.232</td><td style=\"text-align: right;\">328000</td><td style=\"text-align: right;\"> 264.285 </td><td style=\"text-align: right;\">           319.598  </td><td style=\"text-align: right;\">             49.2654</td><td style=\"text-align: right;\">            236.08</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 408000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-30-45\n","  done: false\n","  episode_len_mean: 101.13\n","  episode_media: {}\n","  episode_reward_max: -3.50908246331133\n","  episode_reward_mean: -160.92411974966168\n","  episode_reward_min: -539.3863467128543\n","  episodes_this_iter: 42\n","  episodes_total: 3694\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 284027.65625\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.49637386202812195\n","          entropy_coeff: 0.0\n","          kl: 0.007164946291595697\n","          model: {}\n","          policy_loss: -0.004261063411831856\n","          total_loss: 2802.61083984375\n","          vf_explained_var: 0.5542383790016174\n","          vf_loss: 767.572021484375\n","    num_agent_steps_sampled: 408000\n","    num_agent_steps_trained: 408000\n","    num_steps_sampled: 408000\n","    num_steps_trained: 408000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 102\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.536363636363637\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07046207925758803\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.27349299427732726\n","    mean_inference_ms: 0.7260876764530242\n","    mean_raw_obs_processing_ms: 0.11276059851111783\n","  time_since_restore: 749.4651453495026\n","  time_this_iter_s: 7.149346590042114\n","  time_total_s: 749.4651453495026\n","  timers:\n","    learn_throughput: 1571.4\n","    learn_time_ms: 2545.501\n","    load_throughput: 9775793.031\n","    load_time_ms: 0.409\n","    sample_throughput: 550.179\n","    sample_time_ms: 7270.363\n","    update_time_ms: 2.923\n","  timestamp: 1649863845\n","  timesteps_since_restore: 408000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 408000\n","  training_iteration: 102\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 276000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-30-47\n","  done: false\n","  episode_len_mean: 416.75\n","  episode_media: {}\n","  episode_reward_max: 225.16093699222873\n","  episode_reward_mean: 23.136851489820813\n","  episode_reward_min: -715.0805705716425\n","  episodes_this_iter: 9\n","  episodes_total: 872\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.9668497443199158\n","          entropy_coeff: 0.0\n","          kl: 0.013302156701683998\n","          model: {}\n","          policy_loss: -0.03838913142681122\n","          total_loss: 277.6046447753906\n","          vf_explained_var: 0.7783503532409668\n","          vf_loss: 277.62957763671875\n","    num_agent_steps_sampled: 276000\n","    num_agent_steps_trained: 276000\n","    num_steps_sampled: 276000\n","    num_steps_trained: 276000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 69\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.15\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07388436923958853\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1233778169542108\n","    mean_inference_ms: 0.7662669149985811\n","    mean_raw_obs_processing_ms: 0.1123353473915999\n","  time_since_restore: 752.8363809585571\n","  time_this_iter_s: 11.69800090789795\n","  time_total_s: 752.8363809585571\n","  timers:\n","    learn_throughput: 1599.759\n","    learn_time_ms: 2500.376\n","    load_throughput: 7933990.353\n","    load_time_ms: 0.504\n","    sample_throughput: 364.062\n","    sample_time_ms: 10987.129\n","    update_time_ms: 2.796\n","  timestamp: 1649863847\n","  timesteps_since_restore: 276000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 276000\n","  training_iteration: 69\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:30:49 (running for 00:12:59.71)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">         749.465</td><td style=\"text-align: right;\">408000</td><td style=\"text-align: right;\">-160.924 </td><td style=\"text-align: right;\">            -3.50908</td><td style=\"text-align: right;\">           -539.386 </td><td style=\"text-align: right;\">            101.13</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         752.836</td><td style=\"text-align: right;\">276000</td><td style=\"text-align: right;\">  23.1369</td><td style=\"text-align: right;\">           225.161  </td><td style=\"text-align: right;\">           -715.081 </td><td style=\"text-align: right;\">            416.75</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">         740.232</td><td style=\"text-align: right;\">328000</td><td style=\"text-align: right;\"> 264.285 </td><td style=\"text-align: right;\">           319.598  </td><td style=\"text-align: right;\">             49.2654</td><td style=\"text-align: right;\">            236.08</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 332000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-30-51\n","  done: false\n","  episode_len_mean: 260.26\n","  episode_media: {}\n","  episode_reward_max: 319.59771310114866\n","  episode_reward_mean: 263.3230663142233\n","  episode_reward_min: 49.26539251093757\n","  episodes_this_iter: 6\n","  episodes_total: 1227\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.557171106338501\n","          entropy_coeff: 0.0\n","          kl: 0.007986867800354958\n","          model: {}\n","          policy_loss: -0.002272017765790224\n","          total_loss: 1282.6058349609375\n","          vf_explained_var: 0.194060817360878\n","          vf_loss: 1282.60693359375\n","    num_agent_steps_sampled: 332000\n","    num_agent_steps_trained: 332000\n","    num_steps_sampled: 332000\n","    num_steps_trained: 332000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 83\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.49230769230769\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0750625505358019\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6649711698421993\n","    mean_inference_ms: 0.7631196780446448\n","    mean_raw_obs_processing_ms: 0.11297855091371327\n","  time_since_restore: 749.482061624527\n","  time_this_iter_s: 9.25016975402832\n","  time_total_s: 749.482061624527\n","  timers:\n","    learn_throughput: 1606.157\n","    learn_time_ms: 2490.417\n","    load_throughput: 8332364.539\n","    load_time_ms: 0.48\n","    sample_throughput: 471.989\n","    sample_time_ms: 8474.781\n","    update_time_ms: 2.899\n","  timestamp: 1649863851\n","  timesteps_since_restore: 332000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 332000\n","  training_iteration: 83\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 412000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-30-53\n","  done: false\n","  episode_len_mean: 112.62\n","  episode_media: {}\n","  episode_reward_max: -3.50908246331133\n","  episode_reward_mean: -182.86354420922686\n","  episode_reward_min: -577.7312209100451\n","  episodes_this_iter: 28\n","  episodes_total: 3722\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 284027.65625\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5465813279151917\n","          entropy_coeff: 0.0\n","          kl: 0.035106513649225235\n","          model: {}\n","          policy_loss: 0.01677326299250126\n","          total_loss: 11336.6162109375\n","          vf_explained_var: 0.529594898223877\n","          vf_loss: 1365.37841796875\n","    num_agent_steps_sampled: 412000\n","    num_agent_steps_trained: 412000\n","    num_steps_sampled: 412000\n","    num_steps_trained: 412000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 103\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.890909090909089\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07047673353854712\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2735198098477384\n","    mean_inference_ms: 0.7262536605882118\n","    mean_raw_obs_processing_ms: 0.11277101424655944\n","  time_since_restore: 757.2943885326385\n","  time_this_iter_s: 7.829243183135986\n","  time_total_s: 757.2943885326385\n","  timers:\n","    learn_throughput: 1573.296\n","    learn_time_ms: 2542.433\n","    load_throughput: 9494745.897\n","    load_time_ms: 0.421\n","    sample_throughput: 544.49\n","    sample_time_ms: 7346.329\n","    update_time_ms: 2.898\n","  timestamp: 1649863853\n","  timesteps_since_restore: 412000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 412000\n","  training_iteration: 103\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:30:55 (running for 00:13:05.30)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         757.294</td><td style=\"text-align: right;\">412000</td><td style=\"text-align: right;\">-182.864 </td><td style=\"text-align: right;\">            -3.50908</td><td style=\"text-align: right;\">           -577.731 </td><td style=\"text-align: right;\">            112.62</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         752.836</td><td style=\"text-align: right;\">276000</td><td style=\"text-align: right;\">  23.1369</td><td style=\"text-align: right;\">           225.161  </td><td style=\"text-align: right;\">           -715.081 </td><td style=\"text-align: right;\">            416.75</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">         749.482</td><td style=\"text-align: right;\">332000</td><td style=\"text-align: right;\"> 263.323 </td><td style=\"text-align: right;\">           319.598  </td><td style=\"text-align: right;\">             49.2654</td><td style=\"text-align: right;\">            260.26</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 280000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-30-58\n","  done: false\n","  episode_len_mean: 399.18\n","  episode_media: {}\n","  episode_reward_max: 225.16093699222873\n","  episode_reward_mean: 17.949304254629485\n","  episode_reward_min: -715.0805705716425\n","  episodes_this_iter: 9\n","  episodes_total: 881\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.9558669924736023\n","          entropy_coeff: 0.0\n","          kl: 0.012091681361198425\n","          model: {}\n","          policy_loss: -0.04212323576211929\n","          total_loss: 775.64013671875\n","          vf_explained_var: 0.7316550612449646\n","          vf_loss: 775.6700439453125\n","    num_agent_steps_sampled: 280000\n","    num_agent_steps_trained: 280000\n","    num_steps_sampled: 280000\n","    num_steps_trained: 280000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 70\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.549999999999999\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0739080701740163\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1232510899949304\n","    mean_inference_ms: 0.7665487135335886\n","    mean_raw_obs_processing_ms: 0.11236339707742346\n","  time_since_restore: 763.9110994338989\n","  time_this_iter_s: 11.074718475341797\n","  time_total_s: 763.9110994338989\n","  timers:\n","    learn_throughput: 1603.326\n","    learn_time_ms: 2494.814\n","    load_throughput: 7929115.743\n","    load_time_ms: 0.504\n","    sample_throughput: 363.987\n","    sample_time_ms: 10989.407\n","    update_time_ms: 2.781\n","  timestamp: 1649863858\n","  timesteps_since_restore: 280000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 280000\n","  training_iteration: 70\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 416000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-31-00\n","  done: false\n","  episode_len_mean: 117.01\n","  episode_media: {}\n","  episode_reward_max: 28.18200124086576\n","  episode_reward_mean: -213.65305804331314\n","  episode_reward_min: -577.7312209100451\n","  episodes_this_iter: 34\n","  episodes_total: 3756\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 426041.5\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5087228417396545\n","          entropy_coeff: 0.0\n","          kl: 0.013768165372312069\n","          model: {}\n","          policy_loss: 0.0011090865591540933\n","          total_loss: 7037.0859375\n","          vf_explained_var: 0.674928605556488\n","          vf_loss: 1171.27490234375\n","    num_agent_steps_sampled: 416000\n","    num_agent_steps_trained: 416000\n","    num_steps_sampled: 416000\n","    num_steps_trained: 416000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 104\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.636363636363637\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07049010365336227\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.27364369092603896\n","    mean_inference_ms: 0.7263905831009739\n","    mean_raw_obs_processing_ms: 0.11278134902102473\n","  time_since_restore: 764.7138559818268\n","  time_this_iter_s: 7.419467449188232\n","  time_total_s: 764.7138559818268\n","  timers:\n","    learn_throughput: 1569.512\n","    learn_time_ms: 2548.564\n","    load_throughput: 9611696.362\n","    load_time_ms: 0.416\n","    sample_throughput: 546.942\n","    sample_time_ms: 7313.386\n","    update_time_ms: 2.945\n","  timestamp: 1649863860\n","  timesteps_since_restore: 416000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 416000\n","  training_iteration: 104\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:31:00 (running for 00:13:10.70)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         764.714</td><td style=\"text-align: right;\">416000</td><td style=\"text-align: right;\">-213.653 </td><td style=\"text-align: right;\">              28.182</td><td style=\"text-align: right;\">           -577.731 </td><td style=\"text-align: right;\">            117.01</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">         763.911</td><td style=\"text-align: right;\">280000</td><td style=\"text-align: right;\">  17.9493</td><td style=\"text-align: right;\">             225.161</td><td style=\"text-align: right;\">           -715.081 </td><td style=\"text-align: right;\">            399.18</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">         749.482</td><td style=\"text-align: right;\">332000</td><td style=\"text-align: right;\"> 263.323 </td><td style=\"text-align: right;\">             319.598</td><td style=\"text-align: right;\">             49.2654</td><td style=\"text-align: right;\">            260.26</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 336000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-31-01\n","  done: false\n","  episode_len_mean: 275.14\n","  episode_media: {}\n","  episode_reward_max: 319.59771310114866\n","  episode_reward_mean: 260.22301541594874\n","  episode_reward_min: 49.26539251093757\n","  episodes_this_iter: 10\n","  episodes_total: 1237\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5975067019462585\n","          entropy_coeff: 0.0\n","          kl: 0.008143149316310883\n","          model: {}\n","          policy_loss: -0.010167459957301617\n","          total_loss: 998.0357666015625\n","          vf_explained_var: 0.33574867248535156\n","          vf_loss: 998.044921875\n","    num_agent_steps_sampled: 336000\n","    num_agent_steps_trained: 336000\n","    num_steps_sampled: 336000\n","    num_steps_trained: 336000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 84\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.02857142857143\n","    ram_util_percent: 15.699999999999994\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07506986709830722\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6639509351425421\n","    mean_inference_ms: 0.7631644071524819\n","    mean_raw_obs_processing_ms: 0.11298380541371204\n","  time_since_restore: 759.2519414424896\n","  time_this_iter_s: 9.769879817962646\n","  time_total_s: 759.2519414424896\n","  timers:\n","    learn_throughput: 1597.134\n","    learn_time_ms: 2504.486\n","    load_throughput: 8036989.701\n","    load_time_ms: 0.498\n","    sample_throughput: 468.968\n","    sample_time_ms: 8529.36\n","    update_time_ms: 2.931\n","  timestamp: 1649863861\n","  timesteps_since_restore: 336000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 336000\n","  training_iteration: 84\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:31:05 (running for 00:13:15.73)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         764.714</td><td style=\"text-align: right;\">416000</td><td style=\"text-align: right;\">-213.653 </td><td style=\"text-align: right;\">              28.182</td><td style=\"text-align: right;\">           -577.731 </td><td style=\"text-align: right;\">            117.01</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">         763.911</td><td style=\"text-align: right;\">280000</td><td style=\"text-align: right;\">  17.9493</td><td style=\"text-align: right;\">             225.161</td><td style=\"text-align: right;\">           -715.081 </td><td style=\"text-align: right;\">            399.18</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         759.252</td><td style=\"text-align: right;\">336000</td><td style=\"text-align: right;\"> 260.223 </td><td style=\"text-align: right;\">             319.598</td><td style=\"text-align: right;\">             49.2654</td><td style=\"text-align: right;\">            275.14</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 420000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-31-08\n","  done: false\n","  episode_len_mean: 136.69\n","  episode_media: {}\n","  episode_reward_max: 28.18200124086576\n","  episode_reward_mean: -250.8452613496819\n","  episode_reward_min: -689.6313221330985\n","  episodes_this_iter: 23\n","  episodes_total: 3779\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 426041.5\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5313278436660767\n","          entropy_coeff: 0.0\n","          kl: 0.022845987230539322\n","          model: {}\n","          policy_loss: 0.008694966323673725\n","          total_loss: 11410.1806640625\n","          vf_explained_var: 0.8172990679740906\n","          vf_loss: 1676.8323974609375\n","    num_agent_steps_sampled: 420000\n","    num_agent_steps_trained: 420000\n","    num_steps_sampled: 420000\n","    num_steps_trained: 420000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 105\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 11.509090909090908\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07049299337050204\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2740584609240779\n","    mean_inference_ms: 0.7264420077097898\n","    mean_raw_obs_processing_ms: 0.11277456809039438\n","  time_since_restore: 772.4311146736145\n","  time_this_iter_s: 7.71725869178772\n","  time_total_s: 772.4311146736145\n","  timers:\n","    learn_throughput: 1564.397\n","    learn_time_ms: 2556.896\n","    load_throughput: 9638200.724\n","    load_time_ms: 0.415\n","    sample_throughput: 543.934\n","    sample_time_ms: 7353.829\n","    update_time_ms: 3.003\n","  timestamp: 1649863868\n","  timesteps_since_restore: 420000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 420000\n","  training_iteration: 105\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 284000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-31-10\n","  done: false\n","  episode_len_mean: 434.25\n","  episode_media: {}\n","  episode_reward_max: 225.16093699222873\n","  episode_reward_mean: 24.47413385239424\n","  episode_reward_min: -715.0805705716425\n","  episodes_this_iter: 6\n","  episodes_total: 887\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.9150773882865906\n","          entropy_coeff: 0.0\n","          kl: 0.011888908222317696\n","          model: {}\n","          policy_loss: -0.037209682166576385\n","          total_loss: 63.537776947021484\n","          vf_explained_var: 0.8504023551940918\n","          vf_loss: 63.56294631958008\n","    num_agent_steps_sampled: 284000\n","    num_agent_steps_trained: 284000\n","    num_steps_sampled: 284000\n","    num_steps_trained: 284000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 71\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.270588235294117\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.073923929881111\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1232732581525144\n","    mean_inference_ms: 0.766754323433083\n","    mean_raw_obs_processing_ms: 0.1123823216162006\n","  time_since_restore: 775.4356956481934\n","  time_this_iter_s: 11.524596214294434\n","  time_total_s: 775.4356956481934\n","  timers:\n","    learn_throughput: 1595.799\n","    learn_time_ms: 2506.581\n","    load_throughput: 7894788.951\n","    load_time_ms: 0.507\n","    sample_throughput: 361.287\n","    sample_time_ms: 11071.515\n","    update_time_ms: 2.816\n","  timestamp: 1649863870\n","  timesteps_since_restore: 284000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 284000\n","  training_iteration: 71\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 340000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-31-10\n","  done: false\n","  episode_len_mean: 285.98\n","  episode_media: {}\n","  episode_reward_max: 319.59771310114866\n","  episode_reward_mean: 259.7476631787869\n","  episode_reward_min: 49.26539251093757\n","  episodes_this_iter: 12\n","  episodes_total: 1249\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5876144766807556\n","          entropy_coeff: 0.0\n","          kl: 0.006323345936834812\n","          model: {}\n","          policy_loss: -0.002520535374060273\n","          total_loss: 333.5474548339844\n","          vf_explained_var: 0.14406800270080566\n","          vf_loss: 333.5491943359375\n","    num_agent_steps_sampled: 340000\n","    num_agent_steps_trained: 340000\n","    num_steps_sampled: 340000\n","    num_steps_trained: 340000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 85\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.138461538461538\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07507764136533328\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6629742409741486\n","    mean_inference_ms: 0.7632481267813737\n","    mean_raw_obs_processing_ms: 0.11298720565661505\n","  time_since_restore: 768.4340353012085\n","  time_this_iter_s: 9.182093858718872\n","  time_total_s: 768.4340353012085\n","  timers:\n","    learn_throughput: 1584.106\n","    learn_time_ms: 2525.084\n","    load_throughput: 8007453.226\n","    load_time_ms: 0.5\n","    sample_throughput: 465.071\n","    sample_time_ms: 8600.837\n","    update_time_ms: 2.943\n","  timestamp: 1649863870\n","  timesteps_since_restore: 340000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 340000\n","  training_iteration: 85\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:31:10 (running for 00:13:20.87)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         772.431</td><td style=\"text-align: right;\">420000</td><td style=\"text-align: right;\">-250.845 </td><td style=\"text-align: right;\">              28.182</td><td style=\"text-align: right;\">           -689.631 </td><td style=\"text-align: right;\">            136.69</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         775.436</td><td style=\"text-align: right;\">284000</td><td style=\"text-align: right;\">  24.4741</td><td style=\"text-align: right;\">             225.161</td><td style=\"text-align: right;\">           -715.081 </td><td style=\"text-align: right;\">            434.25</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         768.434</td><td style=\"text-align: right;\">340000</td><td style=\"text-align: right;\"> 259.748 </td><td style=\"text-align: right;\">             319.598</td><td style=\"text-align: right;\">             49.2654</td><td style=\"text-align: right;\">            285.98</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:31:15 (running for 00:13:25.95)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         772.431</td><td style=\"text-align: right;\">420000</td><td style=\"text-align: right;\">-250.845 </td><td style=\"text-align: right;\">              28.182</td><td style=\"text-align: right;\">           -689.631 </td><td style=\"text-align: right;\">            136.69</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         775.436</td><td style=\"text-align: right;\">284000</td><td style=\"text-align: right;\">  24.4741</td><td style=\"text-align: right;\">             225.161</td><td style=\"text-align: right;\">           -715.081 </td><td style=\"text-align: right;\">            434.25</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         768.434</td><td style=\"text-align: right;\">340000</td><td style=\"text-align: right;\"> 259.748 </td><td style=\"text-align: right;\">             319.598</td><td style=\"text-align: right;\">             49.2654</td><td style=\"text-align: right;\">            285.98</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 424000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-31-15\n","  done: false\n","  episode_len_mean: 136.26\n","  episode_media: {}\n","  episode_reward_max: 28.18200124086576\n","  episode_reward_mean: -271.6432956557179\n","  episode_reward_min: -689.6313221330985\n","  episodes_this_iter: 31\n","  episodes_total: 3810\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 639062.25\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5273040533065796\n","          entropy_coeff: 0.0\n","          kl: 0.022204963490366936\n","          model: {}\n","          policy_loss: 0.005409594159573317\n","          total_loss: 15112.9228515625\n","          vf_explained_var: 0.7599015831947327\n","          vf_loss: 922.5635986328125\n","    num_agent_steps_sampled: 424000\n","    num_agent_steps_trained: 424000\n","    num_steps_sampled: 424000\n","    num_steps_trained: 424000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 106\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.52\n","    ram_util_percent: 15.699999999999998\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0705000388198492\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2744976048950072\n","    mean_inference_ms: 0.7266097920284927\n","    mean_raw_obs_processing_ms: 0.11277451702981206\n","  time_since_restore: 779.9714729785919\n","  time_this_iter_s: 7.540358304977417\n","  time_total_s: 779.9714729785919\n","  timers:\n","    learn_throughput: 1574.014\n","    learn_time_ms: 2541.274\n","    load_throughput: 9893976.529\n","    load_time_ms: 0.404\n","    sample_throughput: 538.693\n","    sample_time_ms: 7425.384\n","    update_time_ms: 2.985\n","  timestamp: 1649863875\n","  timesteps_since_restore: 424000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 424000\n","  training_iteration: 106\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 344000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-31-19\n","  done: false\n","  episode_len_mean: 297.32\n","  episode_media: {}\n","  episode_reward_max: 319.59771310114866\n","  episode_reward_mean: 263.746752602283\n","  episode_reward_min: 54.18544296561788\n","  episodes_this_iter: 13\n","  episodes_total: 1262\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5622995495796204\n","          entropy_coeff: 0.0\n","          kl: 0.009380361065268517\n","          model: {}\n","          policy_loss: -0.009850641712546349\n","          total_loss: 372.7475891113281\n","          vf_explained_var: -0.012045860290527344\n","          vf_loss: 372.7562561035156\n","    num_agent_steps_sampled: 344000\n","    num_agent_steps_trained: 344000\n","    num_steps_sampled: 344000\n","    num_steps_trained: 344000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 86\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 11.6\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07508442899228462\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6620095611659415\n","    mean_inference_ms: 0.7633434184721873\n","    mean_raw_obs_processing_ms: 0.11298593513896733\n","  time_since_restore: 776.9920361042023\n","  time_this_iter_s: 8.558000802993774\n","  time_total_s: 776.9920361042023\n","  timers:\n","    learn_throughput: 1589.68\n","    learn_time_ms: 2516.229\n","    load_throughput: 8000961.419\n","    load_time_ms: 0.5\n","    sample_throughput: 462.249\n","    sample_time_ms: 8653.34\n","    update_time_ms: 2.924\n","  timestamp: 1649863879\n","  timesteps_since_restore: 344000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 344000\n","  training_iteration: 86\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:31:21 (running for 00:13:31.47)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   106</td><td style=\"text-align: right;\">         779.971</td><td style=\"text-align: right;\">424000</td><td style=\"text-align: right;\">-271.643 </td><td style=\"text-align: right;\">              28.182</td><td style=\"text-align: right;\">           -689.631 </td><td style=\"text-align: right;\">            136.26</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         775.436</td><td style=\"text-align: right;\">284000</td><td style=\"text-align: right;\">  24.4741</td><td style=\"text-align: right;\">             225.161</td><td style=\"text-align: right;\">           -715.081 </td><td style=\"text-align: right;\">            434.25</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         776.992</td><td style=\"text-align: right;\">344000</td><td style=\"text-align: right;\"> 263.747 </td><td style=\"text-align: right;\">             319.598</td><td style=\"text-align: right;\">             54.1854</td><td style=\"text-align: right;\">            297.32</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 288000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-31-22\n","  done: false\n","  episode_len_mean: 425.26\n","  episode_media: {}\n","  episode_reward_max: 225.16093699222873\n","  episode_reward_mean: 23.2345604724503\n","  episode_reward_min: -715.0805705716425\n","  episodes_this_iter: 6\n","  episodes_total: 893\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.9378468990325928\n","          entropy_coeff: 0.0\n","          kl: 0.011044953018426895\n","          model: {}\n","          policy_loss: -0.03346830978989601\n","          total_loss: 175.68414306640625\n","          vf_explained_var: 0.8227779269218445\n","          vf_loss: 175.7064208984375\n","    num_agent_steps_sampled: 288000\n","    num_agent_steps_trained: 288000\n","    num_steps_sampled: 288000\n","    num_steps_trained: 288000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 72\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.852941176470589\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07393914784950012\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1235791624185572\n","    mean_inference_ms: 0.7669689273872237\n","    mean_raw_obs_processing_ms: 0.11240027327955118\n","  time_since_restore: 787.4007565975189\n","  time_this_iter_s: 11.965060949325562\n","  time_total_s: 787.4007565975189\n","  timers:\n","    learn_throughput: 1592.214\n","    learn_time_ms: 2512.225\n","    load_throughput: 7986108.149\n","    load_time_ms: 0.501\n","    sample_throughput: 357.072\n","    sample_time_ms: 11202.21\n","    update_time_ms: 2.819\n","  timestamp: 1649863882\n","  timesteps_since_restore: 288000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 288000\n","  training_iteration: 72\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 428000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-31-23\n","  done: false\n","  episode_len_mean: 136.63\n","  episode_media: {}\n","  episode_reward_max: 45.04284701348985\n","  episode_reward_mean: -268.78602975047465\n","  episode_reward_min: -689.6313221330985\n","  episodes_this_iter: 34\n","  episodes_total: 3844\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 958593.375\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5341130495071411\n","          entropy_coeff: 0.0\n","          kl: 0.02197047881782055\n","          model: {}\n","          policy_loss: 0.0048404536210000515\n","          total_loss: 22122.169921875\n","          vf_explained_var: 0.6207275390625\n","          vf_loss: 1061.4085693359375\n","    num_agent_steps_sampled: 428000\n","    num_agent_steps_trained: 428000\n","    num_steps_sampled: 428000\n","    num_steps_trained: 428000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 107\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.263636363636364\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07050672677117084\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.27481568993947475\n","    mean_inference_ms: 0.7268099465654504\n","    mean_raw_obs_processing_ms: 0.112780727731454\n","  time_since_restore: 787.3677659034729\n","  time_this_iter_s: 7.3962929248809814\n","  time_total_s: 787.3677659034729\n","  timers:\n","    learn_throughput: 1578.986\n","    learn_time_ms: 2533.272\n","    load_throughput: 9787769.675\n","    load_time_ms: 0.409\n","    sample_throughput: 536.78\n","    sample_time_ms: 7451.837\n","    update_time_ms: 2.941\n","  timestamp: 1649863883\n","  timesteps_since_restore: 428000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 428000\n","  training_iteration: 107\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:31:26 (running for 00:13:36.56)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         787.368</td><td style=\"text-align: right;\">428000</td><td style=\"text-align: right;\">-268.786 </td><td style=\"text-align: right;\">             45.0428</td><td style=\"text-align: right;\">           -689.631 </td><td style=\"text-align: right;\">            136.63</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         787.401</td><td style=\"text-align: right;\">288000</td><td style=\"text-align: right;\">  23.2346</td><td style=\"text-align: right;\">            225.161 </td><td style=\"text-align: right;\">           -715.081 </td><td style=\"text-align: right;\">            425.26</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         776.992</td><td style=\"text-align: right;\">344000</td><td style=\"text-align: right;\"> 263.747 </td><td style=\"text-align: right;\">            319.598 </td><td style=\"text-align: right;\">             54.1854</td><td style=\"text-align: right;\">            297.32</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 348000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-31-27\n","  done: false\n","  episode_len_mean: 310.02\n","  episode_media: {}\n","  episode_reward_max: 318.8150450860983\n","  episode_reward_mean: 262.4417142324161\n","  episode_reward_min: 54.18544296561788\n","  episodes_this_iter: 11\n","  episodes_total: 1273\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5669751167297363\n","          entropy_coeff: 0.0\n","          kl: 0.005806758534163237\n","          model: {}\n","          policy_loss: -0.007640789728611708\n","          total_loss: 295.5702819824219\n","          vf_explained_var: 0.07923759520053864\n","          vf_loss: 295.5771789550781\n","    num_agent_steps_sampled: 348000\n","    num_agent_steps_trained: 348000\n","    num_steps_sampled: 348000\n","    num_steps_trained: 348000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 87\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.446153846153845\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07509001889803776\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6613056752196462\n","    mean_inference_ms: 0.7634242404932527\n","    mean_raw_obs_processing_ms: 0.11298313577442753\n","  time_since_restore: 785.7049474716187\n","  time_this_iter_s: 8.712911367416382\n","  time_total_s: 785.7049474716187\n","  timers:\n","    learn_throughput: 1599.943\n","    learn_time_ms: 2500.089\n","    load_throughput: 7778393.064\n","    load_time_ms: 0.514\n","    sample_throughput: 458.572\n","    sample_time_ms: 8722.722\n","    update_time_ms: 2.864\n","  timestamp: 1649863887\n","  timesteps_since_restore: 348000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 348000\n","  training_iteration: 87\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 432000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-31-30\n","  done: false\n","  episode_len_mean: 134.61\n","  episode_media: {}\n","  episode_reward_max: 45.04284701348985\n","  episode_reward_mean: -276.82852863575596\n","  episode_reward_min: -667.1862976416326\n","  episodes_this_iter: 28\n","  episodes_total: 3872\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1437890.125\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5005984902381897\n","          entropy_coeff: 0.0\n","          kl: 0.05172375962138176\n","          model: {}\n","          policy_loss: 0.017580533400177956\n","          total_loss: 75724.390625\n","          vf_explained_var: 0.620557963848114\n","          vf_loss: 1351.288818359375\n","    num_agent_steps_sampled: 432000\n","    num_agent_steps_trained: 432000\n","    num_steps_sampled: 432000\n","    num_steps_trained: 432000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 108\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.236363636363636\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07051522461754192\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2750390003052171\n","    mean_inference_ms: 0.7269520979831293\n","    mean_raw_obs_processing_ms: 0.11278865684628313\n","  time_since_restore: 794.782143831253\n","  time_this_iter_s: 7.414377927780151\n","  time_total_s: 794.782143831253\n","  timers:\n","    learn_throughput: 1581.914\n","    learn_time_ms: 2528.583\n","    load_throughput: 9357586.034\n","    load_time_ms: 0.427\n","    sample_throughput: 535.922\n","    sample_time_ms: 7463.773\n","    update_time_ms: 2.916\n","  timestamp: 1649863890\n","  timesteps_since_restore: 432000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 432000\n","  training_iteration: 108\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:31:31 (running for 00:13:41.93)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         794.782</td><td style=\"text-align: right;\">432000</td><td style=\"text-align: right;\">-276.829 </td><td style=\"text-align: right;\">             45.0428</td><td style=\"text-align: right;\">           -667.186 </td><td style=\"text-align: right;\">            134.61</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         787.401</td><td style=\"text-align: right;\">288000</td><td style=\"text-align: right;\">  23.2346</td><td style=\"text-align: right;\">            225.161 </td><td style=\"text-align: right;\">           -715.081 </td><td style=\"text-align: right;\">            425.26</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">         785.705</td><td style=\"text-align: right;\">348000</td><td style=\"text-align: right;\"> 262.442 </td><td style=\"text-align: right;\">            318.815 </td><td style=\"text-align: right;\">             54.1854</td><td style=\"text-align: right;\">            310.02</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 292000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-31-32\n","  done: false\n","  episode_len_mean: 452.32\n","  episode_media: {}\n","  episode_reward_max: 225.16093699222873\n","  episode_reward_mean: 27.093242808311178\n","  episode_reward_min: -715.0805705716425\n","  episodes_this_iter: 9\n","  episodes_total: 902\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.9119042158126831\n","          entropy_coeff: 0.0\n","          kl: 0.013468739576637745\n","          model: {}\n","          policy_loss: -0.03418034687638283\n","          total_loss: 303.4787902832031\n","          vf_explained_var: 0.8259349465370178\n","          vf_loss: 303.49932861328125\n","    num_agent_steps_sampled: 292000\n","    num_agent_steps_trained: 292000\n","    num_steps_sampled: 292000\n","    num_steps_trained: 292000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 73\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.966666666666667\n","    ram_util_percent: 15.699999999999994\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07395990281901714\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1240570004227097\n","    mean_inference_ms: 0.7672875538710667\n","    mean_raw_obs_processing_ms: 0.11242653866335871\n","  time_since_restore: 798.1836695671082\n","  time_this_iter_s: 10.782912969589233\n","  time_total_s: 798.1836695671082\n","  timers:\n","    learn_throughput: 1601.347\n","    learn_time_ms: 2497.898\n","    load_throughput: 8154968.162\n","    load_time_ms: 0.49\n","    sample_throughput: 356.971\n","    sample_time_ms: 11205.381\n","    update_time_ms: 2.821\n","  timestamp: 1649863892\n","  timesteps_since_restore: 292000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 292000\n","  training_iteration: 73\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 352000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-31-36\n","  done: false\n","  episode_len_mean: 322.26\n","  episode_media: {}\n","  episode_reward_max: 318.8150450860983\n","  episode_reward_mean: 261.2011512977206\n","  episode_reward_min: 54.18544296561788\n","  episodes_this_iter: 12\n","  episodes_total: 1285\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6349039077758789\n","          entropy_coeff: 0.0\n","          kl: 0.011163555085659027\n","          model: {}\n","          policy_loss: -0.0091111334040761\n","          total_loss: 384.46478271484375\n","          vf_explained_var: 0.25682738423347473\n","          vf_loss: 384.4724426269531\n","    num_agent_steps_sampled: 352000\n","    num_agent_steps_trained: 352000\n","    num_steps_sampled: 352000\n","    num_steps_trained: 352000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 88\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.953846153846156\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07509301695643168\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6606752288115737\n","    mean_inference_ms: 0.7634874349770027\n","    mean_raw_obs_processing_ms: 0.11297625350587427\n","  time_since_restore: 794.5243566036224\n","  time_this_iter_s: 8.819409132003784\n","  time_total_s: 794.5243566036224\n","  timers:\n","    learn_throughput: 1608.206\n","    learn_time_ms: 2487.244\n","    load_throughput: 7823369.55\n","    load_time_ms: 0.511\n","    sample_throughput: 456.418\n","    sample_time_ms: 8763.901\n","    update_time_ms: 2.896\n","  timestamp: 1649863896\n","  timesteps_since_restore: 352000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 352000\n","  training_iteration: 88\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:31:36 (running for 00:13:47.16)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         794.782</td><td style=\"text-align: right;\">432000</td><td style=\"text-align: right;\">-276.829 </td><td style=\"text-align: right;\">             45.0428</td><td style=\"text-align: right;\">           -667.186 </td><td style=\"text-align: right;\">            134.61</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         798.184</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  27.0932</td><td style=\"text-align: right;\">            225.161 </td><td style=\"text-align: right;\">           -715.081 </td><td style=\"text-align: right;\">            452.32</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         794.524</td><td style=\"text-align: right;\">352000</td><td style=\"text-align: right;\"> 261.201 </td><td style=\"text-align: right;\">            318.815 </td><td style=\"text-align: right;\">             54.1854</td><td style=\"text-align: right;\">            322.26</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 436000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-31-38\n","  done: false\n","  episode_len_mean: 130.03\n","  episode_media: {}\n","  episode_reward_max: 45.04284701348985\n","  episode_reward_mean: -286.26445624691087\n","  episode_reward_min: -667.1862976416326\n","  episodes_this_iter: 28\n","  episodes_total: 3900\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 2156835.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.4806104898452759\n","          entropy_coeff: 0.0\n","          kl: 0.04240214079618454\n","          model: {}\n","          policy_loss: 0.01734025590121746\n","          total_loss: 92776.875\n","          vf_explained_var: 0.48650500178337097\n","          vf_loss: 1322.4453125\n","    num_agent_steps_sampled: 436000\n","    num_agent_steps_trained: 436000\n","    num_steps_sampled: 436000\n","    num_steps_trained: 436000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 109\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.270000000000001\n","    ram_util_percent: 15.699999999999998\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.070521921451294\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.27522879730618954\n","    mean_inference_ms: 0.7270202373071237\n","    mean_raw_obs_processing_ms: 0.11279444462896439\n","  time_since_restore: 802.2835648059845\n","  time_this_iter_s: 7.501420974731445\n","  time_total_s: 802.2835648059845\n","  timers:\n","    learn_throughput: 1589.058\n","    learn_time_ms: 2517.214\n","    load_throughput: 9189470.34\n","    load_time_ms: 0.435\n","    sample_throughput: 533.044\n","    sample_time_ms: 7504.065\n","    update_time_ms: 2.875\n","  timestamp: 1649863898\n","  timesteps_since_restore: 436000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 436000\n","  training_iteration: 109\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:31:42 (running for 00:13:52.47)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         802.284</td><td style=\"text-align: right;\">436000</td><td style=\"text-align: right;\">-286.264 </td><td style=\"text-align: right;\">             45.0428</td><td style=\"text-align: right;\">           -667.186 </td><td style=\"text-align: right;\">            130.03</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         798.184</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  27.0932</td><td style=\"text-align: right;\">            225.161 </td><td style=\"text-align: right;\">           -715.081 </td><td style=\"text-align: right;\">            452.32</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         794.524</td><td style=\"text-align: right;\">352000</td><td style=\"text-align: right;\"> 261.201 </td><td style=\"text-align: right;\">            318.815 </td><td style=\"text-align: right;\">             54.1854</td><td style=\"text-align: right;\">            322.26</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 296000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-31-43\n","  done: false\n","  episode_len_mean: 436.29\n","  episode_media: {}\n","  episode_reward_max: 225.16093699222873\n","  episode_reward_mean: 24.94940434269368\n","  episode_reward_min: -715.0805705716425\n","  episodes_this_iter: 10\n","  episodes_total: 912\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.926091730594635\n","          entropy_coeff: 0.0\n","          kl: 0.015964308753609657\n","          model: {}\n","          policy_loss: -0.04835129529237747\n","          total_loss: 445.29705810546875\n","          vf_explained_var: 0.8337647318840027\n","          vf_loss: 445.3292541503906\n","    num_agent_steps_sampled: 296000\n","    num_agent_steps_trained: 296000\n","    num_steps_sampled: 296000\n","    num_steps_trained: 296000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 74\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.44375\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0739845611982964\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.124511750463171\n","    mean_inference_ms: 0.7676602127488659\n","    mean_raw_obs_processing_ms: 0.11245969315596131\n","  time_since_restore: 809.0072250366211\n","  time_this_iter_s: 10.82355546951294\n","  time_total_s: 809.0072250366211\n","  timers:\n","    learn_throughput: 1600.489\n","    learn_time_ms: 2499.236\n","    load_throughput: 8161712.395\n","    load_time_ms: 0.49\n","    sample_throughput: 357.874\n","    sample_time_ms: 11177.123\n","    update_time_ms: 2.829\n","  timestamp: 1649863903\n","  timesteps_since_restore: 296000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 296000\n","  training_iteration: 74\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 356000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-31-44\n","  done: false\n","  episode_len_mean: 322.21\n","  episode_media: {}\n","  episode_reward_max: 318.8150450860983\n","  episode_reward_mean: 263.81359506324515\n","  episode_reward_min: 54.18544296561788\n","  episodes_this_iter: 18\n","  episodes_total: 1303\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6635638475418091\n","          entropy_coeff: 0.0\n","          kl: 0.008885188028216362\n","          model: {}\n","          policy_loss: -0.014198441058397293\n","          total_loss: 105.6606216430664\n","          vf_explained_var: 0.457588791847229\n","          vf_loss: 105.67369079589844\n","    num_agent_steps_sampled: 356000\n","    num_agent_steps_trained: 356000\n","    num_steps_sampled: 356000\n","    num_steps_trained: 356000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 89\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.936363636363637\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0750963715189293\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.659740785225292\n","    mean_inference_ms: 0.7635776516768432\n","    mean_raw_obs_processing_ms: 0.11296554708982087\n","  time_since_restore: 802.5811433792114\n","  time_this_iter_s: 8.05678677558899\n","  time_total_s: 802.5811433792114\n","  timers:\n","    learn_throughput: 1599.279\n","    learn_time_ms: 2501.126\n","    load_throughput: 7821181.297\n","    load_time_ms: 0.511\n","    sample_throughput: 459.109\n","    sample_time_ms: 8712.52\n","    update_time_ms: 2.944\n","  timestamp: 1649863904\n","  timesteps_since_restore: 356000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 356000\n","  training_iteration: 89\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 440000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-31-46\n","  done: false\n","  episode_len_mean: 137.6\n","  episode_media: {}\n","  episode_reward_max: 32.85401120662169\n","  episode_reward_mean: -305.2824876961925\n","  episode_reward_min: -667.1862976416326\n","  episodes_this_iter: 29\n","  episodes_total: 3929\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 3235252.75\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5071350336074829\n","          entropy_coeff: 0.0\n","          kl: 0.03661346435546875\n","          model: {}\n","          policy_loss: 0.011848889291286469\n","          total_loss: 119618.9921875\n","          vf_explained_var: 0.627594530582428\n","          vf_loss: 1165.1646728515625\n","    num_agent_steps_sampled: 440000\n","    num_agent_steps_trained: 440000\n","    num_steps_sampled: 440000\n","    num_steps_trained: 440000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 110\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.1\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0705287343818494\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.275578483796153\n","    mean_inference_ms: 0.727093132073301\n","    mean_raw_obs_processing_ms: 0.11279750036426714\n","  time_since_restore: 810.0307166576385\n","  time_this_iter_s: 7.747151851654053\n","  time_total_s: 810.0307166576385\n","  timers:\n","    learn_throughput: 1581.816\n","    learn_time_ms: 2528.739\n","    load_throughput: 8901796.572\n","    load_time_ms: 0.449\n","    sample_throughput: 531.121\n","    sample_time_ms: 7531.246\n","    update_time_ms: 2.969\n","  timestamp: 1649863906\n","  timesteps_since_restore: 440000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 440000\n","  training_iteration: 110\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:31:48 (running for 00:13:58.33)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   110</td><td style=\"text-align: right;\">         810.031</td><td style=\"text-align: right;\">440000</td><td style=\"text-align: right;\">-305.282 </td><td style=\"text-align: right;\">              32.854</td><td style=\"text-align: right;\">           -667.186 </td><td style=\"text-align: right;\">            137.6 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         809.007</td><td style=\"text-align: right;\">296000</td><td style=\"text-align: right;\">  24.9494</td><td style=\"text-align: right;\">             225.161</td><td style=\"text-align: right;\">           -715.081 </td><td style=\"text-align: right;\">            436.29</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         802.581</td><td style=\"text-align: right;\">356000</td><td style=\"text-align: right;\"> 263.814 </td><td style=\"text-align: right;\">             318.815</td><td style=\"text-align: right;\">             54.1854</td><td style=\"text-align: right;\">            322.21</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 360000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-31-53\n","  done: false\n","  episode_len_mean: 321.47\n","  episode_media: {}\n","  episode_reward_max: 318.8150450860983\n","  episode_reward_mean: 265.546759108324\n","  episode_reward_min: 57.77437867352573\n","  episodes_this_iter: 17\n","  episodes_total: 1320\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6725903749465942\n","          entropy_coeff: 0.0\n","          kl: 0.012651162222027779\n","          model: {}\n","          policy_loss: -0.020351212471723557\n","          total_loss: 80.92152404785156\n","          vf_explained_var: 0.5698614716529846\n","          vf_loss: 80.94027709960938\n","    num_agent_steps_sampled: 360000\n","    num_agent_steps_trained: 360000\n","    num_steps_sampled: 360000\n","    num_steps_trained: 360000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 90\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.516666666666667\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07509363867301419\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6588327042352556\n","    mean_inference_ms: 0.7635909786948727\n","    mean_raw_obs_processing_ms: 0.11294636356974742\n","  time_since_restore: 810.6327147483826\n","  time_this_iter_s: 8.051571369171143\n","  time_total_s: 810.6327147483826\n","  timers:\n","    learn_throughput: 1598.121\n","    learn_time_ms: 2502.94\n","    load_throughput: 7797553.449\n","    load_time_ms: 0.513\n","    sample_throughput: 460.071\n","    sample_time_ms: 8694.308\n","    update_time_ms: 2.909\n","  timestamp: 1649863913\n","  timesteps_since_restore: 360000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 360000\n","  training_iteration: 90\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 444000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-31-53\n","  done: false\n","  episode_len_mean: 123.64\n","  episode_media: {}\n","  episode_reward_max: -2.495485136803225\n","  episode_reward_mean: -274.9696223089443\n","  episode_reward_min: -594.2378749038093\n","  episodes_this_iter: 39\n","  episodes_total: 3968\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 4852879.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.4329915940761566\n","          entropy_coeff: 0.0\n","          kl: 0.029269911348819733\n","          model: {}\n","          policy_loss: 0.0115832993760705\n","          total_loss: 144038.375\n","          vf_explained_var: 0.5331755876541138\n","          vf_loss: 1995.021484375\n","    num_agent_steps_sampled: 444000\n","    num_agent_steps_trained: 444000\n","    num_steps_sampled: 444000\n","    num_steps_trained: 444000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 111\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.280000000000001\n","    ram_util_percent: 15.699999999999998\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07052909594941306\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2758409657901978\n","    mean_inference_ms: 0.7270995187864976\n","    mean_raw_obs_processing_ms: 0.11279222647864277\n","  time_since_restore: 817.236382484436\n","  time_this_iter_s: 7.205665826797485\n","  time_total_s: 817.236382484436\n","  timers:\n","    learn_throughput: 1575.007\n","    learn_time_ms: 2539.672\n","    load_throughput: 8815730.125\n","    load_time_ms: 0.454\n","    sample_throughput: 531.843\n","    sample_time_ms: 7521.021\n","    update_time_ms: 3.016\n","  timestamp: 1649863913\n","  timesteps_since_restore: 444000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 444000\n","  training_iteration: 111\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:31:53 (running for 00:14:03.50)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         817.236</td><td style=\"text-align: right;\">444000</td><td style=\"text-align: right;\">-274.97  </td><td style=\"text-align: right;\">            -2.49549</td><td style=\"text-align: right;\">           -594.238 </td><td style=\"text-align: right;\">            123.64</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         809.007</td><td style=\"text-align: right;\">296000</td><td style=\"text-align: right;\">  24.9494</td><td style=\"text-align: right;\">           225.161  </td><td style=\"text-align: right;\">           -715.081 </td><td style=\"text-align: right;\">            436.29</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         810.633</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> 265.547 </td><td style=\"text-align: right;\">           318.815  </td><td style=\"text-align: right;\">             57.7744</td><td style=\"text-align: right;\">            321.47</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 300000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-31-54\n","  done: false\n","  episode_len_mean: 448.91\n","  episode_media: {}\n","  episode_reward_max: 209.5449364255402\n","  episode_reward_mean: 33.010453216166205\n","  episode_reward_min: -167.92305148561758\n","  episodes_this_iter: 11\n","  episodes_total: 923\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.9130907654762268\n","          entropy_coeff: 0.0\n","          kl: 0.01374109461903572\n","          model: {}\n","          policy_loss: -0.051271673291921616\n","          total_loss: 865.439453125\n","          vf_explained_var: 0.6811093091964722\n","          vf_loss: 865.476806640625\n","    num_agent_steps_sampled: 300000\n","    num_agent_steps_trained: 300000\n","    num_steps_sampled: 300000\n","    num_steps_trained: 300000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 75\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.42\n","    ram_util_percent: 15.699999999999994\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07401247465888723\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1249324026061809\n","    mean_inference_ms: 0.7680458939824176\n","    mean_raw_obs_processing_ms: 0.1124976647778875\n","  time_since_restore: 819.7064442634583\n","  time_this_iter_s: 10.699219226837158\n","  time_total_s: 819.7064442634583\n","  timers:\n","    learn_throughput: 1600.211\n","    learn_time_ms: 2499.671\n","    load_throughput: 8159330.804\n","    load_time_ms: 0.49\n","    sample_throughput: 359.699\n","    sample_time_ms: 11120.411\n","    update_time_ms: 2.844\n","  timestamp: 1649863914\n","  timesteps_since_restore: 300000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 300000\n","  training_iteration: 75\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:31:58 (running for 00:14:08.92)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         817.236</td><td style=\"text-align: right;\">444000</td><td style=\"text-align: right;\">-274.97  </td><td style=\"text-align: right;\">            -2.49549</td><td style=\"text-align: right;\">           -594.238 </td><td style=\"text-align: right;\">            123.64</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         819.706</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  33.0105</td><td style=\"text-align: right;\">           209.545  </td><td style=\"text-align: right;\">           -167.923 </td><td style=\"text-align: right;\">            448.91</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         810.633</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> 265.547 </td><td style=\"text-align: right;\">           318.815  </td><td style=\"text-align: right;\">             57.7744</td><td style=\"text-align: right;\">            321.47</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 448000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-32-00\n","  done: false\n","  episode_len_mean: 111.09\n","  episode_media: {}\n","  episode_reward_max: 35.49570398286849\n","  episode_reward_mean: -224.3951624765746\n","  episode_reward_min: -590.6760512019227\n","  episodes_this_iter: 38\n","  episodes_total: 4006\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 7279318.5\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.462398499250412\n","          entropy_coeff: 0.0\n","          kl: 0.014764939434826374\n","          model: {}\n","          policy_loss: -0.0002826229319907725\n","          total_loss: 108629.3125\n","          vf_explained_var: 0.6703264117240906\n","          vf_loss: 1150.6138916015625\n","    num_agent_steps_sampled: 448000\n","    num_agent_steps_trained: 448000\n","    num_steps_sampled: 448000\n","    num_steps_trained: 448000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 112\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.89\n","    ram_util_percent: 15.699999999999998\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07052641222431472\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2757739675024337\n","    mean_inference_ms: 0.7270485758609999\n","    mean_raw_obs_processing_ms: 0.11278574863746876\n","  time_since_restore: 824.4361455440521\n","  time_this_iter_s: 7.199763059616089\n","  time_total_s: 824.4361455440521\n","  timers:\n","    learn_throughput: 1569.579\n","    learn_time_ms: 2548.454\n","    load_throughput: 8828719.676\n","    load_time_ms: 0.453\n","    sample_throughput: 531.314\n","    sample_time_ms: 7528.499\n","    update_time_ms: 3.037\n","  timestamp: 1649863920\n","  timesteps_since_restore: 448000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 448000\n","  training_iteration: 112\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 364000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-32-01\n","  done: false\n","  episode_len_mean: 275.83\n","  episode_media: {}\n","  episode_reward_max: 318.8150450860983\n","  episode_reward_mean: 268.51785117907673\n","  episode_reward_min: 57.77437867352573\n","  episodes_this_iter: 18\n","  episodes_total: 1338\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.694381594657898\n","          entropy_coeff: 0.0\n","          kl: 0.013837719336152077\n","          model: {}\n","          policy_loss: -0.014559217728674412\n","          total_loss: 60.13268280029297\n","          vf_explained_var: 0.5931712985038757\n","          vf_loss: 60.14548873901367\n","    num_agent_steps_sampled: 364000\n","    num_agent_steps_trained: 364000\n","    num_steps_sampled: 364000\n","    num_steps_trained: 364000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 91\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.472727272727274\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07508363738848324\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6571512157680713\n","    mean_inference_ms: 0.763508888292761\n","    mean_raw_obs_processing_ms: 0.11292353854604972\n","  time_since_restore: 818.6852490901947\n","  time_this_iter_s: 8.052534341812134\n","  time_total_s: 818.6852490901947\n","  timers:\n","    learn_throughput: 1592.367\n","    learn_time_ms: 2511.984\n","    load_throughput: 7635377.964\n","    load_time_ms: 0.524\n","    sample_throughput: 459.853\n","    sample_time_ms: 8698.424\n","    update_time_ms: 2.928\n","  timestamp: 1649863921\n","  timesteps_since_restore: 364000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 364000\n","  training_iteration: 91\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:32:04 (running for 00:14:14.35)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   112</td><td style=\"text-align: right;\">         824.436</td><td style=\"text-align: right;\">448000</td><td style=\"text-align: right;\">-224.395 </td><td style=\"text-align: right;\">             35.4957</td><td style=\"text-align: right;\">           -590.676 </td><td style=\"text-align: right;\">            111.09</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         819.706</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  33.0105</td><td style=\"text-align: right;\">            209.545 </td><td style=\"text-align: right;\">           -167.923 </td><td style=\"text-align: right;\">            448.91</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         818.685</td><td style=\"text-align: right;\">364000</td><td style=\"text-align: right;\"> 268.518 </td><td style=\"text-align: right;\">            318.815 </td><td style=\"text-align: right;\">             57.7744</td><td style=\"text-align: right;\">            275.83</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 304000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-32-06\n","  done: false\n","  episode_len_mean: 440.13\n","  episode_media: {}\n","  episode_reward_max: 209.5449364255402\n","  episode_reward_mean: 31.465697239319365\n","  episode_reward_min: -167.92305148561758\n","  episodes_this_iter: 8\n","  episodes_total: 931\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.9332398772239685\n","          entropy_coeff: 0.0\n","          kl: 0.013070031069219112\n","          model: {}\n","          policy_loss: -0.04389612004160881\n","          total_loss: 221.14512634277344\n","          vf_explained_var: 0.8706640601158142\n","          vf_loss: 221.17579650878906\n","    num_agent_steps_sampled: 304000\n","    num_agent_steps_trained: 304000\n","    num_steps_sampled: 304000\n","    num_steps_trained: 304000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 76\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.35625\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07403240526370797\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1252761646765324\n","    mean_inference_ms: 0.768313571333383\n","    mean_raw_obs_processing_ms: 0.11252468111804986\n","  time_since_restore: 831.1255102157593\n","  time_this_iter_s: 11.419065952301025\n","  time_total_s: 831.1255102157593\n","  timers:\n","    learn_throughput: 1596.779\n","    learn_time_ms: 2505.043\n","    load_throughput: 8338991.004\n","    load_time_ms: 0.48\n","    sample_throughput: 355.628\n","    sample_time_ms: 11247.7\n","    update_time_ms: 2.849\n","  timestamp: 1649863926\n","  timesteps_since_restore: 304000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 304000\n","  training_iteration: 76\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 452000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-32-07\n","  done: false\n","  episode_len_mean: 107.81\n","  episode_media: {}\n","  episode_reward_max: 35.49570398286849\n","  episode_reward_mean: -209.80936529818982\n","  episode_reward_min: -665.4552850359056\n","  episodes_this_iter: 35\n","  episodes_total: 4041\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 7279318.5\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.49465516209602356\n","          entropy_coeff: 0.0\n","          kl: 0.0090333865955472\n","          model: {}\n","          policy_loss: 0.002998940646648407\n","          total_loss: 67794.2890625\n","          vf_explained_var: 0.44672995805740356\n","          vf_loss: 2037.3834228515625\n","    num_agent_steps_sampled: 452000\n","    num_agent_steps_trained: 452000\n","    num_steps_sampled: 452000\n","    num_steps_trained: 452000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 113\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.309999999999999\n","    ram_util_percent: 15.699999999999998\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07051645947884827\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.27554095767710796\n","    mean_inference_ms: 0.7268817599400268\n","    mean_raw_obs_processing_ms: 0.11277206349302117\n","  time_since_restore: 831.6086237430573\n","  time_this_iter_s: 7.172478199005127\n","  time_total_s: 831.6086237430573\n","  timers:\n","    learn_throughput: 1570.116\n","    learn_time_ms: 2547.583\n","    load_throughput: 8848742.616\n","    load_time_ms: 0.452\n","    sample_throughput: 535.258\n","    sample_time_ms: 7473.026\n","    update_time_ms: 3.033\n","  timestamp: 1649863927\n","  timesteps_since_restore: 452000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 452000\n","  training_iteration: 113\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 368000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-32-09\n","  done: false\n","  episode_len_mean: 264.89\n","  episode_media: {}\n","  episode_reward_max: 312.09961081439167\n","  episode_reward_mean: 270.29694811827096\n","  episode_reward_min: 57.77437867352573\n","  episodes_this_iter: 14\n","  episodes_total: 1352\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6381179690361023\n","          entropy_coeff: 0.0\n","          kl: 0.010724070481956005\n","          model: {}\n","          policy_loss: -0.004126706160604954\n","          total_loss: 366.572998046875\n","          vf_explained_var: 0.44276687502861023\n","          vf_loss: 366.57574462890625\n","    num_agent_steps_sampled: 368000\n","    num_agent_steps_trained: 368000\n","    num_steps_sampled: 368000\n","    num_steps_trained: 368000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 92\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.491666666666667\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07507286916675927\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6557138615155503\n","    mean_inference_ms: 0.7633654860923044\n","    mean_raw_obs_processing_ms: 0.11290454664801806\n","  time_since_restore: 827.247888803482\n","  time_this_iter_s: 8.562639713287354\n","  time_total_s: 827.247888803482\n","  timers:\n","    learn_throughput: 1595.293\n","    learn_time_ms: 2507.377\n","    load_throughput: 7806624.168\n","    load_time_ms: 0.512\n","    sample_throughput: 457.532\n","    sample_time_ms: 8742.562\n","    update_time_ms: 2.896\n","  timestamp: 1649863929\n","  timesteps_since_restore: 368000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 368000\n","  training_iteration: 92\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:32:09 (running for 00:14:19.94)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         831.609</td><td style=\"text-align: right;\">452000</td><td style=\"text-align: right;\">-209.809 </td><td style=\"text-align: right;\">             35.4957</td><td style=\"text-align: right;\">           -665.455 </td><td style=\"text-align: right;\">            107.81</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         831.126</td><td style=\"text-align: right;\">304000</td><td style=\"text-align: right;\">  31.4657</td><td style=\"text-align: right;\">            209.545 </td><td style=\"text-align: right;\">           -167.923 </td><td style=\"text-align: right;\">            440.13</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         827.248</td><td style=\"text-align: right;\">368000</td><td style=\"text-align: right;\"> 270.297 </td><td style=\"text-align: right;\">            312.1   </td><td style=\"text-align: right;\">             57.7744</td><td style=\"text-align: right;\">            264.89</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:32:14 (running for 00:14:24.95)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         831.609</td><td style=\"text-align: right;\">452000</td><td style=\"text-align: right;\">-209.809 </td><td style=\"text-align: right;\">             35.4957</td><td style=\"text-align: right;\">           -665.455 </td><td style=\"text-align: right;\">            107.81</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         831.126</td><td style=\"text-align: right;\">304000</td><td style=\"text-align: right;\">  31.4657</td><td style=\"text-align: right;\">            209.545 </td><td style=\"text-align: right;\">           -167.923 </td><td style=\"text-align: right;\">            440.13</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         827.248</td><td style=\"text-align: right;\">368000</td><td style=\"text-align: right;\"> 270.297 </td><td style=\"text-align: right;\">            312.1   </td><td style=\"text-align: right;\">             57.7744</td><td style=\"text-align: right;\">            264.89</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 456000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-32-14\n","  done: false\n","  episode_len_mean: 108.31\n","  episode_media: {}\n","  episode_reward_max: 29.521914662108173\n","  episode_reward_mean: -216.94482211041722\n","  episode_reward_min: -665.4552850359056\n","  episodes_this_iter: 38\n","  episodes_total: 4079\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 7279318.5\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.4494427442550659\n","          entropy_coeff: 0.0\n","          kl: 0.020740294829010963\n","          model: {}\n","          policy_loss: 0.005114693660289049\n","          total_loss: 151692.9375\n","          vf_explained_var: 0.7190802693367004\n","          vf_loss: 717.7092895507812\n","    num_agent_steps_sampled: 456000\n","    num_agent_steps_trained: 456000\n","    num_steps_sampled: 456000\n","    num_steps_trained: 456000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 114\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.618181818181819\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07051075043426773\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.27533502466646603\n","    mean_inference_ms: 0.7267091467728639\n","    mean_raw_obs_processing_ms: 0.11276713753703431\n","  time_since_restore: 838.6779053211212\n","  time_this_iter_s: 7.069281578063965\n","  time_total_s: 838.6779053211212\n","  timers:\n","    learn_throughput: 1583.457\n","    learn_time_ms: 2526.118\n","    load_throughput: 8594004.713\n","    load_time_ms: 0.465\n","    sample_throughput: 536.194\n","    sample_time_ms: 7459.983\n","    update_time_ms: 3.003\n","  timestamp: 1649863934\n","  timesteps_since_restore: 456000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 456000\n","  training_iteration: 114\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 308000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-32-17\n","  done: false\n","  episode_len_mean: 447.82\n","  episode_media: {}\n","  episode_reward_max: 209.5449364255402\n","  episode_reward_mean: 35.40821783421759\n","  episode_reward_min: -94.69270621774945\n","  episodes_this_iter: 8\n","  episodes_total: 939\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.9351971745491028\n","          entropy_coeff: 0.0\n","          kl: 0.013682981953024864\n","          model: {}\n","          policy_loss: -0.04491734504699707\n","          total_loss: 112.08817291259766\n","          vf_explained_var: 0.9287293553352356\n","          vf_loss: 112.11923217773438\n","    num_agent_steps_sampled: 308000\n","    num_agent_steps_trained: 308000\n","    num_steps_sampled: 308000\n","    num_steps_trained: 308000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 77\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.318750000000001\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07404863468897084\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1259048345772822\n","    mean_inference_ms: 0.7685386289066843\n","    mean_raw_obs_processing_ms: 0.11254835079453171\n","  time_since_restore: 842.2370226383209\n","  time_this_iter_s: 11.111512422561646\n","  time_total_s: 842.2370226383209\n","  timers:\n","    learn_throughput: 1608.063\n","    learn_time_ms: 2487.465\n","    load_throughput: 8307197.465\n","    load_time_ms: 0.482\n","    sample_throughput: 354.213\n","    sample_time_ms: 11292.65\n","    update_time_ms: 2.852\n","  timestamp: 1649863937\n","  timesteps_since_restore: 308000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 308000\n","  training_iteration: 77\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 372000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-32-17\n","  done: false\n","  episode_len_mean: 245.67\n","  episode_media: {}\n","  episode_reward_max: 314.48910933687984\n","  episode_reward_mean: 269.50634539983304\n","  episode_reward_min: 57.77437867352573\n","  episodes_this_iter: 19\n","  episodes_total: 1371\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6225093603134155\n","          entropy_coeff: 0.0\n","          kl: 0.007633357774466276\n","          model: {}\n","          policy_loss: -0.014713387005031109\n","          total_loss: 415.0109558105469\n","          vf_explained_var: 0.5173670053482056\n","          vf_loss: 415.0246887207031\n","    num_agent_steps_sampled: 372000\n","    num_agent_steps_trained: 372000\n","    num_steps_sampled: 372000\n","    num_steps_trained: 372000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 93\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.975\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07505497649581072\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6535182349151136\n","    mean_inference_ms: 0.763081918061183\n","    mean_raw_obs_processing_ms: 0.1128796441531683\n","  time_since_restore: 835.1250340938568\n","  time_this_iter_s: 7.877145290374756\n","  time_total_s: 835.1250340938568\n","  timers:\n","    learn_throughput: 1594.557\n","    learn_time_ms: 2508.534\n","    load_throughput: 8124953.267\n","    load_time_ms: 0.492\n","    sample_throughput: 465.159\n","    sample_time_ms: 8599.209\n","    update_time_ms: 2.875\n","  timestamp: 1649863937\n","  timesteps_since_restore: 372000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 372000\n","  training_iteration: 93\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:32:20 (running for 00:14:30.93)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   114</td><td style=\"text-align: right;\">         838.678</td><td style=\"text-align: right;\">456000</td><td style=\"text-align: right;\">-216.945 </td><td style=\"text-align: right;\">             29.5219</td><td style=\"text-align: right;\">           -665.455 </td><td style=\"text-align: right;\">            108.31</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">         842.237</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  35.4082</td><td style=\"text-align: right;\">            209.545 </td><td style=\"text-align: right;\">            -94.6927</td><td style=\"text-align: right;\">            447.82</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         835.125</td><td style=\"text-align: right;\">372000</td><td style=\"text-align: right;\"> 269.506 </td><td style=\"text-align: right;\">            314.489 </td><td style=\"text-align: right;\">             57.7744</td><td style=\"text-align: right;\">            245.67</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 460000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-32-22\n","  done: false\n","  episode_len_mean: 119.79\n","  episode_media: {}\n","  episode_reward_max: 29.521914662108173\n","  episode_reward_mean: -232.8568173818517\n","  episode_reward_min: -665.4552850359056\n","  episodes_this_iter: 28\n","  episodes_total: 4107\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 10918978.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.4639224708080292\n","          entropy_coeff: 0.0\n","          kl: 0.04149508848786354\n","          model: {}\n","          policy_loss: 0.01582939364016056\n","          total_loss: 455063.53125\n","          vf_explained_var: 0.7195225954055786\n","          vf_loss: 1979.54833984375\n","    num_agent_steps_sampled: 460000\n","    num_agent_steps_trained: 460000\n","    num_steps_sampled: 460000\n","    num_steps_trained: 460000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 115\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.136363636363638\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07051162144317769\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.27540647932758866\n","    mean_inference_ms: 0.7266494931746876\n","    mean_raw_obs_processing_ms: 0.11277131335474631\n","  time_since_restore: 846.2958540916443\n","  time_this_iter_s: 7.617948770523071\n","  time_total_s: 846.2958540916443\n","  timers:\n","    learn_throughput: 1589.335\n","    learn_time_ms: 2516.777\n","    load_throughput: 8515056.59\n","    load_time_ms: 0.47\n","    sample_throughput: 537.793\n","    sample_time_ms: 7437.811\n","    update_time_ms: 2.95\n","  timestamp: 1649863942\n","  timesteps_since_restore: 460000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 460000\n","  training_iteration: 115\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 376000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-32-25\n","  done: false\n","  episode_len_mean: 233.74\n","  episode_media: {}\n","  episode_reward_max: 314.48910933687984\n","  episode_reward_mean: 272.77727037575715\n","  episode_reward_min: 58.68657758580042\n","  episodes_this_iter: 17\n","  episodes_total: 1388\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6643986105918884\n","          entropy_coeff: 0.0\n","          kl: 0.009861485101282597\n","          model: {}\n","          policy_loss: -0.017358936369419098\n","          total_loss: 77.871337890625\n","          vf_explained_var: 0.5952227115631104\n","          vf_loss: 77.88745880126953\n","    num_agent_steps_sampled: 376000\n","    num_agent_steps_trained: 376000\n","    num_steps_sampled: 376000\n","    num_steps_trained: 376000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 94\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 11.954545454545455\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07503752048609037\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6513374080863873\n","    mean_inference_ms: 0.7627952689336049\n","    mean_raw_obs_processing_ms: 0.11285638603738611\n","  time_since_restore: 843.0226826667786\n","  time_this_iter_s: 7.897648572921753\n","  time_total_s: 843.0226826667786\n","  timers:\n","    learn_throughput: 1600.499\n","    learn_time_ms: 2499.221\n","    load_throughput: 8505990.671\n","    load_time_ms: 0.47\n","    sample_throughput: 474.94\n","    sample_time_ms: 8422.121\n","    update_time_ms: 2.848\n","  timestamp: 1649863945\n","  timesteps_since_restore: 376000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 376000\n","  training_iteration: 94\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:32:26 (running for 00:14:36.78)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   115</td><td style=\"text-align: right;\">         846.296</td><td style=\"text-align: right;\">460000</td><td style=\"text-align: right;\">-232.857 </td><td style=\"text-align: right;\">             29.5219</td><td style=\"text-align: right;\">           -665.455 </td><td style=\"text-align: right;\">            119.79</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">         842.237</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  35.4082</td><td style=\"text-align: right;\">            209.545 </td><td style=\"text-align: right;\">            -94.6927</td><td style=\"text-align: right;\">            447.82</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         843.023</td><td style=\"text-align: right;\">376000</td><td style=\"text-align: right;\"> 272.777 </td><td style=\"text-align: right;\">            314.489 </td><td style=\"text-align: right;\">             58.6866</td><td style=\"text-align: right;\">            233.74</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 312000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-32-28\n","  done: false\n","  episode_len_mean: 457.94\n","  episode_media: {}\n","  episode_reward_max: 209.5449364255402\n","  episode_reward_mean: 35.24517906025058\n","  episode_reward_min: -94.69270621774945\n","  episodes_this_iter: 8\n","  episodes_total: 947\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.9306568503379822\n","          entropy_coeff: 0.0\n","          kl: 0.016404934227466583\n","          model: {}\n","          policy_loss: -0.03912752494215965\n","          total_loss: 232.3316650390625\n","          vf_explained_var: 0.8863699436187744\n","          vf_loss: 232.3542022705078\n","    num_agent_steps_sampled: 312000\n","    num_agent_steps_trained: 312000\n","    num_steps_sampled: 312000\n","    num_steps_trained: 312000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 78\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.129411764705884\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07405997925678234\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.126824902380461\n","    mean_inference_ms: 0.7687287862746524\n","    mean_raw_obs_processing_ms: 0.11256730025569063\n","  time_since_restore: 853.9262580871582\n","  time_this_iter_s: 11.68923544883728\n","  time_total_s: 853.9262580871582\n","  timers:\n","    learn_throughput: 1604.182\n","    learn_time_ms: 2493.483\n","    load_throughput: 8576870.303\n","    load_time_ms: 0.466\n","    sample_throughput: 353.485\n","    sample_time_ms: 11315.89\n","    update_time_ms: 2.862\n","  timestamp: 1649863948\n","  timesteps_since_restore: 312000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 312000\n","  training_iteration: 78\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 464000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-32-30\n","  done: false\n","  episode_len_mean: 120.47\n","  episode_media: {}\n","  episode_reward_max: 14.177329123683776\n","  episode_reward_mean: -222.2785401917736\n","  episode_reward_min: -567.6801796119363\n","  episodes_this_iter: 33\n","  episodes_total: 4140\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 16378467.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.4796734154224396\n","          entropy_coeff: 0.0\n","          kl: 0.018034646287560463\n","          model: {}\n","          policy_loss: -0.00412370078265667\n","          total_loss: 297837.3125\n","          vf_explained_var: 0.5907024145126343\n","          vf_loss: 2457.49560546875\n","    num_agent_steps_sampled: 464000\n","    num_agent_steps_trained: 464000\n","    num_steps_sampled: 464000\n","    num_steps_trained: 464000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 116\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.229999999999999\n","    ram_util_percent: 15.699999999999998\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07052101409778432\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2755861497319864\n","    mean_inference_ms: 0.7266952875029845\n","    mean_raw_obs_processing_ms: 0.11278684467853128\n","  time_since_restore: 853.8123457431793\n","  time_this_iter_s: 7.516491651535034\n","  time_total_s: 853.8123457431793\n","  timers:\n","    learn_throughput: 1585.034\n","    learn_time_ms: 2523.605\n","    load_throughput: 8052419.486\n","    load_time_ms: 0.497\n","    sample_throughput: 539.22\n","    sample_time_ms: 7418.117\n","    update_time_ms: 2.937\n","  timestamp: 1649863950\n","  timesteps_since_restore: 464000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 464000\n","  training_iteration: 116\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:32:32 (running for 00:14:42.29)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   116</td><td style=\"text-align: right;\">         853.812</td><td style=\"text-align: right;\">464000</td><td style=\"text-align: right;\">-222.279 </td><td style=\"text-align: right;\">             14.1773</td><td style=\"text-align: right;\">           -567.68  </td><td style=\"text-align: right;\">            120.47</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         853.926</td><td style=\"text-align: right;\">312000</td><td style=\"text-align: right;\">  35.2452</td><td style=\"text-align: right;\">            209.545 </td><td style=\"text-align: right;\">            -94.6927</td><td style=\"text-align: right;\">            457.94</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         843.023</td><td style=\"text-align: right;\">376000</td><td style=\"text-align: right;\"> 272.777 </td><td style=\"text-align: right;\">            314.489 </td><td style=\"text-align: right;\">             58.6866</td><td style=\"text-align: right;\">            233.74</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 380000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-32-33\n","  done: false\n","  episode_len_mean: 240.45\n","  episode_media: {}\n","  episode_reward_max: 314.48910933687984\n","  episode_reward_mean: 272.12613921270565\n","  episode_reward_min: 58.68657758580042\n","  episodes_this_iter: 15\n","  episodes_total: 1403\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6224653124809265\n","          entropy_coeff: 0.0\n","          kl: 0.014463881962001324\n","          model: {}\n","          policy_loss: -0.0027172898408025503\n","          total_loss: 466.9795227050781\n","          vf_explained_var: 0.4994344711303711\n","          vf_loss: 466.9804382324219\n","    num_agent_steps_sampled: 380000\n","    num_agent_steps_trained: 380000\n","    num_steps_sampled: 380000\n","    num_steps_trained: 380000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 95\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.516666666666666\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07502789819999398\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.649554077464287\n","    mean_inference_ms: 0.7626091554049029\n","    mean_raw_obs_processing_ms: 0.11284306354913456\n","  time_since_restore: 851.4193439483643\n","  time_this_iter_s: 8.396661281585693\n","  time_total_s: 851.4193439483643\n","  timers:\n","    learn_throughput: 1619.471\n","    learn_time_ms: 2469.942\n","    load_throughput: 8090083.904\n","    load_time_ms: 0.494\n","    sample_throughput: 478.27\n","    sample_time_ms: 8363.472\n","    update_time_ms: 2.824\n","  timestamp: 1649863953\n","  timesteps_since_restore: 380000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 380000\n","  training_iteration: 95\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 468000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-32-37\n","  done: false\n","  episode_len_mean: 128.43\n","  episode_media: {}\n","  episode_reward_max: 11.279695249853617\n","  episode_reward_mean: -257.93979059852586\n","  episode_reward_min: -673.0291010993593\n","  episodes_this_iter: 31\n","  episodes_total: 4171\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 16378467.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.4712758958339691\n","          entropy_coeff: 0.0\n","          kl: 0.04946492612361908\n","          model: {}\n","          policy_loss: 0.017695952206850052\n","          total_loss: 811708.5625\n","          vf_explained_var: 0.5162233710289001\n","          vf_loss: 1548.9456787109375\n","    num_agent_steps_sampled: 468000\n","    num_agent_steps_trained: 468000\n","    num_steps_sampled: 468000\n","    num_steps_trained: 468000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 117\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.081818181818182\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07052255521050123\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2760006249318584\n","    mean_inference_ms: 0.7267442125713646\n","    mean_raw_obs_processing_ms: 0.1127875975814311\n","  time_since_restore: 861.2922592163086\n","  time_this_iter_s: 7.4799134731292725\n","  time_total_s: 861.2922592163086\n","  timers:\n","    learn_throughput: 1589.186\n","    learn_time_ms: 2517.012\n","    load_throughput: 8187202.811\n","    load_time_ms: 0.489\n","    sample_throughput: 537.653\n","    sample_time_ms: 7439.74\n","    update_time_ms: 2.965\n","  timestamp: 1649863957\n","  timesteps_since_restore: 468000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 468000\n","  training_iteration: 117\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:32:37 (running for 00:14:47.81)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         861.292</td><td style=\"text-align: right;\">468000</td><td style=\"text-align: right;\">-257.94  </td><td style=\"text-align: right;\">             11.2797</td><td style=\"text-align: right;\">           -673.029 </td><td style=\"text-align: right;\">            128.43</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         853.926</td><td style=\"text-align: right;\">312000</td><td style=\"text-align: right;\">  35.2452</td><td style=\"text-align: right;\">            209.545 </td><td style=\"text-align: right;\">            -94.6927</td><td style=\"text-align: right;\">            457.94</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         851.419</td><td style=\"text-align: right;\">380000</td><td style=\"text-align: right;\"> 272.126 </td><td style=\"text-align: right;\">            314.489 </td><td style=\"text-align: right;\">             58.6866</td><td style=\"text-align: right;\">            240.45</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 316000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-32-39\n","  done: false\n","  episode_len_mean: 475.18\n","  episode_media: {}\n","  episode_reward_max: 209.5449364255402\n","  episode_reward_mean: 40.63966393858202\n","  episode_reward_min: -94.69270621774945\n","  episodes_this_iter: 6\n","  episodes_total: 953\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8770837783813477\n","          entropy_coeff: 0.0\n","          kl: 0.013175527565181255\n","          model: {}\n","          policy_loss: -0.03893543779850006\n","          total_loss: 75.59696197509766\n","          vf_explained_var: 0.876926600933075\n","          vf_loss: 75.62256622314453\n","    num_agent_steps_sampled: 316000\n","    num_agent_steps_trained: 316000\n","    num_steps_sampled: 316000\n","    num_steps_trained: 316000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 79\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.1875\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07406622108046251\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.127552596191356\n","    mean_inference_ms: 0.7688577643791744\n","    mean_raw_obs_processing_ms: 0.11257876118532291\n","  time_since_restore: 864.8178191184998\n","  time_this_iter_s: 10.891561031341553\n","  time_total_s: 864.8178191184998\n","  timers:\n","    learn_throughput: 1603.9\n","    learn_time_ms: 2493.921\n","    load_throughput: 8568109.902\n","    load_time_ms: 0.467\n","    sample_throughput: 355.843\n","    sample_time_ms: 11240.918\n","    update_time_ms: 2.864\n","  timestamp: 1649863959\n","  timesteps_since_restore: 316000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 316000\n","  training_iteration: 79\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 384000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-32-41\n","  done: false\n","  episode_len_mean: 236.5\n","  episode_media: {}\n","  episode_reward_max: 314.48910933687984\n","  episode_reward_mean: 272.61399009410957\n","  episode_reward_min: 58.68657758580042\n","  episodes_this_iter: 19\n","  episodes_total: 1422\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6087213158607483\n","          entropy_coeff: 0.0\n","          kl: 0.008494913578033447\n","          model: {}\n","          policy_loss: -0.011390486732125282\n","          total_loss: 70.25923919677734\n","          vf_explained_var: 0.7182254791259766\n","          vf_loss: 70.26954650878906\n","    num_agent_steps_sampled: 384000\n","    num_agent_steps_trained: 384000\n","    num_steps_sampled: 384000\n","    num_steps_trained: 384000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 96\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.718181818181817\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07502694110224407\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.647344422943557\n","    mean_inference_ms: 0.7624725965930947\n","    mean_raw_obs_processing_ms: 0.11284023258864737\n","  time_since_restore: 859.3869211673737\n","  time_this_iter_s: 7.967577219009399\n","  time_total_s: 859.3869211673737\n","  timers:\n","    learn_throughput: 1620.714\n","    learn_time_ms: 2468.048\n","    load_throughput: 7962230.554\n","    load_time_ms: 0.502\n","    sample_throughput: 483.286\n","    sample_time_ms: 8276.678\n","    update_time_ms: 2.794\n","  timestamp: 1649863961\n","  timesteps_since_restore: 384000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 384000\n","  training_iteration: 96\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:32:43 (running for 00:14:53.21)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         861.292</td><td style=\"text-align: right;\">468000</td><td style=\"text-align: right;\">-257.94  </td><td style=\"text-align: right;\">             11.2797</td><td style=\"text-align: right;\">           -673.029 </td><td style=\"text-align: right;\">            128.43</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         864.818</td><td style=\"text-align: right;\">316000</td><td style=\"text-align: right;\">  40.6397</td><td style=\"text-align: right;\">            209.545 </td><td style=\"text-align: right;\">            -94.6927</td><td style=\"text-align: right;\">            475.18</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         859.387</td><td style=\"text-align: right;\">384000</td><td style=\"text-align: right;\"> 272.614 </td><td style=\"text-align: right;\">            314.489 </td><td style=\"text-align: right;\">             58.6866</td><td style=\"text-align: right;\">            236.5 </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 472000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-32-45\n","  done: false\n","  episode_len_mean: 125.29\n","  episode_media: {}\n","  episode_reward_max: 11.279695249853617\n","  episode_reward_mean: -271.99762300565277\n","  episode_reward_min: -673.0291010993593\n","  episodes_this_iter: 31\n","  episodes_total: 4202\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 24567700.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.4701206088066101\n","          entropy_coeff: 0.0\n","          kl: 0.04793088510632515\n","          model: {}\n","          policy_loss: 0.015103972516953945\n","          total_loss: 1178437.625\n","          vf_explained_var: 0.6327670812606812\n","          vf_loss: 886.0745849609375\n","    num_agent_steps_sampled: 472000\n","    num_agent_steps_trained: 472000\n","    num_steps_sampled: 472000\n","    num_steps_trained: 472000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 118\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.063636363636364\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07051924069008617\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2764496962628988\n","    mean_inference_ms: 0.7267650159804444\n","    mean_raw_obs_processing_ms: 0.1127795708663777\n","  time_since_restore: 868.7963185310364\n","  time_this_iter_s: 7.504059314727783\n","  time_total_s: 868.7963185310364\n","  timers:\n","    learn_throughput: 1591.728\n","    learn_time_ms: 2512.992\n","    load_throughput: 8243927.08\n","    load_time_ms: 0.485\n","    sample_throughput: 537.144\n","    sample_time_ms: 7446.797\n","    update_time_ms: 2.95\n","  timestamp: 1649863965\n","  timesteps_since_restore: 472000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 472000\n","  training_iteration: 118\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:32:48 (running for 00:14:58.35)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   118</td><td style=\"text-align: right;\">         868.796</td><td style=\"text-align: right;\">472000</td><td style=\"text-align: right;\">-271.998 </td><td style=\"text-align: right;\">             11.2797</td><td style=\"text-align: right;\">           -673.029 </td><td style=\"text-align: right;\">            125.29</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         864.818</td><td style=\"text-align: right;\">316000</td><td style=\"text-align: right;\">  40.6397</td><td style=\"text-align: right;\">            209.545 </td><td style=\"text-align: right;\">            -94.6927</td><td style=\"text-align: right;\">            475.18</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         859.387</td><td style=\"text-align: right;\">384000</td><td style=\"text-align: right;\"> 272.614 </td><td style=\"text-align: right;\">            314.489 </td><td style=\"text-align: right;\">             58.6866</td><td style=\"text-align: right;\">            236.5 </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 388000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-32-49\n","  done: false\n","  episode_len_mean: 235.49\n","  episode_media: {}\n","  episode_reward_max: 314.48910933687984\n","  episode_reward_mean: 273.42591354716365\n","  episode_reward_min: 58.68657758580042\n","  episodes_this_iter: 18\n","  episodes_total: 1440\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5940021276473999\n","          entropy_coeff: 0.0\n","          kl: 0.008624464273452759\n","          model: {}\n","          policy_loss: -0.01795993559062481\n","          total_loss: 71.24004364013672\n","          vf_explained_var: 0.7088831663131714\n","          vf_loss: 71.25691223144531\n","    num_agent_steps_sampled: 388000\n","    num_agent_steps_trained: 388000\n","    num_steps_sampled: 388000\n","    num_steps_trained: 388000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 97\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.341666666666667\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07502286766204296\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6452299844453229\n","    mean_inference_ms: 0.762305627220179\n","    mean_raw_obs_processing_ms: 0.112835578134507\n","  time_since_restore: 867.1330261230469\n","  time_this_iter_s: 7.746104955673218\n","  time_total_s: 867.1330261230469\n","  timers:\n","    learn_throughput: 1619.396\n","    learn_time_ms: 2470.056\n","    load_throughput: 7999816.899\n","    load_time_ms: 0.5\n","    sample_throughput: 489.282\n","    sample_time_ms: 8175.25\n","    update_time_ms: 2.788\n","  timestamp: 1649863969\n","  timesteps_since_restore: 388000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 388000\n","  training_iteration: 97\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 320000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-32-51\n","  done: false\n","  episode_len_mean: 492.49\n","  episode_media: {}\n","  episode_reward_max: 209.5449364255402\n","  episode_reward_mean: 42.60644854430828\n","  episode_reward_min: -94.69270621774945\n","  episodes_this_iter: 7\n","  episodes_total: 960\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.9052697420120239\n","          entropy_coeff: 0.0\n","          kl: 0.011005627922713757\n","          model: {}\n","          policy_loss: -0.0447658933699131\n","          total_loss: 224.4895782470703\n","          vf_explained_var: 0.8879067301750183\n","          vf_loss: 224.52322387695312\n","    num_agent_steps_sampled: 320000\n","    num_agent_steps_trained: 320000\n","    num_steps_sampled: 320000\n","    num_steps_trained: 320000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 80\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.705882352941176\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07407202934652427\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1285856333398328\n","    mean_inference_ms: 0.7689806747195759\n","    mean_raw_obs_processing_ms: 0.11258768396309751\n","  time_since_restore: 876.8346614837646\n","  time_this_iter_s: 12.016842365264893\n","  time_total_s: 876.8346614837646\n","  timers:\n","    learn_throughput: 1605.175\n","    learn_time_ms: 2491.94\n","    load_throughput: 8574678.524\n","    load_time_ms: 0.466\n","    sample_throughput: 352.811\n","    sample_time_ms: 11337.525\n","    update_time_ms: 2.873\n","  timestamp: 1649863971\n","  timesteps_since_restore: 320000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 320000\n","  training_iteration: 80\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 476000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-32-52\n","  done: false\n","  episode_len_mean: 133.94\n","  episode_media: {}\n","  episode_reward_max: -23.35360925656508\n","  episode_reward_mean: -287.6429657894272\n","  episode_reward_min: -697.3955461822347\n","  episodes_this_iter: 27\n","  episodes_total: 4229\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 36851548.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.5025133490562439\n","          entropy_coeff: 0.0\n","          kl: 0.03572625666856766\n","          model: {}\n","          policy_loss: 0.006094994023442268\n","          total_loss: 1317727.125\n","          vf_explained_var: 0.3718735873699188\n","          vf_loss: 1159.2840576171875\n","    num_agent_steps_sampled: 476000\n","    num_agent_steps_trained: 476000\n","    num_steps_sampled: 476000\n","    num_steps_trained: 476000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 119\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.072727272727274\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0705113948567106\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.27694846176629917\n","    mean_inference_ms: 0.7267261814596108\n","    mean_raw_obs_processing_ms: 0.11276296275338847\n","  time_since_restore: 876.4250452518463\n","  time_this_iter_s: 7.6287267208099365\n","  time_total_s: 876.4250452518463\n","  timers:\n","    learn_throughput: 1590.733\n","    learn_time_ms: 2514.564\n","    load_throughput: 8329882.33\n","    load_time_ms: 0.48\n","    sample_throughput: 536.678\n","    sample_time_ms: 7453.253\n","    update_time_ms: 3.021\n","  timestamp: 1649863972\n","  timesteps_since_restore: 476000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 476000\n","  training_iteration: 119\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:32:53 (running for 00:15:04.01)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         876.425</td><td style=\"text-align: right;\">476000</td><td style=\"text-align: right;\">-287.643 </td><td style=\"text-align: right;\">            -23.3536</td><td style=\"text-align: right;\">           -697.396 </td><td style=\"text-align: right;\">            133.94</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         876.835</td><td style=\"text-align: right;\">320000</td><td style=\"text-align: right;\">  42.6064</td><td style=\"text-align: right;\">            209.545 </td><td style=\"text-align: right;\">            -94.6927</td><td style=\"text-align: right;\">            492.49</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         867.133</td><td style=\"text-align: right;\">388000</td><td style=\"text-align: right;\"> 273.426 </td><td style=\"text-align: right;\">            314.489 </td><td style=\"text-align: right;\">             58.6866</td><td style=\"text-align: right;\">            235.49</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 392000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-32-57\n","  done: false\n","  episode_len_mean: 224.88\n","  episode_media: {}\n","  episode_reward_max: 310.8378508189888\n","  episode_reward_mean: 273.4378484663888\n","  episode_reward_min: 58.68657758580042\n","  episodes_this_iter: 19\n","  episodes_total: 1459\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6464856266975403\n","          entropy_coeff: 0.0\n","          kl: 0.009033489972352982\n","          model: {}\n","          policy_loss: -0.012201259844005108\n","          total_loss: 51.41233444213867\n","          vf_explained_var: 0.6981218457221985\n","          vf_loss: 51.423397064208984\n","    num_agent_steps_sampled: 392000\n","    num_agent_steps_trained: 392000\n","    num_steps_sampled: 392000\n","    num_steps_trained: 392000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 98\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.70909090909091\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07501950587015666\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6428198082610931\n","    mean_inference_ms: 0.7621401050010698\n","    mean_raw_obs_processing_ms: 0.11283165854757121\n","  time_since_restore: 874.8727586269379\n","  time_this_iter_s: 7.739732503890991\n","  time_total_s: 874.8727586269379\n","  timers:\n","    learn_throughput: 1623.972\n","    learn_time_ms: 2463.097\n","    load_throughput: 8147839.347\n","    load_time_ms: 0.491\n","    sample_throughput: 495.235\n","    sample_time_ms: 8076.977\n","    update_time_ms: 2.727\n","  timestamp: 1649863977\n","  timesteps_since_restore: 392000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 392000\n","  training_iteration: 98\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:32:59 (running for 00:15:09.77)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         876.425</td><td style=\"text-align: right;\">476000</td><td style=\"text-align: right;\">-287.643 </td><td style=\"text-align: right;\">            -23.3536</td><td style=\"text-align: right;\">           -697.396 </td><td style=\"text-align: right;\">            133.94</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         876.835</td><td style=\"text-align: right;\">320000</td><td style=\"text-align: right;\">  42.6064</td><td style=\"text-align: right;\">            209.545 </td><td style=\"text-align: right;\">            -94.6927</td><td style=\"text-align: right;\">            492.49</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         874.873</td><td style=\"text-align: right;\">392000</td><td style=\"text-align: right;\"> 273.438 </td><td style=\"text-align: right;\">            310.838 </td><td style=\"text-align: right;\">             58.6866</td><td style=\"text-align: right;\">            224.88</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 480000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-33-01\n","  done: false\n","  episode_len_mean: 144.85\n","  episode_media: {}\n","  episode_reward_max: -35.123079391739026\n","  episode_reward_mean: -306.10935140285056\n","  episode_reward_min: -858.7361507449677\n","  episodes_this_iter: 23\n","  episodes_total: 4252\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 55277324.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.3935586214065552\n","          entropy_coeff: 0.0\n","          kl: 0.12091366201639175\n","          model: {}\n","          policy_loss: 0.035211142152547836\n","          total_loss: 6685935.0\n","          vf_explained_var: 0.46446093916893005\n","          vf_loss: 2151.511474609375\n","    num_agent_steps_sampled: 480000\n","    num_agent_steps_trained: 480000\n","    num_steps_sampled: 480000\n","    num_steps_trained: 480000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 120\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 11.554545454545455\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07050475605144951\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2777639432850101\n","    mean_inference_ms: 0.7266916107225978\n","    mean_raw_obs_processing_ms: 0.11274634516869739\n","  time_since_restore: 884.6528389453888\n","  time_this_iter_s: 8.22779369354248\n","  time_total_s: 884.6528389453888\n","  timers:\n","    learn_throughput: 1599.321\n","    learn_time_ms: 2501.062\n","    load_throughput: 8628479.737\n","    load_time_ms: 0.464\n","    sample_throughput: 532.18\n","    sample_time_ms: 7516.252\n","    update_time_ms: 2.931\n","  timestamp: 1649863981\n","  timesteps_since_restore: 480000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 480000\n","  training_iteration: 120\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 324000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-33-03\n","  done: false\n","  episode_len_mean: 491.51\n","  episode_media: {}\n","  episode_reward_max: 209.5449364255402\n","  episode_reward_mean: 45.233743408173595\n","  episode_reward_min: -94.69270621774945\n","  episodes_this_iter: 6\n","  episodes_total: 966\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8962336182594299\n","          entropy_coeff: 0.0\n","          kl: 0.009648546576499939\n","          model: {}\n","          policy_loss: -0.033690281212329865\n","          total_loss: 421.45281982421875\n","          vf_explained_var: 0.7276990413665771\n","          vf_loss: 421.47674560546875\n","    num_agent_steps_sampled: 324000\n","    num_agent_steps_trained: 324000\n","    num_steps_sampled: 324000\n","    num_steps_trained: 324000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 81\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.58125\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07407435021463434\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1294736961819454\n","    mean_inference_ms: 0.7690620211565985\n","    mean_raw_obs_processing_ms: 0.11259126665031242\n","  time_since_restore: 888.1134762763977\n","  time_this_iter_s: 11.278814792633057\n","  time_total_s: 888.1134762763977\n","  timers:\n","    learn_throughput: 1621.282\n","    learn_time_ms: 2467.183\n","    load_throughput: 8758204.218\n","    load_time_ms: 0.457\n","    sample_throughput: 352.868\n","    sample_time_ms: 11335.692\n","    update_time_ms: 2.849\n","  timestamp: 1649863983\n","  timesteps_since_restore: 324000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 324000\n","  training_iteration: 81\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:33:05 (running for 00:15:15.50)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   120</td><td style=\"text-align: right;\">         884.653</td><td style=\"text-align: right;\">480000</td><td style=\"text-align: right;\">-306.109 </td><td style=\"text-align: right;\">            -35.1231</td><td style=\"text-align: right;\">           -858.736 </td><td style=\"text-align: right;\">            144.85</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         888.113</td><td style=\"text-align: right;\">324000</td><td style=\"text-align: right;\">  45.2337</td><td style=\"text-align: right;\">            209.545 </td><td style=\"text-align: right;\">            -94.6927</td><td style=\"text-align: right;\">            491.51</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         874.873</td><td style=\"text-align: right;\">392000</td><td style=\"text-align: right;\"> 273.438 </td><td style=\"text-align: right;\">            310.838 </td><td style=\"text-align: right;\">             58.6866</td><td style=\"text-align: right;\">            224.88</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 396000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-33-05\n","  done: false\n","  episode_len_mean: 222.85\n","  episode_media: {}\n","  episode_reward_max: 310.8378508189888\n","  episode_reward_mean: 273.29952188641374\n","  episode_reward_min: 20.63746211831905\n","  episodes_this_iter: 19\n","  episodes_total: 1478\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6232004761695862\n","          entropy_coeff: 0.0\n","          kl: 0.005010586231946945\n","          model: {}\n","          policy_loss: -0.01422041840851307\n","          total_loss: 287.4630126953125\n","          vf_explained_var: 0.733997106552124\n","          vf_loss: 287.47662353515625\n","    num_agent_steps_sampled: 396000\n","    num_agent_steps_trained: 396000\n","    num_steps_sampled: 396000\n","    num_steps_trained: 396000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 99\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.654545454545454\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07502153292950674\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6404562734841819\n","    mean_inference_ms: 0.7620303095657441\n","    mean_raw_obs_processing_ms: 0.11283508496813316\n","  time_since_restore: 882.794947385788\n","  time_this_iter_s: 7.922188758850098\n","  time_total_s: 882.794947385788\n","  timers:\n","    learn_throughput: 1639.426\n","    learn_time_ms: 2439.878\n","    load_throughput: 8137169.464\n","    load_time_ms: 0.492\n","    sample_throughput: 495.069\n","    sample_time_ms: 8079.677\n","    update_time_ms: 2.685\n","  timestamp: 1649863985\n","  timesteps_since_restore: 396000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 396000\n","  training_iteration: 99\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 484000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-33-08\n","  done: false\n","  episode_len_mean: 151.93\n","  episode_media: {}\n","  episode_reward_max: -35.123079391739026\n","  episode_reward_mean: -326.405583642254\n","  episode_reward_min: -859.7212989173933\n","  episodes_this_iter: 25\n","  episodes_total: 4277\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 82915984.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.39905041456222534\n","          entropy_coeff: 0.0\n","          kl: 0.08571667224168777\n","          model: {}\n","          policy_loss: 0.03206019848585129\n","          total_loss: 7111784.5\n","          vf_explained_var: 0.3663092851638794\n","          vf_loss: 4501.57177734375\n","    num_agent_steps_sampled: 484000\n","    num_agent_steps_trained: 484000\n","    num_steps_sampled: 484000\n","    num_steps_trained: 484000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 121\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.725\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07050033763767241\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.27882550204248363\n","    mean_inference_ms: 0.7266871419602022\n","    mean_raw_obs_processing_ms: 0.11273223316009041\n","  time_since_restore: 892.5606410503387\n","  time_this_iter_s: 7.907802104949951\n","  time_total_s: 892.5606410503387\n","  timers:\n","    learn_throughput: 1608.469\n","    learn_time_ms: 2486.837\n","    load_throughput: 8545416.391\n","    load_time_ms: 0.468\n","    sample_throughput: 527.234\n","    sample_time_ms: 7586.757\n","    update_time_ms: 2.909\n","  timestamp: 1649863988\n","  timesteps_since_restore: 484000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 484000\n","  training_iteration: 121\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:33:11 (running for 00:15:21.30)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   121</td><td style=\"text-align: right;\">         892.561</td><td style=\"text-align: right;\">484000</td><td style=\"text-align: right;\">-326.406 </td><td style=\"text-align: right;\">            -35.1231</td><td style=\"text-align: right;\">           -859.721 </td><td style=\"text-align: right;\">            151.93</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         888.113</td><td style=\"text-align: right;\">324000</td><td style=\"text-align: right;\">  45.2337</td><td style=\"text-align: right;\">            209.545 </td><td style=\"text-align: right;\">            -94.6927</td><td style=\"text-align: right;\">            491.51</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         882.795</td><td style=\"text-align: right;\">396000</td><td style=\"text-align: right;\"> 273.3   </td><td style=\"text-align: right;\">            310.838 </td><td style=\"text-align: right;\">             20.6375</td><td style=\"text-align: right;\">            222.85</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 400000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-33-13\n","  done: false\n","  episode_len_mean: 212.63\n","  episode_media: {}\n","  episode_reward_max: 312.3499059324712\n","  episode_reward_mean: 274.8134048261291\n","  episode_reward_min: 20.63746211831905\n","  episodes_this_iter: 19\n","  episodes_total: 1497\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6891722679138184\n","          entropy_coeff: 0.0\n","          kl: 0.018900824710726738\n","          model: {}\n","          policy_loss: -0.011832034215331078\n","          total_loss: 50.88547134399414\n","          vf_explained_var: 0.7423385381698608\n","          vf_loss: 50.89491271972656\n","    num_agent_steps_sampled: 400000\n","    num_agent_steps_trained: 400000\n","    num_steps_sampled: 400000\n","    num_steps_trained: 400000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 100\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.4\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07502511631352753\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6381016119462467\n","    mean_inference_ms: 0.76192875882073\n","    mean_raw_obs_processing_ms: 0.11284346324726956\n","  time_since_restore: 890.8468809127808\n","  time_this_iter_s: 8.051933526992798\n","  time_total_s: 890.8468809127808\n","  timers:\n","    learn_throughput: 1647.078\n","    learn_time_ms: 2428.543\n","    load_throughput: 8133619.043\n","    load_time_ms: 0.492\n","    sample_throughput: 495.845\n","    sample_time_ms: 8067.032\n","    update_time_ms: 2.663\n","  timestamp: 1649863993\n","  timesteps_since_restore: 400000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 400000\n","  training_iteration: 100\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 328000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-33-14\n","  done: false\n","  episode_len_mean: 509.14\n","  episode_media: {}\n","  episode_reward_max: 209.5449364255402\n","  episode_reward_mean: 47.3419260798811\n","  episode_reward_min: -94.69270621774945\n","  episodes_this_iter: 7\n","  episodes_total: 973\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.9062526226043701\n","          entropy_coeff: 0.0\n","          kl: 0.01467895694077015\n","          model: {}\n","          policy_loss: -0.03650408610701561\n","          total_loss: 80.62547302246094\n","          vf_explained_var: 0.8787522912025452\n","          vf_loss: 80.64710998535156\n","    num_agent_steps_sampled: 328000\n","    num_agent_steps_trained: 328000\n","    num_steps_sampled: 328000\n","    num_steps_trained: 328000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 82\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.70625\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0740757584946938\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1304097147276007\n","    mean_inference_ms: 0.7691478005315537\n","    mean_raw_obs_processing_ms: 0.11259286796362865\n","  time_since_restore: 899.0948948860168\n","  time_this_iter_s: 10.98141860961914\n","  time_total_s: 899.0948948860168\n","  timers:\n","    learn_throughput: 1619.87\n","    learn_time_ms: 2469.334\n","    load_throughput: 8708650.921\n","    load_time_ms: 0.459\n","    sample_throughput: 356.821\n","    sample_time_ms: 11210.117\n","    update_time_ms: 2.848\n","  timestamp: 1649863994\n","  timesteps_since_restore: 328000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 328000\n","  training_iteration: 82\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:33:16 (running for 00:15:26.52)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   121</td><td style=\"text-align: right;\">         892.561</td><td style=\"text-align: right;\">484000</td><td style=\"text-align: right;\">-326.406 </td><td style=\"text-align: right;\">            -35.1231</td><td style=\"text-align: right;\">           -859.721 </td><td style=\"text-align: right;\">            151.93</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">         899.095</td><td style=\"text-align: right;\">328000</td><td style=\"text-align: right;\">  47.3419</td><td style=\"text-align: right;\">            209.545 </td><td style=\"text-align: right;\">            -94.6927</td><td style=\"text-align: right;\">            509.14</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         890.847</td><td style=\"text-align: right;\">400000</td><td style=\"text-align: right;\"> 274.813 </td><td style=\"text-align: right;\">            312.35  </td><td style=\"text-align: right;\">             20.6375</td><td style=\"text-align: right;\">            212.63</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 488000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-33-16\n","  done: false\n","  episode_len_mean: 157.34\n","  episode_media: {}\n","  episode_reward_max: -35.123079391739026\n","  episode_reward_mean: -361.25356903888166\n","  episode_reward_min: -1124.3868700284688\n","  episodes_this_iter: 26\n","  episodes_total: 4303\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 124373984.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.3973637819290161\n","          entropy_coeff: 0.0\n","          kl: 0.06706011295318604\n","          model: {}\n","          policy_loss: 0.02782442606985569\n","          total_loss: 8344564.0\n","          vf_explained_var: 0.5831591486930847\n","          vf_loss: 4030.069091796875\n","    num_agent_steps_sampled: 488000\n","    num_agent_steps_trained: 488000\n","    num_steps_sampled: 488000\n","    num_steps_trained: 488000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 122\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.100000000000001\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07050444371542902\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2799585720082885\n","    mean_inference_ms: 0.7267650497005207\n","    mean_raw_obs_processing_ms: 0.1127315682607677\n","  time_since_restore: 900.3092629909515\n","  time_this_iter_s: 7.748621940612793\n","  time_total_s: 900.3092629909515\n","  timers:\n","    learn_throughput: 1616.443\n","    learn_time_ms: 2474.569\n","    load_throughput: 8414271.528\n","    load_time_ms: 0.475\n","    sample_throughput: 523.602\n","    sample_time_ms: 7639.393\n","    update_time_ms: 2.823\n","  timestamp: 1649863996\n","  timesteps_since_restore: 488000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 488000\n","  training_iteration: 122\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:33:21 (running for 00:15:32.10)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   122</td><td style=\"text-align: right;\">         900.309</td><td style=\"text-align: right;\">488000</td><td style=\"text-align: right;\">-361.254 </td><td style=\"text-align: right;\">            -35.1231</td><td style=\"text-align: right;\">          -1124.39  </td><td style=\"text-align: right;\">            157.34</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">         899.095</td><td style=\"text-align: right;\">328000</td><td style=\"text-align: right;\">  47.3419</td><td style=\"text-align: right;\">            209.545 </td><td style=\"text-align: right;\">            -94.6927</td><td style=\"text-align: right;\">            509.14</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         890.847</td><td style=\"text-align: right;\">400000</td><td style=\"text-align: right;\"> 274.813 </td><td style=\"text-align: right;\">            312.35  </td><td style=\"text-align: right;\">             20.6375</td><td style=\"text-align: right;\">            212.63</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 404000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-33-22\n","  done: false\n","  episode_len_mean: 227.58\n","  episode_media: {}\n","  episode_reward_max: 312.3499059324712\n","  episode_reward_mean: 271.4291388212309\n","  episode_reward_min: 20.63746211831905\n","  episodes_this_iter: 12\n","  episodes_total: 1509\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.12656250596046448\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5829746127128601\n","          entropy_coeff: 0.0\n","          kl: 0.02086913399398327\n","          model: {}\n","          policy_loss: -0.011073836125433445\n","          total_loss: 541.8792114257812\n","          vf_explained_var: 0.494087278842926\n","          vf_loss: 541.8876342773438\n","    num_agent_steps_sampled: 404000\n","    num_agent_steps_trained: 404000\n","    num_steps_sampled: 404000\n","    num_steps_trained: 404000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 101\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.1\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07502237880939398\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6368444601775676\n","    mean_inference_ms: 0.7618289522101211\n","    mean_raw_obs_processing_ms: 0.1128422834568866\n","  time_since_restore: 899.5937814712524\n","  time_this_iter_s: 8.74690055847168\n","  time_total_s: 899.5937814712524\n","  timers:\n","    learn_throughput: 1655.734\n","    learn_time_ms: 2415.847\n","    load_throughput: 8024304.572\n","    load_time_ms: 0.498\n","    sample_throughput: 491.565\n","    sample_time_ms: 8137.274\n","    update_time_ms: 2.638\n","  timestamp: 1649864002\n","  timesteps_since_restore: 404000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 404000\n","  training_iteration: 101\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 492000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-33-24\n","  done: false\n","  episode_len_mean: 148.65\n","  episode_media: {}\n","  episode_reward_max: -89.37269141534239\n","  episode_reward_mean: -390.4948497046958\n","  episode_reward_min: -1124.3868700284688\n","  episodes_this_iter: 33\n","  episodes_total: 4336\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 186560976.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.287407785654068\n","          entropy_coeff: 0.0\n","          kl: 0.14101089537143707\n","          model: {}\n","          policy_loss: 0.042530860751867294\n","          total_loss: 26308014.0\n","          vf_explained_var: 0.4418335258960724\n","          vf_loss: 883.3870239257812\n","    num_agent_steps_sampled: 492000\n","    num_agent_steps_trained: 492000\n","    num_steps_sampled: 492000\n","    num_steps_trained: 492000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 123\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.01818181818182\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07051907634462191\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.28113687212100674\n","    mean_inference_ms: 0.726932151678492\n","    mean_raw_obs_processing_ms: 0.11275128743754809\n","  time_since_restore: 907.9350860118866\n","  time_this_iter_s: 7.625823020935059\n","  time_total_s: 907.9350860118866\n","  timers:\n","    learn_throughput: 1616.201\n","    learn_time_ms: 2474.94\n","    load_throughput: 8522842.774\n","    load_time_ms: 0.469\n","    sample_throughput: 521.445\n","    sample_time_ms: 7670.995\n","    update_time_ms: 2.842\n","  timestamp: 1649864004\n","  timesteps_since_restore: 492000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 492000\n","  training_iteration: 123\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 332000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-33-25\n","  done: false\n","  episode_len_mean: 536.25\n","  episode_media: {}\n","  episode_reward_max: 209.5449364255402\n","  episode_reward_mean: 53.16531102497368\n","  episode_reward_min: -79.86942866799153\n","  episodes_this_iter: 6\n","  episodes_total: 979\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.9455729126930237\n","          entropy_coeff: 0.0\n","          kl: 0.014770446345210075\n","          model: {}\n","          policy_loss: -0.04164402186870575\n","          total_loss: 217.03427124023438\n","          vf_explained_var: 0.8424193263053894\n","          vf_loss: 217.0609588623047\n","    num_agent_steps_sampled: 332000\n","    num_agent_steps_trained: 332000\n","    num_steps_sampled: 332000\n","    num_steps_trained: 332000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 83\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.49375\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07407539778795431\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1312542017442337\n","    mean_inference_ms: 0.7692013296827983\n","    mean_raw_obs_processing_ms: 0.112591613696544\n","  time_since_restore: 910.2924971580505\n","  time_this_iter_s: 11.197602272033691\n","  time_total_s: 910.2924971580505\n","  timers:\n","    learn_throughput: 1614.416\n","    learn_time_ms: 2477.676\n","    load_throughput: 8748157.264\n","    load_time_ms: 0.457\n","    sample_throughput: 355.708\n","    sample_time_ms: 11245.187\n","    update_time_ms: 2.848\n","  timestamp: 1649864005\n","  timesteps_since_restore: 332000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 332000\n","  training_iteration: 83\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:33:27 (running for 00:15:37.76)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   123</td><td style=\"text-align: right;\">         907.935</td><td style=\"text-align: right;\">492000</td><td style=\"text-align: right;\">-390.495 </td><td style=\"text-align: right;\">            -89.3727</td><td style=\"text-align: right;\">          -1124.39  </td><td style=\"text-align: right;\">            148.65</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">         910.292</td><td style=\"text-align: right;\">332000</td><td style=\"text-align: right;\">  53.1653</td><td style=\"text-align: right;\">            209.545 </td><td style=\"text-align: right;\">            -79.8694</td><td style=\"text-align: right;\">            536.25</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         899.594</td><td style=\"text-align: right;\">404000</td><td style=\"text-align: right;\"> 271.429 </td><td style=\"text-align: right;\">            312.35  </td><td style=\"text-align: right;\">             20.6375</td><td style=\"text-align: right;\">            227.58</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 408000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-33-30\n","  done: false\n","  episode_len_mean: 233.6\n","  episode_media: {}\n","  episode_reward_max: 321.4234674737594\n","  episode_reward_mean: 273.3697640126822\n","  episode_reward_min: 20.63746211831905\n","  episodes_this_iter: 16\n","  episodes_total: 1525\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.606616199016571\n","          entropy_coeff: 0.0\n","          kl: 0.006043028552085161\n","          model: {}\n","          policy_loss: -0.0006248399731703103\n","          total_loss: 181.00869750976562\n","          vf_explained_var: 0.633010745048523\n","          vf_loss: 181.0081787109375\n","    num_agent_steps_sampled: 408000\n","    num_agent_steps_trained: 408000\n","    num_steps_sampled: 408000\n","    num_steps_trained: 408000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 102\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.266666666666666\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07501889647665266\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6351584076942945\n","    mean_inference_ms: 0.7616993336849543\n","    mean_raw_obs_processing_ms: 0.11284350732246867\n","  time_since_restore: 907.7462356090546\n","  time_this_iter_s: 8.152454137802124\n","  time_total_s: 907.7462356090546\n","  timers:\n","    learn_throughput: 1652.713\n","    learn_time_ms: 2420.264\n","    load_throughput: 8036604.714\n","    load_time_ms: 0.498\n","    sample_throughput: 495.082\n","    sample_time_ms: 8079.473\n","    update_time_ms: 2.654\n","  timestamp: 1649864010\n","  timesteps_since_restore: 408000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 408000\n","  training_iteration: 102\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 496000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-33-31\n","  done: false\n","  episode_len_mean: 143.84\n","  episode_media: {}\n","  episode_reward_max: -89.37269141534239\n","  episode_reward_mean: -400.04221990513923\n","  episode_reward_min: -1124.3868700284688\n","  episodes_this_iter: 25\n","  episodes_total: 4361\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 279841472.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.4014918804168701\n","          entropy_coeff: 0.0\n","          kl: 0.0372462123632431\n","          model: {}\n","          policy_loss: 0.015618189238011837\n","          total_loss: 10426513.0\n","          vf_explained_var: 0.5545156598091125\n","          vf_loss: 3477.927001953125\n","    num_agent_steps_sampled: 496000\n","    num_agent_steps_trained: 496000\n","    num_steps_sampled: 496000\n","    num_steps_trained: 496000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 124\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.23\n","    ram_util_percent: 15.699999999999998\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0705272926470406\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.28164209110026284\n","    mean_inference_ms: 0.7270164873545574\n","    mean_raw_obs_processing_ms: 0.11276136000391059\n","  time_since_restore: 915.3328747749329\n","  time_this_iter_s: 7.397788763046265\n","  time_total_s: 915.3328747749329\n","  timers:\n","    learn_throughput: 1613.44\n","    learn_time_ms: 2479.174\n","    load_throughput: 8763694.108\n","    load_time_ms: 0.456\n","    sample_throughput: 519.53\n","    sample_time_ms: 7699.269\n","    update_time_ms: 2.814\n","  timestamp: 1649864011\n","  timesteps_since_restore: 496000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 496000\n","  training_iteration: 124\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:33:32 (running for 00:15:43.18)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   124</td><td style=\"text-align: right;\">         915.333</td><td style=\"text-align: right;\">496000</td><td style=\"text-align: right;\">-400.042 </td><td style=\"text-align: right;\">            -89.3727</td><td style=\"text-align: right;\">          -1124.39  </td><td style=\"text-align: right;\">            143.84</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">         910.292</td><td style=\"text-align: right;\">332000</td><td style=\"text-align: right;\">  53.1653</td><td style=\"text-align: right;\">            209.545 </td><td style=\"text-align: right;\">            -79.8694</td><td style=\"text-align: right;\">            536.25</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">         907.746</td><td style=\"text-align: right;\">408000</td><td style=\"text-align: right;\"> 273.37  </td><td style=\"text-align: right;\">            321.423 </td><td style=\"text-align: right;\">             20.6375</td><td style=\"text-align: right;\">            233.6 </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 336000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-33-36\n","  done: false\n","  episode_len_mean: 552.92\n","  episode_media: {}\n","  episode_reward_max: 209.5449364255402\n","  episode_reward_mean: 56.33430794453768\n","  episode_reward_min: -79.86942866799153\n","  episodes_this_iter: 4\n","  episodes_total: 983\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8906962275505066\n","          entropy_coeff: 0.0\n","          kl: 0.012278529815375805\n","          model: {}\n","          policy_loss: -0.032056037336587906\n","          total_loss: 26.717453002929688\n","          vf_explained_var: 0.9575836062431335\n","          vf_loss: 26.737075805664062\n","    num_agent_steps_sampled: 336000\n","    num_agent_steps_trained: 336000\n","    num_steps_sampled: 336000\n","    num_steps_trained: 336000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 84\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.4625\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07407435811716105\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1318339360603278\n","    mean_inference_ms: 0.7692258178937372\n","    mean_raw_obs_processing_ms: 0.11258977230307268\n","  time_since_restore: 921.4898798465729\n","  time_this_iter_s: 11.197382688522339\n","  time_total_s: 921.4898798465729\n","  timers:\n","    learn_throughput: 1621.768\n","    learn_time_ms: 2466.444\n","    load_throughput: 8504697.116\n","    load_time_ms: 0.47\n","    sample_throughput: 353.912\n","    sample_time_ms: 11302.258\n","    update_time_ms: 2.815\n","  timestamp: 1649864016\n","  timesteps_since_restore: 336000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 336000\n","  training_iteration: 84\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 412000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-33-38\n","  done: false\n","  episode_len_mean: 235.54\n","  episode_media: {}\n","  episode_reward_max: 321.4234674737594\n","  episode_reward_mean: 266.87405812028607\n","  episode_reward_min: 20.63746211831905\n","  episodes_this_iter: 17\n","  episodes_total: 1542\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6277161240577698\n","          entropy_coeff: 0.0\n","          kl: 0.006299352739006281\n","          model: {}\n","          policy_loss: -0.008931877091526985\n","          total_loss: 537.9190673828125\n","          vf_explained_var: 0.4428679347038269\n","          vf_loss: 537.9268188476562\n","    num_agent_steps_sampled: 412000\n","    num_agent_steps_trained: 412000\n","    num_steps_sampled: 412000\n","    num_steps_trained: 412000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 103\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.936363636363636\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07501961658859685\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6334210682916347\n","    mean_inference_ms: 0.761586791104693\n","    mean_raw_obs_processing_ms: 0.11284780546435096\n","  time_since_restore: 915.747546672821\n","  time_this_iter_s: 8.00131106376648\n","  time_total_s: 915.747546672821\n","  timers:\n","    learn_throughput: 1652.638\n","    learn_time_ms: 2420.373\n","    load_throughput: 7930614.985\n","    load_time_ms: 0.504\n","    sample_throughput: 494.023\n","    sample_time_ms: 8096.797\n","    update_time_ms: 2.687\n","  timestamp: 1649864018\n","  timesteps_since_restore: 412000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 412000\n","  training_iteration: 103\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:33:38 (running for 00:15:48.83)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   124</td><td style=\"text-align: right;\">         915.333</td><td style=\"text-align: right;\">496000</td><td style=\"text-align: right;\">-400.042 </td><td style=\"text-align: right;\">            -89.3727</td><td style=\"text-align: right;\">          -1124.39  </td><td style=\"text-align: right;\">            143.84</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         921.49 </td><td style=\"text-align: right;\">336000</td><td style=\"text-align: right;\">  56.3343</td><td style=\"text-align: right;\">            209.545 </td><td style=\"text-align: right;\">            -79.8694</td><td style=\"text-align: right;\">            552.92</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         915.748</td><td style=\"text-align: right;\">412000</td><td style=\"text-align: right;\"> 266.874 </td><td style=\"text-align: right;\">            321.423 </td><td style=\"text-align: right;\">             20.6375</td><td style=\"text-align: right;\">            235.54</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 500000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-33-39\n","  done: false\n","  episode_len_mean: 140.4\n","  episode_media: {}\n","  episode_reward_max: -137.2301523696965\n","  episode_reward_mean: -397.06037056429057\n","  episode_reward_min: -1124.3868700284688\n","  episodes_this_iter: 29\n","  episodes_total: 4390\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 419762176.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.32963827252388\n","          entropy_coeff: 0.0\n","          kl: 0.11678790301084518\n","          model: {}\n","          policy_loss: 0.027356376871466637\n","          total_loss: 49024648.0\n","          vf_explained_var: 0.48641082644462585\n","          vf_loss: 1506.292724609375\n","    num_agent_steps_sampled: 500000\n","    num_agent_steps_trained: 500000\n","    num_steps_sampled: 500000\n","    num_steps_trained: 500000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 125\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.154545454545454\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0705362849645218\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.28206318344168363\n","    mean_inference_ms: 0.7270980398639346\n","    mean_raw_obs_processing_ms: 0.11277393690374835\n","  time_since_restore: 922.9779834747314\n","  time_this_iter_s: 7.645108699798584\n","  time_total_s: 922.9779834747314\n","  timers:\n","    learn_throughput: 1609.106\n","    learn_time_ms: 2485.852\n","    load_throughput: 8356019.524\n","    load_time_ms: 0.479\n","    sample_throughput: 519.614\n","    sample_time_ms: 7698.016\n","    update_time_ms: 2.813\n","  timestamp: 1649864019\n","  timesteps_since_restore: 500000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 500000\n","  training_iteration: 125\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:33:43 (running for 00:15:53.86)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   125</td><td style=\"text-align: right;\">         922.978</td><td style=\"text-align: right;\">500000</td><td style=\"text-align: right;\">-397.06  </td><td style=\"text-align: right;\">            -137.23 </td><td style=\"text-align: right;\">          -1124.39  </td><td style=\"text-align: right;\">            140.4 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         921.49 </td><td style=\"text-align: right;\">336000</td><td style=\"text-align: right;\">  56.3343</td><td style=\"text-align: right;\">             209.545</td><td style=\"text-align: right;\">            -79.8694</td><td style=\"text-align: right;\">            552.92</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         915.748</td><td style=\"text-align: right;\">412000</td><td style=\"text-align: right;\"> 266.874 </td><td style=\"text-align: right;\">             321.423</td><td style=\"text-align: right;\">             20.6375</td><td style=\"text-align: right;\">            235.54</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 416000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-33-46\n","  done: false\n","  episode_len_mean: 238.62\n","  episode_media: {}\n","  episode_reward_max: 321.4234674737594\n","  episode_reward_mean: 264.6995561941269\n","  episode_reward_min: 20.63746211831905\n","  episodes_this_iter: 18\n","  episodes_total: 1560\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6179113388061523\n","          entropy_coeff: 0.0\n","          kl: 0.00815725140273571\n","          model: {}\n","          policy_loss: -0.013754402287304401\n","          total_loss: 363.2328186035156\n","          vf_explained_var: 0.5878583192825317\n","          vf_loss: 363.2450256347656\n","    num_agent_steps_sampled: 416000\n","    num_agent_steps_trained: 416000\n","    num_steps_sampled: 416000\n","    num_steps_trained: 416000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 104\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.227272727272727\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07501522222874031\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6316023272875301\n","    mean_inference_ms: 0.7614054834568313\n","    mean_raw_obs_processing_ms: 0.11284508499929384\n","  time_since_restore: 923.4911859035492\n","  time_this_iter_s: 7.743639230728149\n","  time_total_s: 923.4911859035492\n","  timers:\n","    learn_throughput: 1647.009\n","    learn_time_ms: 2428.644\n","    load_throughput: 7748933.537\n","    load_time_ms: 0.516\n","    sample_throughput: 495.414\n","    sample_time_ms: 8074.062\n","    update_time_ms: 2.679\n","  timestamp: 1649864026\n","  timesteps_since_restore: 416000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 416000\n","  training_iteration: 104\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 504000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-33-46\n","  done: false\n","  episode_len_mean: 137.94\n","  episode_media: {}\n","  episode_reward_max: -137.2301523696965\n","  episode_reward_mean: -380.7914948724501\n","  episode_reward_min: -903.434238235658\n","  episodes_this_iter: 30\n","  episodes_total: 4420\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 629643264.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.3494012653827667\n","          entropy_coeff: 0.0\n","          kl: 0.06777434051036835\n","          model: {}\n","          policy_loss: 0.01742364466190338\n","          total_loss: 42675752.0\n","          vf_explained_var: 0.4643048644065857\n","          vf_loss: 2096.85693359375\n","    num_agent_steps_sampled: 504000\n","    num_agent_steps_trained: 504000\n","    num_steps_sampled: 504000\n","    num_steps_trained: 504000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 126\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.9\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0705291547647412\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.28239714008598166\n","    mean_inference_ms: 0.7270066077643085\n","    mean_raw_obs_processing_ms: 0.11276151907060093\n","  time_since_restore: 930.3452801704407\n","  time_this_iter_s: 7.3672966957092285\n","  time_total_s: 930.3452801704407\n","  timers:\n","    learn_throughput: 1602.559\n","    learn_time_ms: 2496.008\n","    load_throughput: 8865575.988\n","    load_time_ms: 0.451\n","    sample_throughput: 520.823\n","    sample_time_ms: 7680.151\n","    update_time_ms: 2.861\n","  timestamp: 1649864026\n","  timesteps_since_restore: 504000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 504000\n","  training_iteration: 126\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 340000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-33-47\n","  done: false\n","  episode_len_mean: 536.48\n","  episode_media: {}\n","  episode_reward_max: 209.5449364255402\n","  episode_reward_mean: 52.7720401439757\n","  episode_reward_min: -79.86942866799153\n","  episodes_this_iter: 8\n","  episodes_total: 991\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8804865479469299\n","          entropy_coeff: 0.0\n","          kl: 0.01566212996840477\n","          model: {}\n","          policy_loss: -0.0440659299492836\n","          total_loss: 464.09100341796875\n","          vf_explained_var: 0.8300110101699829\n","          vf_loss: 464.1192321777344\n","    num_agent_steps_sampled: 340000\n","    num_agent_steps_trained: 340000\n","    num_steps_sampled: 340000\n","    num_steps_trained: 340000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 85\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 15.193333333333332\n","    ram_util_percent: 15.699999999999994\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0740723325995027\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1326983072245003\n","    mean_inference_ms: 0.7692557715156635\n","    mean_raw_obs_processing_ms: 0.11258688072144904\n","  time_since_restore: 932.1041214466095\n","  time_this_iter_s: 10.614241600036621\n","  time_total_s: 932.1041214466095\n","  timers:\n","    learn_throughput: 1618.085\n","    learn_time_ms: 2472.058\n","    load_throughput: 8310489.4\n","    load_time_ms: 0.481\n","    sample_throughput: 354.735\n","    sample_time_ms: 11276.031\n","    update_time_ms: 2.803\n","  timestamp: 1649864027\n","  timesteps_since_restore: 340000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 340000\n","  training_iteration: 85\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:33:49 (running for 00:15:59.64)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   126</td><td style=\"text-align: right;\">         930.345</td><td style=\"text-align: right;\">504000</td><td style=\"text-align: right;\">-380.791</td><td style=\"text-align: right;\">            -137.23 </td><td style=\"text-align: right;\">           -903.434 </td><td style=\"text-align: right;\">            137.94</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         932.104</td><td style=\"text-align: right;\">340000</td><td style=\"text-align: right;\">  52.772</td><td style=\"text-align: right;\">             209.545</td><td style=\"text-align: right;\">            -79.8694</td><td style=\"text-align: right;\">            536.48</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         923.491</td><td style=\"text-align: right;\">416000</td><td style=\"text-align: right;\"> 264.7  </td><td style=\"text-align: right;\">             321.423</td><td style=\"text-align: right;\">             20.6375</td><td style=\"text-align: right;\">            238.62</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 420000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-33-54\n","  done: false\n","  episode_len_mean: 241.77\n","  episode_media: {}\n","  episode_reward_max: 321.4234674737594\n","  episode_reward_mean: 266.40351051205795\n","  episode_reward_min: 34.62742519402639\n","  episodes_this_iter: 18\n","  episodes_total: 1578\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6320376396179199\n","          entropy_coeff: 0.0\n","          kl: 0.015071109868586063\n","          model: {}\n","          policy_loss: -0.012981122359633446\n","          total_loss: 129.4528045654297\n","          vf_explained_var: 0.6622039079666138\n","          vf_loss: 129.46292114257812\n","    num_agent_steps_sampled: 420000\n","    num_agent_steps_trained: 420000\n","    num_steps_sampled: 420000\n","    num_steps_trained: 420000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 105\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.149999999999999\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07500509374653454\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6297911667313327\n","    mean_inference_ms: 0.761152008350684\n","    mean_raw_obs_processing_ms: 0.1128339864352758\n","  time_since_restore: 931.3289012908936\n","  time_this_iter_s: 7.83771538734436\n","  time_total_s: 931.3289012908936\n","  timers:\n","    learn_throughput: 1634.116\n","    learn_time_ms: 2447.807\n","    load_throughput: 8005542.778\n","    load_time_ms: 0.5\n","    sample_throughput: 499.527\n","    sample_time_ms: 8007.577\n","    update_time_ms: 2.693\n","  timestamp: 1649864034\n","  timesteps_since_restore: 420000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 420000\n","  training_iteration: 105\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 508000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-33-54\n","  done: false\n","  episode_len_mean: 140.0\n","  episode_media: {}\n","  episode_reward_max: -109.15026582856598\n","  episode_reward_mean: -391.99484143562785\n","  episode_reward_min: -903.434238235658\n","  episodes_this_iter: 29\n","  episodes_total: 4449\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 944464896.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.3305406868457794\n","          entropy_coeff: 0.0\n","          kl: 0.11721169203519821\n","          model: {}\n","          policy_loss: 0.03453599661588669\n","          total_loss: 110703928.0\n","          vf_explained_var: 0.5136894583702087\n","          vf_loss: 1608.7615966796875\n","    num_agent_steps_sampled: 508000\n","    num_agent_steps_trained: 508000\n","    num_steps_sampled: 508000\n","    num_steps_trained: 508000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 127\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.489999999999998\n","    ram_util_percent: 15.699999999999998\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07051338023787207\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.28265570372149496\n","    mean_inference_ms: 0.7268377779898394\n","    mean_raw_obs_processing_ms: 0.11273611077470043\n","  time_since_restore: 937.6228897571564\n","  time_this_iter_s: 7.277609586715698\n","  time_total_s: 937.6228897571564\n","  timers:\n","    learn_throughput: 1595.681\n","    learn_time_ms: 2506.767\n","    load_throughput: 8888120.364\n","    load_time_ms: 0.45\n","    sample_throughput: 522.215\n","    sample_time_ms: 7659.68\n","    update_time_ms: 2.818\n","  timestamp: 1649864034\n","  timesteps_since_restore: 508000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 508000\n","  training_iteration: 127\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:33:55 (running for 00:16:05.58)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   127</td><td style=\"text-align: right;\">         937.623</td><td style=\"text-align: right;\">508000</td><td style=\"text-align: right;\">-391.995</td><td style=\"text-align: right;\">            -109.15 </td><td style=\"text-align: right;\">           -903.434 </td><td style=\"text-align: right;\">            140   </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         932.104</td><td style=\"text-align: right;\">340000</td><td style=\"text-align: right;\">  52.772</td><td style=\"text-align: right;\">             209.545</td><td style=\"text-align: right;\">            -79.8694</td><td style=\"text-align: right;\">            536.48</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         931.329</td><td style=\"text-align: right;\">420000</td><td style=\"text-align: right;\"> 266.404</td><td style=\"text-align: right;\">             321.423</td><td style=\"text-align: right;\">             34.6274</td><td style=\"text-align: right;\">            241.77</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 344000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-33-59\n","  done: false\n","  episode_len_mean: 536.12\n","  episode_media: {}\n","  episode_reward_max: 209.5449364255402\n","  episode_reward_mean: 53.259032858886876\n","  episode_reward_min: -79.86942866799153\n","  episodes_this_iter: 6\n","  episodes_total: 997\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8529988527297974\n","          entropy_coeff: 0.0\n","          kl: 0.014934565871953964\n","          model: {}\n","          policy_loss: -0.04670070484280586\n","          total_loss: 193.935546875\n","          vf_explained_var: 0.8505351543426514\n","          vf_loss: 193.96713256835938\n","    num_agent_steps_sampled: 344000\n","    num_agent_steps_trained: 344000\n","    num_steps_sampled: 344000\n","    num_steps_trained: 344000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 86\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.11176470588235\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07407050319239121\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1333864926843396\n","    mean_inference_ms: 0.7692716106996323\n","    mean_raw_obs_processing_ms: 0.1125843044821194\n","  time_since_restore: 943.8176312446594\n","  time_this_iter_s: 11.713509798049927\n","  time_total_s: 943.8176312446594\n","  timers:\n","    learn_throughput: 1621.378\n","    learn_time_ms: 2467.037\n","    load_throughput: 8267896.708\n","    load_time_ms: 0.484\n","    sample_throughput: 353.486\n","    sample_time_ms: 11315.857\n","    update_time_ms: 2.789\n","  timestamp: 1649864039\n","  timesteps_since_restore: 344000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 344000\n","  training_iteration: 86\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:34:01 (running for 00:16:11.39)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   127</td><td style=\"text-align: right;\">         937.623</td><td style=\"text-align: right;\">508000</td><td style=\"text-align: right;\">-391.995</td><td style=\"text-align: right;\">            -109.15 </td><td style=\"text-align: right;\">           -903.434 </td><td style=\"text-align: right;\">            140   </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         943.818</td><td style=\"text-align: right;\">344000</td><td style=\"text-align: right;\">  53.259</td><td style=\"text-align: right;\">             209.545</td><td style=\"text-align: right;\">            -79.8694</td><td style=\"text-align: right;\">            536.12</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         931.329</td><td style=\"text-align: right;\">420000</td><td style=\"text-align: right;\"> 266.404</td><td style=\"text-align: right;\">             321.423</td><td style=\"text-align: right;\">             34.6274</td><td style=\"text-align: right;\">            241.77</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 512000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-34-02\n","  done: false\n","  episode_len_mean: 136.26\n","  episode_media: {}\n","  episode_reward_max: -109.15026582856598\n","  episode_reward_mean: -391.91672661834434\n","  episode_reward_min: -896.8560037515551\n","  episodes_this_iter: 29\n","  episodes_total: 4478\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1416697344.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.3871692419052124\n","          entropy_coeff: 0.0\n","          kl: 0.09063448011875153\n","          model: {}\n","          policy_loss: 0.017338918522000313\n","          total_loss: 128402536.0\n","          vf_explained_var: 0.5557375550270081\n","          vf_loss: 919.0524291992188\n","    num_agent_steps_sampled: 512000\n","    num_agent_steps_trained: 512000\n","    num_steps_sampled: 512000\n","    num_steps_trained: 512000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 128\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.15\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07050742314926339\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.28285621595791327\n","    mean_inference_ms: 0.7267748564082516\n","    mean_raw_obs_processing_ms: 0.11272674587753677\n","  time_since_restore: 945.4343590736389\n","  time_this_iter_s: 7.811469316482544\n","  time_total_s: 945.4343590736389\n","  timers:\n","    learn_throughput: 1585.083\n","    learn_time_ms: 2523.527\n","    load_throughput: 8846876.186\n","    load_time_ms: 0.452\n","    sample_throughput: 520.068\n","    sample_time_ms: 7691.297\n","    update_time_ms: 2.862\n","  timestamp: 1649864042\n","  timesteps_since_restore: 512000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 512000\n","  training_iteration: 128\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 424000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-34-02\n","  done: false\n","  episode_len_mean: 241.2\n","  episode_media: {}\n","  episode_reward_max: 325.3744083682052\n","  episode_reward_mean: 264.3493177200696\n","  episode_reward_min: 34.62742519402639\n","  episodes_this_iter: 17\n","  episodes_total: 1595\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6102167963981628\n","          entropy_coeff: 0.0\n","          kl: 0.006026832852512598\n","          model: {}\n","          policy_loss: -0.012540718540549278\n","          total_loss: 301.9627380371094\n","          vf_explained_var: 0.6240664720535278\n","          vf_loss: 301.97412109375\n","    num_agent_steps_sampled: 424000\n","    num_agent_steps_trained: 424000\n","    num_steps_sampled: 424000\n","    num_steps_trained: 424000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 106\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.618181818181817\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07499200491672225\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6281242592603435\n","    mean_inference_ms: 0.760891025302639\n","    mean_raw_obs_processing_ms: 0.11281498387324848\n","  time_since_restore: 939.3836653232574\n","  time_this_iter_s: 8.054764032363892\n","  time_total_s: 939.3836653232574\n","  timers:\n","    learn_throughput: 1623.023\n","    learn_time_ms: 2464.536\n","    load_throughput: 8134407.758\n","    load_time_ms: 0.492\n","    sample_throughput: 498.814\n","    sample_time_ms: 8019.026\n","    update_time_ms: 2.723\n","  timestamp: 1649864042\n","  timesteps_since_restore: 424000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 424000\n","  training_iteration: 106\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:34:06 (running for 00:16:16.65)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   128</td><td style=\"text-align: right;\">         945.434</td><td style=\"text-align: right;\">512000</td><td style=\"text-align: right;\">-391.917</td><td style=\"text-align: right;\">            -109.15 </td><td style=\"text-align: right;\">           -896.856 </td><td style=\"text-align: right;\">            136.26</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         943.818</td><td style=\"text-align: right;\">344000</td><td style=\"text-align: right;\">  53.259</td><td style=\"text-align: right;\">             209.545</td><td style=\"text-align: right;\">            -79.8694</td><td style=\"text-align: right;\">            536.12</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   106</td><td style=\"text-align: right;\">         939.384</td><td style=\"text-align: right;\">424000</td><td style=\"text-align: right;\"> 264.349</td><td style=\"text-align: right;\">             325.374</td><td style=\"text-align: right;\">             34.6274</td><td style=\"text-align: right;\">            241.2 </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 516000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-34-09\n","  done: false\n","  episode_len_mean: 135.9\n","  episode_media: {}\n","  episode_reward_max: -109.15026582856598\n","  episode_reward_mean: -406.39928714268274\n","  episode_reward_min: -1054.5048792455132\n","  episodes_this_iter: 30\n","  episodes_total: 4508\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 2125046016.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.2783556878566742\n","          entropy_coeff: 0.0\n","          kl: 0.13390998542308807\n","          model: {}\n","          policy_loss: 0.025248266756534576\n","          total_loss: 284567872.0\n","          vf_explained_var: 0.6276742219924927\n","          vf_loss: 2982.907958984375\n","    num_agent_steps_sampled: 516000\n","    num_agent_steps_trained: 516000\n","    num_steps_sampled: 516000\n","    num_steps_trained: 516000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 129\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.47272727272727\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07049527720296414\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.28311933741741363\n","    mean_inference_ms: 0.7266747657909691\n","    mean_raw_obs_processing_ms: 0.11270792901604175\n","  time_since_restore: 952.9864408969879\n","  time_this_iter_s: 7.552081823348999\n","  time_total_s: 952.9864408969879\n","  timers:\n","    learn_throughput: 1576.942\n","    learn_time_ms: 2536.555\n","    load_throughput: 8952623.266\n","    load_time_ms: 0.447\n","    sample_throughput: 520.335\n","    sample_time_ms: 7687.362\n","    update_time_ms: 2.896\n","  timestamp: 1649864049\n","  timesteps_since_restore: 516000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 516000\n","  training_iteration: 129\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 348000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-34-11\n","  done: false\n","  episode_len_mean: 536.92\n","  episode_media: {}\n","  episode_reward_max: 209.5449364255402\n","  episode_reward_mean: 50.921857669071024\n","  episode_reward_min: -156.235027916002\n","  episodes_this_iter: 9\n","  episodes_total: 1006\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8785215020179749\n","          entropy_coeff: 0.0\n","          kl: 0.016875984147191048\n","          model: {}\n","          policy_loss: -0.046201519668102264\n","          total_loss: 273.3064270019531\n","          vf_explained_var: 0.8203100562095642\n","          vf_loss: 273.3355407714844\n","    num_agent_steps_sampled: 348000\n","    num_agent_steps_trained: 348000\n","    num_steps_sampled: 348000\n","    num_steps_trained: 348000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 87\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.558823529411764\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07406894384875842\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.134624266827682\n","    mean_inference_ms: 0.7693045972335004\n","    mean_raw_obs_processing_ms: 0.1125813343307512\n","  time_since_restore: 955.7693147659302\n","  time_this_iter_s: 11.951683521270752\n","  time_total_s: 955.7693147659302\n","  timers:\n","    learn_throughput: 1605.224\n","    learn_time_ms: 2491.864\n","    load_throughput: 8523708.784\n","    load_time_ms: 0.469\n","    sample_throughput: 351.839\n","    sample_time_ms: 11368.851\n","    update_time_ms: 2.773\n","  timestamp: 1649864051\n","  timesteps_since_restore: 348000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 348000\n","  training_iteration: 87\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 428000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-34-11\n","  done: false\n","  episode_len_mean: 243.71\n","  episode_media: {}\n","  episode_reward_max: 325.3744083682052\n","  episode_reward_mean: 265.9117094359073\n","  episode_reward_min: 34.62742519402639\n","  episodes_this_iter: 12\n","  episodes_total: 1607\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6281340718269348\n","          entropy_coeff: 0.0\n","          kl: 0.011297674849629402\n","          model: {}\n","          policy_loss: -0.008021165616810322\n","          total_loss: 416.5727844238281\n","          vf_explained_var: 0.3511095345020294\n","          vf_loss: 416.57867431640625\n","    num_agent_steps_sampled: 428000\n","    num_agent_steps_trained: 428000\n","    num_steps_sampled: 428000\n","    num_steps_trained: 428000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 107\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.653846153846153\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07498269037995892\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6269595753744299\n","    mean_inference_ms: 0.7607043747068056\n","    mean_raw_obs_processing_ms: 0.11280162160494431\n","  time_since_restore: 948.399120092392\n","  time_this_iter_s: 9.015454769134521\n","  time_total_s: 948.399120092392\n","  timers:\n","    learn_throughput: 1605.513\n","    learn_time_ms: 2491.416\n","    load_throughput: 8337333.4\n","    load_time_ms: 0.48\n","    sample_throughput: 491.652\n","    sample_time_ms: 8135.841\n","    update_time_ms: 2.716\n","  timestamp: 1649864051\n","  timesteps_since_restore: 428000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 428000\n","  training_iteration: 107\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:34:12 (running for 00:16:22.62)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   129</td><td style=\"text-align: right;\">         952.986</td><td style=\"text-align: right;\">516000</td><td style=\"text-align: right;\">-406.399 </td><td style=\"text-align: right;\">            -109.15 </td><td style=\"text-align: right;\">          -1054.5   </td><td style=\"text-align: right;\">            135.9 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">         955.769</td><td style=\"text-align: right;\">348000</td><td style=\"text-align: right;\">  50.9219</td><td style=\"text-align: right;\">             209.545</td><td style=\"text-align: right;\">           -156.235 </td><td style=\"text-align: right;\">            536.92</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         948.399</td><td style=\"text-align: right;\">428000</td><td style=\"text-align: right;\"> 265.912 </td><td style=\"text-align: right;\">             325.374</td><td style=\"text-align: right;\">             34.6274</td><td style=\"text-align: right;\">            243.71</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 520000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-34-17\n","  done: false\n","  episode_len_mean: 133.51\n","  episode_media: {}\n","  episode_reward_max: -111.89324759533704\n","  episode_reward_mean: -398.6453203043129\n","  episode_reward_min: -1054.5048792455132\n","  episodes_this_iter: 32\n","  episodes_total: 4540\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 3187569152.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.32457059621810913\n","          entropy_coeff: 0.0\n","          kl: 0.1401904672384262\n","          model: {}\n","          policy_loss: 0.025585629045963287\n","          total_loss: 446868032.0\n","          vf_explained_var: 0.5407531261444092\n","          vf_loss: 1183.876220703125\n","    num_agent_steps_sampled: 520000\n","    num_agent_steps_trained: 520000\n","    num_steps_sampled: 520000\n","    num_steps_trained: 520000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 130\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.55\n","    ram_util_percent: 15.699999999999998\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07049367531707271\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2833959171805033\n","    mean_inference_ms: 0.7267033011819735\n","    mean_raw_obs_processing_ms: 0.1127048462825874\n","  time_since_restore: 960.5619189739227\n","  time_this_iter_s: 7.5754780769348145\n","  time_total_s: 960.5619189739227\n","  timers:\n","    learn_throughput: 1567.956\n","    learn_time_ms: 2551.093\n","    load_throughput: 8630699.11\n","    load_time_ms: 0.463\n","    sample_throughput: 524.791\n","    sample_time_ms: 7622.089\n","    update_time_ms: 2.956\n","  timestamp: 1649864057\n","  timesteps_since_restore: 520000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 520000\n","  training_iteration: 130\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:34:17 (running for 00:16:27.65)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   130</td><td style=\"text-align: right;\">         960.562</td><td style=\"text-align: right;\">520000</td><td style=\"text-align: right;\">-398.645 </td><td style=\"text-align: right;\">            -111.893</td><td style=\"text-align: right;\">          -1054.5   </td><td style=\"text-align: right;\">            133.51</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">         955.769</td><td style=\"text-align: right;\">348000</td><td style=\"text-align: right;\">  50.9219</td><td style=\"text-align: right;\">             209.545</td><td style=\"text-align: right;\">           -156.235 </td><td style=\"text-align: right;\">            536.92</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         948.399</td><td style=\"text-align: right;\">428000</td><td style=\"text-align: right;\"> 265.912 </td><td style=\"text-align: right;\">             325.374</td><td style=\"text-align: right;\">             34.6274</td><td style=\"text-align: right;\">            243.71</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 432000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-34-19\n","  done: false\n","  episode_len_mean: 234.78\n","  episode_media: {}\n","  episode_reward_max: 325.3744083682052\n","  episode_reward_mean: 264.58969762852274\n","  episode_reward_min: 34.62742519402639\n","  episodes_this_iter: 19\n","  episodes_total: 1626\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6086931228637695\n","          entropy_coeff: 0.0\n","          kl: 0.009214155375957489\n","          model: {}\n","          policy_loss: -0.01036258228123188\n","          total_loss: 104.3025894165039\n","          vf_explained_var: 0.6988873481750488\n","          vf_loss: 104.31119537353516\n","    num_agent_steps_sampled: 432000\n","    num_agent_steps_trained: 432000\n","    num_steps_sampled: 432000\n","    num_steps_trained: 432000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 108\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.291666666666666\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07496926282367637\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6250429539992896\n","    mean_inference_ms: 0.7604550175906826\n","    mean_raw_obs_processing_ms: 0.112784017456679\n","  time_since_restore: 956.4765648841858\n","  time_this_iter_s: 8.077444791793823\n","  time_total_s: 956.4765648841858\n","  timers:\n","    learn_throughput: 1598.284\n","    learn_time_ms: 2502.684\n","    load_throughput: 8301853.63\n","    load_time_ms: 0.482\n","    sample_throughput: 488.717\n","    sample_time_ms: 8184.697\n","    update_time_ms: 2.756\n","  timestamp: 1649864059\n","  timesteps_since_restore: 432000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 432000\n","  training_iteration: 108\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 352000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-34-21\n","  done: false\n","  episode_len_mean: 552.05\n","  episode_media: {}\n","  episode_reward_max: 209.5449364255402\n","  episode_reward_mean: 53.951999339954035\n","  episode_reward_min: -156.235027916002\n","  episodes_this_iter: 8\n","  episodes_total: 1014\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8302848935127258\n","          entropy_coeff: 0.0\n","          kl: 0.01244080439209938\n","          model: {}\n","          policy_loss: -0.043398160487413406\n","          total_loss: 219.84005737304688\n","          vf_explained_var: 0.8051866888999939\n","          vf_loss: 219.870849609375\n","    num_agent_steps_sampled: 352000\n","    num_agent_steps_trained: 352000\n","    num_steps_sampled: 352000\n","    num_steps_trained: 352000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 88\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.780000000000001\n","    ram_util_percent: 15.699999999999994\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07406876848759265\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1356880366303652\n","    mean_inference_ms: 0.7693405506242879\n","    mean_raw_obs_processing_ms: 0.11257730675379524\n","  time_since_restore: 966.4177010059357\n","  time_this_iter_s: 10.648386240005493\n","  time_total_s: 966.4177010059357\n","  timers:\n","    learn_throughput: 1609.101\n","    learn_time_ms: 2485.86\n","    load_throughput: 8049328.791\n","    load_time_ms: 0.497\n","    sample_throughput: 354.146\n","    sample_time_ms: 11294.791\n","    update_time_ms: 2.812\n","  timestamp: 1649864061\n","  timesteps_since_restore: 352000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 352000\n","  training_iteration: 88\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:34:22 (running for 00:16:33.08)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   130</td><td style=\"text-align: right;\">         960.562</td><td style=\"text-align: right;\">520000</td><td style=\"text-align: right;\">-398.645</td><td style=\"text-align: right;\">            -111.893</td><td style=\"text-align: right;\">          -1054.5   </td><td style=\"text-align: right;\">            133.51</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         966.418</td><td style=\"text-align: right;\">352000</td><td style=\"text-align: right;\">  53.952</td><td style=\"text-align: right;\">             209.545</td><td style=\"text-align: right;\">           -156.235 </td><td style=\"text-align: right;\">            552.05</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         956.477</td><td style=\"text-align: right;\">432000</td><td style=\"text-align: right;\"> 264.59 </td><td style=\"text-align: right;\">             325.374</td><td style=\"text-align: right;\">             34.6274</td><td style=\"text-align: right;\">            234.78</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 524000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-34-25\n","  done: false\n","  episode_len_mean: 137.19\n","  episode_media: {}\n","  episode_reward_max: -111.89324759533704\n","  episode_reward_mean: -411.6484635560435\n","  episode_reward_min: -1109.9915498354267\n","  episodes_this_iter: 23\n","  episodes_total: 4563\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 4781353472.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.37648335099220276\n","          entropy_coeff: 0.0\n","          kl: 0.07830708473920822\n","          model: {}\n","          policy_loss: 0.02287471666932106\n","          total_loss: 374416832.0\n","          vf_explained_var: 0.34840625524520874\n","          vf_loss: 2948.411376953125\n","    num_agent_steps_sampled: 524000\n","    num_agent_steps_trained: 524000\n","    num_steps_sampled: 524000\n","    num_steps_trained: 524000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 131\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.883333333333335\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07049326655544583\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2837660425609004\n","    mean_inference_ms: 0.7267550188372488\n","    mean_raw_obs_processing_ms: 0.11270149728524684\n","  time_since_restore: 968.5839948654175\n","  time_this_iter_s: 8.022075891494751\n","  time_total_s: 968.5839948654175\n","  timers:\n","    learn_throughput: 1565.638\n","    learn_time_ms: 2554.869\n","    load_throughput: 8761863.38\n","    load_time_ms: 0.457\n","    sample_throughput: 523.246\n","    sample_time_ms: 7644.589\n","    update_time_ms: 2.942\n","  timestamp: 1649864065\n","  timesteps_since_restore: 524000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 524000\n","  training_iteration: 131\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 436000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-34-27\n","  done: false\n","  episode_len_mean: 234.22\n","  episode_media: {}\n","  episode_reward_max: 325.3744083682052\n","  episode_reward_mean: 270.0333192017262\n","  episode_reward_min: 34.62742519402639\n","  episodes_this_iter: 18\n","  episodes_total: 1644\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6438194513320923\n","          entropy_coeff: 0.0\n","          kl: 0.0078517971560359\n","          model: {}\n","          policy_loss: -0.020669154822826385\n","          total_loss: 60.504241943359375\n","          vf_explained_var: 0.7265240550041199\n","          vf_loss: 60.52342224121094\n","    num_agent_steps_sampled: 436000\n","    num_agent_steps_trained: 436000\n","    num_steps_sampled: 436000\n","    num_steps_trained: 436000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 109\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.636363636363637\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07496072957957661\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6233325004559301\n","    mean_inference_ms: 0.7602945378896553\n","    mean_raw_obs_processing_ms: 0.11277473163778609\n","  time_since_restore: 964.5903661251068\n","  time_this_iter_s: 8.11380124092102\n","  time_total_s: 964.5903661251068\n","  timers:\n","    learn_throughput: 1597.481\n","    learn_time_ms: 2503.942\n","    load_throughput: 8554130.424\n","    load_time_ms: 0.468\n","    sample_throughput: 486.939\n","    sample_time_ms: 8214.582\n","    update_time_ms: 2.761\n","  timestamp: 1649864067\n","  timesteps_since_restore: 436000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 436000\n","  training_iteration: 109\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:34:28 (running for 00:16:38.88)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   131</td><td style=\"text-align: right;\">         968.584</td><td style=\"text-align: right;\">524000</td><td style=\"text-align: right;\">-411.648</td><td style=\"text-align: right;\">            -111.893</td><td style=\"text-align: right;\">          -1109.99  </td><td style=\"text-align: right;\">            137.19</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         966.418</td><td style=\"text-align: right;\">352000</td><td style=\"text-align: right;\">  53.952</td><td style=\"text-align: right;\">             209.545</td><td style=\"text-align: right;\">           -156.235 </td><td style=\"text-align: right;\">            552.05</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         964.59 </td><td style=\"text-align: right;\">436000</td><td style=\"text-align: right;\"> 270.033</td><td style=\"text-align: right;\">             325.374</td><td style=\"text-align: right;\">             34.6274</td><td style=\"text-align: right;\">            234.22</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 528000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-34-32\n","  done: false\n","  episode_len_mean: 142.98\n","  episode_media: {}\n","  episode_reward_max: -111.89324759533704\n","  episode_reward_mean: -422.66740020214843\n","  episode_reward_min: -1109.9915498354267\n","  episodes_this_iter: 29\n","  episodes_total: 4592\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 7172030464.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.3630099296569824\n","          entropy_coeff: 0.0\n","          kl: 0.0687965452671051\n","          model: {}\n","          policy_loss: 0.01605822704732418\n","          total_loss: 493412512.0\n","          vf_explained_var: 0.5321537256240845\n","          vf_loss: 1614.1591796875\n","    num_agent_steps_sampled: 528000\n","    num_agent_steps_trained: 528000\n","    num_steps_sampled: 528000\n","    num_steps_trained: 528000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 132\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.01818181818182\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07049389106969067\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2842047239427815\n","    mean_inference_ms: 0.7268002921236956\n","    mean_raw_obs_processing_ms: 0.11269850835765968\n","  time_since_restore: 976.0468397140503\n","  time_this_iter_s: 7.4628448486328125\n","  time_total_s: 976.0468397140503\n","  timers:\n","    learn_throughput: 1561.133\n","    learn_time_ms: 2562.242\n","    load_throughput: 8835228.817\n","    load_time_ms: 0.453\n","    sample_throughput: 525.455\n","    sample_time_ms: 7612.447\n","    update_time_ms: 3.008\n","  timestamp: 1649864072\n","  timesteps_since_restore: 528000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 528000\n","  training_iteration: 132\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:34:34 (running for 00:16:44.21)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   132</td><td style=\"text-align: right;\">         976.047</td><td style=\"text-align: right;\">528000</td><td style=\"text-align: right;\">-422.667</td><td style=\"text-align: right;\">            -111.893</td><td style=\"text-align: right;\">          -1109.99  </td><td style=\"text-align: right;\">            142.98</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         966.418</td><td style=\"text-align: right;\">352000</td><td style=\"text-align: right;\">  53.952</td><td style=\"text-align: right;\">             209.545</td><td style=\"text-align: right;\">           -156.235 </td><td style=\"text-align: right;\">            552.05</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         964.59 </td><td style=\"text-align: right;\">436000</td><td style=\"text-align: right;\"> 270.033</td><td style=\"text-align: right;\">             325.374</td><td style=\"text-align: right;\">             34.6274</td><td style=\"text-align: right;\">            234.22</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 356000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-34-34\n","  done: false\n","  episode_len_mean: 572.88\n","  episode_media: {}\n","  episode_reward_max: 208.11565379471324\n","  episode_reward_mean: 55.53039015205325\n","  episode_reward_min: -156.235027916002\n","  episodes_this_iter: 6\n","  episodes_total: 1020\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8333927989006042\n","          entropy_coeff: 0.0\n","          kl: 0.012864126823842525\n","          model: {}\n","          policy_loss: -0.045276496559381485\n","          total_loss: 140.7509765625\n","          vf_explained_var: 0.8048684000968933\n","          vf_loss: 140.78323364257812\n","    num_agent_steps_sampled: 356000\n","    num_agent_steps_trained: 356000\n","    num_steps_sampled: 356000\n","    num_steps_trained: 356000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 89\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.472222222222223\n","    ram_util_percent: 15.699999999999998\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07406784958008475\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1367597189002627\n","    mean_inference_ms: 0.769369893367998\n","    mean_raw_obs_processing_ms: 0.11257380046344352\n","  time_since_restore: 978.8306987285614\n","  time_this_iter_s: 12.412997722625732\n","  time_total_s: 978.8306987285614\n","  timers:\n","    learn_throughput: 1603.79\n","    learn_time_ms: 2494.092\n","    load_throughput: 8377716.968\n","    load_time_ms: 0.477\n","    sample_throughput: 349.864\n","    sample_time_ms: 11433.018\n","    update_time_ms: 2.805\n","  timestamp: 1649864074\n","  timesteps_since_restore: 356000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 356000\n","  training_iteration: 89\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 440000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-34-35\n","  done: false\n","  episode_len_mean: 234.19\n","  episode_media: {}\n","  episode_reward_max: 325.3744083682052\n","  episode_reward_mean: 273.02197214743404\n","  episode_reward_min: 86.55359776063958\n","  episodes_this_iter: 19\n","  episodes_total: 1663\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5790299773216248\n","          entropy_coeff: 0.0\n","          kl: 0.006094228010624647\n","          model: {}\n","          policy_loss: -0.011032863520085812\n","          total_loss: 70.80194854736328\n","          vf_explained_var: 0.7286277413368225\n","          vf_loss: 70.81182861328125\n","    num_agent_steps_sampled: 440000\n","    num_agent_steps_trained: 440000\n","    num_steps_sampled: 440000\n","    num_steps_trained: 440000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 110\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.783333333333333\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07495653288958382\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.621639552362184\n","    mean_inference_ms: 0.7601967284875515\n","    mean_raw_obs_processing_ms: 0.11277295826194074\n","  time_since_restore: 972.5383541584015\n","  time_this_iter_s: 7.947988033294678\n","  time_total_s: 972.5383541584015\n","  timers:\n","    learn_throughput: 1600.382\n","    learn_time_ms: 2499.403\n","    load_throughput: 8392384.573\n","    load_time_ms: 0.477\n","    sample_throughput: 487.198\n","    sample_time_ms: 8210.217\n","    update_time_ms: 2.752\n","  timestamp: 1649864075\n","  timesteps_since_restore: 440000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 440000\n","  training_iteration: 110\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:34:39 (running for 00:16:49.95)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   132</td><td style=\"text-align: right;\">         976.047</td><td style=\"text-align: right;\">528000</td><td style=\"text-align: right;\">-422.667 </td><td style=\"text-align: right;\">            -111.893</td><td style=\"text-align: right;\">          -1109.99  </td><td style=\"text-align: right;\">            142.98</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         978.831</td><td style=\"text-align: right;\">356000</td><td style=\"text-align: right;\">  55.5304</td><td style=\"text-align: right;\">             208.116</td><td style=\"text-align: right;\">           -156.235 </td><td style=\"text-align: right;\">            572.88</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   110</td><td style=\"text-align: right;\">         972.538</td><td style=\"text-align: right;\">440000</td><td style=\"text-align: right;\"> 273.022 </td><td style=\"text-align: right;\">             325.374</td><td style=\"text-align: right;\">             86.5536</td><td style=\"text-align: right;\">            234.19</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 532000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-34-40\n","  done: false\n","  episode_len_mean: 142.2\n","  episode_media: {}\n","  episode_reward_max: -110.73388582442949\n","  episode_reward_mean: -403.9706049226989\n","  episode_reward_min: -1109.9915498354267\n","  episodes_this_iter: 30\n","  episodes_total: 4622\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 10758045696.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.3167288899421692\n","          entropy_coeff: 0.0\n","          kl: 0.08595574647188187\n","          model: {}\n","          policy_loss: 0.019039534032344818\n","          total_loss: 924717184.0\n","          vf_explained_var: 0.4035486578941345\n","          vf_loss: 1349.79833984375\n","    num_agent_steps_sampled: 532000\n","    num_agent_steps_trained: 532000\n","    num_steps_sampled: 532000\n","    num_steps_trained: 532000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 133\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.727272727272727\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0705007324144159\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2846469994205334\n","    mean_inference_ms: 0.7268829824463254\n","    mean_raw_obs_processing_ms: 0.11270390929547112\n","  time_since_restore: 983.6833209991455\n","  time_this_iter_s: 7.636481285095215\n","  time_total_s: 983.6833209991455\n","  timers:\n","    learn_throughput: 1555.732\n","    learn_time_ms: 2571.137\n","    load_throughput: 8730857.619\n","    load_time_ms: 0.458\n","    sample_throughput: 525.419\n","    sample_time_ms: 7612.974\n","    update_time_ms: 2.98\n","  timestamp: 1649864080\n","  timesteps_since_restore: 532000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 532000\n","  training_iteration: 133\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 444000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-34-43\n","  done: false\n","  episode_len_mean: 232.44\n","  episode_media: {}\n","  episode_reward_max: 325.3744083682052\n","  episode_reward_mean: 272.10592964347745\n","  episode_reward_min: 86.55359776063958\n","  episodes_this_iter: 14\n","  episodes_total: 1677\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6203184127807617\n","          entropy_coeff: 0.0\n","          kl: 0.0063247219659388065\n","          model: {}\n","          policy_loss: -0.005500808358192444\n","          total_loss: 242.85321044921875\n","          vf_explained_var: 0.5345813632011414\n","          vf_loss: 242.85751342773438\n","    num_agent_steps_sampled: 444000\n","    num_agent_steps_trained: 444000\n","    num_steps_sampled: 444000\n","    num_steps_trained: 444000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 111\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.154545454545454\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0749547631894931\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6204531339547217\n","    mean_inference_ms: 0.7602087858380253\n","    mean_raw_obs_processing_ms: 0.11276946141692112\n","  time_since_restore: 980.8062407970428\n","  time_this_iter_s: 8.267886638641357\n","  time_total_s: 980.8062407970428\n","  timers:\n","    learn_throughput: 1599.704\n","    learn_time_ms: 2500.463\n","    load_throughput: 8628479.737\n","    load_time_ms: 0.464\n","    sample_throughput: 490.405\n","    sample_time_ms: 8156.517\n","    update_time_ms: 2.737\n","  timestamp: 1649864083\n","  timesteps_since_restore: 444000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 444000\n","  training_iteration: 111\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:34:44 (running for 00:16:55.18)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   133</td><td style=\"text-align: right;\">         983.683</td><td style=\"text-align: right;\">532000</td><td style=\"text-align: right;\">-403.971 </td><td style=\"text-align: right;\">            -110.734</td><td style=\"text-align: right;\">          -1109.99  </td><td style=\"text-align: right;\">            142.2 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         978.831</td><td style=\"text-align: right;\">356000</td><td style=\"text-align: right;\">  55.5304</td><td style=\"text-align: right;\">             208.116</td><td style=\"text-align: right;\">           -156.235 </td><td style=\"text-align: right;\">            572.88</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         980.806</td><td style=\"text-align: right;\">444000</td><td style=\"text-align: right;\"> 272.106 </td><td style=\"text-align: right;\">             325.374</td><td style=\"text-align: right;\">             86.5536</td><td style=\"text-align: right;\">            232.44</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 360000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-34-45\n","  done: false\n","  episode_len_mean: 577.82\n","  episode_media: {}\n","  episode_reward_max: 208.11565379471324\n","  episode_reward_mean: 57.875962434432786\n","  episode_reward_min: -156.235027916002\n","  episodes_this_iter: 7\n","  episodes_total: 1027\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8477121591567993\n","          entropy_coeff: 0.0\n","          kl: 0.008502359502017498\n","          model: {}\n","          policy_loss: -0.0564228855073452\n","          total_loss: 262.2131652832031\n","          vf_explained_var: 0.7327468991279602\n","          vf_loss: 262.260986328125\n","    num_agent_steps_sampled: 360000\n","    num_agent_steps_trained: 360000\n","    num_steps_sampled: 360000\n","    num_steps_trained: 360000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 90\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.1375\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07406518483573044\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1380574155260497\n","    mean_inference_ms: 0.769429198479595\n","    mean_raw_obs_processing_ms: 0.1125668312741328\n","  time_since_restore: 990.4628756046295\n","  time_this_iter_s: 11.632176876068115\n","  time_total_s: 990.4628756046295\n","  timers:\n","    learn_throughput: 1606.336\n","    learn_time_ms: 2490.139\n","    load_throughput: 8156950.603\n","    load_time_ms: 0.49\n","    sample_throughput: 350.676\n","    sample_time_ms: 11406.552\n","    update_time_ms: 2.792\n","  timestamp: 1649864085\n","  timesteps_since_restore: 360000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 360000\n","  training_iteration: 90\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 536000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-34-48\n","  done: false\n","  episode_len_mean: 136.78\n","  episode_media: {}\n","  episode_reward_max: -110.73388582442949\n","  episode_reward_mean: -397.81711197840866\n","  episode_reward_min: -1085.3120768417511\n","  episodes_this_iter: 30\n","  episodes_total: 4652\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 16137068544.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.3251112997531891\n","          entropy_coeff: 0.0\n","          kl: 0.048884905874729156\n","          model: {}\n","          policy_loss: 0.015666330233216286\n","          total_loss: 788860288.0\n","          vf_explained_var: 0.6809226870536804\n","          vf_loss: 1214.5677490234375\n","    num_agent_steps_sampled: 536000\n","    num_agent_steps_trained: 536000\n","    num_steps_sampled: 536000\n","    num_steps_trained: 536000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 134\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.0\n","    ram_util_percent: 15.699999999999998\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07050739431487575\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.28506205384084393\n","    mean_inference_ms: 0.726969278937244\n","    mean_raw_obs_processing_ms: 0.11271005218951873\n","  time_since_restore: 991.2613017559052\n","  time_this_iter_s: 7.5779807567596436\n","  time_total_s: 991.2613017559052\n","  timers:\n","    learn_throughput: 1556.038\n","    learn_time_ms: 2570.632\n","    load_throughput: 8800469.996\n","    load_time_ms: 0.455\n","    sample_throughput: 523.614\n","    sample_time_ms: 7639.221\n","    update_time_ms: 2.994\n","  timestamp: 1649864088\n","  timesteps_since_restore: 536000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 536000\n","  training_iteration: 134\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:34:50 (running for 00:17:00.49)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   134</td><td style=\"text-align: right;\">         991.261</td><td style=\"text-align: right;\">536000</td><td style=\"text-align: right;\">-397.817</td><td style=\"text-align: right;\">            -110.734</td><td style=\"text-align: right;\">          -1085.31  </td><td style=\"text-align: right;\">            136.78</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         990.463</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  57.876</td><td style=\"text-align: right;\">             208.116</td><td style=\"text-align: right;\">           -156.235 </td><td style=\"text-align: right;\">            577.82</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         980.806</td><td style=\"text-align: right;\">444000</td><td style=\"text-align: right;\"> 272.106</td><td style=\"text-align: right;\">             325.374</td><td style=\"text-align: right;\">             86.5536</td><td style=\"text-align: right;\">            232.44</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 448000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-34-52\n","  done: false\n","  episode_len_mean: 247.33\n","  episode_media: {}\n","  episode_reward_max: 322.52988145225027\n","  episode_reward_mean: 270.09580518409723\n","  episode_reward_min: 124.83471892321154\n","  episodes_this_iter: 16\n","  episodes_total: 1693\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6308391690254211\n","          entropy_coeff: 0.0\n","          kl: 0.010052445344626904\n","          model: {}\n","          policy_loss: -0.010949325747787952\n","          total_loss: 156.0379638671875\n","          vf_explained_var: 0.6097835898399353\n","          vf_loss: 156.04701232910156\n","    num_agent_steps_sampled: 448000\n","    num_agent_steps_trained: 448000\n","    num_steps_sampled: 448000\n","    num_steps_trained: 448000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 112\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.558333333333332\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07495461274326033\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6192545218880728\n","    mean_inference_ms: 0.7602180059350653\n","    mean_raw_obs_processing_ms: 0.11276607920707363\n","  time_since_restore: 989.1397078037262\n","  time_this_iter_s: 8.33346700668335\n","  time_total_s: 989.1397078037262\n","  timers:\n","    learn_throughput: 1600.879\n","    learn_time_ms: 2498.628\n","    load_throughput: 8235833.292\n","    load_time_ms: 0.486\n","    sample_throughput: 489.117\n","    sample_time_ms: 8178.001\n","    update_time_ms: 2.675\n","  timestamp: 1649864092\n","  timesteps_since_restore: 448000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 448000\n","  training_iteration: 112\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:34:55 (running for 00:17:05.54)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   134</td><td style=\"text-align: right;\">         991.261</td><td style=\"text-align: right;\">536000</td><td style=\"text-align: right;\">-397.817</td><td style=\"text-align: right;\">            -110.734</td><td style=\"text-align: right;\">           -1085.31 </td><td style=\"text-align: right;\">            136.78</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         990.463</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  57.876</td><td style=\"text-align: right;\">             208.116</td><td style=\"text-align: right;\">            -156.235</td><td style=\"text-align: right;\">            577.82</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   112</td><td style=\"text-align: right;\">         989.14 </td><td style=\"text-align: right;\">448000</td><td style=\"text-align: right;\"> 270.096</td><td style=\"text-align: right;\">             322.53 </td><td style=\"text-align: right;\">             124.835</td><td style=\"text-align: right;\">            247.33</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 540000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-34-56\n","  done: false\n","  episode_len_mean: 141.51\n","  episode_media: {}\n","  episode_reward_max: -110.73388582442949\n","  episode_reward_mean: -397.05994391736976\n","  episode_reward_min: -1085.3120768417511\n","  episodes_this_iter: 23\n","  episodes_total: 4675\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 24205602816.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.4239884316921234\n","          entropy_coeff: 0.0\n","          kl: 0.05165752023458481\n","          model: {}\n","          policy_loss: 0.014975196681916714\n","          total_loss: 1250402816.0\n","          vf_explained_var: 0.39665544033050537\n","          vf_loss: 1387.154052734375\n","    num_agent_steps_sampled: 540000\n","    num_agent_steps_trained: 540000\n","    num_steps_sampled: 540000\n","    num_steps_trained: 540000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 135\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.325000000000001\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.070510927890593\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.28541624257766474\n","    mean_inference_ms: 0.7270102961292997\n","    mean_raw_obs_processing_ms: 0.11271131867912362\n","  time_since_restore: 999.0553388595581\n","  time_this_iter_s: 7.794037103652954\n","  time_total_s: 999.0553388595581\n","  timers:\n","    learn_throughput: 1558.023\n","    learn_time_ms: 2567.357\n","    load_throughput: 9166875.751\n","    load_time_ms: 0.436\n","    sample_throughput: 522.395\n","    sample_time_ms: 7657.037\n","    update_time_ms: 2.989\n","  timestamp: 1649864096\n","  timesteps_since_restore: 540000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 540000\n","  training_iteration: 135\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 364000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-34-56\n","  done: false\n","  episode_len_mean: 570.3\n","  episode_media: {}\n","  episode_reward_max: 208.11565379471324\n","  episode_reward_mean: 57.9168784813157\n","  episode_reward_min: -156.235027916002\n","  episodes_this_iter: 8\n","  episodes_total: 1035\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8695788979530334\n","          entropy_coeff: 0.0\n","          kl: 0.01712212897837162\n","          model: {}\n","          policy_loss: -0.052857544273138046\n","          total_loss: 367.6026306152344\n","          vf_explained_var: 0.7879244685173035\n","          vf_loss: 367.63818359375\n","    num_agent_steps_sampled: 364000\n","    num_agent_steps_trained: 364000\n","    num_steps_sampled: 364000\n","    num_steps_trained: 364000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 91\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.674999999999999\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07406089985597313\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1394758321006133\n","    mean_inference_ms: 0.7694791091264683\n","    mean_raw_obs_processing_ms: 0.11255587179932729\n","  time_since_restore: 1001.3920273780823\n","  time_this_iter_s: 10.929151773452759\n","  time_total_s: 1001.3920273780823\n","  timers:\n","    learn_throughput: 1602.633\n","    learn_time_ms: 2495.892\n","    load_throughput: 8013955.577\n","    load_time_ms: 0.499\n","    sample_throughput: 352.074\n","    sample_time_ms: 11361.263\n","    update_time_ms: 2.773\n","  timestamp: 1649864096\n","  timesteps_since_restore: 364000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 364000\n","  training_iteration: 91\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 452000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-35-00\n","  done: false\n","  episode_len_mean: 254.02\n","  episode_media: {}\n","  episode_reward_max: 322.52988145225027\n","  episode_reward_mean: 269.0430957047193\n","  episode_reward_min: 124.83471892321154\n","  episodes_this_iter: 11\n","  episodes_total: 1704\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6099206805229187\n","          entropy_coeff: 0.0\n","          kl: 0.00911923311650753\n","          model: {}\n","          policy_loss: 0.009344878606498241\n","          total_loss: 567.6382446289062\n","          vf_explained_var: 0.46938952803611755\n","          vf_loss: 567.6271362304688\n","    num_agent_steps_sampled: 452000\n","    num_agent_steps_trained: 452000\n","    num_steps_sampled: 452000\n","    num_steps_trained: 452000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 113\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.508333333333333\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07495704941406714\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6183486297740375\n","    mean_inference_ms: 0.7602371862586178\n","    mean_raw_obs_processing_ms: 0.11276627556812802\n","  time_since_restore: 997.5055584907532\n","  time_this_iter_s: 8.365850687026978\n","  time_total_s: 997.5055584907532\n","  timers:\n","    learn_throughput: 1607.641\n","    learn_time_ms: 2488.118\n","    load_throughput: 8512464.356\n","    load_time_ms: 0.47\n","    sample_throughput: 486.457\n","    sample_time_ms: 8222.716\n","    update_time_ms: 2.676\n","  timestamp: 1649864100\n","  timesteps_since_restore: 452000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 452000\n","  training_iteration: 113\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:35:00 (running for 00:17:10.95)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   135</td><td style=\"text-align: right;\">         999.055</td><td style=\"text-align: right;\">540000</td><td style=\"text-align: right;\">-397.06  </td><td style=\"text-align: right;\">            -110.734</td><td style=\"text-align: right;\">           -1085.31 </td><td style=\"text-align: right;\">            141.51</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">        1001.39 </td><td style=\"text-align: right;\">364000</td><td style=\"text-align: right;\">  57.9169</td><td style=\"text-align: right;\">             208.116</td><td style=\"text-align: right;\">            -156.235</td><td style=\"text-align: right;\">            570.3 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         997.506</td><td style=\"text-align: right;\">452000</td><td style=\"text-align: right;\"> 269.043 </td><td style=\"text-align: right;\">             322.53 </td><td style=\"text-align: right;\">             124.835</td><td style=\"text-align: right;\">            254.02</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 544000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-35-03\n","  done: false\n","  episode_len_mean: 149.1\n","  episode_media: {}\n","  episode_reward_max: -110.73388582442949\n","  episode_reward_mean: -411.4156804627386\n","  episode_reward_min: -1085.3120768417511\n","  episodes_this_iter: 24\n","  episodes_total: 4699\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 36308402176.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.3454355299472809\n","          entropy_coeff: 0.0\n","          kl: 0.11779524385929108\n","          model: {}\n","          policy_loss: 0.032116957008838654\n","          total_loss: 4276959488.0\n","          vf_explained_var: 0.4617662727832794\n","          vf_loss: 2507.17578125\n","    num_agent_steps_sampled: 544000\n","    num_agent_steps_trained: 544000\n","    num_steps_sampled: 544000\n","    num_steps_trained: 544000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 136\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.681818181818182\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07051438785709198\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.28595282852715476\n","    mean_inference_ms: 0.7270689873691494\n","    mean_raw_obs_processing_ms: 0.11271113610345138\n","  time_since_restore: 1006.8467364311218\n","  time_this_iter_s: 7.791397571563721\n","  time_total_s: 1006.8467364311218\n","  timers:\n","    learn_throughput: 1571.68\n","    learn_time_ms: 2545.047\n","    load_throughput: 9210153.711\n","    load_time_ms: 0.434\n","    sample_throughput: 518.281\n","    sample_time_ms: 7717.823\n","    update_time_ms: 2.939\n","  timestamp: 1649864103\n","  timesteps_since_restore: 544000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 544000\n","  training_iteration: 136\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:35:05 (running for 00:17:16.14)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   136</td><td style=\"text-align: right;\">        1006.85 </td><td style=\"text-align: right;\">544000</td><td style=\"text-align: right;\">-411.416 </td><td style=\"text-align: right;\">            -110.734</td><td style=\"text-align: right;\">           -1085.31 </td><td style=\"text-align: right;\">            149.1 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">        1001.39 </td><td style=\"text-align: right;\">364000</td><td style=\"text-align: right;\">  57.9169</td><td style=\"text-align: right;\">             208.116</td><td style=\"text-align: right;\">            -156.235</td><td style=\"text-align: right;\">            570.3 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         997.506</td><td style=\"text-align: right;\">452000</td><td style=\"text-align: right;\"> 269.043 </td><td style=\"text-align: right;\">             322.53 </td><td style=\"text-align: right;\">             124.835</td><td style=\"text-align: right;\">            254.02</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 368000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-35-07\n","  done: false\n","  episode_len_mean: 579.82\n","  episode_media: {}\n","  episode_reward_max: 208.11565379471324\n","  episode_reward_mean: 59.775463232664734\n","  episode_reward_min: -156.235027916002\n","  episodes_this_iter: 10\n","  episodes_total: 1045\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.867480456829071\n","          entropy_coeff: 0.0\n","          kl: 0.015050871297717094\n","          model: {}\n","          policy_loss: -0.052475567907094955\n","          total_loss: 305.50079345703125\n","          vf_explained_var: 0.8518734574317932\n","          vf_loss: 305.53802490234375\n","    num_agent_steps_sampled: 368000\n","    num_agent_steps_trained: 368000\n","    num_steps_sampled: 368000\n","    num_steps_trained: 368000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 92\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.866666666666667\n","    ram_util_percent: 15.699999999999994\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07405786201819291\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.140951876883638\n","    mean_inference_ms: 0.7695412017679993\n","    mean_raw_obs_processing_ms: 0.11254109356514228\n","  time_since_restore: 1011.9073297977448\n","  time_this_iter_s: 10.515302419662476\n","  time_total_s: 1011.9073297977448\n","  timers:\n","    learn_throughput: 1605.671\n","    learn_time_ms: 2491.17\n","    load_throughput: 7793206.986\n","    load_time_ms: 0.513\n","    sample_throughput: 353.228\n","    sample_time_ms: 11324.119\n","    update_time_ms: 2.761\n","  timestamp: 1649864107\n","  timesteps_since_restore: 368000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 368000\n","  training_iteration: 92\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 456000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-35-08\n","  done: false\n","  episode_len_mean: 250.16\n","  episode_media: {}\n","  episode_reward_max: 322.52988145225027\n","  episode_reward_mean: 267.43993070572805\n","  episode_reward_min: 28.799625333337985\n","  episodes_this_iter: 17\n","  episodes_total: 1721\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5697047114372253\n","          entropy_coeff: 0.0\n","          kl: 0.007774197496473789\n","          model: {}\n","          policy_loss: -0.01099412702023983\n","          total_loss: 589.8157958984375\n","          vf_explained_var: 0.5033001899719238\n","          vf_loss: 589.8252563476562\n","    num_agent_steps_sampled: 456000\n","    num_agent_steps_trained: 456000\n","    num_steps_sampled: 456000\n","    num_steps_trained: 456000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 114\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.79166666666667\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07495853960960538\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6169606823462722\n","    mean_inference_ms: 0.7602183070816606\n","    mean_raw_obs_processing_ms: 0.11276284165627005\n","  time_since_restore: 1005.5228533744812\n","  time_this_iter_s: 8.017294883728027\n","  time_total_s: 1005.5228533744812\n","  timers:\n","    learn_throughput: 1611.025\n","    learn_time_ms: 2482.891\n","    load_throughput: 8644039.363\n","    load_time_ms: 0.463\n","    sample_throughput: 485.176\n","    sample_time_ms: 8244.429\n","    update_time_ms: 2.675\n","  timestamp: 1649864108\n","  timesteps_since_restore: 456000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 456000\n","  training_iteration: 114\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 548000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-35-11\n","  done: false\n","  episode_len_mean: 151.93\n","  episode_media: {}\n","  episode_reward_max: -161.96811603404035\n","  episode_reward_mean: -397.43210064833164\n","  episode_reward_min: -1076.0855187399702\n","  episodes_this_iter: 29\n","  episodes_total: 4728\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 54462607360.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.37836194038391113\n","          entropy_coeff: 0.0\n","          kl: 0.10588463395833969\n","          model: {}\n","          policy_loss: 0.021782169118523598\n","          total_loss: 5766754816.0\n","          vf_explained_var: 0.38239285349845886\n","          vf_loss: 1235.340576171875\n","    num_agent_steps_sampled: 548000\n","    num_agent_steps_trained: 548000\n","    num_steps_sampled: 548000\n","    num_steps_trained: 548000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 137\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.045454545454543\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07052173944695264\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2865981910011259\n","    mean_inference_ms: 0.7271903060039313\n","    mean_raw_obs_processing_ms: 0.11271522515510769\n","  time_since_restore: 1014.4184548854828\n","  time_this_iter_s: 7.571718454360962\n","  time_total_s: 1014.4184548854828\n","  timers:\n","    learn_throughput: 1580.137\n","    learn_time_ms: 2531.426\n","    load_throughput: 9049199.569\n","    load_time_ms: 0.442\n","    sample_throughput: 516.94\n","    sample_time_ms: 7737.837\n","    update_time_ms: 2.913\n","  timestamp: 1649864111\n","  timesteps_since_restore: 548000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 548000\n","  training_iteration: 137\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:35:11 (running for 00:17:21.74)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   137</td><td style=\"text-align: right;\">         1014.42</td><td style=\"text-align: right;\">548000</td><td style=\"text-align: right;\">-397.432 </td><td style=\"text-align: right;\">            -161.968</td><td style=\"text-align: right;\">          -1076.09  </td><td style=\"text-align: right;\">            151.93</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         1011.91</td><td style=\"text-align: right;\">368000</td><td style=\"text-align: right;\">  59.7755</td><td style=\"text-align: right;\">             208.116</td><td style=\"text-align: right;\">           -156.235 </td><td style=\"text-align: right;\">            579.82</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   114</td><td style=\"text-align: right;\">         1005.52</td><td style=\"text-align: right;\">456000</td><td style=\"text-align: right;\"> 267.44  </td><td style=\"text-align: right;\">             322.53 </td><td style=\"text-align: right;\">             28.7996</td><td style=\"text-align: right;\">            250.16</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:35:16 (running for 00:17:26.75)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   137</td><td style=\"text-align: right;\">         1014.42</td><td style=\"text-align: right;\">548000</td><td style=\"text-align: right;\">-397.432 </td><td style=\"text-align: right;\">            -161.968</td><td style=\"text-align: right;\">          -1076.09  </td><td style=\"text-align: right;\">            151.93</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         1011.91</td><td style=\"text-align: right;\">368000</td><td style=\"text-align: right;\">  59.7755</td><td style=\"text-align: right;\">             208.116</td><td style=\"text-align: right;\">           -156.235 </td><td style=\"text-align: right;\">            579.82</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   114</td><td style=\"text-align: right;\">         1005.52</td><td style=\"text-align: right;\">456000</td><td style=\"text-align: right;\"> 267.44  </td><td style=\"text-align: right;\">             322.53 </td><td style=\"text-align: right;\">             28.7996</td><td style=\"text-align: right;\">            250.16</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 460000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-35-17\n","  done: false\n","  episode_len_mean: 259.02\n","  episode_media: {}\n","  episode_reward_max: 312.3768352765343\n","  episode_reward_mean: 265.10453813680255\n","  episode_reward_min: 28.799625333337985\n","  episodes_this_iter: 15\n","  episodes_total: 1736\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.551710844039917\n","          entropy_coeff: 0.0\n","          kl: 0.007620092481374741\n","          model: {}\n","          policy_loss: -0.011871475726366043\n","          total_loss: 322.23736572265625\n","          vf_explained_var: 0.5285005569458008\n","          vf_loss: 322.2477722167969\n","    num_agent_steps_sampled: 460000\n","    num_agent_steps_trained: 460000\n","    num_steps_sampled: 460000\n","    num_steps_trained: 460000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 115\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.824999999999998\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07495497618463016\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6158285379579052\n","    mean_inference_ms: 0.7601360695687263\n","    mean_raw_obs_processing_ms: 0.11275240550618694\n","  time_since_restore: 1013.796633720398\n","  time_this_iter_s: 8.273780345916748\n","  time_total_s: 1013.796633720398\n","  timers:\n","    learn_throughput: 1613.198\n","    learn_time_ms: 2479.547\n","    load_throughput: 8801393.348\n","    load_time_ms: 0.454\n","    sample_throughput: 482.683\n","    sample_time_ms: 8287.015\n","    update_time_ms: 2.689\n","  timestamp: 1649864117\n","  timesteps_since_restore: 460000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 460000\n","  training_iteration: 115\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 372000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-35-18\n","  done: false\n","  episode_len_mean: 546.69\n","  episode_media: {}\n","  episode_reward_max: 208.11565379471324\n","  episode_reward_mean: 56.30997088695901\n","  episode_reward_min: -156.235027916002\n","  episodes_this_iter: 10\n","  episodes_total: 1055\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8594216108322144\n","          entropy_coeff: 0.0\n","          kl: 0.015821311622858047\n","          model: {}\n","          policy_loss: -0.057746101170778275\n","          total_loss: 378.7688293457031\n","          vf_explained_var: 0.5557071566581726\n","          vf_loss: 378.810546875\n","    num_agent_steps_sampled: 372000\n","    num_agent_steps_trained: 372000\n","    num_steps_sampled: 372000\n","    num_steps_trained: 372000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 93\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.168750000000001\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07405580531075523\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1421958618436825\n","    mean_inference_ms: 0.7696066970706233\n","    mean_raw_obs_processing_ms: 0.11252836711383907\n","  time_since_restore: 1022.7243859767914\n","  time_this_iter_s: 10.81705617904663\n","  time_total_s: 1022.7243859767914\n","  timers:\n","    learn_throughput: 1603.146\n","    learn_time_ms: 2495.094\n","    load_throughput: 7794293.148\n","    load_time_ms: 0.513\n","    sample_throughput: 354.658\n","    sample_time_ms: 11278.484\n","    update_time_ms: 2.757\n","  timestamp: 1649864118\n","  timesteps_since_restore: 372000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 372000\n","  training_iteration: 93\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 552000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-35-19\n","  done: false\n","  episode_len_mean: 153.28\n","  episode_media: {}\n","  episode_reward_max: -161.96811603404035\n","  episode_reward_mean: -394.4670065712661\n","  episode_reward_min: -1076.0855187399702\n","  episodes_this_iter: 28\n","  episodes_total: 4756\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 81693908992.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.3932152986526489\n","          entropy_coeff: 0.0\n","          kl: 0.06882470101118088\n","          model: {}\n","          policy_loss: 0.0174197219312191\n","          total_loss: 5622559232.0\n","          vf_explained_var: 0.6385740637779236\n","          vf_loss: 815.4881591796875\n","    num_agent_steps_sampled: 552000\n","    num_agent_steps_trained: 552000\n","    num_steps_sampled: 552000\n","    num_steps_trained: 552000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 138\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.181818181818185\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07052894619564398\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.28724332510565864\n","    mean_inference_ms: 0.7272965277252342\n","    mean_raw_obs_processing_ms: 0.11271910400935671\n","  time_since_restore: 1022.1527490615845\n","  time_this_iter_s: 7.734294176101685\n","  time_total_s: 1022.1527490615845\n","  timers:\n","    learn_throughput: 1583.485\n","    learn_time_ms: 2526.074\n","    load_throughput: 8879182.853\n","    load_time_ms: 0.45\n","    sample_throughput: 518.547\n","    sample_time_ms: 7713.869\n","    update_time_ms: 2.901\n","  timestamp: 1649864119\n","  timesteps_since_restore: 552000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 552000\n","  training_iteration: 138\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:35:22 (running for 00:17:32.60)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   138</td><td style=\"text-align: right;\">         1022.15</td><td style=\"text-align: right;\">552000</td><td style=\"text-align: right;\">-394.467</td><td style=\"text-align: right;\">            -161.968</td><td style=\"text-align: right;\">          -1076.09  </td><td style=\"text-align: right;\">            153.28</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         1022.72</td><td style=\"text-align: right;\">372000</td><td style=\"text-align: right;\">  56.31 </td><td style=\"text-align: right;\">             208.116</td><td style=\"text-align: right;\">           -156.235 </td><td style=\"text-align: right;\">            546.69</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   115</td><td style=\"text-align: right;\">         1013.8 </td><td style=\"text-align: right;\">460000</td><td style=\"text-align: right;\"> 265.105</td><td style=\"text-align: right;\">             312.377</td><td style=\"text-align: right;\">             28.7996</td><td style=\"text-align: right;\">            259.02</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 464000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-35-25\n","  done: false\n","  episode_len_mean: 261.44\n","  episode_media: {}\n","  episode_reward_max: 312.3768352765343\n","  episode_reward_mean: 262.82771723474235\n","  episode_reward_min: 28.799625333337985\n","  episodes_this_iter: 16\n","  episodes_total: 1752\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5875627398490906\n","          entropy_coeff: 0.0\n","          kl: 0.007102117408066988\n","          model: {}\n","          policy_loss: 0.0009215730242431164\n","          total_loss: 85.32743072509766\n","          vf_explained_var: 0.6637908220291138\n","          vf_loss: 85.32514953613281\n","    num_agent_steps_sampled: 464000\n","    num_agent_steps_trained: 464000\n","    num_steps_sampled: 464000\n","    num_steps_trained: 464000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 116\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.391666666666667\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07494941610173181\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6148004721097418\n","    mean_inference_ms: 0.7600124461627658\n","    mean_raw_obs_processing_ms: 0.11273555926927736\n","  time_since_restore: 1022.3390383720398\n","  time_this_iter_s: 8.542404651641846\n","  time_total_s: 1022.3390383720398\n","  timers:\n","    learn_throughput: 1617.139\n","    learn_time_ms: 2473.505\n","    load_throughput: 8812025.842\n","    load_time_ms: 0.454\n","    sample_throughput: 479.668\n","    sample_time_ms: 8339.101\n","    update_time_ms: 2.728\n","  timestamp: 1649864125\n","  timesteps_since_restore: 464000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 464000\n","  training_iteration: 116\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 556000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-35-26\n","  done: false\n","  episode_len_mean: 147.1\n","  episode_media: {}\n","  episode_reward_max: -191.26399829449235\n","  episode_reward_mean: -404.61226072106786\n","  episode_reward_min: -1008.5225899970284\n","  episodes_this_iter: 27\n","  episodes_total: 4783\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 122540867584.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.3488023281097412\n","          entropy_coeff: 0.0\n","          kl: 0.09021073579788208\n","          model: {}\n","          policy_loss: 0.029866542667150497\n","          total_loss: 11054503936.0\n","          vf_explained_var: 0.6037275791168213\n","          vf_loss: 1935.7305908203125\n","    num_agent_steps_sampled: 556000\n","    num_agent_steps_trained: 556000\n","    num_steps_sampled: 556000\n","    num_steps_trained: 556000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 139\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.110000000000001\n","    ram_util_percent: 15.699999999999998\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07052981899045388\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.287734753262463\n","    mean_inference_ms: 0.727325709949946\n","    mean_raw_obs_processing_ms: 0.1127156263468656\n","  time_since_restore: 1029.7143445014954\n","  time_this_iter_s: 7.561595439910889\n","  time_total_s: 1029.7143445014954\n","  timers:\n","    learn_throughput: 1587.702\n","    learn_time_ms: 2519.364\n","    load_throughput: 8500388.104\n","    load_time_ms: 0.471\n","    sample_throughput: 518.395\n","    sample_time_ms: 7716.118\n","    update_time_ms: 2.846\n","  timestamp: 1649864126\n","  timesteps_since_restore: 556000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 556000\n","  training_iteration: 139\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:35:27 (running for 00:17:38.11)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   139</td><td style=\"text-align: right;\">         1029.71</td><td style=\"text-align: right;\">556000</td><td style=\"text-align: right;\">-404.612</td><td style=\"text-align: right;\">            -191.264</td><td style=\"text-align: right;\">          -1008.52  </td><td style=\"text-align: right;\">            147.1 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         1022.72</td><td style=\"text-align: right;\">372000</td><td style=\"text-align: right;\">  56.31 </td><td style=\"text-align: right;\">             208.116</td><td style=\"text-align: right;\">           -156.235 </td><td style=\"text-align: right;\">            546.69</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   116</td><td style=\"text-align: right;\">         1022.34</td><td style=\"text-align: right;\">464000</td><td style=\"text-align: right;\"> 262.828</td><td style=\"text-align: right;\">             312.377</td><td style=\"text-align: right;\">             28.7996</td><td style=\"text-align: right;\">            261.44</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 376000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-35-28\n","  done: false\n","  episode_len_mean: 551.44\n","  episode_media: {}\n","  episode_reward_max: 208.11565379471324\n","  episode_reward_mean: 53.09653674220196\n","  episode_reward_min: -211.0426676398177\n","  episodes_this_iter: 6\n","  episodes_total: 1061\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8695566058158875\n","          entropy_coeff: 0.0\n","          kl: 0.012682904489338398\n","          model: {}\n","          policy_loss: -0.037065472453832626\n","          total_loss: 319.8045349121094\n","          vf_explained_var: 0.7689096331596375\n","          vf_loss: 319.8287658691406\n","    num_agent_steps_sampled: 376000\n","    num_agent_steps_trained: 376000\n","    num_steps_sampled: 376000\n","    num_steps_trained: 376000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 94\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.078571428571427\n","    ram_util_percent: 15.699999999999994\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07405452881573787\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1426787091499018\n","    mean_inference_ms: 0.7696464562148576\n","    mean_raw_obs_processing_ms: 0.1125205135715262\n","  time_since_restore: 1033.1040215492249\n","  time_this_iter_s: 10.379635572433472\n","  time_total_s: 1033.1040215492249\n","  timers:\n","    learn_throughput: 1603.044\n","    learn_time_ms: 2495.253\n","    load_throughput: 7947144.143\n","    load_time_ms: 0.503\n","    sample_throughput: 357.115\n","    sample_time_ms: 11200.867\n","    update_time_ms: 2.818\n","  timestamp: 1649864128\n","  timesteps_since_restore: 376000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 376000\n","  training_iteration: 94\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:35:33 (running for 00:17:44.10)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   139</td><td style=\"text-align: right;\">         1029.71</td><td style=\"text-align: right;\">556000</td><td style=\"text-align: right;\">-404.612 </td><td style=\"text-align: right;\">            -191.264</td><td style=\"text-align: right;\">          -1008.52  </td><td style=\"text-align: right;\">            147.1 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         1033.1 </td><td style=\"text-align: right;\">376000</td><td style=\"text-align: right;\">  53.0965</td><td style=\"text-align: right;\">             208.116</td><td style=\"text-align: right;\">           -211.043 </td><td style=\"text-align: right;\">            551.44</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   116</td><td style=\"text-align: right;\">         1022.34</td><td style=\"text-align: right;\">464000</td><td style=\"text-align: right;\"> 262.828 </td><td style=\"text-align: right;\">             312.377</td><td style=\"text-align: right;\">             28.7996</td><td style=\"text-align: right;\">            261.44</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 468000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-35-34\n","  done: false\n","  episode_len_mean: 270.26\n","  episode_media: {}\n","  episode_reward_max: 312.3768352765343\n","  episode_reward_mean: 261.8110280321814\n","  episode_reward_min: 28.799625333337985\n","  episodes_this_iter: 15\n","  episodes_total: 1767\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5816015005111694\n","          entropy_coeff: 0.0\n","          kl: 0.007957191206514835\n","          model: {}\n","          policy_loss: -0.00784740224480629\n","          total_loss: 148.93846130371094\n","          vf_explained_var: 0.6123949289321899\n","          vf_loss: 148.94479370117188\n","    num_agent_steps_sampled: 468000\n","    num_agent_steps_trained: 468000\n","    num_steps_sampled: 468000\n","    num_steps_trained: 468000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 117\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.783333333333333\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.074945474097659\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6139347268046936\n","    mean_inference_ms: 0.7598968722084897\n","    mean_raw_obs_processing_ms: 0.11272120882691962\n","  time_since_restore: 1030.8670227527618\n","  time_this_iter_s: 8.527984380722046\n","  time_total_s: 1030.8670227527618\n","  timers:\n","    learn_throughput: 1631.044\n","    learn_time_ms: 2452.417\n","    load_throughput: 8785262.607\n","    load_time_ms: 0.455\n","    sample_throughput: 481.591\n","    sample_time_ms: 8305.808\n","    update_time_ms: 2.798\n","  timestamp: 1649864134\n","  timesteps_since_restore: 468000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 468000\n","  training_iteration: 117\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 560000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-35-34\n","  done: false\n","  episode_len_mean: 144.45\n","  episode_media: {}\n","  episode_reward_max: -157.2508365779761\n","  episode_reward_mean: -402.1577899103297\n","  episode_reward_min: -972.0753703714086\n","  episodes_this_iter: 28\n","  episodes_total: 4811\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 183811293184.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.34514427185058594\n","          entropy_coeff: 0.0\n","          kl: 0.1115904450416565\n","          model: {}\n","          policy_loss: 0.02599480003118515\n","          total_loss: 20511584256.0\n","          vf_explained_var: 0.6730718612670898\n","          vf_loss: 2407.45849609375\n","    num_agent_steps_sampled: 560000\n","    num_agent_steps_trained: 560000\n","    num_steps_sampled: 560000\n","    num_steps_trained: 560000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 140\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.950000000000001\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07052538323523146\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.288265136295365\n","    mean_inference_ms: 0.7272943980673887\n","    mean_raw_obs_processing_ms: 0.11270626433889194\n","  time_since_restore: 1037.498471736908\n","  time_this_iter_s: 7.784127235412598\n","  time_total_s: 1037.498471736908\n","  timers:\n","    learn_throughput: 1592.1\n","    learn_time_ms: 2512.406\n","    load_throughput: 8250007.868\n","    load_time_ms: 0.485\n","    sample_throughput: 517.056\n","    sample_time_ms: 7736.108\n","    update_time_ms: 2.747\n","  timestamp: 1649864134\n","  timesteps_since_restore: 560000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 560000\n","  training_iteration: 140\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:35:39 (running for 00:17:49.93)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   140</td><td style=\"text-align: right;\">         1037.5 </td><td style=\"text-align: right;\">560000</td><td style=\"text-align: right;\">-402.158 </td><td style=\"text-align: right;\">            -157.251</td><td style=\"text-align: right;\">           -972.075 </td><td style=\"text-align: right;\">            144.45</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         1033.1 </td><td style=\"text-align: right;\">376000</td><td style=\"text-align: right;\">  53.0965</td><td style=\"text-align: right;\">             208.116</td><td style=\"text-align: right;\">           -211.043 </td><td style=\"text-align: right;\">            551.44</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         1030.87</td><td style=\"text-align: right;\">468000</td><td style=\"text-align: right;\"> 261.811 </td><td style=\"text-align: right;\">             312.377</td><td style=\"text-align: right;\">             28.7996</td><td style=\"text-align: right;\">            270.26</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 380000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-35-39\n","  done: false\n","  episode_len_mean: 547.85\n","  episode_media: {}\n","  episode_reward_max: 206.6155081886272\n","  episode_reward_mean: 51.37377931243928\n","  episode_reward_min: -211.0426676398177\n","  episodes_this_iter: 8\n","  episodes_total: 1069\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8096837401390076\n","          entropy_coeff: 0.0\n","          kl: 0.012129722163081169\n","          model: {}\n","          policy_loss: -0.0328671969473362\n","          total_loss: 560.1083374023438\n","          vf_explained_var: 0.6084930896759033\n","          vf_loss: 560.12890625\n","    num_agent_steps_sampled: 380000\n","    num_agent_steps_trained: 380000\n","    num_steps_sampled: 380000\n","    num_steps_trained: 380000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 95\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.368749999999999\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07405284724950939\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1432602755598982\n","    mean_inference_ms: 0.7696836911949874\n","    mean_raw_obs_processing_ms: 0.11251043625048901\n","  time_since_restore: 1044.082509279251\n","  time_this_iter_s: 10.978487730026245\n","  time_total_s: 1044.082509279251\n","  timers:\n","    learn_throughput: 1611.607\n","    learn_time_ms: 2481.994\n","    load_throughput: 8245142.52\n","    load_time_ms: 0.485\n","    sample_throughput: 355.527\n","    sample_time_ms: 11250.893\n","    update_time_ms: 2.838\n","  timestamp: 1649864139\n","  timesteps_since_restore: 380000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 380000\n","  training_iteration: 95\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 564000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-35-42\n","  done: false\n","  episode_len_mean: 144.34\n","  episode_media: {}\n","  episode_reward_max: -157.2508365779761\n","  episode_reward_mean: -436.08763844811745\n","  episode_reward_min: -1210.9069264309587\n","  episodes_this_iter: 29\n","  episodes_total: 4840\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 275716931584.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.37927788496017456\n","          entropy_coeff: 0.0\n","          kl: 0.07372817397117615\n","          model: {}\n","          policy_loss: 0.02325555868446827\n","          total_loss: 20328103936.0\n","          vf_explained_var: 0.5658681392669678\n","          vf_loss: 1407.0760498046875\n","    num_agent_steps_sampled: 564000\n","    num_agent_steps_trained: 564000\n","    num_steps_sampled: 564000\n","    num_steps_trained: 564000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 141\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.918181818181818\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07051719650654842\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2888224288155874\n","    mean_inference_ms: 0.7272368518598554\n","    mean_raw_obs_processing_ms: 0.11269305169894166\n","  time_since_restore: 1045.2086308002472\n","  time_this_iter_s: 7.710159063339233\n","  time_total_s: 1045.2086308002472\n","  timers:\n","    learn_throughput: 1588.935\n","    learn_time_ms: 2517.409\n","    load_throughput: 8363100.543\n","    load_time_ms: 0.478\n","    sample_throughput: 520.01\n","    sample_time_ms: 7692.157\n","    update_time_ms: 2.755\n","  timestamp: 1649864142\n","  timesteps_since_restore: 564000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 564000\n","  training_iteration: 141\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 472000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-35-42\n","  done: false\n","  episode_len_mean: 261.5\n","  episode_media: {}\n","  episode_reward_max: 312.3768352765343\n","  episode_reward_mean: 264.2075944408325\n","  episode_reward_min: 28.799625333337985\n","  episodes_this_iter: 15\n","  episodes_total: 1782\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5994703769683838\n","          entropy_coeff: 0.0\n","          kl: 0.008050167001783848\n","          model: {}\n","          policy_loss: -0.0073769292794167995\n","          total_loss: 81.59567260742188\n","          vf_explained_var: 0.5499611496925354\n","          vf_loss: 81.60151672363281\n","    num_agent_steps_sampled: 472000\n","    num_agent_steps_trained: 472000\n","    num_steps_sampled: 472000\n","    num_steps_trained: 472000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 118\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.20833333333333\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07493949984274799\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6131148872186373\n","    mean_inference_ms: 0.7597445445943906\n","    mean_raw_obs_processing_ms: 0.112706382691735\n","  time_since_restore: 1039.2052748203278\n","  time_this_iter_s: 8.338252067565918\n","  time_total_s: 1039.2052748203278\n","  timers:\n","    learn_throughput: 1627.18\n","    learn_time_ms: 2458.241\n","    load_throughput: 8634696.861\n","    load_time_ms: 0.463\n","    sample_throughput: 481.594\n","    sample_time_ms: 8305.757\n","    update_time_ms: 2.795\n","  timestamp: 1649864142\n","  timesteps_since_restore: 472000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 472000\n","  training_iteration: 118\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:35:45 (running for 00:17:55.85)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   141</td><td style=\"text-align: right;\">         1045.21</td><td style=\"text-align: right;\">564000</td><td style=\"text-align: right;\">-436.088 </td><td style=\"text-align: right;\">            -157.251</td><td style=\"text-align: right;\">          -1210.91  </td><td style=\"text-align: right;\">            144.34</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         1044.08</td><td style=\"text-align: right;\">380000</td><td style=\"text-align: right;\">  51.3738</td><td style=\"text-align: right;\">             206.616</td><td style=\"text-align: right;\">           -211.043 </td><td style=\"text-align: right;\">            547.85</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   118</td><td style=\"text-align: right;\">         1039.21</td><td style=\"text-align: right;\">472000</td><td style=\"text-align: right;\"> 264.208 </td><td style=\"text-align: right;\">             312.377</td><td style=\"text-align: right;\">             28.7996</td><td style=\"text-align: right;\">            261.5 </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 568000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-35-50\n","  done: false\n","  episode_len_mean: 143.68\n","  episode_media: {}\n","  episode_reward_max: -157.2508365779761\n","  episode_reward_mean: -430.86520556133576\n","  episode_reward_min: -1210.9069264309587\n","  episodes_this_iter: 25\n","  episodes_total: 4865\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 413575413760.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.4355523884296417\n","          entropy_coeff: 0.0\n","          kl: 0.06738299131393433\n","          model: {}\n","          policy_loss: 0.023035144433379173\n","          total_loss: 27867953152.0\n","          vf_explained_var: 0.6137610673904419\n","          vf_loss: 1293.7830810546875\n","    num_agent_steps_sampled: 568000\n","    num_agent_steps_trained: 568000\n","    num_steps_sampled: 568000\n","    num_steps_trained: 568000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 142\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.41818181818182\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07050573155482995\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.28932711391177796\n","    mean_inference_ms: 0.7271462008988283\n","    mean_raw_obs_processing_ms: 0.1126740657462592\n","  time_since_restore: 1052.8568856716156\n","  time_this_iter_s: 7.648254871368408\n","  time_total_s: 1052.8568856716156\n","  timers:\n","    learn_throughput: 1583.518\n","    learn_time_ms: 2526.021\n","    load_throughput: 8051260.198\n","    load_time_ms: 0.497\n","    sample_throughput: 519.001\n","    sample_time_ms: 7707.107\n","    update_time_ms: 2.775\n","  timestamp: 1649864150\n","  timesteps_since_restore: 568000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 568000\n","  training_iteration: 142\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 384000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-35-51\n","  done: false\n","  episode_len_mean: 539.88\n","  episode_media: {}\n","  episode_reward_max: 254.37470392482837\n","  episode_reward_mean: 53.457812626240056\n","  episode_reward_min: -211.0426676398177\n","  episodes_this_iter: 8\n","  episodes_total: 1077\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8282656073570251\n","          entropy_coeff: 0.0\n","          kl: 0.013003084808588028\n","          model: {}\n","          policy_loss: -0.04005842283368111\n","          total_loss: 604.5260620117188\n","          vf_explained_var: 0.7102466821670532\n","          vf_loss: 604.552978515625\n","    num_agent_steps_sampled: 384000\n","    num_agent_steps_trained: 384000\n","    num_steps_sampled: 384000\n","    num_steps_trained: 384000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 96\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.443750000000001\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07405210329740677\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1438277320263404\n","    mean_inference_ms: 0.7697216691247573\n","    mean_raw_obs_processing_ms: 0.11250113564710518\n","  time_since_restore: 1055.3491489887238\n","  time_this_iter_s: 11.266639709472656\n","  time_total_s: 1055.3491489887238\n","  timers:\n","    learn_throughput: 1598.028\n","    learn_time_ms: 2503.085\n","    load_throughput: 8324509.279\n","    load_time_ms: 0.481\n","    sample_throughput: 358.038\n","    sample_time_ms: 11171.988\n","    update_time_ms: 2.831\n","  timestamp: 1649864151\n","  timesteps_since_restore: 384000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 384000\n","  training_iteration: 96\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:35:51 (running for 00:18:01.41)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   142</td><td style=\"text-align: right;\">         1052.86</td><td style=\"text-align: right;\">568000</td><td style=\"text-align: right;\">-430.865 </td><td style=\"text-align: right;\">            -157.251</td><td style=\"text-align: right;\">          -1210.91  </td><td style=\"text-align: right;\">            143.68</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         1055.35</td><td style=\"text-align: right;\">384000</td><td style=\"text-align: right;\">  53.4578</td><td style=\"text-align: right;\">             254.375</td><td style=\"text-align: right;\">           -211.043 </td><td style=\"text-align: right;\">            539.88</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   118</td><td style=\"text-align: right;\">         1039.21</td><td style=\"text-align: right;\">472000</td><td style=\"text-align: right;\"> 264.208 </td><td style=\"text-align: right;\">             312.377</td><td style=\"text-align: right;\">             28.7996</td><td style=\"text-align: right;\">            261.5 </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 476000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-35-51\n","  done: false\n","  episode_len_mean: 273.76\n","  episode_media: {}\n","  episode_reward_max: 312.3768352765343\n","  episode_reward_mean: 258.3958988817018\n","  episode_reward_min: -81.18577515756519\n","  episodes_this_iter: 14\n","  episodes_total: 1796\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5679223537445068\n","          entropy_coeff: 0.0\n","          kl: 0.0072738537564873695\n","          model: {}\n","          policy_loss: -0.012744387611746788\n","          total_loss: 707.477294921875\n","          vf_explained_var: 0.5994988679885864\n","          vf_loss: 707.4885864257812\n","    num_agent_steps_sampled: 476000\n","    num_agent_steps_trained: 476000\n","    num_steps_sampled: 476000\n","    num_steps_trained: 476000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 119\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.469230769230766\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07493316954112976\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6125179155360345\n","    mean_inference_ms: 0.7596005011376923\n","    mean_raw_obs_processing_ms: 0.1126918331713311\n","  time_since_restore: 1048.3091976642609\n","  time_this_iter_s: 9.103922843933105\n","  time_total_s: 1048.3091976642609\n","  timers:\n","    learn_throughput: 1612.967\n","    learn_time_ms: 2479.902\n","    load_throughput: 8277686.994\n","    load_time_ms: 0.483\n","    sample_throughput: 476.852\n","    sample_time_ms: 8388.339\n","    update_time_ms: 2.782\n","  timestamp: 1649864151\n","  timesteps_since_restore: 476000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 476000\n","  training_iteration: 119\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:35:56 (running for 00:18:07.00)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   142</td><td style=\"text-align: right;\">         1052.86</td><td style=\"text-align: right;\">568000</td><td style=\"text-align: right;\">-430.865 </td><td style=\"text-align: right;\">            -157.251</td><td style=\"text-align: right;\">          -1210.91  </td><td style=\"text-align: right;\">            143.68</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         1055.35</td><td style=\"text-align: right;\">384000</td><td style=\"text-align: right;\">  53.4578</td><td style=\"text-align: right;\">             254.375</td><td style=\"text-align: right;\">           -211.043 </td><td style=\"text-align: right;\">            539.88</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         1048.31</td><td style=\"text-align: right;\">476000</td><td style=\"text-align: right;\"> 258.396 </td><td style=\"text-align: right;\">             312.377</td><td style=\"text-align: right;\">            -81.1858</td><td style=\"text-align: right;\">            273.76</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 572000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-35-58\n","  done: false\n","  episode_len_mean: 145.7\n","  episode_media: {}\n","  episode_reward_max: -157.2508365779761\n","  episode_reward_mean: -424.82233566242365\n","  episode_reward_min: -1210.9069264309587\n","  episodes_this_iter: 27\n","  episodes_total: 4892\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 620363120640.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.4103027880191803\n","          entropy_coeff: 0.0\n","          kl: 0.1054222360253334\n","          model: {}\n","          policy_loss: 0.03111019916832447\n","          total_loss: 65400057856.0\n","          vf_explained_var: 0.5529975295066833\n","          vf_loss: 1472.1568603515625\n","    num_agent_steps_sampled: 572000\n","    num_agent_steps_trained: 572000\n","    num_steps_sampled: 572000\n","    num_steps_trained: 572000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 143\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.654545454545454\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0704994003041653\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2898638111459286\n","    mean_inference_ms: 0.7271328747456391\n","    mean_raw_obs_processing_ms: 0.11266276236746457\n","  time_since_restore: 1060.6775879859924\n","  time_this_iter_s: 7.820702314376831\n","  time_total_s: 1060.6775879859924\n","  timers:\n","    learn_throughput: 1588.261\n","    learn_time_ms: 2518.478\n","    load_throughput: 8244737.334\n","    load_time_ms: 0.485\n","    sample_throughput: 516.661\n","    sample_time_ms: 7742.028\n","    update_time_ms: 2.8\n","  timestamp: 1649864158\n","  timesteps_since_restore: 572000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 572000\n","  training_iteration: 143\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 480000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-35-59\n","  done: false\n","  episode_len_mean: 252.4\n","  episode_media: {}\n","  episode_reward_max: 311.4639149724437\n","  episode_reward_mean: 259.3134848368279\n","  episode_reward_min: -81.18577515756519\n","  episodes_this_iter: 19\n","  episodes_total: 1815\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5276107788085938\n","          entropy_coeff: 0.0\n","          kl: 0.006542664021253586\n","          model: {}\n","          policy_loss: -0.019593622535467148\n","          total_loss: 359.2886962890625\n","          vf_explained_var: 0.696936309337616\n","          vf_loss: 359.30706787109375\n","    num_agent_steps_sampled: 480000\n","    num_agent_steps_trained: 480000\n","    num_steps_sampled: 480000\n","    num_steps_trained: 480000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 120\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.0\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07492360357499037\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6116605299849571\n","    mean_inference_ms: 0.7593985672219498\n","    mean_raw_obs_processing_ms: 0.11267367023539535\n","  time_since_restore: 1056.2074682712555\n","  time_this_iter_s: 7.898270606994629\n","  time_total_s: 1056.2074682712555\n","  timers:\n","    learn_throughput: 1608.85\n","    learn_time_ms: 2486.249\n","    load_throughput: 8151006.17\n","    load_time_ms: 0.491\n","    sample_throughput: 476.196\n","    sample_time_ms: 8399.897\n","    update_time_ms: 2.79\n","  timestamp: 1649864159\n","  timesteps_since_restore: 480000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 480000\n","  training_iteration: 120\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:36:01 (running for 00:18:12.00)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   143</td><td style=\"text-align: right;\">         1060.68</td><td style=\"text-align: right;\">572000</td><td style=\"text-align: right;\">-424.822 </td><td style=\"text-align: right;\">            -157.251</td><td style=\"text-align: right;\">          -1210.91  </td><td style=\"text-align: right;\">            145.7 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         1055.35</td><td style=\"text-align: right;\">384000</td><td style=\"text-align: right;\">  53.4578</td><td style=\"text-align: right;\">             254.375</td><td style=\"text-align: right;\">           -211.043 </td><td style=\"text-align: right;\">            539.88</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   120</td><td style=\"text-align: right;\">         1056.21</td><td style=\"text-align: right;\">480000</td><td style=\"text-align: right;\"> 259.313 </td><td style=\"text-align: right;\">             311.464</td><td style=\"text-align: right;\">            -81.1858</td><td style=\"text-align: right;\">            252.4 </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 388000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-36-02\n","  done: false\n","  episode_len_mean: 531.94\n","  episode_media: {}\n","  episode_reward_max: 254.37470392482837\n","  episode_reward_mean: 53.16390059228954\n","  episode_reward_min: -211.0426676398177\n","  episodes_this_iter: 5\n","  episodes_total: 1082\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8674185276031494\n","          entropy_coeff: 0.0\n","          kl: 0.00890383217483759\n","          model: {}\n","          policy_loss: -0.03453418239951134\n","          total_loss: 245.03427124023438\n","          vf_explained_var: 0.7713099122047424\n","          vf_loss: 245.05978393554688\n","    num_agent_steps_sampled: 388000\n","    num_agent_steps_trained: 388000\n","    num_steps_sampled: 388000\n","    num_steps_trained: 388000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 97\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.835294117647058\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07405279524354538\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1441878903391922\n","    mean_inference_ms: 0.7697639899220675\n","    mean_raw_obs_processing_ms: 0.1124971579427366\n","  time_since_restore: 1066.8372447490692\n","  time_this_iter_s: 11.488095760345459\n","  time_total_s: 1066.8372447490692\n","  timers:\n","    learn_throughput: 1618.101\n","    learn_time_ms: 2472.034\n","    load_throughput: 8524141.856\n","    load_time_ms: 0.469\n","    sample_throughput: 357.825\n","    sample_time_ms: 11178.658\n","    update_time_ms: 2.817\n","  timestamp: 1649864162\n","  timesteps_since_restore: 388000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 388000\n","  training_iteration: 97\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 576000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-36-05\n","  done: false\n","  episode_len_mean: 140.05\n","  episode_media: {}\n","  episode_reward_max: -222.18540744984523\n","  episode_reward_mean: -430.2807083515849\n","  episode_reward_min: -1210.9069264309587\n","  episodes_this_iter: 34\n","  episodes_total: 4926\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 930544680960.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.37870195508003235\n","          entropy_coeff: 0.0\n","          kl: 0.04950645938515663\n","          model: {}\n","          policy_loss: 0.020171238109469414\n","          total_loss: 46067974144.0\n","          vf_explained_var: 0.7395719885826111\n","          vf_loss: 1603.402099609375\n","    num_agent_steps_sampled: 576000\n","    num_agent_steps_trained: 576000\n","    num_steps_sampled: 576000\n","    num_steps_trained: 576000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 144\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.836363636363638\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0704976017331967\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2903505180233067\n","    mean_inference_ms: 0.7271877769033943\n","    mean_raw_obs_processing_ms: 0.11265924653690025\n","  time_since_restore: 1068.2689719200134\n","  time_this_iter_s: 7.591383934020996\n","  time_total_s: 1068.2689719200134\n","  timers:\n","    learn_throughput: 1583.738\n","    learn_time_ms: 2525.671\n","    load_throughput: 8054739.066\n","    load_time_ms: 0.497\n","    sample_throughput: 517.518\n","    sample_time_ms: 7729.194\n","    update_time_ms: 2.845\n","  timestamp: 1649864165\n","  timesteps_since_restore: 576000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 576000\n","  training_iteration: 144\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:36:07 (running for 00:18:17.86)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   144</td><td style=\"text-align: right;\">         1068.27</td><td style=\"text-align: right;\">576000</td><td style=\"text-align: right;\">-430.281 </td><td style=\"text-align: right;\">            -222.185</td><td style=\"text-align: right;\">          -1210.91  </td><td style=\"text-align: right;\">            140.05</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         1066.84</td><td style=\"text-align: right;\">388000</td><td style=\"text-align: right;\">  53.1639</td><td style=\"text-align: right;\">             254.375</td><td style=\"text-align: right;\">           -211.043 </td><td style=\"text-align: right;\">            531.94</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   120</td><td style=\"text-align: right;\">         1056.21</td><td style=\"text-align: right;\">480000</td><td style=\"text-align: right;\"> 259.313 </td><td style=\"text-align: right;\">             311.464</td><td style=\"text-align: right;\">            -81.1858</td><td style=\"text-align: right;\">            252.4 </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 484000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-36-07\n","  done: false\n","  episode_len_mean: 241.99\n","  episode_media: {}\n","  episode_reward_max: 315.3296325163134\n","  episode_reward_mean: 264.1876943064878\n","  episode_reward_min: -81.18577515756519\n","  episodes_this_iter: 20\n","  episodes_total: 1835\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5185511708259583\n","          entropy_coeff: 0.0\n","          kl: 0.006531072780489922\n","          model: {}\n","          policy_loss: -0.017285460606217384\n","          total_loss: 85.01429748535156\n","          vf_explained_var: 0.7757087349891663\n","          vf_loss: 85.03034210205078\n","    num_agent_steps_sampled: 484000\n","    num_agent_steps_trained: 484000\n","    num_steps_sampled: 484000\n","    num_steps_trained: 484000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 121\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.758333333333333\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07491955455572147\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.610677945212658\n","    mean_inference_ms: 0.7592714923057645\n","    mean_raw_obs_processing_ms: 0.1126644385216613\n","  time_since_restore: 1064.2546679973602\n","  time_this_iter_s: 8.047199726104736\n","  time_total_s: 1064.2546679973602\n","  timers:\n","    learn_throughput: 1607.486\n","    learn_time_ms: 2488.358\n","    load_throughput: 8071013.614\n","    load_time_ms: 0.496\n","    sample_throughput: 477.138\n","    sample_time_ms: 8383.32\n","    update_time_ms: 2.827\n","  timestamp: 1649864167\n","  timesteps_since_restore: 484000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 484000\n","  training_iteration: 121\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:36:12 (running for 00:18:23.12)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   144</td><td style=\"text-align: right;\">         1068.27</td><td style=\"text-align: right;\">576000</td><td style=\"text-align: right;\">-430.281 </td><td style=\"text-align: right;\">            -222.185</td><td style=\"text-align: right;\">          -1210.91  </td><td style=\"text-align: right;\">            140.05</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         1066.84</td><td style=\"text-align: right;\">388000</td><td style=\"text-align: right;\">  53.1639</td><td style=\"text-align: right;\">             254.375</td><td style=\"text-align: right;\">           -211.043 </td><td style=\"text-align: right;\">            531.94</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   121</td><td style=\"text-align: right;\">         1064.25</td><td style=\"text-align: right;\">484000</td><td style=\"text-align: right;\"> 264.188 </td><td style=\"text-align: right;\">             315.33 </td><td style=\"text-align: right;\">            -81.1858</td><td style=\"text-align: right;\">            241.99</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 392000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-36-12\n","  done: false\n","  episode_len_mean: 531.67\n","  episode_media: {}\n","  episode_reward_max: 254.37470392482837\n","  episode_reward_mean: 50.57361594972508\n","  episode_reward_min: -260.51422907411654\n","  episodes_this_iter: 8\n","  episodes_total: 1090\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8736541867256165\n","          entropy_coeff: 0.0\n","          kl: 0.013135161250829697\n","          model: {}\n","          policy_loss: -0.04574211686849594\n","          total_loss: 1536.21142578125\n","          vf_explained_var: 0.8386478424072266\n","          vf_loss: 1536.2437744140625\n","    num_agent_steps_sampled: 392000\n","    num_agent_steps_trained: 392000\n","    num_steps_sampled: 392000\n","    num_steps_trained: 392000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 98\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.873333333333333\n","    ram_util_percent: 15.699999999999994\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07405481050990378\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.144659064260181\n","    mean_inference_ms: 0.7698325972101623\n","    mean_raw_obs_processing_ms: 0.11249108434412061\n","  time_since_restore: 1077.137090921402\n","  time_this_iter_s: 10.299846172332764\n","  time_total_s: 1077.137090921402\n","  timers:\n","    learn_throughput: 1610.891\n","    learn_time_ms: 2483.098\n","    load_throughput: 9031176.186\n","    load_time_ms: 0.443\n","    sample_throughput: 360.32\n","    sample_time_ms: 11101.232\n","    update_time_ms: 2.796\n","  timestamp: 1649864172\n","  timesteps_since_restore: 392000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 392000\n","  training_iteration: 98\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 580000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-36-13\n","  done: false\n","  episode_len_mean: 131.26\n","  episode_media: {}\n","  episode_reward_max: -191.36044009542815\n","  episode_reward_mean: -434.0985950906364\n","  episode_reward_min: -1028.3280734381483\n","  episodes_this_iter: 34\n","  episodes_total: 4960\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1395817054208.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.3254023492336273\n","          entropy_coeff: 0.0\n","          kl: 0.08107650279998779\n","          model: {}\n","          policy_loss: 0.02171260304749012\n","          total_loss: 113167949824.0\n","          vf_explained_var: 0.8011050820350647\n","          vf_loss: 812.8041381835938\n","    num_agent_steps_sampled: 580000\n","    num_agent_steps_trained: 580000\n","    num_steps_sampled: 580000\n","    num_steps_trained: 580000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 145\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.981818181818182\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07050299937619064\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.29066788619836126\n","    mean_inference_ms: 0.7273484589489673\n","    mean_raw_obs_processing_ms: 0.11266748025064413\n","  time_since_restore: 1075.9661684036255\n","  time_this_iter_s: 7.6971964836120605\n","  time_total_s: 1075.9661684036255\n","  timers:\n","    learn_throughput: 1573.429\n","    learn_time_ms: 2542.219\n","    load_throughput: 8184007.805\n","    load_time_ms: 0.489\n","    sample_throughput: 518.728\n","    sample_time_ms: 7711.175\n","    update_time_ms: 2.881\n","  timestamp: 1649864173\n","  timesteps_since_restore: 580000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 580000\n","  training_iteration: 145\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 488000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-36-15\n","  done: false\n","  episode_len_mean: 234.3\n","  episode_media: {}\n","  episode_reward_max: 315.3296325163134\n","  episode_reward_mean: 264.7562051891698\n","  episode_reward_min: -81.18577515756519\n","  episodes_this_iter: 20\n","  episodes_total: 1855\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.606752872467041\n","          entropy_coeff: 0.0\n","          kl: 0.011111724190413952\n","          model: {}\n","          policy_loss: -0.011011573486030102\n","          total_loss: 56.02484893798828\n","          vf_explained_var: 0.7936009168624878\n","          vf_loss: 56.033748626708984\n","    num_agent_steps_sampled: 488000\n","    num_agent_steps_trained: 488000\n","    num_steps_sampled: 488000\n","    num_steps_trained: 488000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 122\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.945454545454544\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07492001843584097\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6094764108699416\n","    mean_inference_ms: 0.7592146534859339\n","    mean_raw_obs_processing_ms: 0.11266441886047257\n","  time_since_restore: 1072.1888370513916\n","  time_this_iter_s: 7.934169054031372\n","  time_total_s: 1072.1888370513916\n","  timers:\n","    learn_throughput: 1605.522\n","    learn_time_ms: 2491.402\n","    load_throughput: 8481480.208\n","    load_time_ms: 0.472\n","    sample_throughput: 479.496\n","    sample_time_ms: 8342.092\n","    update_time_ms: 2.888\n","  timestamp: 1649864175\n","  timesteps_since_restore: 488000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 488000\n","  training_iteration: 122\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:36:18 (running for 00:18:29.00)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   145</td><td style=\"text-align: right;\">         1075.97</td><td style=\"text-align: right;\">580000</td><td style=\"text-align: right;\">-434.099 </td><td style=\"text-align: right;\">            -191.36 </td><td style=\"text-align: right;\">          -1028.33  </td><td style=\"text-align: right;\">            131.26</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         1077.14</td><td style=\"text-align: right;\">392000</td><td style=\"text-align: right;\">  50.5736</td><td style=\"text-align: right;\">             254.375</td><td style=\"text-align: right;\">           -260.514 </td><td style=\"text-align: right;\">            531.67</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   122</td><td style=\"text-align: right;\">         1072.19</td><td style=\"text-align: right;\">488000</td><td style=\"text-align: right;\"> 264.756 </td><td style=\"text-align: right;\">             315.33 </td><td style=\"text-align: right;\">            -81.1858</td><td style=\"text-align: right;\">            234.3 </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 584000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-36-21\n","  done: false\n","  episode_len_mean: 122.14\n","  episode_media: {}\n","  episode_reward_max: -185.81539231965678\n","  episode_reward_mean: -417.4099099180643\n","  episode_reward_min: -868.5464218580724\n","  episodes_this_iter: 30\n","  episodes_total: 4990\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 2093725515776.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.3608521521091461\n","          entropy_coeff: 0.0\n","          kl: 0.10510936379432678\n","          model: {}\n","          policy_loss: 0.02042165771126747\n","          total_loss: 220070166528.0\n","          vf_explained_var: 0.6141557097434998\n","          vf_loss: 651.2881469726562\n","    num_agent_steps_sampled: 584000\n","    num_agent_steps_trained: 584000\n","    num_steps_sampled: 584000\n","    num_steps_trained: 584000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 146\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.02727272727273\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0705102133601745\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2908403069509379\n","    mean_inference_ms: 0.7275251277254574\n","    mean_raw_obs_processing_ms: 0.11267881277315263\n","  time_since_restore: 1083.6821699142456\n","  time_this_iter_s: 7.716001510620117\n","  time_total_s: 1083.6821699142456\n","  timers:\n","    learn_throughput: 1565.58\n","    learn_time_ms: 2554.963\n","    load_throughput: 8134013.381\n","    load_time_ms: 0.492\n","    sample_throughput: 518.95\n","    sample_time_ms: 7707.876\n","    update_time_ms: 2.904\n","  timestamp: 1649864181\n","  timesteps_since_restore: 584000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 584000\n","  training_iteration: 146\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 492000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-36-23\n","  done: false\n","  episode_len_mean: 223.19\n","  episode_media: {}\n","  episode_reward_max: 315.3296325163134\n","  episode_reward_mean: 265.42045685456475\n","  episode_reward_min: -81.18577515756519\n","  episodes_this_iter: 20\n","  episodes_total: 1875\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5688006281852722\n","          entropy_coeff: 0.0\n","          kl: 0.005899003241211176\n","          model: {}\n","          policy_loss: -0.020413553342223167\n","          total_loss: 45.5608024597168\n","          vf_explained_var: 0.8625351786613464\n","          vf_loss: 45.580101013183594\n","    num_agent_steps_sampled: 492000\n","    num_agent_steps_trained: 492000\n","    num_steps_sampled: 492000\n","    num_steps_trained: 492000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 123\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.858333333333336\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07492078673798089\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6080883340807622\n","    mean_inference_ms: 0.7591789612491511\n","    mean_raw_obs_processing_ms: 0.11266737585221925\n","  time_since_restore: 1080.1068999767303\n","  time_this_iter_s: 7.918062925338745\n","  time_total_s: 1080.1068999767303\n","  timers:\n","    learn_throughput: 1598.391\n","    learn_time_ms: 2502.517\n","    load_throughput: 8515921.019\n","    load_time_ms: 0.47\n","    sample_throughput: 482.526\n","    sample_time_ms: 8289.716\n","    update_time_ms: 2.914\n","  timestamp: 1649864183\n","  timesteps_since_restore: 492000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 492000\n","  training_iteration: 123\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:36:24 (running for 00:18:34.96)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   146</td><td style=\"text-align: right;\">         1083.68</td><td style=\"text-align: right;\">584000</td><td style=\"text-align: right;\">-417.41  </td><td style=\"text-align: right;\">            -185.815</td><td style=\"text-align: right;\">           -868.546 </td><td style=\"text-align: right;\">            122.14</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         1077.14</td><td style=\"text-align: right;\">392000</td><td style=\"text-align: right;\">  50.5736</td><td style=\"text-align: right;\">             254.375</td><td style=\"text-align: right;\">           -260.514 </td><td style=\"text-align: right;\">            531.67</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   123</td><td style=\"text-align: right;\">         1080.11</td><td style=\"text-align: right;\">492000</td><td style=\"text-align: right;\"> 265.42  </td><td style=\"text-align: right;\">             315.33 </td><td style=\"text-align: right;\">            -81.1858</td><td style=\"text-align: right;\">            223.19</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 396000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-36-25\n","  done: false\n","  episode_len_mean: 539.86\n","  episode_media: {}\n","  episode_reward_max: 254.37470392482837\n","  episode_reward_mean: 50.8949060818639\n","  episode_reward_min: -260.51422907411654\n","  episodes_this_iter: 5\n","  episodes_total: 1095\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8524799942970276\n","          entropy_coeff: 0.0\n","          kl: 0.012204620987176895\n","          model: {}\n","          policy_loss: -0.03556499257683754\n","          total_loss: 258.5322265625\n","          vf_explained_var: 0.862425684928894\n","          vf_loss: 258.5554504394531\n","    num_agent_steps_sampled: 396000\n","    num_agent_steps_trained: 396000\n","    num_steps_sampled: 396000\n","    num_steps_trained: 396000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 99\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.394117647058822\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07405717917737323\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1449697306648117\n","    mean_inference_ms: 0.7698961736372933\n","    mean_raw_obs_processing_ms: 0.11248944171615616\n","  time_since_restore: 1089.1274733543396\n","  time_this_iter_s: 11.990382432937622\n","  time_total_s: 1089.1274733543396\n","  timers:\n","    learn_throughput: 1611.138\n","    learn_time_ms: 2482.718\n","    load_throughput: 9201061.753\n","    load_time_ms: 0.435\n","    sample_throughput: 361.305\n","    sample_time_ms: 11070.987\n","    update_time_ms: 2.805\n","  timestamp: 1649864185\n","  timesteps_since_restore: 396000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 396000\n","  training_iteration: 99\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 588000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-36-29\n","  done: false\n","  episode_len_mean: 126.83\n","  episode_media: {}\n","  episode_reward_max: -185.81539231965678\n","  episode_reward_mean: -410.5139246986511\n","  episode_reward_min: -868.5464218580724\n","  episodes_this_iter: 30\n","  episodes_total: 5020\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 3140588404736.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.3708297312259674\n","          entropy_coeff: 0.0\n","          kl: 0.09123093634843826\n","          model: {}\n","          policy_loss: 0.020475391298532486\n","          total_loss: 286518837248.0\n","          vf_explained_var: 0.7370290160179138\n","          vf_loss: 1253.1046142578125\n","    num_agent_steps_sampled: 588000\n","    num_agent_steps_trained: 588000\n","    num_steps_sampled: 588000\n","    num_steps_trained: 588000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 147\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.009090909090908\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07051872261660223\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.29108432938815343\n","    mean_inference_ms: 0.7277271443285255\n","    mean_raw_obs_processing_ms: 0.11269014228048561\n","  time_since_restore: 1091.524132490158\n","  time_this_iter_s: 7.841962575912476\n","  time_total_s: 1091.524132490158\n","  timers:\n","    learn_throughput: 1561.045\n","    learn_time_ms: 2562.386\n","    load_throughput: 8181613.186\n","    load_time_ms: 0.489\n","    sample_throughput: 516.755\n","    sample_time_ms: 7740.609\n","    update_time_ms: 2.932\n","  timestamp: 1649864189\n","  timesteps_since_restore: 588000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 588000\n","  training_iteration: 147\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:36:30 (running for 00:18:40.23)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   147</td><td style=\"text-align: right;\">         1091.52</td><td style=\"text-align: right;\">588000</td><td style=\"text-align: right;\">-410.514 </td><td style=\"text-align: right;\">            -185.815</td><td style=\"text-align: right;\">           -868.546 </td><td style=\"text-align: right;\">            126.83</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         1089.13</td><td style=\"text-align: right;\">396000</td><td style=\"text-align: right;\">  50.8949</td><td style=\"text-align: right;\">             254.375</td><td style=\"text-align: right;\">           -260.514 </td><td style=\"text-align: right;\">            539.86</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   123</td><td style=\"text-align: right;\">         1080.11</td><td style=\"text-align: right;\">492000</td><td style=\"text-align: right;\"> 265.42  </td><td style=\"text-align: right;\">             315.33 </td><td style=\"text-align: right;\">            -81.1858</td><td style=\"text-align: right;\">            223.19</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 496000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-36-31\n","  done: false\n","  episode_len_mean: 200.74\n","  episode_media: {}\n","  episode_reward_max: 315.3296325163134\n","  episode_reward_mean: 270.12171853886514\n","  episode_reward_min: 57.54893879534066\n","  episodes_this_iter: 20\n","  episodes_total: 1895\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5450171232223511\n","          entropy_coeff: 0.0\n","          kl: 0.00877303909510374\n","          model: {}\n","          policy_loss: -0.019122473895549774\n","          total_loss: 365.61383056640625\n","          vf_explained_var: 0.7781938910484314\n","          vf_loss: 365.6313171386719\n","    num_agent_steps_sampled: 496000\n","    num_agent_steps_trained: 496000\n","    num_steps_sampled: 496000\n","    num_steps_trained: 496000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 124\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.17272727272727\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07492315340106301\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6064008821888346\n","    mean_inference_ms: 0.7591556361058258\n","    mean_raw_obs_processing_ms: 0.11267509633651654\n","  time_since_restore: 1087.8833332061768\n","  time_this_iter_s: 7.776433229446411\n","  time_total_s: 1087.8833332061768\n","  timers:\n","    learn_throughput: 1603.874\n","    learn_time_ms: 2493.961\n","    load_throughput: 8558057.539\n","    load_time_ms: 0.467\n","    sample_throughput: 482.749\n","    sample_time_ms: 8285.881\n","    update_time_ms: 2.955\n","  timestamp: 1649864191\n","  timesteps_since_restore: 496000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 496000\n","  training_iteration: 124\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:36:35 (running for 00:18:45.85)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   147</td><td style=\"text-align: right;\">         1091.52</td><td style=\"text-align: right;\">588000</td><td style=\"text-align: right;\">-410.514 </td><td style=\"text-align: right;\">            -185.815</td><td style=\"text-align: right;\">           -868.546 </td><td style=\"text-align: right;\">            126.83</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         1089.13</td><td style=\"text-align: right;\">396000</td><td style=\"text-align: right;\">  50.8949</td><td style=\"text-align: right;\">             254.375</td><td style=\"text-align: right;\">           -260.514 </td><td style=\"text-align: right;\">            539.86</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   124</td><td style=\"text-align: right;\">         1087.88</td><td style=\"text-align: right;\">496000</td><td style=\"text-align: right;\"> 270.122 </td><td style=\"text-align: right;\">             315.33 </td><td style=\"text-align: right;\">             57.5489</td><td style=\"text-align: right;\">            200.74</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 400000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-36-36\n","  done: false\n","  episode_len_mean: 548.91\n","  episode_media: {}\n","  episode_reward_max: 254.37470392482837\n","  episode_reward_mean: 52.78006186779352\n","  episode_reward_min: -260.51422907411654\n","  episodes_this_iter: 5\n","  episodes_total: 1100\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8317087292671204\n","          entropy_coeff: 0.0\n","          kl: 0.011487471871078014\n","          model: {}\n","          policy_loss: -0.03456132858991623\n","          total_loss: 38.57543182373047\n","          vf_explained_var: 0.8651057481765747\n","          vf_loss: 38.59836196899414\n","    num_agent_steps_sampled: 400000\n","    num_agent_steps_trained: 400000\n","    num_steps_sampled: 400000\n","    num_steps_trained: 400000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 100\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.88\n","    ram_util_percent: 15.699999999999994\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07405855587263263\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1452051653506667\n","    mean_inference_ms: 0.769951165394825\n","    mean_raw_obs_processing_ms: 0.11248645428307032\n","  time_since_restore: 1100.1365177631378\n","  time_this_iter_s: 11.009044408798218\n","  time_total_s: 1100.1365177631378\n","  timers:\n","    learn_throughput: 1608.566\n","    learn_time_ms: 2486.687\n","    load_throughput: 9173893.263\n","    load_time_ms: 0.436\n","    sample_throughput: 363.486\n","    sample_time_ms: 11004.555\n","    update_time_ms: 2.792\n","  timestamp: 1649864196\n","  timesteps_since_restore: 400000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 400000\n","  training_iteration: 100\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 592000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-36-36\n","  done: false\n","  episode_len_mean: 134.38\n","  episode_media: {}\n","  episode_reward_max: -185.81539231965678\n","  episode_reward_mean: -407.8557982477022\n","  episode_reward_min: -981.6468547766024\n","  episodes_this_iter: 28\n","  episodes_total: 5048\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 4710882344960.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.3905218243598938\n","          entropy_coeff: 0.0\n","          kl: 0.11045869439840317\n","          model: {}\n","          policy_loss: 0.03238484635949135\n","          total_loss: 520357937152.0\n","          vf_explained_var: 0.5853858590126038\n","          vf_loss: 1474.4056396484375\n","    num_agent_steps_sampled: 592000\n","    num_agent_steps_trained: 592000\n","    num_steps_sampled: 592000\n","    num_steps_trained: 592000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 148\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.072727272727274\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0705221371228861\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.29142475085453645\n","    mean_inference_ms: 0.7278411611150362\n","    mean_raw_obs_processing_ms: 0.11269233833612766\n","  time_since_restore: 1099.1372451782227\n","  time_this_iter_s: 7.613112688064575\n","  time_total_s: 1099.1372451782227\n","  timers:\n","    learn_throughput: 1562.134\n","    learn_time_ms: 2560.599\n","    load_throughput: 8580379.481\n","    load_time_ms: 0.466\n","    sample_throughput: 516.94\n","    sample_time_ms: 7737.848\n","    update_time_ms: 2.888\n","  timestamp: 1649864196\n","  timesteps_since_restore: 592000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 592000\n","  training_iteration: 148\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 500000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-36-39\n","  done: false\n","  episode_len_mean: 198.44\n","  episode_media: {}\n","  episode_reward_max: 316.138284763903\n","  episode_reward_mean: 270.896347304234\n","  episode_reward_min: 57.54893879534066\n","  episodes_this_iter: 21\n","  episodes_total: 1916\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5452381372451782\n","          entropy_coeff: 0.0\n","          kl: 0.005945417098701\n","          model: {}\n","          policy_loss: -0.011544032022356987\n","          total_loss: 257.67529296875\n","          vf_explained_var: 0.8075631260871887\n","          vf_loss: 257.6856994628906\n","    num_agent_steps_sampled: 500000\n","    num_agent_steps_trained: 500000\n","    num_steps_sampled: 500000\n","    num_steps_trained: 500000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 125\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.981818181818182\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07492659692832611\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6045950393455105\n","    mean_inference_ms: 0.759147835116824\n","    mean_raw_obs_processing_ms: 0.11268494757778497\n","  time_since_restore: 1095.6240785121918\n","  time_this_iter_s: 7.740745306015015\n","  time_total_s: 1095.6240785121918\n","  timers:\n","    learn_throughput: 1612.278\n","    learn_time_ms: 2480.961\n","    load_throughput: 8536720.094\n","    load_time_ms: 0.469\n","    sample_throughput: 485.683\n","    sample_time_ms: 8235.816\n","    update_time_ms: 2.962\n","  timestamp: 1649864199\n","  timesteps_since_restore: 500000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 500000\n","  training_iteration: 125\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:36:41 (running for 00:18:51.55)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   148</td><td style=\"text-align: right;\">         1099.14</td><td style=\"text-align: right;\">592000</td><td style=\"text-align: right;\">-407.856 </td><td style=\"text-align: right;\">            -185.815</td><td style=\"text-align: right;\">           -981.647 </td><td style=\"text-align: right;\">            134.38</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         1100.14</td><td style=\"text-align: right;\">400000</td><td style=\"text-align: right;\">  52.7801</td><td style=\"text-align: right;\">             254.375</td><td style=\"text-align: right;\">           -260.514 </td><td style=\"text-align: right;\">            548.91</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   125</td><td style=\"text-align: right;\">         1095.62</td><td style=\"text-align: right;\">500000</td><td style=\"text-align: right;\"> 270.896 </td><td style=\"text-align: right;\">             316.138</td><td style=\"text-align: right;\">             57.5489</td><td style=\"text-align: right;\">            198.44</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 596000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-36-44\n","  done: false\n","  episode_len_mean: 139.21\n","  episode_media: {}\n","  episode_reward_max: -185.81539231965678\n","  episode_reward_mean: -424.26280292755456\n","  episode_reward_min: -981.6468547766024\n","  episodes_this_iter: 28\n","  episodes_total: 5076\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 7066323779584.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.37657320499420166\n","          entropy_coeff: 0.0\n","          kl: 0.1491168588399887\n","          model: {}\n","          policy_loss: 0.029258523136377335\n","          total_loss: 1053707862016.0\n","          vf_explained_var: 0.6889094710350037\n","          vf_loss: 956.9681396484375\n","    num_agent_steps_sampled: 596000\n","    num_agent_steps_trained: 596000\n","    num_steps_sampled: 596000\n","    num_steps_trained: 596000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 149\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.336363636363636\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07051873202896627\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.29183176173524084\n","    mean_inference_ms: 0.7278645765481033\n","    mean_raw_obs_processing_ms: 0.11268364382620363\n","  time_since_restore: 1106.5658648014069\n","  time_this_iter_s: 7.428619623184204\n","  time_total_s: 1106.5658648014069\n","  timers:\n","    learn_throughput: 1571.599\n","    learn_time_ms: 2545.178\n","    load_throughput: 8869325.439\n","    load_time_ms: 0.451\n","    sample_throughput: 516.932\n","    sample_time_ms: 7737.958\n","    update_time_ms: 2.903\n","  timestamp: 1649864204\n","  timesteps_since_restore: 596000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 596000\n","  training_iteration: 149\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 404000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-36-46\n","  done: false\n","  episode_len_mean: 548.33\n","  episode_media: {}\n","  episode_reward_max: 254.37470392482837\n","  episode_reward_mean: 53.50267816811718\n","  episode_reward_min: -260.51422907411654\n","  episodes_this_iter: 9\n","  episodes_total: 1109\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8277164101600647\n","          entropy_coeff: 0.0\n","          kl: 0.015493229031562805\n","          model: {}\n","          policy_loss: -0.04142323136329651\n","          total_loss: 567.6165771484375\n","          vf_explained_var: 0.7316223978996277\n","          vf_loss: 567.642333984375\n","    num_agent_steps_sampled: 404000\n","    num_agent_steps_trained: 404000\n","    num_steps_sampled: 404000\n","    num_steps_trained: 404000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 101\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.026666666666667\n","    ram_util_percent: 15.699999999999994\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07405916965591192\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1454546632599805\n","    mean_inference_ms: 0.7700209014545544\n","    mean_raw_obs_processing_ms: 0.11247686033604565\n","  time_since_restore: 1110.4236550331116\n","  time_this_iter_s: 10.287137269973755\n","  time_total_s: 1110.4236550331116\n","  timers:\n","    learn_throughput: 1605.623\n","    learn_time_ms: 2491.245\n","    load_throughput: 8957403.097\n","    load_time_ms: 0.447\n","    sample_throughput: 365.64\n","    sample_time_ms: 10939.735\n","    update_time_ms: 2.805\n","  timestamp: 1649864206\n","  timesteps_since_restore: 404000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 404000\n","  training_iteration: 101\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:36:46 (running for 00:18:56.61)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   149</td><td style=\"text-align: right;\">         1106.57</td><td style=\"text-align: right;\">596000</td><td style=\"text-align: right;\">-424.263 </td><td style=\"text-align: right;\">            -185.815</td><td style=\"text-align: right;\">           -981.647 </td><td style=\"text-align: right;\">            139.21</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         1110.42</td><td style=\"text-align: right;\">404000</td><td style=\"text-align: right;\">  53.5027</td><td style=\"text-align: right;\">             254.375</td><td style=\"text-align: right;\">           -260.514 </td><td style=\"text-align: right;\">            548.33</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   125</td><td style=\"text-align: right;\">         1095.62</td><td style=\"text-align: right;\">500000</td><td style=\"text-align: right;\"> 270.896 </td><td style=\"text-align: right;\">             316.138</td><td style=\"text-align: right;\">             57.5489</td><td style=\"text-align: right;\">            198.44</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 504000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-36-47\n","  done: false\n","  episode_len_mean: 197.38\n","  episode_media: {}\n","  episode_reward_max: 316.138284763903\n","  episode_reward_mean: 267.89028967169486\n","  episode_reward_min: 57.54893879534066\n","  episodes_this_iter: 21\n","  episodes_total: 1937\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5300845503807068\n","          entropy_coeff: 0.0\n","          kl: 0.00737761938944459\n","          model: {}\n","          policy_loss: -0.015151318162679672\n","          total_loss: 670.4581909179688\n","          vf_explained_var: 0.6762653589248657\n","          vf_loss: 670.471923828125\n","    num_agent_steps_sampled: 504000\n","    num_agent_steps_trained: 504000\n","    num_steps_sampled: 504000\n","    num_steps_trained: 504000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 126\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.990909090909089\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07492370758392447\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.6027918890846065\n","    mean_inference_ms: 0.7590645227105131\n","    mean_raw_obs_processing_ms: 0.1126838648940996\n","  time_since_restore: 1103.3303842544556\n","  time_this_iter_s: 7.706305742263794\n","  time_total_s: 1103.3303842544556\n","  timers:\n","    learn_throughput: 1612.911\n","    learn_time_ms: 2479.988\n","    load_throughput: 8497374.392\n","    load_time_ms: 0.471\n","    sample_throughput: 491.402\n","    sample_time_ms: 8139.981\n","    update_time_ms: 2.879\n","  timestamp: 1649864207\n","  timesteps_since_restore: 504000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 504000\n","  training_iteration: 126\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 600000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-36-51\n","  done: false\n","  episode_len_mean: 142.64\n","  episode_media: {}\n","  episode_reward_max: -211.8954432431538\n","  episode_reward_mean: -433.7396024438617\n","  episode_reward_min: -981.6468547766024\n","  episodes_this_iter: 27\n","  episodes_total: 5103\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 10599485407232.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.39777931571006775\n","          entropy_coeff: 0.0\n","          kl: 0.08960510790348053\n","          model: {}\n","          policy_loss: 0.019657213240861893\n","          total_loss: 949768093696.0\n","          vf_explained_var: 0.5425177216529846\n","          vf_loss: 1655.6612548828125\n","    num_agent_steps_sampled: 600000\n","    num_agent_steps_trained: 600000\n","    num_steps_sampled: 600000\n","    num_steps_trained: 600000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 150\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.940000000000001\n","    ram_util_percent: 15.699999999999998\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07051637096289314\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.29218770568037544\n","    mean_inference_ms: 0.7278657828762681\n","    mean_raw_obs_processing_ms: 0.11267337421426189\n","  time_since_restore: 1114.1341812610626\n","  time_this_iter_s: 7.568316459655762\n","  time_total_s: 1114.1341812610626\n","  timers:\n","    learn_throughput: 1575.868\n","    learn_time_ms: 2538.283\n","    load_throughput: 9472766.078\n","    load_time_ms: 0.422\n","    sample_throughput: 518.939\n","    sample_time_ms: 7708.041\n","    update_time_ms: 2.929\n","  timestamp: 1649864211\n","  timesteps_since_restore: 600000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 600000\n","  training_iteration: 150\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:36:51 (running for 00:19:01.95)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   150</td><td style=\"text-align: right;\">         1114.13</td><td style=\"text-align: right;\">600000</td><td style=\"text-align: right;\">-433.74  </td><td style=\"text-align: right;\">            -211.895</td><td style=\"text-align: right;\">           -981.647 </td><td style=\"text-align: right;\">            142.64</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         1110.42</td><td style=\"text-align: right;\">404000</td><td style=\"text-align: right;\">  53.5027</td><td style=\"text-align: right;\">             254.375</td><td style=\"text-align: right;\">           -260.514 </td><td style=\"text-align: right;\">            548.33</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   126</td><td style=\"text-align: right;\">         1103.33</td><td style=\"text-align: right;\">504000</td><td style=\"text-align: right;\"> 267.89  </td><td style=\"text-align: right;\">             316.138</td><td style=\"text-align: right;\">             57.5489</td><td style=\"text-align: right;\">            197.38</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 508000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-36-54\n","  done: false\n","  episode_len_mean: 194.71\n","  episode_media: {}\n","  episode_reward_max: 316.138284763903\n","  episode_reward_mean: 267.9466325804904\n","  episode_reward_min: 57.54893879534066\n","  episodes_this_iter: 20\n","  episodes_total: 1957\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.517104983329773\n","          entropy_coeff: 0.0\n","          kl: 0.005591581575572491\n","          model: {}\n","          policy_loss: -0.016031773760914803\n","          total_loss: 177.00880432128906\n","          vf_explained_var: 0.8077282309532166\n","          vf_loss: 177.02378845214844\n","    num_agent_steps_sampled: 508000\n","    num_agent_steps_trained: 508000\n","    num_steps_sampled: 508000\n","    num_steps_trained: 508000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 127\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.245454545454548\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07491899141500934\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.601078645839279\n","    mean_inference_ms: 0.7589834392722217\n","    mean_raw_obs_processing_ms: 0.11268125592240189\n","  time_since_restore: 1111.1708903312683\n","  time_this_iter_s: 7.840506076812744\n","  time_total_s: 1111.1708903312683\n","  timers:\n","    learn_throughput: 1615.21\n","    learn_time_ms: 2476.458\n","    load_throughput: 8434152.423\n","    load_time_ms: 0.474\n","    sample_throughput: 495.419\n","    sample_time_ms: 8073.974\n","    update_time_ms: 2.859\n","  timestamp: 1649864214\n","  timesteps_since_restore: 508000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 508000\n","  training_iteration: 127\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 408000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-36-56\n","  done: false\n","  episode_len_mean: 524.5\n","  episode_media: {}\n","  episode_reward_max: 268.2990697424575\n","  episode_reward_mean: 51.54413303392069\n","  episode_reward_min: -260.51422907411654\n","  episodes_this_iter: 10\n","  episodes_total: 1119\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8062307238578796\n","          entropy_coeff: 0.0\n","          kl: 0.015680138021707535\n","          model: {}\n","          policy_loss: -0.04438208416104317\n","          total_loss: 1008.1005249023438\n","          vf_explained_var: 0.5991483926773071\n","          vf_loss: 1008.1290893554688\n","    num_agent_steps_sampled: 408000\n","    num_agent_steps_trained: 408000\n","    num_steps_sampled: 408000\n","    num_steps_trained: 408000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 102\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.393333333333333\n","    ram_util_percent: 15.699999999999994\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07406046237725547\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1453857995307604\n","    mean_inference_ms: 0.7700894622709249\n","    mean_raw_obs_processing_ms: 0.11246481614638619\n","  time_since_restore: 1120.5068616867065\n","  time_this_iter_s: 10.08320665359497\n","  time_total_s: 1120.5068616867065\n","  timers:\n","    learn_throughput: 1606.345\n","    learn_time_ms: 2490.126\n","    load_throughput: 9305683.066\n","    load_time_ms: 0.43\n","    sample_throughput: 366.888\n","    sample_time_ms: 10902.517\n","    update_time_ms: 2.776\n","  timestamp: 1649864216\n","  timesteps_since_restore: 408000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 408000\n","  training_iteration: 102\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:36:57 (running for 00:19:07.73)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   150</td><td style=\"text-align: right;\">         1114.13</td><td style=\"text-align: right;\">600000</td><td style=\"text-align: right;\">-433.74  </td><td style=\"text-align: right;\">            -211.895</td><td style=\"text-align: right;\">           -981.647 </td><td style=\"text-align: right;\">            142.64</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">         1120.51</td><td style=\"text-align: right;\">408000</td><td style=\"text-align: right;\">  51.5441</td><td style=\"text-align: right;\">             268.299</td><td style=\"text-align: right;\">           -260.514 </td><td style=\"text-align: right;\">            524.5 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   127</td><td style=\"text-align: right;\">         1111.17</td><td style=\"text-align: right;\">508000</td><td style=\"text-align: right;\"> 267.947 </td><td style=\"text-align: right;\">             316.138</td><td style=\"text-align: right;\">             57.5489</td><td style=\"text-align: right;\">            194.71</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 604000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-36-59\n","  done: false\n","  episode_len_mean: 148.74\n","  episode_media: {}\n","  episode_reward_max: -216.746800147059\n","  episode_reward_mean: -455.261494101995\n","  episode_reward_min: -981.6468547766024\n","  episodes_this_iter: 26\n","  episodes_total: 5129\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 15899228635136.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.34401074051856995\n","          entropy_coeff: 0.0\n","          kl: 0.07926881313323975\n","          model: {}\n","          policy_loss: 0.017805999144911766\n","          total_loss: 1260312985600.0\n","          vf_explained_var: 0.5592857003211975\n","          vf_loss: 1169.489501953125\n","    num_agent_steps_sampled: 604000\n","    num_agent_steps_trained: 604000\n","    num_steps_sampled: 604000\n","    num_steps_trained: 604000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 151\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.018181818181818\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07051353809345208\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.29256723408657526\n","    mean_inference_ms: 0.7278577084617658\n","    mean_raw_obs_processing_ms: 0.11266108613376226\n","  time_since_restore: 1121.7972989082336\n","  time_this_iter_s: 7.6631176471710205\n","  time_total_s: 1121.7972989082336\n","  timers:\n","    learn_throughput: 1587.258\n","    learn_time_ms: 2520.069\n","    load_throughput: 9399527.144\n","    load_time_ms: 0.426\n","    sample_throughput: 518.436\n","    sample_time_ms: 7715.517\n","    update_time_ms: 2.899\n","  timestamp: 1649864219\n","  timesteps_since_restore: 604000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 604000\n","  training_iteration: 151\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 512000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-37-03\n","  done: false\n","  episode_len_mean: 203.14\n","  episode_media: {}\n","  episode_reward_max: 317.23297094081\n","  episode_reward_mean: 265.1265788050434\n","  episode_reward_min: 52.37895262697879\n","  episodes_this_iter: 16\n","  episodes_total: 1973\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6073192358016968\n","          entropy_coeff: 0.0\n","          kl: 0.007736946456134319\n","          model: {}\n","          policy_loss: -0.015204571187496185\n","          total_loss: 401.31280517578125\n","          vf_explained_var: 0.6122819185256958\n","          vf_loss: 401.3265380859375\n","    num_agent_steps_sampled: 512000\n","    num_agent_steps_trained: 512000\n","    num_steps_sampled: 512000\n","    num_steps_trained: 512000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 128\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.266666666666667\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07491294663896086\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5999002649246588\n","    mean_inference_ms: 0.7588779785332327\n","    mean_raw_obs_processing_ms: 0.11267470183223431\n","  time_since_restore: 1119.4521753787994\n","  time_this_iter_s: 8.281285047531128\n","  time_total_s: 1119.4521753787994\n","  timers:\n","    learn_throughput: 1626.103\n","    learn_time_ms: 2459.868\n","    load_throughput: 8610323.839\n","    load_time_ms: 0.465\n","    sample_throughput: 494.982\n","    sample_time_ms: 8081.099\n","    update_time_ms: 2.836\n","  timestamp: 1649864223\n","  timesteps_since_restore: 512000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 512000\n","  training_iteration: 128\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:37:03 (running for 00:19:13.49)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   151</td><td style=\"text-align: right;\">         1121.8 </td><td style=\"text-align: right;\">604000</td><td style=\"text-align: right;\">-455.261 </td><td style=\"text-align: right;\">            -216.747</td><td style=\"text-align: right;\">            -981.647</td><td style=\"text-align: right;\">            148.74</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">         1120.51</td><td style=\"text-align: right;\">408000</td><td style=\"text-align: right;\">  51.5441</td><td style=\"text-align: right;\">             268.299</td><td style=\"text-align: right;\">            -260.514</td><td style=\"text-align: right;\">            524.5 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   128</td><td style=\"text-align: right;\">         1119.45</td><td style=\"text-align: right;\">512000</td><td style=\"text-align: right;\"> 265.127 </td><td style=\"text-align: right;\">             317.233</td><td style=\"text-align: right;\">              52.379</td><td style=\"text-align: right;\">            203.14</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 412000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-37-07\n","  done: false\n","  episode_len_mean: 501.52\n","  episode_media: {}\n","  episode_reward_max: 268.2990697424575\n","  episode_reward_mean: 47.87461826579456\n","  episode_reward_min: -260.51422907411654\n","  episodes_this_iter: 11\n","  episodes_total: 1130\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.7865169644355774\n","          entropy_coeff: 0.0\n","          kl: 0.013467991724610329\n","          model: {}\n","          policy_loss: -0.0509793683886528\n","          total_loss: 333.7355651855469\n","          vf_explained_var: 0.7951594591140747\n","          vf_loss: 333.7728576660156\n","    num_agent_steps_sampled: 412000\n","    num_agent_steps_trained: 412000\n","    num_steps_sampled: 412000\n","    num_steps_trained: 412000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 103\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.606666666666667\n","    ram_util_percent: 15.699999999999994\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07406227855086678\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1448464264470455\n","    mean_inference_ms: 0.7701007067299923\n","    mean_raw_obs_processing_ms: 0.11245342674621348\n","  time_since_restore: 1131.07284617424\n","  time_this_iter_s: 10.56598448753357\n","  time_total_s: 1131.07284617424\n","  timers:\n","    learn_throughput: 1607.13\n","    learn_time_ms: 2488.909\n","    load_throughput: 9290738.731\n","    load_time_ms: 0.431\n","    sample_throughput: 367.769\n","    sample_time_ms: 10876.38\n","    update_time_ms: 2.753\n","  timestamp: 1649864227\n","  timesteps_since_restore: 412000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 412000\n","  training_iteration: 103\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 608000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-37-07\n","  done: false\n","  episode_len_mean: 149.57\n","  episode_media: {}\n","  episode_reward_max: -216.746800147059\n","  episode_reward_mean: -473.1061931949368\n","  episode_reward_min: -1011.130509211377\n","  episodes_this_iter: 26\n","  episodes_total: 5155\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 23848841904128.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.3894772231578827\n","          entropy_coeff: 0.0\n","          kl: 0.1003665030002594\n","          model: {}\n","          policy_loss: 0.021878255531191826\n","          total_loss: 2393624805376.0\n","          vf_explained_var: 0.530605673789978\n","          vf_loss: 1767.36572265625\n","    num_agent_steps_sampled: 608000\n","    num_agent_steps_trained: 608000\n","    num_steps_sampled: 608000\n","    num_steps_trained: 608000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 152\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.908333333333333\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07051357420058413\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.29299875488573734\n","    mean_inference_ms: 0.7278784875315251\n","    mean_raw_obs_processing_ms: 0.11265471872692427\n","  time_since_restore: 1129.6312892436981\n","  time_this_iter_s: 7.8339903354644775\n","  time_total_s: 1129.6312892436981\n","  timers:\n","    learn_throughput: 1589.724\n","    learn_time_ms: 2516.161\n","    load_throughput: 9879411.141\n","    load_time_ms: 0.405\n","    sample_throughput: 518.151\n","    sample_time_ms: 7719.761\n","    update_time_ms: 2.85\n","  timestamp: 1649864227\n","  timesteps_since_restore: 608000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 608000\n","  training_iteration: 152\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:37:08 (running for 00:19:18.52)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   152</td><td style=\"text-align: right;\">         1129.63</td><td style=\"text-align: right;\">608000</td><td style=\"text-align: right;\">-473.106 </td><td style=\"text-align: right;\">            -216.747</td><td style=\"text-align: right;\">           -1011.13 </td><td style=\"text-align: right;\">            149.57</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         1131.07</td><td style=\"text-align: right;\">412000</td><td style=\"text-align: right;\">  47.8746</td><td style=\"text-align: right;\">             268.299</td><td style=\"text-align: right;\">            -260.514</td><td style=\"text-align: right;\">            501.52</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   128</td><td style=\"text-align: right;\">         1119.45</td><td style=\"text-align: right;\">512000</td><td style=\"text-align: right;\"> 265.127 </td><td style=\"text-align: right;\">             317.233</td><td style=\"text-align: right;\">              52.379</td><td style=\"text-align: right;\">            203.14</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 516000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-37-11\n","  done: false\n","  episode_len_mean: 211.25\n","  episode_media: {}\n","  episode_reward_max: 317.23297094081\n","  episode_reward_mean: 263.64460658610534\n","  episode_reward_min: 52.37895262697879\n","  episodes_this_iter: 17\n","  episodes_total: 1990\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6039905548095703\n","          entropy_coeff: 0.0\n","          kl: 0.006547522731125355\n","          model: {}\n","          policy_loss: -0.006672403775155544\n","          total_loss: 387.82342529296875\n","          vf_explained_var: 0.5612316727638245\n","          vf_loss: 387.8288269042969\n","    num_agent_steps_sampled: 516000\n","    num_agent_steps_trained: 516000\n","    num_steps_sampled: 516000\n","    num_steps_trained: 516000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 129\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.550000000000002\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07490757801934946\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5988245814678297\n","    mean_inference_ms: 0.7587579286816168\n","    mean_raw_obs_processing_ms: 0.11266817189095864\n","  time_since_restore: 1127.8153398036957\n","  time_this_iter_s: 8.36316442489624\n","  time_total_s: 1127.8153398036957\n","  timers:\n","    learn_throughput: 1639.036\n","    learn_time_ms: 2440.459\n","    load_throughput: 8486199.292\n","    load_time_ms: 0.471\n","    sample_throughput: 499.4\n","    sample_time_ms: 8009.605\n","    update_time_ms: 2.848\n","  timestamp: 1649864231\n","  timesteps_since_restore: 516000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 516000\n","  training_iteration: 129\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:37:13 (running for 00:19:23.89)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   152</td><td style=\"text-align: right;\">         1129.63</td><td style=\"text-align: right;\">608000</td><td style=\"text-align: right;\">-473.106 </td><td style=\"text-align: right;\">            -216.747</td><td style=\"text-align: right;\">           -1011.13 </td><td style=\"text-align: right;\">            149.57</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         1131.07</td><td style=\"text-align: right;\">412000</td><td style=\"text-align: right;\">  47.8746</td><td style=\"text-align: right;\">             268.299</td><td style=\"text-align: right;\">            -260.514</td><td style=\"text-align: right;\">            501.52</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   129</td><td style=\"text-align: right;\">         1127.82</td><td style=\"text-align: right;\">516000</td><td style=\"text-align: right;\"> 263.645 </td><td style=\"text-align: right;\">             317.233</td><td style=\"text-align: right;\">              52.379</td><td style=\"text-align: right;\">            211.25</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 612000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-37-14\n","  done: false\n","  episode_len_mean: 144.87\n","  episode_media: {}\n","  episode_reward_max: -216.746800147059\n","  episode_reward_mean: -479.8344541005684\n","  episode_reward_min: -1011.130509211377\n","  episodes_this_iter: 31\n","  episodes_total: 5186\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 35773264953344.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.30147239565849304\n","          entropy_coeff: 0.0\n","          kl: 0.08605284988880157\n","          model: {}\n","          policy_loss: 0.019815100356936455\n","          total_loss: 3078391332864.0\n","          vf_explained_var: 0.7435550689697266\n","          vf_loss: 2090.821533203125\n","    num_agent_steps_sampled: 612000\n","    num_agent_steps_trained: 612000\n","    num_steps_sampled: 612000\n","    num_steps_trained: 612000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 153\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.02\n","    ram_util_percent: 15.699999999999998\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07052003806294371\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.29343865626385446\n","    mean_inference_ms: 0.727948376875606\n","    mean_raw_obs_processing_ms: 0.11265706099888924\n","  time_since_restore: 1137.0582699775696\n","  time_this_iter_s: 7.42698073387146\n","  time_total_s: 1137.0582699775696\n","  timers:\n","    learn_throughput: 1599.029\n","    learn_time_ms: 2501.519\n","    load_throughput: 9845206.267\n","    load_time_ms: 0.406\n","    sample_throughput: 520.153\n","    sample_time_ms: 7690.05\n","    update_time_ms: 2.825\n","  timestamp: 1649864234\n","  timesteps_since_restore: 612000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 612000\n","  training_iteration: 153\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 416000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-37-17\n","  done: false\n","  episode_len_mean: 490.09\n","  episode_media: {}\n","  episode_reward_max: 268.2990697424575\n","  episode_reward_mean: 49.360771961462184\n","  episode_reward_min: -260.51422907411654\n","  episodes_this_iter: 9\n","  episodes_total: 1139\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.7967936396598816\n","          entropy_coeff: 0.0\n","          kl: 0.016688046976923943\n","          model: {}\n","          policy_loss: -0.04415401443839073\n","          total_loss: 393.6205749511719\n","          vf_explained_var: 0.5879480242729187\n","          vf_loss: 393.6478576660156\n","    num_agent_steps_sampled: 416000\n","    num_agent_steps_trained: 416000\n","    num_steps_sampled: 416000\n","    num_steps_trained: 416000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 104\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.564285714285715\n","    ram_util_percent: 15.699999999999994\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07406344243743812\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.144301230585825\n","    mean_inference_ms: 0.7701217830450259\n","    mean_raw_obs_processing_ms: 0.11244540209550113\n","  time_since_restore: 1141.3616955280304\n","  time_this_iter_s: 10.288849353790283\n","  time_total_s: 1141.3616955280304\n","  timers:\n","    learn_throughput: 1609.442\n","    learn_time_ms: 2485.333\n","    load_throughput: 9208131.723\n","    load_time_ms: 0.434\n","    sample_throughput: 367.989\n","    sample_time_ms: 10869.88\n","    update_time_ms: 2.676\n","  timestamp: 1649864237\n","  timesteps_since_restore: 416000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 416000\n","  training_iteration: 104\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:37:19 (running for 00:19:29.67)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   153</td><td style=\"text-align: right;\">         1137.06</td><td style=\"text-align: right;\">612000</td><td style=\"text-align: right;\">-479.834 </td><td style=\"text-align: right;\">            -216.747</td><td style=\"text-align: right;\">           -1011.13 </td><td style=\"text-align: right;\">            144.87</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         1141.36</td><td style=\"text-align: right;\">416000</td><td style=\"text-align: right;\">  49.3608</td><td style=\"text-align: right;\">             268.299</td><td style=\"text-align: right;\">            -260.514</td><td style=\"text-align: right;\">            490.09</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   129</td><td style=\"text-align: right;\">         1127.82</td><td style=\"text-align: right;\">516000</td><td style=\"text-align: right;\"> 263.645 </td><td style=\"text-align: right;\">             317.233</td><td style=\"text-align: right;\">              52.379</td><td style=\"text-align: right;\">            211.25</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 520000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-37-20\n","  done: false\n","  episode_len_mean: 229.61\n","  episode_media: {}\n","  episode_reward_max: 317.23297094081\n","  episode_reward_mean: 263.4162612412091\n","  episode_reward_min: 52.37895262697879\n","  episodes_this_iter: 12\n","  episodes_total: 2002\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5726712346076965\n","          entropy_coeff: 0.0\n","          kl: 0.016555270180106163\n","          model: {}\n","          policy_loss: -0.009246360510587692\n","          total_loss: 517.631103515625\n","          vf_explained_var: 0.5144073963165283\n","          vf_loss: 517.63720703125\n","    num_agent_steps_sampled: 520000\n","    num_agent_steps_trained: 520000\n","    num_steps_sampled: 520000\n","    num_steps_trained: 520000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 130\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.446153846153846\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07490459198963471\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5982742196893382\n","    mean_inference_ms: 0.7586868783650172\n","    mean_raw_obs_processing_ms: 0.11266211421822987\n","  time_since_restore: 1136.8188865184784\n","  time_this_iter_s: 9.003546714782715\n","  time_total_s: 1136.8188865184784\n","  timers:\n","    learn_throughput: 1641.949\n","    learn_time_ms: 2436.129\n","    load_throughput: 8874955.565\n","    load_time_ms: 0.451\n","    sample_throughput: 493.582\n","    sample_time_ms: 8104.024\n","    update_time_ms: 2.885\n","  timestamp: 1649864240\n","  timesteps_since_restore: 520000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 520000\n","  training_iteration: 130\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 616000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-37-22\n","  done: false\n","  episode_len_mean: 145.31\n","  episode_media: {}\n","  episode_reward_max: -258.44989274914053\n","  episode_reward_mean: -454.14179147698377\n","  episode_reward_min: -1011.130509211377\n","  episodes_this_iter: 27\n","  episodes_total: 5213\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 53659895332864.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.4147982597351074\n","          entropy_coeff: 0.0\n","          kl: 0.07987593859434128\n","          model: {}\n","          policy_loss: 0.016948770731687546\n","          total_loss: 4286134616064.0\n","          vf_explained_var: 0.533099353313446\n","          vf_loss: 1226.1558837890625\n","    num_agent_steps_sampled: 616000\n","    num_agent_steps_trained: 616000\n","    num_steps_sampled: 616000\n","    num_steps_trained: 616000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 154\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.072727272727276\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07052127097792461\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2937922865529681\n","    mean_inference_ms: 0.7279732279586061\n","    mean_raw_obs_processing_ms: 0.1126548947350991\n","  time_since_restore: 1144.5687775611877\n","  time_this_iter_s: 7.510507583618164\n","  time_total_s: 1144.5687775611877\n","  timers:\n","    learn_throughput: 1599.812\n","    learn_time_ms: 2500.294\n","    load_throughput: 9760437.489\n","    load_time_ms: 0.41\n","    sample_throughput: 521.461\n","    sample_time_ms: 7670.752\n","    update_time_ms: 2.797\n","  timestamp: 1649864242\n","  timesteps_since_restore: 616000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 616000\n","  training_iteration: 154\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:37:25 (running for 00:19:35.64)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   154</td><td style=\"text-align: right;\">         1144.57</td><td style=\"text-align: right;\">616000</td><td style=\"text-align: right;\">-454.142 </td><td style=\"text-align: right;\">            -258.45 </td><td style=\"text-align: right;\">           -1011.13 </td><td style=\"text-align: right;\">            145.31</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         1141.36</td><td style=\"text-align: right;\">416000</td><td style=\"text-align: right;\">  49.3608</td><td style=\"text-align: right;\">             268.299</td><td style=\"text-align: right;\">            -260.514</td><td style=\"text-align: right;\">            490.09</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   130</td><td style=\"text-align: right;\">         1136.82</td><td style=\"text-align: right;\">520000</td><td style=\"text-align: right;\"> 263.416 </td><td style=\"text-align: right;\">             317.233</td><td style=\"text-align: right;\">              52.379</td><td style=\"text-align: right;\">            229.61</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 420000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-37-27\n","  done: false\n","  episode_len_mean: 480.09\n","  episode_media: {}\n","  episode_reward_max: 268.2990697424575\n","  episode_reward_mean: 42.74330616690605\n","  episode_reward_min: -260.51422907411654\n","  episodes_this_iter: 11\n","  episodes_total: 1150\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8092231154441833\n","          entropy_coeff: 0.0\n","          kl: 0.013124820776283741\n","          model: {}\n","          policy_loss: -0.044750623404979706\n","          total_loss: 714.7303466796875\n","          vf_explained_var: 0.5114808082580566\n","          vf_loss: 714.7619018554688\n","    num_agent_steps_sampled: 420000\n","    num_agent_steps_trained: 420000\n","    num_steps_sampled: 420000\n","    num_steps_trained: 420000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 105\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.786666666666667\n","    ram_util_percent: 15.699999999999994\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07406717440489703\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1435303651079882\n","    mean_inference_ms: 0.7701642789782349\n","    mean_raw_obs_processing_ms: 0.11243838750979325\n","  time_since_restore: 1151.5986511707306\n","  time_this_iter_s: 10.236955642700195\n","  time_total_s: 1151.5986511707306\n","  timers:\n","    learn_throughput: 1607.396\n","    learn_time_ms: 2488.497\n","    load_throughput: 8957403.097\n","    load_time_ms: 0.447\n","    sample_throughput: 370.765\n","    sample_time_ms: 10788.511\n","    update_time_ms: 2.721\n","  timestamp: 1649864247\n","  timesteps_since_restore: 420000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 420000\n","  training_iteration: 105\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 524000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-37-29\n","  done: false\n","  episode_len_mean: 237.39\n","  episode_media: {}\n","  episode_reward_max: 317.23297094081\n","  episode_reward_mean: 260.2005543846604\n","  episode_reward_min: 32.27540302759769\n","  episodes_this_iter: 15\n","  episodes_total: 2017\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6147339940071106\n","          entropy_coeff: 0.0\n","          kl: 0.010484736412763596\n","          model: {}\n","          policy_loss: -0.010771744884550571\n","          total_loss: 159.45689392089844\n","          vf_explained_var: 0.6916049122810364\n","          vf_loss: 159.46568298339844\n","    num_agent_steps_sampled: 524000\n","    num_agent_steps_trained: 524000\n","    num_steps_sampled: 524000\n","    num_steps_trained: 524000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 131\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.36923076923077\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07490299861384947\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.597716381618993\n","    mean_inference_ms: 0.7586142116867285\n","    mean_raw_obs_processing_ms: 0.11265492417486421\n","  time_since_restore: 1145.6417346000671\n","  time_this_iter_s: 8.822848081588745\n","  time_total_s: 1145.6417346000671\n","  timers:\n","    learn_throughput: 1637.377\n","    learn_time_ms: 2442.932\n","    load_throughput: 9001618.199\n","    load_time_ms: 0.444\n","    sample_throughput: 489.556\n","    sample_time_ms: 8170.669\n","    update_time_ms: 2.873\n","  timestamp: 1649864249\n","  timesteps_since_restore: 524000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 524000\n","  training_iteration: 131\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 620000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-37-29\n","  done: false\n","  episode_len_mean: 132.3\n","  episode_media: {}\n","  episode_reward_max: -238.97919974101893\n","  episode_reward_mean: -438.4448421786793\n","  episode_reward_min: -1011.130509211377\n","  episodes_this_iter: 34\n","  episodes_total: 5247\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 80489842999296.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.2787174880504608\n","          entropy_coeff: 0.0\n","          kl: 0.08671288937330246\n","          model: {}\n","          policy_loss: 0.020520417019724846\n","          total_loss: 6979505881088.0\n","          vf_explained_var: 0.7952251434326172\n","          vf_loss: 1143.7711181640625\n","    num_agent_steps_sampled: 620000\n","    num_agent_steps_trained: 620000\n","    num_steps_sampled: 620000\n","    num_steps_trained: 620000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 155\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.172727272727274\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07051865352726855\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.29407438197016567\n","    mean_inference_ms: 0.7279923466019962\n","    mean_raw_obs_processing_ms: 0.1126494672348775\n","  time_since_restore: 1152.1100935935974\n","  time_this_iter_s: 7.541316032409668\n","  time_total_s: 1152.1100935935974\n","  timers:\n","    learn_throughput: 1606.896\n","    learn_time_ms: 2489.271\n","    load_throughput: 9532509.091\n","    load_time_ms: 0.42\n","    sample_throughput: 521.931\n","    sample_time_ms: 7663.852\n","    update_time_ms: 2.752\n","  timestamp: 1649864249\n","  timesteps_since_restore: 620000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 620000\n","  training_iteration: 155\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:37:30 (running for 00:19:41.12)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   155</td><td style=\"text-align: right;\">         1152.11</td><td style=\"text-align: right;\">620000</td><td style=\"text-align: right;\">-438.445 </td><td style=\"text-align: right;\">            -238.979</td><td style=\"text-align: right;\">          -1011.13  </td><td style=\"text-align: right;\">            132.3 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         1151.6 </td><td style=\"text-align: right;\">420000</td><td style=\"text-align: right;\">  42.7433</td><td style=\"text-align: right;\">             268.299</td><td style=\"text-align: right;\">           -260.514 </td><td style=\"text-align: right;\">            480.09</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   131</td><td style=\"text-align: right;\">         1145.64</td><td style=\"text-align: right;\">524000</td><td style=\"text-align: right;\"> 260.201 </td><td style=\"text-align: right;\">             317.233</td><td style=\"text-align: right;\">             32.2754</td><td style=\"text-align: right;\">            237.39</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:37:36 (running for 00:19:46.22)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   155</td><td style=\"text-align: right;\">         1152.11</td><td style=\"text-align: right;\">620000</td><td style=\"text-align: right;\">-438.445 </td><td style=\"text-align: right;\">            -238.979</td><td style=\"text-align: right;\">          -1011.13  </td><td style=\"text-align: right;\">            132.3 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         1151.6 </td><td style=\"text-align: right;\">420000</td><td style=\"text-align: right;\">  42.7433</td><td style=\"text-align: right;\">             268.299</td><td style=\"text-align: right;\">           -260.514 </td><td style=\"text-align: right;\">            480.09</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   131</td><td style=\"text-align: right;\">         1145.64</td><td style=\"text-align: right;\">524000</td><td style=\"text-align: right;\"> 260.201 </td><td style=\"text-align: right;\">             317.233</td><td style=\"text-align: right;\">             32.2754</td><td style=\"text-align: right;\">            237.39</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 624000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-37-37\n","  done: false\n","  episode_len_mean: 133.53\n","  episode_media: {}\n","  episode_reward_max: -228.04850141673552\n","  episode_reward_mean: -410.57730574815207\n","  episode_reward_min: -892.8782475680125\n","  episodes_this_iter: 31\n","  episodes_total: 5278\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 120734768693248.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.3824313282966614\n","          entropy_coeff: 0.0\n","          kl: 0.07142709940671921\n","          model: {}\n","          policy_loss: 0.03737263381481171\n","          total_loss: 8623734390784.0\n","          vf_explained_var: 0.7491543292999268\n","          vf_loss: 961.1747436523438\n","    num_agent_steps_sampled: 624000\n","    num_agent_steps_trained: 624000\n","    num_steps_sampled: 624000\n","    num_steps_trained: 624000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 156\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.120000000000001\n","    ram_util_percent: 15.699999999999998\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07050641505309484\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2942032728700648\n","    mean_inference_ms: 0.7279015907382411\n","    mean_raw_obs_processing_ms: 0.11262992566779303\n","  time_since_restore: 1159.285868883133\n","  time_this_iter_s: 7.1757752895355225\n","  time_total_s: 1159.285868883133\n","  timers:\n","    learn_throughput: 1608.822\n","    learn_time_ms: 2486.291\n","    load_throughput: 9558577.94\n","    load_time_ms: 0.418\n","    sample_throughput: 526.241\n","    sample_time_ms: 7601.074\n","    update_time_ms: 2.765\n","  timestamp: 1649864257\n","  timesteps_since_restore: 624000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 624000\n","  training_iteration: 156\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 528000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-37-37\n","  done: false\n","  episode_len_mean: 237.44\n","  episode_media: {}\n","  episode_reward_max: 317.23297094081\n","  episode_reward_mean: 258.51006821731073\n","  episode_reward_min: -132.91181781972855\n","  episodes_this_iter: 21\n","  episodes_total: 2038\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5768885612487793\n","          entropy_coeff: 0.0\n","          kl: 0.005934278480708599\n","          model: {}\n","          policy_loss: -0.012641172856092453\n","          total_loss: 795.987548828125\n","          vf_explained_var: 0.7717480659484863\n","          vf_loss: 795.9991455078125\n","    num_agent_steps_sampled: 528000\n","    num_agent_steps_trained: 528000\n","    num_steps_sampled: 528000\n","    num_steps_trained: 528000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 132\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.172727272727274\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07489866614504292\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5969520891677246\n","    mean_inference_ms: 0.7584870845465156\n","    mean_raw_obs_processing_ms: 0.1126430050664768\n","  time_since_restore: 1153.261732339859\n","  time_this_iter_s: 7.61999773979187\n","  time_total_s: 1153.261732339859\n","  timers:\n","    learn_throughput: 1636.43\n","    learn_time_ms: 2444.346\n","    load_throughput: 8706843.116\n","    load_time_ms: 0.459\n","    sample_throughput: 491.153\n","    sample_time_ms: 8144.098\n","    update_time_ms: 2.87\n","  timestamp: 1649864257\n","  timesteps_since_restore: 528000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 528000\n","  training_iteration: 132\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 424000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-37-38\n","  done: false\n","  episode_len_mean: 477.53\n","  episode_media: {}\n","  episode_reward_max: 268.2990697424575\n","  episode_reward_mean: 38.729340195921\n","  episode_reward_min: -286.3958640007147\n","  episodes_this_iter: 11\n","  episodes_total: 1161\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8154944181442261\n","          entropy_coeff: 0.0\n","          kl: 0.016355592757463455\n","          model: {}\n","          policy_loss: -0.04348026216030121\n","          total_loss: 900.9645385742188\n","          vf_explained_var: 0.502638578414917\n","          vf_loss: 900.9913940429688\n","    num_agent_steps_sampled: 424000\n","    num_agent_steps_trained: 424000\n","    num_steps_sampled: 424000\n","    num_steps_trained: 424000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 106\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.8125\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0740729569016114\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1429176727351924\n","    mean_inference_ms: 0.7702161224875784\n","    mean_raw_obs_processing_ms: 0.11243741310795638\n","  time_since_restore: 1162.7614681720734\n","  time_this_iter_s: 11.162817001342773\n","  time_total_s: 1162.7614681720734\n","  timers:\n","    learn_throughput: 1620.007\n","    learn_time_ms: 2469.125\n","    load_throughput: 8719966.736\n","    load_time_ms: 0.459\n","    sample_throughput: 370.308\n","    sample_time_ms: 10801.824\n","    update_time_ms: 2.676\n","  timestamp: 1649864258\n","  timesteps_since_restore: 424000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 424000\n","  training_iteration: 106\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:37:41 (running for 00:19:52.16)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   156</td><td style=\"text-align: right;\">         1159.29</td><td style=\"text-align: right;\">624000</td><td style=\"text-align: right;\">-410.577 </td><td style=\"text-align: right;\">            -228.049</td><td style=\"text-align: right;\">            -892.878</td><td style=\"text-align: right;\">            133.53</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   106</td><td style=\"text-align: right;\">         1162.76</td><td style=\"text-align: right;\">424000</td><td style=\"text-align: right;\">  38.7293</td><td style=\"text-align: right;\">             268.299</td><td style=\"text-align: right;\">            -286.396</td><td style=\"text-align: right;\">            477.53</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   132</td><td style=\"text-align: right;\">         1153.26</td><td style=\"text-align: right;\">528000</td><td style=\"text-align: right;\"> 258.51  </td><td style=\"text-align: right;\">             317.233</td><td style=\"text-align: right;\">            -132.912</td><td style=\"text-align: right;\">            237.44</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 628000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-37-44\n","  done: false\n","  episode_len_mean: 127.05\n","  episode_media: {}\n","  episode_reward_max: -228.04850141673552\n","  episode_reward_mean: -453.15818005844466\n","  episode_reward_min: -1194.579024074987\n","  episodes_this_iter: 31\n","  episodes_total: 5309\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 181102144651264.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.2461743801832199\n","          entropy_coeff: 0.0\n","          kl: 0.2400602549314499\n","          model: {}\n","          policy_loss: 0.0504845529794693\n","          total_loss: 43475433160704.0\n","          vf_explained_var: 0.6621168851852417\n","          vf_loss: 2852.183837890625\n","    num_agent_steps_sampled: 628000\n","    num_agent_steps_trained: 628000\n","    num_steps_sampled: 628000\n","    num_steps_trained: 628000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 157\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.045454545454545\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07049487054056044\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2943401091833772\n","    mean_inference_ms: 0.7278018922876436\n","    mean_raw_obs_processing_ms: 0.11261500494294932\n","  time_since_restore: 1166.8197720050812\n","  time_this_iter_s: 7.533903121948242\n","  time_total_s: 1166.8197720050812\n","  timers:\n","    learn_throughput: 1608.594\n","    learn_time_ms: 2486.643\n","    load_throughput: 9569482.09\n","    load_time_ms: 0.418\n","    sample_throughput: 528.585\n","    sample_time_ms: 7567.379\n","    update_time_ms: 2.757\n","  timestamp: 1649864264\n","  timesteps_since_restore: 628000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 628000\n","  training_iteration: 157\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 532000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-37-44\n","  done: false\n","  episode_len_mean: 238.04\n","  episode_media: {}\n","  episode_reward_max: 321.57628803721934\n","  episode_reward_mean: 258.73277123285897\n","  episode_reward_min: -132.91181781972855\n","  episodes_this_iter: 20\n","  episodes_total: 2058\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5439887046813965\n","          entropy_coeff: 0.0\n","          kl: 0.006769159808754921\n","          model: {}\n","          policy_loss: -0.01722250133752823\n","          total_loss: 346.0511474609375\n","          vf_explained_var: 0.669113039970398\n","          vf_loss: 346.06707763671875\n","    num_agent_steps_sampled: 532000\n","    num_agent_steps_trained: 532000\n","    num_steps_sampled: 532000\n","    num_steps_trained: 532000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 133\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.500000000000002\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07489252407712269\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5962331070055725\n","    mean_inference_ms: 0.7583133648880042\n","    mean_raw_obs_processing_ms: 0.11262987624095425\n","  time_since_restore: 1160.9654490947723\n","  time_this_iter_s: 7.70371675491333\n","  time_total_s: 1160.9654490947723\n","  timers:\n","    learn_throughput: 1638.275\n","    learn_time_ms: 2441.593\n","    load_throughput: 8432456.775\n","    load_time_ms: 0.474\n","    sample_throughput: 492.173\n","    sample_time_ms: 8127.225\n","    update_time_ms: 2.796\n","  timestamp: 1649864264\n","  timesteps_since_restore: 532000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 532000\n","  training_iteration: 133\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:37:47 (running for 00:19:57.27)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   157</td><td style=\"text-align: right;\">         1166.82</td><td style=\"text-align: right;\">628000</td><td style=\"text-align: right;\">-453.158 </td><td style=\"text-align: right;\">            -228.049</td><td style=\"text-align: right;\">           -1194.58 </td><td style=\"text-align: right;\">            127.05</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   106</td><td style=\"text-align: right;\">         1162.76</td><td style=\"text-align: right;\">424000</td><td style=\"text-align: right;\">  38.7293</td><td style=\"text-align: right;\">             268.299</td><td style=\"text-align: right;\">            -286.396</td><td style=\"text-align: right;\">            477.53</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   133</td><td style=\"text-align: right;\">         1160.97</td><td style=\"text-align: right;\">532000</td><td style=\"text-align: right;\"> 258.733 </td><td style=\"text-align: right;\">             321.576</td><td style=\"text-align: right;\">            -132.912</td><td style=\"text-align: right;\">            238.04</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 428000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-37-48\n","  done: false\n","  episode_len_mean: 440.65\n","  episode_media: {}\n","  episode_reward_max: 268.2990697424575\n","  episode_reward_mean: 29.761448586623768\n","  episode_reward_min: -361.0023318393476\n","  episodes_this_iter: 16\n","  episodes_total: 1177\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.7543486952781677\n","          entropy_coeff: 0.0\n","          kl: 0.016349876299500465\n","          model: {}\n","          policy_loss: -0.03179066255688667\n","          total_loss: 751.18115234375\n","          vf_explained_var: 0.5755226612091064\n","          vf_loss: 751.1963500976562\n","    num_agent_steps_sampled: 428000\n","    num_agent_steps_trained: 428000\n","    num_steps_sampled: 428000\n","    num_steps_trained: 428000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 107\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.935714285714285\n","    ram_util_percent: 15.699999999999994\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07408120073854643\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1416268092631932\n","    mean_inference_ms: 0.770270969769225\n","    mean_raw_obs_processing_ms: 0.1124378511747107\n","  time_since_restore: 1172.363200187683\n","  time_this_iter_s: 9.601732015609741\n","  time_total_s: 1172.363200187683\n","  timers:\n","    learn_throughput: 1622.934\n","    learn_time_ms: 2464.672\n","    load_throughput: 8739043.65\n","    load_time_ms: 0.458\n","    sample_throughput: 377.415\n","    sample_time_ms: 10598.425\n","    update_time_ms: 2.694\n","  timestamp: 1649864268\n","  timesteps_since_restore: 428000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 428000\n","  training_iteration: 107\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 632000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-37-52\n","  done: false\n","  episode_len_mean: 134.44\n","  episode_media: {}\n","  episode_reward_max: -228.04850141673552\n","  episode_reward_mean: -487.9426317020508\n","  episode_reward_min: -1194.579024074987\n","  episodes_this_iter: 26\n","  episodes_total: 5335\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 271653225365504.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.2939048111438751\n","          entropy_coeff: 0.0\n","          kl: 0.13088029623031616\n","          model: {}\n","          policy_loss: 0.03627192601561546\n","          total_loss: 35554058043392.0\n","          vf_explained_var: 0.4655316174030304\n","          vf_loss: 3649.45849609375\n","    num_agent_steps_sampled: 632000\n","    num_agent_steps_trained: 632000\n","    num_steps_sampled: 632000\n","    num_steps_trained: 632000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 158\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.01818181818182\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.070485302011215\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2945244092150164\n","    mean_inference_ms: 0.7276902943006383\n","    mean_raw_obs_processing_ms: 0.11260038374344017\n","  time_since_restore: 1174.4182405471802\n","  time_this_iter_s: 7.598468542098999\n","  time_total_s: 1174.4182405471802\n","  timers:\n","    learn_throughput: 1611.454\n","    learn_time_ms: 2482.23\n","    load_throughput: 9593559.012\n","    load_time_ms: 0.417\n","    sample_throughput: 528.335\n","    sample_time_ms: 7570.948\n","    update_time_ms: 2.819\n","  timestamp: 1649864272\n","  timesteps_since_restore: 632000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 632000\n","  training_iteration: 158\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:37:52 (running for 00:20:02.54)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   158</td><td style=\"text-align: right;\">         1174.42</td><td style=\"text-align: right;\">632000</td><td style=\"text-align: right;\">-487.943 </td><td style=\"text-align: right;\">            -228.049</td><td style=\"text-align: right;\">           -1194.58 </td><td style=\"text-align: right;\">            134.44</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         1172.36</td><td style=\"text-align: right;\">428000</td><td style=\"text-align: right;\">  29.7614</td><td style=\"text-align: right;\">             268.299</td><td style=\"text-align: right;\">            -361.002</td><td style=\"text-align: right;\">            440.65</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   133</td><td style=\"text-align: right;\">         1160.97</td><td style=\"text-align: right;\">532000</td><td style=\"text-align: right;\"> 258.733 </td><td style=\"text-align: right;\">             321.576</td><td style=\"text-align: right;\">            -132.912</td><td style=\"text-align: right;\">            238.04</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 536000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-37-53\n","  done: false\n","  episode_len_mean: 244.37\n","  episode_media: {}\n","  episode_reward_max: 321.57628803721934\n","  episode_reward_mean: 253.46129359969626\n","  episode_reward_min: -132.91181781972855\n","  episodes_this_iter: 13\n","  episodes_total: 2071\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6739542484283447\n","          entropy_coeff: 0.0\n","          kl: 0.01961919106543064\n","          model: {}\n","          policy_loss: -0.01928986795246601\n","          total_loss: 656.6522827148438\n","          vf_explained_var: 0.54324871301651\n","          vf_loss: 656.6677856445312\n","    num_agent_steps_sampled: 536000\n","    num_agent_steps_trained: 536000\n","    num_steps_sampled: 536000\n","    num_steps_trained: 536000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 134\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.108333333333334\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07488926293416891\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.595884538240145\n","    mean_inference_ms: 0.7582144814700377\n","    mean_raw_obs_processing_ms: 0.11262183837823596\n","  time_since_restore: 1169.8082556724548\n","  time_this_iter_s: 8.842806577682495\n","  time_total_s: 1169.8082556724548\n","  timers:\n","    learn_throughput: 1637.458\n","    learn_time_ms: 2442.811\n","    load_throughput: 8429067.524\n","    load_time_ms: 0.475\n","    sample_throughput: 486.071\n","    sample_time_ms: 8229.255\n","    update_time_ms: 2.763\n","  timestamp: 1649864273\n","  timesteps_since_restore: 536000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 536000\n","  training_iteration: 134\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:37:57 (running for 00:20:08.17)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   158</td><td style=\"text-align: right;\">         1174.42</td><td style=\"text-align: right;\">632000</td><td style=\"text-align: right;\">-487.943 </td><td style=\"text-align: right;\">            -228.049</td><td style=\"text-align: right;\">           -1194.58 </td><td style=\"text-align: right;\">            134.44</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         1172.36</td><td style=\"text-align: right;\">428000</td><td style=\"text-align: right;\">  29.7614</td><td style=\"text-align: right;\">             268.299</td><td style=\"text-align: right;\">            -361.002</td><td style=\"text-align: right;\">            440.65</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   134</td><td style=\"text-align: right;\">         1169.81</td><td style=\"text-align: right;\">536000</td><td style=\"text-align: right;\"> 253.461 </td><td style=\"text-align: right;\">             321.576</td><td style=\"text-align: right;\">            -132.912</td><td style=\"text-align: right;\">            244.37</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 432000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-37-59\n","  done: false\n","  episode_len_mean: 397.75\n","  episode_media: {}\n","  episode_reward_max: 268.2990697424575\n","  episode_reward_mean: 19.351377341195597\n","  episode_reward_min: -361.0023318393476\n","  episodes_this_iter: 12\n","  episodes_total: 1189\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8258073925971985\n","          entropy_coeff: 0.0\n","          kl: 0.01630862057209015\n","          model: {}\n","          policy_loss: -0.047946155071258545\n","          total_loss: 1167.7701416015625\n","          vf_explained_var: 0.48018503189086914\n","          vf_loss: 1167.8016357421875\n","    num_agent_steps_sampled: 432000\n","    num_agent_steps_trained: 432000\n","    num_steps_sampled: 432000\n","    num_steps_trained: 432000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 108\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.42666666666667\n","    ram_util_percent: 15.699999999999994\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0740819307999514\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.140589381936409\n","    mean_inference_ms: 0.7702355079152948\n","    mean_raw_obs_processing_ms: 0.11243127106479488\n","  time_since_restore: 1182.960342168808\n","  time_this_iter_s: 10.597141981124878\n","  time_total_s: 1182.960342168808\n","  timers:\n","    learn_throughput: 1629.132\n","    learn_time_ms: 2455.295\n","    load_throughput: 8781124.254\n","    load_time_ms: 0.456\n","    sample_throughput: 376.188\n","    sample_time_ms: 10632.969\n","    update_time_ms: 2.678\n","  timestamp: 1649864279\n","  timesteps_since_restore: 432000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 432000\n","  training_iteration: 108\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 636000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-37-59\n","  done: false\n","  episode_len_mean: 135.11\n","  episode_media: {}\n","  episode_reward_max: -228.04850141673552\n","  episode_reward_mean: -503.7660650340035\n","  episode_reward_min: -1194.579024074987\n","  episodes_this_iter: 31\n","  episodes_total: 5366\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 407479821271040.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.3031219244003296\n","          entropy_coeff: 0.0\n","          kl: 0.2178734391927719\n","          model: {}\n","          policy_loss: 0.0365411639213562\n","          total_loss: 88779037605888.0\n","          vf_explained_var: 0.7173775434494019\n","          vf_loss: 938.999755859375\n","    num_agent_steps_sampled: 636000\n","    num_agent_steps_trained: 636000\n","    num_steps_sampled: 636000\n","    num_steps_trained: 636000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 159\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.86\n","    ram_util_percent: 15.699999999999998\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07047399680399158\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.29476138287315995\n","    mean_inference_ms: 0.7275439566026407\n","    mean_raw_obs_processing_ms: 0.11258320999166478\n","  time_since_restore: 1181.710731267929\n","  time_this_iter_s: 7.292490720748901\n","  time_total_s: 1181.710731267929\n","  timers:\n","    learn_throughput: 1605.407\n","    learn_time_ms: 2491.58\n","    load_throughput: 9467954.853\n","    load_time_ms: 0.422\n","    sample_throughput: 530.214\n","    sample_time_ms: 7544.123\n","    update_time_ms: 2.789\n","  timestamp: 1649864279\n","  timesteps_since_restore: 636000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 636000\n","  training_iteration: 159\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 540000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-38-01\n","  done: false\n","  episode_len_mean: 238.3\n","  episode_media: {}\n","  episode_reward_max: 321.57628803721934\n","  episode_reward_mean: 256.9448677827552\n","  episode_reward_min: -132.91181781972855\n","  episodes_this_iter: 19\n","  episodes_total: 2090\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5637082457542419\n","          entropy_coeff: 0.0\n","          kl: 0.008109906688332558\n","          model: {}\n","          policy_loss: -0.023534897714853287\n","          total_loss: 100.457763671875\n","          vf_explained_var: 0.7578338384628296\n","          vf_loss: 100.47976684570312\n","    num_agent_steps_sampled: 540000\n","    num_agent_steps_trained: 540000\n","    num_steps_sampled: 540000\n","    num_steps_trained: 540000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 135\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.090909090909092\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07488509198466092\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5951682301043607\n","    mean_inference_ms: 0.7580686496624641\n","    mean_raw_obs_processing_ms: 0.11261172122924851\n","  time_since_restore: 1177.5622808933258\n","  time_this_iter_s: 7.754025220870972\n","  time_total_s: 1177.5622808933258\n","  timers:\n","    learn_throughput: 1635.815\n","    learn_time_ms: 2445.265\n","    load_throughput: 8136774.819\n","    load_time_ms: 0.492\n","    sample_throughput: 486.046\n","    sample_time_ms: 8229.672\n","    update_time_ms: 2.719\n","  timestamp: 1649864281\n","  timesteps_since_restore: 540000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 540000\n","  training_iteration: 135\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:38:03 (running for 00:20:13.87)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   159</td><td style=\"text-align: right;\">         1181.71</td><td style=\"text-align: right;\">636000</td><td style=\"text-align: right;\">-503.766 </td><td style=\"text-align: right;\">            -228.049</td><td style=\"text-align: right;\">           -1194.58 </td><td style=\"text-align: right;\">            135.11</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         1182.96</td><td style=\"text-align: right;\">432000</td><td style=\"text-align: right;\">  19.3514</td><td style=\"text-align: right;\">             268.299</td><td style=\"text-align: right;\">            -361.002</td><td style=\"text-align: right;\">            397.75</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   135</td><td style=\"text-align: right;\">         1177.56</td><td style=\"text-align: right;\">540000</td><td style=\"text-align: right;\"> 256.945 </td><td style=\"text-align: right;\">             321.576</td><td style=\"text-align: right;\">            -132.912</td><td style=\"text-align: right;\">            238.3 </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 640000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-38-07\n","  done: false\n","  episode_len_mean: 135.59\n","  episode_media: {}\n","  episode_reward_max: -246.20686465460162\n","  episode_reward_mean: -504.10651812420286\n","  episode_reward_min: -1228.2469590637807\n","  episodes_this_iter: 32\n","  episodes_total: 5398\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 611219748683776.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.35875678062438965\n","          entropy_coeff: 0.0\n","          kl: 0.11685829609632492\n","          model: {}\n","          policy_loss: 0.028871437534689903\n","          total_loss: 71426103050240.0\n","          vf_explained_var: 0.7955310344696045\n","          vf_loss: 643.9658203125\n","    num_agent_steps_sampled: 640000\n","    num_agent_steps_trained: 640000\n","    num_steps_sampled: 640000\n","    num_steps_trained: 640000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 160\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.263636363636362\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07046843288590413\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.29502759949810925\n","    mean_inference_ms: 0.7274695271233452\n","    mean_raw_obs_processing_ms: 0.11257233808542855\n","  time_since_restore: 1189.241107225418\n","  time_this_iter_s: 7.530375957489014\n","  time_total_s: 1189.241107225418\n","  timers:\n","    learn_throughput: 1608.262\n","    learn_time_ms: 2487.157\n","    load_throughput: 9159868.967\n","    load_time_ms: 0.437\n","    sample_throughput: 529.52\n","    sample_time_ms: 7554.01\n","    update_time_ms: 2.787\n","  timestamp: 1649864287\n","  timesteps_since_restore: 640000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 640000\n","  training_iteration: 160\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:38:09 (running for 00:20:19.53)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1189.24</td><td style=\"text-align: right;\">640000</td><td style=\"text-align: right;\">-504.107 </td><td style=\"text-align: right;\">            -246.207</td><td style=\"text-align: right;\">           -1228.25 </td><td style=\"text-align: right;\">            135.59</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         1182.96</td><td style=\"text-align: right;\">432000</td><td style=\"text-align: right;\">  19.3514</td><td style=\"text-align: right;\">             268.299</td><td style=\"text-align: right;\">            -361.002</td><td style=\"text-align: right;\">            397.75</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   135</td><td style=\"text-align: right;\">         1177.56</td><td style=\"text-align: right;\">540000</td><td style=\"text-align: right;\"> 256.945 </td><td style=\"text-align: right;\">             321.576</td><td style=\"text-align: right;\">            -132.912</td><td style=\"text-align: right;\">            238.3 </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 436000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-38-09\n","  done: false\n","  episode_len_mean: 389.5\n","  episode_media: {}\n","  episode_reward_max: 268.2990697424575\n","  episode_reward_mean: 22.066575152064683\n","  episode_reward_min: -361.0023318393476\n","  episodes_this_iter: 7\n","  episodes_total: 1196\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8255524635314941\n","          entropy_coeff: 0.0\n","          kl: 0.011998739093542099\n","          model: {}\n","          policy_loss: -0.042062822729349136\n","          total_loss: 98.83177185058594\n","          vf_explained_var: 0.6197894811630249\n","          vf_loss: 98.86168670654297\n","    num_agent_steps_sampled: 436000\n","    num_agent_steps_trained: 436000\n","    num_steps_sampled: 436000\n","    num_steps_trained: 436000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 109\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.546666666666663\n","    ram_util_percent: 15.699999999999994\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07408090816496016\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.139877910221826\n","    mean_inference_ms: 0.7701905194649933\n","    mean_raw_obs_processing_ms: 0.11242541573857112\n","  time_since_restore: 1193.6235961914062\n","  time_this_iter_s: 10.663254022598267\n","  time_total_s: 1193.6235961914062\n","  timers:\n","    learn_throughput: 1632.992\n","    learn_time_ms: 2449.492\n","    load_throughput: 8742686.816\n","    load_time_ms: 0.458\n","    sample_throughput: 381.11\n","    sample_time_ms: 10495.667\n","    update_time_ms: 2.686\n","  timestamp: 1649864289\n","  timesteps_since_restore: 436000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 436000\n","  training_iteration: 109\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 544000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-38-10\n","  done: false\n","  episode_len_mean: 238.58\n","  episode_media: {}\n","  episode_reward_max: 321.57628803721934\n","  episode_reward_mean: 254.50639120224457\n","  episode_reward_min: -132.91181781972855\n","  episodes_this_iter: 12\n","  episodes_total: 2102\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5995579361915588\n","          entropy_coeff: 0.0\n","          kl: 0.008336127735674381\n","          model: {}\n","          policy_loss: -0.014340043067932129\n","          total_loss: 470.5233459472656\n","          vf_explained_var: 0.5353901982307434\n","          vf_loss: 470.5361022949219\n","    num_agent_steps_sampled: 544000\n","    num_agent_steps_trained: 544000\n","    num_steps_sampled: 544000\n","    num_steps_trained: 544000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 136\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.261538461538462\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07488062179860454\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5947159764728072\n","    mean_inference_ms: 0.7579667033344398\n","    mean_raw_obs_processing_ms: 0.11260340972550381\n","  time_since_restore: 1186.4540264606476\n","  time_this_iter_s: 8.891745567321777\n","  time_total_s: 1186.4540264606476\n","  timers:\n","    learn_throughput: 1638.529\n","    learn_time_ms: 2441.214\n","    load_throughput: 8191200.078\n","    load_time_ms: 0.488\n","    sample_throughput: 478.783\n","    sample_time_ms: 8354.519\n","    update_time_ms: 2.732\n","  timestamp: 1649864290\n","  timesteps_since_restore: 544000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 544000\n","  training_iteration: 136\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:38:14 (running for 00:20:24.80)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1189.24</td><td style=\"text-align: right;\">640000</td><td style=\"text-align: right;\">-504.107 </td><td style=\"text-align: right;\">            -246.207</td><td style=\"text-align: right;\">           -1228.25 </td><td style=\"text-align: right;\">            135.59</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         1193.62</td><td style=\"text-align: right;\">436000</td><td style=\"text-align: right;\">  22.0666</td><td style=\"text-align: right;\">             268.299</td><td style=\"text-align: right;\">            -361.002</td><td style=\"text-align: right;\">            389.5 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   136</td><td style=\"text-align: right;\">         1186.45</td><td style=\"text-align: right;\">544000</td><td style=\"text-align: right;\"> 254.506 </td><td style=\"text-align: right;\">             321.576</td><td style=\"text-align: right;\">            -132.912</td><td style=\"text-align: right;\">            238.58</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 644000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-38-14\n","  done: false\n","  episode_len_mean: 124.15\n","  episode_media: {}\n","  episode_reward_max: -233.67951235959384\n","  episode_reward_mean: -471.07904821057446\n","  episode_reward_min: -1228.2469590637807\n","  episodes_this_iter: 36\n","  episodes_total: 5434\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 916829623025664.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.19110211730003357\n","          entropy_coeff: 0.0\n","          kl: 0.17344695329666138\n","          model: {}\n","          policy_loss: 0.027749203145503998\n","          total_loss: 159021298352128.0\n","          vf_explained_var: 0.8183183073997498\n","          vf_loss: 1120.298095703125\n","    num_agent_steps_sampled: 644000\n","    num_agent_steps_trained: 644000\n","    num_steps_sampled: 644000\n","    num_steps_trained: 644000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 161\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.109090909090908\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07046653507779452\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.295227498824195\n","    mean_inference_ms: 0.7274405680589712\n","    mean_raw_obs_processing_ms: 0.11257242921470766\n","  time_since_restore: 1196.731620311737\n","  time_this_iter_s: 7.49051308631897\n","  time_total_s: 1196.731620311737\n","  timers:\n","    learn_throughput: 1606.163\n","    learn_time_ms: 2490.408\n","    load_throughput: 9130954.61\n","    load_time_ms: 0.438\n","    sample_throughput: 531.326\n","    sample_time_ms: 7528.337\n","    update_time_ms: 2.793\n","  timestamp: 1649864294\n","  timesteps_since_restore: 644000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 644000\n","  training_iteration: 161\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:38:19 (running for 00:20:30.06)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   161</td><td style=\"text-align: right;\">         1196.73</td><td style=\"text-align: right;\">644000</td><td style=\"text-align: right;\">-471.079 </td><td style=\"text-align: right;\">            -233.68 </td><td style=\"text-align: right;\">           -1228.25 </td><td style=\"text-align: right;\">            124.15</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         1193.62</td><td style=\"text-align: right;\">436000</td><td style=\"text-align: right;\">  22.0666</td><td style=\"text-align: right;\">             268.299</td><td style=\"text-align: right;\">            -361.002</td><td style=\"text-align: right;\">            389.5 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   136</td><td style=\"text-align: right;\">         1186.45</td><td style=\"text-align: right;\">544000</td><td style=\"text-align: right;\"> 254.506 </td><td style=\"text-align: right;\">             321.576</td><td style=\"text-align: right;\">            -132.912</td><td style=\"text-align: right;\">            238.58</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 548000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-38-20\n","  done: false\n","  episode_len_mean: 258.86\n","  episode_media: {}\n","  episode_reward_max: 321.57628803721934\n","  episode_reward_mean: 249.9535328429417\n","  episode_reward_min: -132.91181781972855\n","  episodes_this_iter: 10\n","  episodes_total: 2112\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6814538240432739\n","          entropy_coeff: 0.0\n","          kl: 0.008997275494039059\n","          model: {}\n","          policy_loss: -0.0019398318836465478\n","          total_loss: 371.96173095703125\n","          vf_explained_var: 0.36346161365509033\n","          vf_loss: 371.96197509765625\n","    num_agent_steps_sampled: 548000\n","    num_agent_steps_trained: 548000\n","    num_steps_sampled: 548000\n","    num_steps_trained: 548000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 137\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.457142857142856\n","    ram_util_percent: 15.699999999999994\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07487699795581101\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5945473522096755\n","    mean_inference_ms: 0.7578848771588388\n","    mean_raw_obs_processing_ms: 0.11259464776330402\n","  time_since_restore: 1196.4124162197113\n","  time_this_iter_s: 9.95838975906372\n","  time_total_s: 1196.4124162197113\n","  timers:\n","    learn_throughput: 1633.205\n","    learn_time_ms: 2449.172\n","    load_throughput: 8090083.904\n","    load_time_ms: 0.494\n","    sample_throughput: 467.635\n","    sample_time_ms: 8553.685\n","    update_time_ms: 2.771\n","  timestamp: 1649864300\n","  timesteps_since_restore: 548000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 548000\n","  training_iteration: 137\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 440000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-38-20\n","  done: false\n","  episode_len_mean: 380.44\n","  episode_media: {}\n","  episode_reward_max: 268.2990697424575\n","  episode_reward_mean: 19.464332329152256\n","  episode_reward_min: -361.0023318393476\n","  episodes_this_iter: 7\n","  episodes_total: 1203\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8334620594978333\n","          entropy_coeff: 0.0\n","          kl: 0.01320827566087246\n","          model: {}\n","          policy_loss: -0.04200993478298187\n","          total_loss: 134.81820678710938\n","          vf_explained_var: 0.6023989915847778\n","          vf_loss: 134.8468475341797\n","    num_agent_steps_sampled: 440000\n","    num_agent_steps_trained: 440000\n","    num_steps_sampled: 440000\n","    num_steps_trained: 440000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 110\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.625\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07407859973856855\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1391572756085515\n","    mean_inference_ms: 0.7701341521726883\n","    mean_raw_obs_processing_ms: 0.11241824769139598\n","  time_since_restore: 1204.316088438034\n","  time_this_iter_s: 10.692492246627808\n","  time_total_s: 1204.316088438034\n","  timers:\n","    learn_throughput: 1630.229\n","    learn_time_ms: 2453.643\n","    load_throughput: 8774694.561\n","    load_time_ms: 0.456\n","    sample_throughput: 382.593\n","    sample_time_ms: 10454.986\n","    update_time_ms: 2.694\n","  timestamp: 1649864300\n","  timesteps_since_restore: 440000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 440000\n","  training_iteration: 110\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 648000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-38-22\n","  done: false\n","  episode_len_mean: 124.63\n","  episode_media: {}\n","  episode_reward_max: -233.67951235959384\n","  episode_reward_mean: -458.92042987483745\n","  episode_reward_min: -1228.2469590637807\n","  episodes_this_iter: 30\n","  episodes_total: 5464\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1375244501647360.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.2787952125072479\n","          entropy_coeff: 0.0\n","          kl: 0.19307595491409302\n","          model: {}\n","          policy_loss: 0.037213034927845\n","          total_loss: 265526622289920.0\n","          vf_explained_var: 0.6287167072296143\n","          vf_loss: 1692.952880859375\n","    num_agent_steps_sampled: 648000\n","    num_agent_steps_trained: 648000\n","    num_steps_sampled: 648000\n","    num_steps_trained: 648000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 162\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.30909090909091\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07047102811463164\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2953691254499141\n","    mean_inference_ms: 0.7274793095999053\n","    mean_raw_obs_processing_ms: 0.11258150323656053\n","  time_since_restore: 1204.1868164539337\n","  time_this_iter_s: 7.455196142196655\n","  time_total_s: 1204.1868164539337\n","  timers:\n","    learn_throughput: 1610.433\n","    learn_time_ms: 2483.804\n","    load_throughput: 9103209.984\n","    load_time_ms: 0.439\n","    sample_throughput: 533.323\n","    sample_time_ms: 7500.139\n","    update_time_ms: 2.798\n","  timestamp: 1649864302\n","  timesteps_since_restore: 648000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 648000\n","  training_iteration: 162\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:38:25 (running for 00:20:35.45)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   162</td><td style=\"text-align: right;\">         1204.19</td><td style=\"text-align: right;\">648000</td><td style=\"text-align: right;\">-458.92  </td><td style=\"text-align: right;\">            -233.68 </td><td style=\"text-align: right;\">           -1228.25 </td><td style=\"text-align: right;\">            124.63</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   110</td><td style=\"text-align: right;\">         1204.32</td><td style=\"text-align: right;\">440000</td><td style=\"text-align: right;\">  19.4643</td><td style=\"text-align: right;\">             268.299</td><td style=\"text-align: right;\">            -361.002</td><td style=\"text-align: right;\">            380.44</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   137</td><td style=\"text-align: right;\">         1196.41</td><td style=\"text-align: right;\">548000</td><td style=\"text-align: right;\"> 249.954 </td><td style=\"text-align: right;\">             321.576</td><td style=\"text-align: right;\">            -132.912</td><td style=\"text-align: right;\">            258.86</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 552000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-38-28\n","  done: false\n","  episode_len_mean: 256.37\n","  episode_media: {}\n","  episode_reward_max: 321.57628803721934\n","  episode_reward_mean: 257.9925970149201\n","  episode_reward_min: -23.0426052342778\n","  episodes_this_iter: 17\n","  episodes_total: 2129\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5305915474891663\n","          entropy_coeff: 0.0\n","          kl: 0.006156296003609896\n","          model: {}\n","          policy_loss: -0.009185263887047768\n","          total_loss: 183.74989318847656\n","          vf_explained_var: 0.6455053091049194\n","          vf_loss: 183.75790405273438\n","    num_agent_steps_sampled: 552000\n","    num_agent_steps_trained: 552000\n","    num_steps_sampled: 552000\n","    num_steps_trained: 552000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 138\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.7\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07486936966974313\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5942432936613686\n","    mean_inference_ms: 0.7577403738129803\n","    mean_raw_obs_processing_ms: 0.11257669645018162\n","  time_since_restore: 1204.1635036468506\n","  time_this_iter_s: 7.751087427139282\n","  time_total_s: 1204.1635036468506\n","  timers:\n","    learn_throughput: 1631.138\n","    learn_time_ms: 2452.275\n","    load_throughput: 8077230.754\n","    load_time_ms: 0.495\n","    sample_throughput: 470.238\n","    sample_time_ms: 8506.337\n","    update_time_ms: 2.759\n","  timestamp: 1649864308\n","  timesteps_since_restore: 552000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 552000\n","  training_iteration: 138\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 652000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-38-29\n","  done: false\n","  episode_len_mean: 126.04\n","  episode_media: {}\n","  episode_reward_max: -233.67951235959384\n","  episode_reward_mean: -458.9025988115346\n","  episode_reward_min: -996.2540055124615\n","  episodes_this_iter: 28\n","  episodes_total: 5492\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 2062866618253312.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.27764731645584106\n","          entropy_coeff: 0.0\n","          kl: 0.17791786789894104\n","          model: {}\n","          policy_loss: 0.038256995379924774\n","          total_loss: 367020826689536.0\n","          vf_explained_var: 0.6114410161972046\n","          vf_loss: 2004.84326171875\n","    num_agent_steps_sampled: 652000\n","    num_agent_steps_trained: 652000\n","    num_steps_sampled: 652000\n","    num_steps_trained: 652000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 163\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.839999999999998\n","    ram_util_percent: 15.699999999999998\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07046994221519963\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.29554360028472937\n","    mean_inference_ms: 0.7274482477772287\n","    mean_raw_obs_processing_ms: 0.11258197774660637\n","  time_since_restore: 1211.7752175331116\n","  time_this_iter_s: 7.5884010791778564\n","  time_total_s: 1211.7752175331116\n","  timers:\n","    learn_throughput: 1598.821\n","    learn_time_ms: 2501.844\n","    load_throughput: 9201061.753\n","    load_time_ms: 0.435\n","    sample_throughput: 533.937\n","    sample_time_ms: 7491.521\n","    update_time_ms: 2.838\n","  timestamp: 1649864309\n","  timesteps_since_restore: 652000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 652000\n","  training_iteration: 163\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 444000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-38-30\n","  done: false\n","  episode_len_mean: 377.48\n","  episode_media: {}\n","  episode_reward_max: 278.44570431138135\n","  episode_reward_mean: 26.850195573819303\n","  episode_reward_min: -361.0023318393476\n","  episodes_this_iter: 11\n","  episodes_total: 1214\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.748084545135498\n","          entropy_coeff: 0.0\n","          kl: 0.013330847956240177\n","          model: {}\n","          policy_loss: -0.0429006963968277\n","          total_loss: 548.6760864257812\n","          vf_explained_var: 0.5015696287155151\n","          vf_loss: 548.7054443359375\n","    num_agent_steps_sampled: 444000\n","    num_agent_steps_trained: 444000\n","    num_steps_sampled: 444000\n","    num_steps_trained: 444000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 111\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.592857142857142\n","    ram_util_percent: 15.699999999999994\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07407353256642818\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1380339875927288\n","    mean_inference_ms: 0.7700314562884055\n","    mean_raw_obs_processing_ms: 0.11240802776599321\n","  time_since_restore: 1214.35711145401\n","  time_this_iter_s: 10.041023015975952\n","  time_total_s: 1214.35711145401\n","  timers:\n","    learn_throughput: 1631.488\n","    learn_time_ms: 2451.749\n","    load_throughput: 9304650.879\n","    load_time_ms: 0.43\n","    sample_throughput: 383.255\n","    sample_time_ms: 10436.914\n","    update_time_ms: 2.689\n","  timestamp: 1649864310\n","  timesteps_since_restore: 444000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 444000\n","  training_iteration: 111\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:38:30 (running for 00:20:40.96)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   163</td><td style=\"text-align: right;\">         1211.78</td><td style=\"text-align: right;\">652000</td><td style=\"text-align: right;\">-458.903 </td><td style=\"text-align: right;\">            -233.68 </td><td style=\"text-align: right;\">           -996.254 </td><td style=\"text-align: right;\">            126.04</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         1214.36</td><td style=\"text-align: right;\">444000</td><td style=\"text-align: right;\">  26.8502</td><td style=\"text-align: right;\">             278.446</td><td style=\"text-align: right;\">           -361.002 </td><td style=\"text-align: right;\">            377.48</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   138</td><td style=\"text-align: right;\">         1204.16</td><td style=\"text-align: right;\">552000</td><td style=\"text-align: right;\"> 257.993 </td><td style=\"text-align: right;\">             321.576</td><td style=\"text-align: right;\">            -23.0426</td><td style=\"text-align: right;\">            256.37</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:38:35 (running for 00:20:45.96)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   163</td><td style=\"text-align: right;\">         1211.78</td><td style=\"text-align: right;\">652000</td><td style=\"text-align: right;\">-458.903 </td><td style=\"text-align: right;\">            -233.68 </td><td style=\"text-align: right;\">           -996.254 </td><td style=\"text-align: right;\">            126.04</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         1214.36</td><td style=\"text-align: right;\">444000</td><td style=\"text-align: right;\">  26.8502</td><td style=\"text-align: right;\">             278.446</td><td style=\"text-align: right;\">           -361.002 </td><td style=\"text-align: right;\">            377.48</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   138</td><td style=\"text-align: right;\">         1204.16</td><td style=\"text-align: right;\">552000</td><td style=\"text-align: right;\"> 257.993 </td><td style=\"text-align: right;\">             321.576</td><td style=\"text-align: right;\">            -23.0426</td><td style=\"text-align: right;\">            256.37</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 556000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-38-36\n","  done: false\n","  episode_len_mean: 264.84\n","  episode_media: {}\n","  episode_reward_max: 321.57628803721934\n","  episode_reward_mean: 256.98872555518466\n","  episode_reward_min: -23.0426052342778\n","  episodes_this_iter: 17\n","  episodes_total: 2146\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5497038960456848\n","          entropy_coeff: 0.0\n","          kl: 0.005780952516943216\n","          model: {}\n","          policy_loss: -0.007721158675849438\n","          total_loss: 338.2943115234375\n","          vf_explained_var: 0.5042062997817993\n","          vf_loss: 338.3009338378906\n","    num_agent_steps_sampled: 556000\n","    num_agent_steps_trained: 556000\n","    num_steps_sampled: 556000\n","    num_steps_trained: 556000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 139\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.450000000000001\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07486214120727226\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5939513155384419\n","    mean_inference_ms: 0.7576129030086043\n","    mean_raw_obs_processing_ms: 0.1125584549365653\n","  time_since_restore: 1212.1281945705414\n","  time_this_iter_s: 7.964690923690796\n","  time_total_s: 1212.1281945705414\n","  timers:\n","    learn_throughput: 1627.962\n","    learn_time_ms: 2457.059\n","    load_throughput: 8323270.328\n","    load_time_ms: 0.481\n","    sample_throughput: 472.485\n","    sample_time_ms: 8465.871\n","    update_time_ms: 2.784\n","  timestamp: 1649864316\n","  timesteps_since_restore: 556000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 556000\n","  training_iteration: 139\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 656000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-38-37\n","  done: false\n","  episode_len_mean: 134.59\n","  episode_media: {}\n","  episode_reward_max: -190.5201900498774\n","  episode_reward_mean: -453.17891409171324\n","  episode_reward_min: -980.6965275390422\n","  episodes_this_iter: 29\n","  episodes_total: 5521\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 3094300061597696.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.2627238631248474\n","          entropy_coeff: 0.0\n","          kl: 0.1119617223739624\n","          model: {}\n","          policy_loss: 0.031070012599229813\n","          total_loss: 346443168612352.0\n","          vf_explained_var: 0.5230951905250549\n","          vf_loss: 1863.3734130859375\n","    num_agent_steps_sampled: 656000\n","    num_agent_steps_trained: 656000\n","    num_steps_sampled: 656000\n","    num_steps_trained: 656000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 164\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.463636363636367\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07046438095322935\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2957580899824077\n","    mean_inference_ms: 0.7273665454868768\n","    mean_raw_obs_processing_ms: 0.11257223989326683\n","  time_since_restore: 1219.2757227420807\n","  time_this_iter_s: 7.500505208969116\n","  time_total_s: 1219.2757227420807\n","  timers:\n","    learn_throughput: 1596.763\n","    learn_time_ms: 2505.068\n","    load_throughput: 9491522.969\n","    load_time_ms: 0.421\n","    sample_throughput: 533.079\n","    sample_time_ms: 7503.579\n","    update_time_ms: 2.797\n","  timestamp: 1649864317\n","  timesteps_since_restore: 656000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 656000\n","  training_iteration: 164\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:38:41 (running for 00:20:51.69)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   164</td><td style=\"text-align: right;\">         1219.28</td><td style=\"text-align: right;\">656000</td><td style=\"text-align: right;\">-453.179 </td><td style=\"text-align: right;\">            -190.52 </td><td style=\"text-align: right;\">           -980.697 </td><td style=\"text-align: right;\">            134.59</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         1214.36</td><td style=\"text-align: right;\">444000</td><td style=\"text-align: right;\">  26.8502</td><td style=\"text-align: right;\">             278.446</td><td style=\"text-align: right;\">           -361.002 </td><td style=\"text-align: right;\">            377.48</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   139</td><td style=\"text-align: right;\">         1212.13</td><td style=\"text-align: right;\">556000</td><td style=\"text-align: right;\"> 256.989 </td><td style=\"text-align: right;\">             321.576</td><td style=\"text-align: right;\">            -23.0426</td><td style=\"text-align: right;\">            264.84</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 448000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-38-41\n","  done: false\n","  episode_len_mean: 376.01\n","  episode_media: {}\n","  episode_reward_max: 278.44570431138135\n","  episode_reward_mean: 27.03717940849689\n","  episode_reward_min: -361.0023318393476\n","  episodes_this_iter: 9\n","  episodes_total: 1223\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.7836785316467285\n","          entropy_coeff: 0.0\n","          kl: 0.013590731658041477\n","          model: {}\n","          policy_loss: -0.0434296689927578\n","          total_loss: 200.96112060546875\n","          vf_explained_var: 0.7186561226844788\n","          vf_loss: 200.9907989501953\n","    num_agent_steps_sampled: 448000\n","    num_agent_steps_trained: 448000\n","    num_steps_sampled: 448000\n","    num_steps_trained: 448000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 112\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.353333333333332\n","    ram_util_percent: 15.699999999999994\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07406766286516525\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.137267029380636\n","    mean_inference_ms: 0.7699454170660767\n","    mean_raw_obs_processing_ms: 0.11239803339510225\n","  time_since_restore: 1225.192018032074\n","  time_this_iter_s: 10.834906578063965\n","  time_total_s: 1225.192018032074\n","  timers:\n","    learn_throughput: 1635.693\n","    learn_time_ms: 2445.447\n","    load_throughput: 9289195.504\n","    load_time_ms: 0.431\n","    sample_throughput: 380.361\n","    sample_time_ms: 10516.318\n","    update_time_ms: 2.71\n","  timestamp: 1649864321\n","  timesteps_since_restore: 448000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 448000\n","  training_iteration: 112\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 560000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-38-44\n","  done: false\n","  episode_len_mean: 254.99\n","  episode_media: {}\n","  episode_reward_max: 319.4324526753977\n","  episode_reward_mean: 257.91952704475545\n","  episode_reward_min: 23.183014842277856\n","  episodes_this_iter: 22\n","  episodes_total: 2168\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5422775149345398\n","          entropy_coeff: 0.0\n","          kl: 0.00820873212069273\n","          model: {}\n","          policy_loss: -0.012186117470264435\n","          total_loss: 393.08197021484375\n","          vf_explained_var: 0.7584893703460693\n","          vf_loss: 393.0926208496094\n","    num_agent_steps_sampled: 560000\n","    num_agent_steps_trained: 560000\n","    num_steps_sampled: 560000\n","    num_steps_trained: 560000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 140\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.909090909090908\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0748509691481337\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5933539971400009\n","    mean_inference_ms: 0.7574381773032286\n","    mean_raw_obs_processing_ms: 0.1125345917151074\n","  time_since_restore: 1219.741427898407\n","  time_this_iter_s: 7.613233327865601\n","  time_total_s: 1219.741427898407\n","  timers:\n","    learn_throughput: 1628.95\n","    learn_time_ms: 2455.569\n","    load_throughput: 8250413.573\n","    load_time_ms: 0.485\n","    sample_throughput: 479.98\n","    sample_time_ms: 8333.688\n","    update_time_ms: 2.755\n","  timestamp: 1649864324\n","  timesteps_since_restore: 560000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 560000\n","  training_iteration: 140\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 660000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-38-45\n","  done: false\n","  episode_len_mean: 147.21\n","  episode_media: {}\n","  episode_reward_max: -190.5201900498774\n","  episode_reward_mean: -439.51680754306324\n","  episode_reward_min: -980.6965275390422\n","  episodes_this_iter: 24\n","  episodes_total: 5545\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 4641449823961088.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.268126517534256\n","          entropy_coeff: 0.0\n","          kl: 0.14092017710208893\n","          model: {}\n","          policy_loss: 0.035548027604818344\n","          total_loss: 654073992839168.0\n","          vf_explained_var: 0.5552173852920532\n","          vf_loss: 1545.9827880859375\n","    num_agent_steps_sampled: 660000\n","    num_agent_steps_trained: 660000\n","    num_steps_sampled: 660000\n","    num_steps_trained: 660000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 165\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.854545454545455\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07045848676517584\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2960736725891693\n","    mean_inference_ms: 0.7272925570523566\n","    mean_raw_obs_processing_ms: 0.11255965298736247\n","  time_since_restore: 1227.069168806076\n","  time_this_iter_s: 7.793446063995361\n","  time_total_s: 1227.069168806076\n","  timers:\n","    learn_throughput: 1599.968\n","    learn_time_ms: 2500.051\n","    load_throughput: 9118547.747\n","    load_time_ms: 0.439\n","    sample_throughput: 530.7\n","    sample_time_ms: 7537.214\n","    update_time_ms: 2.827\n","  timestamp: 1649864325\n","  timesteps_since_restore: 660000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 660000\n","  training_iteration: 165\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:38:47 (running for 00:20:57.44)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   165</td><td style=\"text-align: right;\">         1227.07</td><td style=\"text-align: right;\">660000</td><td style=\"text-align: right;\">-439.517 </td><td style=\"text-align: right;\">            -190.52 </td><td style=\"text-align: right;\">            -980.697</td><td style=\"text-align: right;\">            147.21</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   112</td><td style=\"text-align: right;\">         1225.19</td><td style=\"text-align: right;\">448000</td><td style=\"text-align: right;\">  27.0372</td><td style=\"text-align: right;\">             278.446</td><td style=\"text-align: right;\">            -361.002</td><td style=\"text-align: right;\">            376.01</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   140</td><td style=\"text-align: right;\">         1219.74</td><td style=\"text-align: right;\">560000</td><td style=\"text-align: right;\"> 257.92  </td><td style=\"text-align: right;\">             319.432</td><td style=\"text-align: right;\">              23.183</td><td style=\"text-align: right;\">            254.99</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 452000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-38-52\n","  done: false\n","  episode_len_mean: 397.35\n","  episode_media: {}\n","  episode_reward_max: 278.44570431138135\n","  episode_reward_mean: 31.05571347718471\n","  episode_reward_min: -361.0023318393476\n","  episodes_this_iter: 8\n","  episodes_total: 1231\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.7746953964233398\n","          entropy_coeff: 0.0\n","          kl: 0.009860137477517128\n","          model: {}\n","          policy_loss: -0.04080073907971382\n","          total_loss: 268.0634765625\n","          vf_explained_var: 0.37874171137809753\n","          vf_loss: 268.0942687988281\n","    num_agent_steps_sampled: 452000\n","    num_agent_steps_trained: 452000\n","    num_steps_sampled: 452000\n","    num_steps_trained: 452000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 113\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.48666666666667\n","    ram_util_percent: 15.699999999999994\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07406247245672186\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.13653548509874\n","    mean_inference_ms: 0.7698750554154812\n","    mean_raw_obs_processing_ms: 0.11238894388979148\n","  time_since_restore: 1235.633902311325\n","  time_this_iter_s: 10.441884279251099\n","  time_total_s: 1235.633902311325\n","  timers:\n","    learn_throughput: 1630.451\n","    learn_time_ms: 2453.31\n","    load_throughput: 9361240.933\n","    load_time_ms: 0.427\n","    sample_throughput: 381.309\n","    sample_time_ms: 10490.168\n","    update_time_ms: 2.771\n","  timestamp: 1649864332\n","  timesteps_since_restore: 452000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 452000\n","  training_iteration: 113\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 564000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-38-52\n","  done: false\n","  episode_len_mean: 261.52\n","  episode_media: {}\n","  episode_reward_max: 319.4324526753977\n","  episode_reward_mean: 256.00695800363684\n","  episode_reward_min: 23.183014842277856\n","  episodes_this_iter: 12\n","  episodes_total: 2180\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6775369644165039\n","          entropy_coeff: 0.0\n","          kl: 0.009444482624530792\n","          model: {}\n","          policy_loss: -0.00934085063636303\n","          total_loss: 118.40907287597656\n","          vf_explained_var: 0.6282396912574768\n","          vf_loss: 118.41661834716797\n","    num_agent_steps_sampled: 564000\n","    num_agent_steps_trained: 564000\n","    num_steps_sampled: 564000\n","    num_steps_trained: 564000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 141\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.575000000000001\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07484316683817797\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.593156213257269\n","    mean_inference_ms: 0.7573401863631851\n","    mean_raw_obs_processing_ms: 0.11251864345600385\n","  time_since_restore: 1228.5857028961182\n","  time_this_iter_s: 8.844274997711182\n","  time_total_s: 1228.5857028961182\n","  timers:\n","    learn_throughput: 1621.763\n","    learn_time_ms: 2466.451\n","    load_throughput: 8212048.948\n","    load_time_ms: 0.487\n","    sample_throughput: 480.616\n","    sample_time_ms: 8322.657\n","    update_time_ms: 2.761\n","  timestamp: 1649864332\n","  timesteps_since_restore: 564000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 564000\n","  training_iteration: 141\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:38:52 (running for 00:21:03.14)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   165</td><td style=\"text-align: right;\">         1227.07</td><td style=\"text-align: right;\">660000</td><td style=\"text-align: right;\">-439.517 </td><td style=\"text-align: right;\">            -190.52 </td><td style=\"text-align: right;\">            -980.697</td><td style=\"text-align: right;\">            147.21</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         1235.63</td><td style=\"text-align: right;\">452000</td><td style=\"text-align: right;\">  31.0557</td><td style=\"text-align: right;\">             278.446</td><td style=\"text-align: right;\">            -361.002</td><td style=\"text-align: right;\">            397.35</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   141</td><td style=\"text-align: right;\">         1228.59</td><td style=\"text-align: right;\">564000</td><td style=\"text-align: right;\"> 256.007 </td><td style=\"text-align: right;\">             319.432</td><td style=\"text-align: right;\">              23.183</td><td style=\"text-align: right;\">            261.52</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 664000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-38-53\n","  done: false\n","  episode_len_mean: 152.07\n","  episode_media: {}\n","  episode_reward_max: -190.5201900498774\n","  episode_reward_mean: -453.97295795837823\n","  episode_reward_min: -1116.0379604926961\n","  episodes_this_iter: 24\n","  episodes_total: 5569\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 6962174735941632.0\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.2258201688528061\n","          entropy_coeff: 0.0\n","          kl: 0.12963925302028656\n","          model: {}\n","          policy_loss: 0.030976075679063797\n","          total_loss: 902571136909312.0\n","          vf_explained_var: 0.5636811852455139\n","          vf_loss: 2036.6514892578125\n","    num_agent_steps_sampled: 664000\n","    num_agent_steps_trained: 664000\n","    num_steps_sampled: 664000\n","    num_steps_trained: 664000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 166\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.958333333333336\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07045621561682344\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2965954785693107\n","    mean_inference_ms: 0.7272533468085919\n","    mean_raw_obs_processing_ms: 0.11254863117206462\n","  time_since_restore: 1235.3254418373108\n","  time_this_iter_s: 8.256273031234741\n","  time_total_s: 1235.3254418373108\n","  timers:\n","    learn_throughput: 1594.301\n","    learn_time_ms: 2508.936\n","    load_throughput: 9064355.719\n","    load_time_ms: 0.441\n","    sample_throughput: 524.152\n","    sample_time_ms: 7631.371\n","    update_time_ms: 2.847\n","  timestamp: 1649864333\n","  timesteps_since_restore: 664000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 664000\n","  training_iteration: 166\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:38:58 (running for 00:21:08.74)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   166</td><td style=\"text-align: right;\">         1235.33</td><td style=\"text-align: right;\">664000</td><td style=\"text-align: right;\">-453.973 </td><td style=\"text-align: right;\">            -190.52 </td><td style=\"text-align: right;\">           -1116.04 </td><td style=\"text-align: right;\">            152.07</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         1235.63</td><td style=\"text-align: right;\">452000</td><td style=\"text-align: right;\">  31.0557</td><td style=\"text-align: right;\">             278.446</td><td style=\"text-align: right;\">            -361.002</td><td style=\"text-align: right;\">            397.35</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   141</td><td style=\"text-align: right;\">         1228.59</td><td style=\"text-align: right;\">564000</td><td style=\"text-align: right;\"> 256.007 </td><td style=\"text-align: right;\">             319.432</td><td style=\"text-align: right;\">              23.183</td><td style=\"text-align: right;\">            261.52</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 568000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-39-00\n","  done: false\n","  episode_len_mean: 244.93\n","  episode_media: {}\n","  episode_reward_max: 319.4324526753977\n","  episode_reward_mean: 258.3204599207571\n","  episode_reward_min: 23.183014842277856\n","  episodes_this_iter: 20\n","  episodes_total: 2200\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.548049807548523\n","          entropy_coeff: 0.0\n","          kl: 0.00667525315657258\n","          model: {}\n","          policy_loss: -0.01627972722053528\n","          total_loss: 262.6348571777344\n","          vf_explained_var: 0.7086774110794067\n","          vf_loss: 262.64984130859375\n","    num_agent_steps_sampled: 568000\n","    num_agent_steps_trained: 568000\n","    num_steps_sampled: 568000\n","    num_steps_trained: 568000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 142\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.058333333333332\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0748289001782511\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5925564320072241\n","    mean_inference_ms: 0.7571385174024892\n","    mean_raw_obs_processing_ms: 0.11249322185018439\n","  time_since_restore: 1236.3513495922089\n","  time_this_iter_s: 7.765646696090698\n","  time_total_s: 1236.3513495922089\n","  timers:\n","    learn_throughput: 1617.162\n","    learn_time_ms: 2473.469\n","    load_throughput: 8399947.93\n","    load_time_ms: 0.476\n","    sample_throughput: 479.525\n","    sample_time_ms: 8341.58\n","    update_time_ms: 2.811\n","  timestamp: 1649864340\n","  timesteps_since_restore: 568000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 568000\n","  training_iteration: 142\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 668000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-39-01\n","  done: false\n","  episode_len_mean: 145.39\n","  episode_media: {}\n","  episode_reward_max: -190.5201900498774\n","  episode_reward_mean: -440.5989440068209\n","  episode_reward_min: -1116.0379604926961\n","  episodes_this_iter: 31\n","  episodes_total: 5600\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0443262372347904e+16\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.22446280717849731\n","          entropy_coeff: 0.0\n","          kl: 0.11892011016607285\n","          model: {}\n","          policy_loss: 0.017574455589056015\n","          total_loss: 1241914087047168.0\n","          vf_explained_var: 0.7519572973251343\n","          vf_loss: 935.6664428710938\n","    num_agent_steps_sampled: 668000\n","    num_agent_steps_trained: 668000\n","    num_steps_sampled: 668000\n","    num_steps_trained: 668000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 167\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.472727272727274\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07045191945677617\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.29720704286199723\n","    mean_inference_ms: 0.7272048886530464\n","    mean_raw_obs_processing_ms: 0.11253254008126574\n","  time_since_restore: 1242.8079628944397\n","  time_this_iter_s: 7.482521057128906\n","  time_total_s: 1242.8079628944397\n","  timers:\n","    learn_throughput: 1587.771\n","    learn_time_ms: 2519.255\n","    load_throughput: 9075633.452\n","    load_time_ms: 0.441\n","    sample_throughput: 524.637\n","    sample_time_ms: 7624.316\n","    update_time_ms: 2.874\n","  timestamp: 1649864341\n","  timesteps_since_restore: 668000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 668000\n","  training_iteration: 167\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 456000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-39-03\n","  done: false\n","  episode_len_mean: 408.42\n","  episode_media: {}\n","  episode_reward_max: 278.44570431138135\n","  episode_reward_mean: 33.221382660610814\n","  episode_reward_min: -361.0023318393476\n","  episodes_this_iter: 7\n","  episodes_total: 1238\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.0125000476837158\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.7313257455825806\n","          entropy_coeff: 0.0\n","          kl: 0.024250341579318047\n","          model: {}\n","          policy_loss: -0.032134976238012314\n","          total_loss: 214.63914489746094\n","          vf_explained_var: 0.48558172583580017\n","          vf_loss: 214.64674377441406\n","    num_agent_steps_sampled: 456000\n","    num_agent_steps_trained: 456000\n","    num_steps_sampled: 456000\n","    num_steps_trained: 456000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 114\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.325000000000001\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07405947061283755\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1359925910576592\n","    mean_inference_ms: 0.7698198208568681\n","    mean_raw_obs_processing_ms: 0.11238230959659312\n","  time_since_restore: 1246.6634035110474\n","  time_this_iter_s: 11.02950119972229\n","  time_total_s: 1246.6634035110474\n","  timers:\n","    learn_throughput: 1626.064\n","    learn_time_ms: 2459.927\n","    load_throughput: 9255884.365\n","    load_time_ms: 0.432\n","    sample_throughput: 378.569\n","    sample_time_ms: 10566.101\n","    update_time_ms: 2.786\n","  timestamp: 1649864343\n","  timesteps_since_restore: 456000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 456000\n","  training_iteration: 114\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:39:04 (running for 00:21:14.39)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   167</td><td style=\"text-align: right;\">         1242.81</td><td style=\"text-align: right;\">668000</td><td style=\"text-align: right;\">-440.599 </td><td style=\"text-align: right;\">            -190.52 </td><td style=\"text-align: right;\">           -1116.04 </td><td style=\"text-align: right;\">            145.39</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   114</td><td style=\"text-align: right;\">         1246.66</td><td style=\"text-align: right;\">456000</td><td style=\"text-align: right;\">  33.2214</td><td style=\"text-align: right;\">             278.446</td><td style=\"text-align: right;\">            -361.002</td><td style=\"text-align: right;\">            408.42</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   142</td><td style=\"text-align: right;\">         1236.35</td><td style=\"text-align: right;\">568000</td><td style=\"text-align: right;\"> 258.32  </td><td style=\"text-align: right;\">             319.432</td><td style=\"text-align: right;\">              23.183</td><td style=\"text-align: right;\">            244.93</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 672000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-39-08\n","  done: false\n","  episode_len_mean: 147.18\n","  episode_media: {}\n","  episode_reward_max: -225.66148266506403\n","  episode_reward_mean: -455.21789220643154\n","  episode_reward_min: -1116.0379604926961\n","  episodes_this_iter: 29\n","  episodes_total: 5629\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.5664893558521856e+16\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.22243481874465942\n","          entropy_coeff: 0.0\n","          kl: 0.1522020548582077\n","          model: {}\n","          policy_loss: 0.030634334310889244\n","          total_loss: 2384229224677376.0\n","          vf_explained_var: 0.7248746752738953\n","          vf_loss: 1382.108642578125\n","    num_agent_steps_sampled: 672000\n","    num_agent_steps_trained: 672000\n","    num_steps_sampled: 672000\n","    num_steps_trained: 672000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 168\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.654545454545454\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07044737697104617\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.29775632658357654\n","    mean_inference_ms: 0.7271657555100478\n","    mean_raw_obs_processing_ms: 0.11251714796156968\n","  time_since_restore: 1250.454921245575\n","  time_this_iter_s: 7.646958351135254\n","  time_total_s: 1250.454921245575\n","  timers:\n","    learn_throughput: 1579.671\n","    learn_time_ms: 2532.172\n","    load_throughput: 9132942.842\n","    load_time_ms: 0.438\n","    sample_throughput: 524.441\n","    sample_time_ms: 7627.164\n","    update_time_ms: 2.823\n","  timestamp: 1649864348\n","  timesteps_since_restore: 672000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 672000\n","  training_iteration: 168\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 572000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-39-09\n","  done: false\n","  episode_len_mean: 231.02\n","  episode_media: {}\n","  episode_reward_max: 318.3885139806489\n","  episode_reward_mean: 261.0756998591792\n","  episode_reward_min: 23.183014842277856\n","  episodes_this_iter: 15\n","  episodes_total: 2215\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5863101482391357\n","          entropy_coeff: 0.0\n","          kl: 0.00643561128526926\n","          model: {}\n","          policy_loss: -0.00764808151870966\n","          total_loss: 205.67449951171875\n","          vf_explained_var: 0.671461284160614\n","          vf_loss: 205.68092346191406\n","    num_agent_steps_sampled: 572000\n","    num_agent_steps_trained: 572000\n","    num_steps_sampled: 572000\n","    num_steps_trained: 572000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 143\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.966666666666667\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07481700325405592\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5917321088539871\n","    mean_inference_ms: 0.7569884747178008\n","    mean_raw_obs_processing_ms: 0.1124772968236086\n","  time_since_restore: 1244.7031688690186\n","  time_this_iter_s: 8.351819276809692\n","  time_total_s: 1244.7031688690186\n","  timers:\n","    learn_throughput: 1612.509\n","    learn_time_ms: 2480.606\n","    load_throughput: 8572049.867\n","    load_time_ms: 0.467\n","    sample_throughput: 475.831\n","    sample_time_ms: 8406.344\n","    update_time_ms: 2.835\n","  timestamp: 1649864349\n","  timesteps_since_restore: 572000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 572000\n","  training_iteration: 143\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:39:10 (running for 00:21:20.33)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   168</td><td style=\"text-align: right;\">         1250.45</td><td style=\"text-align: right;\">672000</td><td style=\"text-align: right;\">-455.218 </td><td style=\"text-align: right;\">            -225.661</td><td style=\"text-align: right;\">           -1116.04 </td><td style=\"text-align: right;\">            147.18</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   114</td><td style=\"text-align: right;\">         1246.66</td><td style=\"text-align: right;\">456000</td><td style=\"text-align: right;\">  33.2214</td><td style=\"text-align: right;\">             278.446</td><td style=\"text-align: right;\">            -361.002</td><td style=\"text-align: right;\">            408.42</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   143</td><td style=\"text-align: right;\">         1244.7 </td><td style=\"text-align: right;\">572000</td><td style=\"text-align: right;\"> 261.076 </td><td style=\"text-align: right;\">             318.389</td><td style=\"text-align: right;\">              23.183</td><td style=\"text-align: right;\">            231.02</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 460000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-39-13\n","  done: false\n","  episode_len_mean: 427.95\n","  episode_media: {}\n","  episode_reward_max: 278.44570431138135\n","  episode_reward_mean: 42.30350853190615\n","  episode_reward_min: -361.0023318393476\n","  episodes_this_iter: 8\n","  episodes_total: 1246\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.5187499523162842\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.737804114818573\n","          entropy_coeff: 0.0\n","          kl: 0.0129685765132308\n","          model: {}\n","          policy_loss: -0.046086736023426056\n","          total_loss: 169.95278930664062\n","          vf_explained_var: 0.5729998350143433\n","          vf_loss: 169.9791717529297\n","    num_agent_steps_sampled: 460000\n","    num_agent_steps_trained: 460000\n","    num_steps_sampled: 460000\n","    num_steps_trained: 460000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 115\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.5625\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07405584569605582\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.13544823948865\n","    mean_inference_ms: 0.7697653472866989\n","    mean_raw_obs_processing_ms: 0.11237594220698215\n","  time_since_restore: 1257.3659086227417\n","  time_this_iter_s: 10.702505111694336\n","  time_total_s: 1257.3659086227417\n","  timers:\n","    learn_throughput: 1627.534\n","    learn_time_ms: 2457.706\n","    load_throughput: 9006934.021\n","    load_time_ms: 0.444\n","    sample_throughput: 376.581\n","    sample_time_ms: 10621.894\n","    update_time_ms: 2.738\n","  timestamp: 1649864353\n","  timesteps_since_restore: 460000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 460000\n","  training_iteration: 115\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:39:15 (running for 00:21:26.14)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   168</td><td style=\"text-align: right;\">         1250.45</td><td style=\"text-align: right;\">672000</td><td style=\"text-align: right;\">-455.218 </td><td style=\"text-align: right;\">            -225.661</td><td style=\"text-align: right;\">           -1116.04 </td><td style=\"text-align: right;\">            147.18</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   115</td><td style=\"text-align: right;\">         1257.37</td><td style=\"text-align: right;\">460000</td><td style=\"text-align: right;\">  42.3035</td><td style=\"text-align: right;\">             278.446</td><td style=\"text-align: right;\">            -361.002</td><td style=\"text-align: right;\">            427.95</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   143</td><td style=\"text-align: right;\">         1244.7 </td><td style=\"text-align: right;\">572000</td><td style=\"text-align: right;\"> 261.076 </td><td style=\"text-align: right;\">             318.389</td><td style=\"text-align: right;\">              23.183</td><td style=\"text-align: right;\">            231.02</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 676000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-39-16\n","  done: false\n","  episode_len_mean: 145.25\n","  episode_media: {}\n","  episode_reward_max: -225.66148266506403\n","  episode_reward_mean: -446.63042647343354\n","  episode_reward_min: -1026.211947422029\n","  episodes_this_iter: 24\n","  episodes_total: 5653\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 2.3497340874653696e+16\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.2365044802427292\n","          entropy_coeff: 0.0\n","          kl: 0.14716804027557373\n","          model: {}\n","          policy_loss: 0.0294034443795681\n","          total_loss: 3458057216458752.0\n","          vf_explained_var: 0.5384320616722107\n","          vf_loss: 1903.98828125\n","    num_agent_steps_sampled: 676000\n","    num_agent_steps_trained: 676000\n","    num_steps_sampled: 676000\n","    num_steps_trained: 676000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 169\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.663636363636364\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07044330727427046\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.29822032754421973\n","    mean_inference_ms: 0.7271404343567542\n","    mean_raw_obs_processing_ms: 0.11250578875285974\n","  time_since_restore: 1258.5702757835388\n","  time_this_iter_s: 8.115354537963867\n","  time_total_s: 1258.5702757835388\n","  timers:\n","    learn_throughput: 1574.743\n","    learn_time_ms: 2540.098\n","    load_throughput: 9233978.755\n","    load_time_ms: 0.433\n","    sample_throughput: 518.513\n","    sample_time_ms: 7714.365\n","    update_time_ms: 2.81\n","  timestamp: 1649864356\n","  timesteps_since_restore: 676000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 676000\n","  training_iteration: 169\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 576000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-39-16\n","  done: false\n","  episode_len_mean: 223.68\n","  episode_media: {}\n","  episode_reward_max: 316.76685531376336\n","  episode_reward_mean: 257.8338090121049\n","  episode_reward_min: 0.6954499069663314\n","  episodes_this_iter: 23\n","  episodes_total: 2238\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5259780883789062\n","          entropy_coeff: 0.0\n","          kl: 0.006409237161278725\n","          model: {}\n","          policy_loss: -0.016738858073949814\n","          total_loss: 524.7863159179688\n","          vf_explained_var: 0.7890610098838806\n","          vf_loss: 524.8018188476562\n","    num_agent_steps_sampled: 576000\n","    num_agent_steps_trained: 576000\n","    num_steps_sampled: 576000\n","    num_steps_trained: 576000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 144\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.845454545454546\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07480192155584107\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5904068384034126\n","    mean_inference_ms: 0.7567767812585204\n","    mean_raw_obs_processing_ms: 0.11246170645301827\n","  time_since_restore: 1252.4997985363007\n","  time_this_iter_s: 7.7966296672821045\n","  time_total_s: 1252.4997985363007\n","  timers:\n","    learn_throughput: 1603.601\n","    learn_time_ms: 2494.385\n","    load_throughput: 8548028.736\n","    load_time_ms: 0.468\n","    sample_throughput: 482.229\n","    sample_time_ms: 8294.821\n","    update_time_ms: 2.819\n","  timestamp: 1649864356\n","  timesteps_since_restore: 576000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 576000\n","  training_iteration: 144\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:39:20 (running for 00:21:31.16)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   169</td><td style=\"text-align: right;\">         1258.57</td><td style=\"text-align: right;\">676000</td><td style=\"text-align: right;\">-446.63  </td><td style=\"text-align: right;\">            -225.661</td><td style=\"text-align: right;\">         -1026.21   </td><td style=\"text-align: right;\">            145.25</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   115</td><td style=\"text-align: right;\">         1257.37</td><td style=\"text-align: right;\">460000</td><td style=\"text-align: right;\">  42.3035</td><td style=\"text-align: right;\">             278.446</td><td style=\"text-align: right;\">          -361.002  </td><td style=\"text-align: right;\">            427.95</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   144</td><td style=\"text-align: right;\">         1252.5 </td><td style=\"text-align: right;\">576000</td><td style=\"text-align: right;\"> 257.834 </td><td style=\"text-align: right;\">             316.767</td><td style=\"text-align: right;\">             0.69545</td><td style=\"text-align: right;\">            223.68</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 680000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-39-24\n","  done: false\n","  episode_len_mean: 140.59\n","  episode_media: {}\n","  episode_reward_max: -238.19777936029558\n","  episode_reward_mean: -432.1261706095769\n","  episode_reward_min: -1026.211947422029\n","  episodes_this_iter: 31\n","  episodes_total: 5684\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 3.5246011311980544e+16\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.17591732740402222\n","          entropy_coeff: 0.0\n","          kl: 0.19274386763572693\n","          model: {}\n","          policy_loss: 0.03578271344304085\n","          total_loss: 6793452851298304.0\n","          vf_explained_var: 0.5169695019721985\n","          vf_loss: 1035.117919921875\n","    num_agent_steps_sampled: 680000\n","    num_agent_steps_trained: 680000\n","    num_steps_sampled: 680000\n","    num_steps_trained: 680000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 170\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.6\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.070430905192852\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.2986610034059917\n","    mean_inference_ms: 0.7270281970376901\n","    mean_raw_obs_processing_ms: 0.11248465145147417\n","  time_since_restore: 1265.9908337593079\n","  time_this_iter_s: 7.420557975769043\n","  time_total_s: 1265.9908337593079\n","  timers:\n","    learn_throughput: 1565.148\n","    learn_time_ms: 2555.668\n","    load_throughput: 9316017.547\n","    load_time_ms: 0.429\n","    sample_throughput: 519.772\n","    sample_time_ms: 7695.686\n","    update_time_ms: 2.825\n","  timestamp: 1649864364\n","  timesteps_since_restore: 680000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 680000\n","  training_iteration: 170\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 580000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-39-25\n","  done: false\n","  episode_len_mean: 225.74\n","  episode_media: {}\n","  episode_reward_max: 316.76685531376336\n","  episode_reward_mean: 263.1954596773873\n","  episode_reward_min: 0.6954499069663314\n","  episodes_this_iter: 16\n","  episodes_total: 2254\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.609556257724762\n","          entropy_coeff: 0.0\n","          kl: 0.007688617799431086\n","          model: {}\n","          policy_loss: -0.016199324280023575\n","          total_loss: 54.59793472290039\n","          vf_explained_var: 0.8772678971290588\n","          vf_loss: 54.612674713134766\n","    num_agent_steps_sampled: 580000\n","    num_agent_steps_trained: 580000\n","    num_steps_sampled: 580000\n","    num_steps_trained: 580000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 145\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.541666666666666\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07479151764862353\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5896705378230179\n","    mean_inference_ms: 0.7566245085563961\n","    mean_raw_obs_processing_ms: 0.11244953030574002\n","  time_since_restore: 1260.9267292022705\n","  time_this_iter_s: 8.426930665969849\n","  time_total_s: 1260.9267292022705\n","  timers:\n","    learn_throughput: 1591.587\n","    learn_time_ms: 2513.216\n","    load_throughput: 8854346.633\n","    load_time_ms: 0.452\n","    sample_throughput: 478.667\n","    sample_time_ms: 8356.544\n","    update_time_ms: 2.893\n","  timestamp: 1649864365\n","  timesteps_since_restore: 580000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 580000\n","  training_iteration: 145\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 464000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-39-25\n","  done: false\n","  episode_len_mean: 431.1\n","  episode_media: {}\n","  episode_reward_max: 278.44570431138135\n","  episode_reward_mean: 49.76380882246741\n","  episode_reward_min: -361.0023318393476\n","  episodes_this_iter: 6\n","  episodes_total: 1252\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.5187499523162842\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.725672721862793\n","          entropy_coeff: 0.0\n","          kl: 0.007552838884294033\n","          model: {}\n","          policy_loss: -0.028794586658477783\n","          total_loss: 214.5435791015625\n","          vf_explained_var: 0.6194601058959961\n","          vf_loss: 214.5609130859375\n","    num_agent_steps_sampled: 464000\n","    num_agent_steps_trained: 464000\n","    num_steps_sampled: 464000\n","    num_steps_trained: 464000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 116\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.662500000000001\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07405339238079751\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1351071223386873\n","    mean_inference_ms: 0.7697299680189289\n","    mean_raw_obs_processing_ms: 0.11237070776220051\n","  time_since_restore: 1268.9365587234497\n","  time_this_iter_s: 11.570650100708008\n","  time_total_s: 1268.9365587234497\n","  timers:\n","    learn_throughput: 1619.442\n","    learn_time_ms: 2469.987\n","    load_throughput: 8740409.482\n","    load_time_ms: 0.458\n","    sample_throughput: 375.689\n","    sample_time_ms: 10647.098\n","    update_time_ms: 2.8\n","  timestamp: 1649864365\n","  timesteps_since_restore: 464000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 464000\n","  training_iteration: 116\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:39:26 (running for 00:21:36.74)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   170</td><td style=\"text-align: right;\">         1265.99</td><td style=\"text-align: right;\">680000</td><td style=\"text-align: right;\">-432.126 </td><td style=\"text-align: right;\">            -238.198</td><td style=\"text-align: right;\">         -1026.21   </td><td style=\"text-align: right;\">            140.59</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   116</td><td style=\"text-align: right;\">         1268.94</td><td style=\"text-align: right;\">464000</td><td style=\"text-align: right;\">  49.7638</td><td style=\"text-align: right;\">             278.446</td><td style=\"text-align: right;\">          -361.002  </td><td style=\"text-align: right;\">            431.1 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   145</td><td style=\"text-align: right;\">         1260.93</td><td style=\"text-align: right;\">580000</td><td style=\"text-align: right;\"> 263.195 </td><td style=\"text-align: right;\">             316.767</td><td style=\"text-align: right;\">             0.69545</td><td style=\"text-align: right;\">            225.74</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:39:31 (running for 00:21:41.75)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   170</td><td style=\"text-align: right;\">         1265.99</td><td style=\"text-align: right;\">680000</td><td style=\"text-align: right;\">-432.126 </td><td style=\"text-align: right;\">            -238.198</td><td style=\"text-align: right;\">         -1026.21   </td><td style=\"text-align: right;\">            140.59</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   116</td><td style=\"text-align: right;\">         1268.94</td><td style=\"text-align: right;\">464000</td><td style=\"text-align: right;\">  49.7638</td><td style=\"text-align: right;\">             278.446</td><td style=\"text-align: right;\">          -361.002  </td><td style=\"text-align: right;\">            431.1 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   145</td><td style=\"text-align: right;\">         1260.93</td><td style=\"text-align: right;\">580000</td><td style=\"text-align: right;\"> 263.195 </td><td style=\"text-align: right;\">             316.767</td><td style=\"text-align: right;\">             0.69545</td><td style=\"text-align: right;\">            225.74</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 684000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-39-31\n","  done: false\n","  episode_len_mean: 133.67\n","  episode_media: {}\n","  episode_reward_max: -244.05804002328222\n","  episode_reward_mean: -452.10581100422746\n","  episode_reward_min: -828.5279258376036\n","  episodes_this_iter: 33\n","  episodes_total: 5717\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 5.286901589422899e+16\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.14426416158676147\n","          entropy_coeff: 0.0\n","          kl: 0.19325876235961914\n","          model: {}\n","          policy_loss: 0.03377917408943176\n","          total_loss: 1.021739970592768e+16\n","          vf_explained_var: 0.8572785258293152\n","          vf_loss: 719.31640625\n","    num_agent_steps_sampled: 684000\n","    num_agent_steps_trained: 684000\n","    num_steps_sampled: 684000\n","    num_steps_trained: 684000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 171\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.727272727272727\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07042187761926737\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.29909106272358105\n","    mean_inference_ms: 0.7269503177215222\n","    mean_raw_obs_processing_ms: 0.11247084540723834\n","  time_since_restore: 1273.435355424881\n","  time_this_iter_s: 7.44452166557312\n","  time_total_s: 1273.435355424881\n","  timers:\n","    learn_throughput: 1564.132\n","    learn_time_ms: 2557.329\n","    load_throughput: 9033607.581\n","    load_time_ms: 0.443\n","    sample_throughput: 519.096\n","    sample_time_ms: 7705.698\n","    update_time_ms: 2.86\n","  timestamp: 1649864371\n","  timesteps_since_restore: 684000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 684000\n","  training_iteration: 171\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 584000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-39-34\n","  done: false\n","  episode_len_mean: 240.66\n","  episode_media: {}\n","  episode_reward_max: 316.76685531376336\n","  episode_reward_mean: 257.70380891126916\n","  episode_reward_min: 0.6954499069663314\n","  episodes_this_iter: 13\n","  episodes_total: 2267\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.6273303627967834\n","          entropy_coeff: 0.0\n","          kl: 0.006356211844831705\n","          model: {}\n","          policy_loss: -0.0040862420573830605\n","          total_loss: 315.71490478515625\n","          vf_explained_var: 0.5052323937416077\n","          vf_loss: 315.7178039550781\n","    num_agent_steps_sampled: 584000\n","    num_agent_steps_trained: 584000\n","    num_steps_sampled: 584000\n","    num_steps_trained: 584000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 146\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.0\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07478201710135662\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5892391413033451\n","    mean_inference_ms: 0.756514850436365\n","    mean_raw_obs_processing_ms: 0.11243767677230838\n","  time_since_restore: 1269.7935376167297\n","  time_this_iter_s: 8.866808414459229\n","  time_total_s: 1269.7935376167297\n","  timers:\n","    learn_throughput: 1593.499\n","    learn_time_ms: 2510.199\n","    load_throughput: 8855748.746\n","    load_time_ms: 0.452\n","    sample_throughput: 477.569\n","    sample_time_ms: 8375.761\n","    update_time_ms: 2.988\n","  timestamp: 1649864374\n","  timesteps_since_restore: 584000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 584000\n","  training_iteration: 146\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 468000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-39-36\n","  done: false\n","  episode_len_mean: 455.17\n","  episode_media: {}\n","  episode_reward_max: 278.44570431138135\n","  episode_reward_mean: 55.998940550408626\n","  episode_reward_min: -361.0023318393476\n","  episodes_this_iter: 6\n","  episodes_total: 1258\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.5187499523162842\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8153405785560608\n","          entropy_coeff: 0.0\n","          kl: 0.01040887925773859\n","          model: {}\n","          policy_loss: -0.021191611886024475\n","          total_loss: 526.5988159179688\n","          vf_explained_var: 0.4038201570510864\n","          vf_loss: 526.6041870117188\n","    num_agent_steps_sampled: 468000\n","    num_agent_steps_trained: 468000\n","    num_steps_sampled: 468000\n","    num_steps_trained: 468000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 117\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.487499999999999\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07405242238354105\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1347387057751182\n","    mean_inference_ms: 0.7697084548612579\n","    mean_raw_obs_processing_ms: 0.11236687641743692\n","  time_since_restore: 1279.8532857894897\n","  time_this_iter_s: 10.916727066040039\n","  time_total_s: 1279.8532857894897\n","  timers:\n","    learn_throughput: 1618.223\n","    learn_time_ms: 2471.847\n","    load_throughput: 8691957.31\n","    load_time_ms: 0.46\n","    sample_throughput: 370.769\n","    sample_time_ms: 10788.393\n","    update_time_ms: 2.801\n","  timestamp: 1649864376\n","  timesteps_since_restore: 468000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 468000\n","  training_iteration: 117\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:39:37 (running for 00:21:47.70)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   171</td><td style=\"text-align: right;\">         1273.44</td><td style=\"text-align: right;\">684000</td><td style=\"text-align: right;\">-452.106 </td><td style=\"text-align: right;\">            -244.058</td><td style=\"text-align: right;\">          -828.528  </td><td style=\"text-align: right;\">            133.67</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         1279.85</td><td style=\"text-align: right;\">468000</td><td style=\"text-align: right;\">  55.9989</td><td style=\"text-align: right;\">             278.446</td><td style=\"text-align: right;\">          -361.002  </td><td style=\"text-align: right;\">            455.17</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   146</td><td style=\"text-align: right;\">         1269.79</td><td style=\"text-align: right;\">584000</td><td style=\"text-align: right;\"> 257.704 </td><td style=\"text-align: right;\">             316.767</td><td style=\"text-align: right;\">             0.69545</td><td style=\"text-align: right;\">            240.66</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 688000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-39-39\n","  done: false\n","  episode_len_mean: 138.57\n","  episode_media: {}\n","  episode_reward_max: -244.05804002328222\n","  episode_reward_mean: -445.83786758820963\n","  episode_reward_min: -831.6796120761535\n","  episodes_this_iter: 24\n","  episodes_total: 5741\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 7.930352169385984e+16\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.1585446298122406\n","          entropy_coeff: 0.0\n","          kl: 0.17002590000629425\n","          model: {}\n","          policy_loss: 0.03392597287893295\n","          total_loss: 1.3483653615058944e+16\n","          vf_explained_var: 0.45903363823890686\n","          vf_loss: 1042.5906982421875\n","    num_agent_steps_sampled: 688000\n","    num_agent_steps_trained: 688000\n","    num_steps_sampled: 688000\n","    num_steps_trained: 688000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 172\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.799999999999999\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07041672390212327\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.29943745187070564\n","    mean_inference_ms: 0.7269185632463249\n","    mean_raw_obs_processing_ms: 0.1124613604304508\n","  time_since_restore: 1281.3405361175537\n","  time_this_iter_s: 7.9051806926727295\n","  time_total_s: 1281.3405361175537\n","  timers:\n","    learn_throughput: 1567.192\n","    learn_time_ms: 2552.336\n","    load_throughput: 9057504.724\n","    load_time_ms: 0.442\n","    sample_throughput: 515.626\n","    sample_time_ms: 7757.559\n","    update_time_ms: 2.848\n","  timestamp: 1649864379\n","  timesteps_since_restore: 688000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 688000\n","  training_iteration: 172\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 588000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-39-42\n","  done: false\n","  episode_len_mean: 225.61\n","  episode_media: {}\n","  episode_reward_max: 316.76685531376336\n","  episode_reward_mean: 263.59338454646576\n","  episode_reward_min: 0.6954499069663314\n","  episodes_this_iter: 21\n","  episodes_total: 2288\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5843432545661926\n","          entropy_coeff: 0.0\n","          kl: 0.017196383327245712\n","          model: {}\n","          policy_loss: -0.01521031092852354\n","          total_loss: 71.75955963134766\n","          vf_explained_var: 0.8127073645591736\n","          vf_loss: 71.7715072631836\n","    num_agent_steps_sampled: 588000\n","    num_agent_steps_trained: 588000\n","    num_steps_sampled: 588000\n","    num_steps_trained: 588000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 147\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.581818181818182\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07477349667848981\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5883377975861955\n","    mean_inference_ms: 0.7564012350456818\n","    mean_raw_obs_processing_ms: 0.11243040994044806\n","  time_since_restore: 1277.6397490501404\n","  time_this_iter_s: 7.8462114334106445\n","  time_total_s: 1277.6397490501404\n","  timers:\n","    learn_throughput: 1602.633\n","    learn_time_ms: 2495.892\n","    load_throughput: 8975613.097\n","    load_time_ms: 0.446\n","    sample_throughput: 489.21\n","    sample_time_ms: 8176.445\n","    update_time_ms: 2.911\n","  timestamp: 1649864382\n","  timesteps_since_restore: 588000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 588000\n","  training_iteration: 147\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:39:43 (running for 00:21:53.41)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   172</td><td style=\"text-align: right;\">         1281.34</td><td style=\"text-align: right;\">688000</td><td style=\"text-align: right;\">-445.838 </td><td style=\"text-align: right;\">            -244.058</td><td style=\"text-align: right;\">          -831.68   </td><td style=\"text-align: right;\">            138.57</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         1279.85</td><td style=\"text-align: right;\">468000</td><td style=\"text-align: right;\">  55.9989</td><td style=\"text-align: right;\">             278.446</td><td style=\"text-align: right;\">          -361.002  </td><td style=\"text-align: right;\">            455.17</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   147</td><td style=\"text-align: right;\">         1277.64</td><td style=\"text-align: right;\">588000</td><td style=\"text-align: right;\"> 263.593 </td><td style=\"text-align: right;\">             316.767</td><td style=\"text-align: right;\">             0.69545</td><td style=\"text-align: right;\">            225.61</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 692000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-39-47\n","  done: false\n","  episode_len_mean: 135.29\n","  episode_media: {}\n","  episode_reward_max: -244.05804002328222\n","  episode_reward_mean: -454.4907534870467\n","  episode_reward_min: -835.8677761383617\n","  episodes_this_iter: 31\n","  episodes_total: 5772\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.1895528683575706e+17\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.14910592138767242\n","          entropy_coeff: 0.0\n","          kl: 0.19891302287578583\n","          model: {}\n","          policy_loss: 0.030033227056264877\n","          total_loss: 2.3661754370228224e+16\n","          vf_explained_var: 0.5881300568580627\n","          vf_loss: 1875.009521484375\n","    num_agent_steps_sampled: 692000\n","    num_agent_steps_trained: 692000\n","    num_steps_sampled: 692000\n","    num_steps_trained: 692000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 173\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.890909090909092\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07041235066248454\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.29975288355128454\n","    mean_inference_ms: 0.7269008817609063\n","    mean_raw_obs_processing_ms: 0.1124536577061537\n","  time_since_restore: 1288.8557496070862\n","  time_this_iter_s: 7.515213489532471\n","  time_total_s: 1288.8557496070862\n","  timers:\n","    learn_throughput: 1568.648\n","    learn_time_ms: 2549.966\n","    load_throughput: 8739043.65\n","    load_time_ms: 0.458\n","    sample_throughput: 516.288\n","    sample_time_ms: 7747.614\n","    update_time_ms: 2.832\n","  timestamp: 1649864387\n","  timesteps_since_restore: 692000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 692000\n","  training_iteration: 173\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 472000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-39-47\n","  done: false\n","  episode_len_mean: 466.28\n","  episode_media: {}\n","  episode_reward_max: 278.44570431138135\n","  episode_reward_mean: 61.350862653223096\n","  episode_reward_min: -361.0023318393476\n","  episodes_this_iter: 6\n","  episodes_total: 1264\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.5187499523162842\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.8215041756629944\n","          entropy_coeff: 0.0\n","          kl: 0.00787992961704731\n","          model: {}\n","          policy_loss: -0.03380635380744934\n","          total_loss: 136.93267822265625\n","          vf_explained_var: 0.5399562120437622\n","          vf_loss: 136.95449829101562\n","    num_agent_steps_sampled: 472000\n","    num_agent_steps_trained: 472000\n","    num_steps_sampled: 472000\n","    num_steps_trained: 472000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 118\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.386666666666665\n","    ram_util_percent: 15.699999999999994\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07405136494491776\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1344564245213804\n","    mean_inference_ms: 0.7696889548305239\n","    mean_raw_obs_processing_ms: 0.11236286675229312\n","  time_since_restore: 1290.7903957366943\n","  time_this_iter_s: 10.93710994720459\n","  time_total_s: 1290.7903957366943\n","  timers:\n","    learn_throughput: 1616.917\n","    learn_time_ms: 2473.843\n","    load_throughput: 8649387.019\n","    load_time_ms: 0.462\n","    sample_throughput: 369.603\n","    sample_time_ms: 10822.425\n","    update_time_ms: 2.786\n","  timestamp: 1649864387\n","  timesteps_since_restore: 472000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 472000\n","  training_iteration: 118\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:39:48 (running for 00:21:58.67)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   173</td><td style=\"text-align: right;\">         1288.86</td><td style=\"text-align: right;\">692000</td><td style=\"text-align: right;\">-454.491 </td><td style=\"text-align: right;\">            -244.058</td><td style=\"text-align: right;\">          -835.868  </td><td style=\"text-align: right;\">            135.29</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   118</td><td style=\"text-align: right;\">         1290.79</td><td style=\"text-align: right;\">472000</td><td style=\"text-align: right;\">  61.3509</td><td style=\"text-align: right;\">             278.446</td><td style=\"text-align: right;\">          -361.002  </td><td style=\"text-align: right;\">            466.28</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   147</td><td style=\"text-align: right;\">         1277.64</td><td style=\"text-align: right;\">588000</td><td style=\"text-align: right;\"> 263.593 </td><td style=\"text-align: right;\">             316.767</td><td style=\"text-align: right;\">             0.69545</td><td style=\"text-align: right;\">            225.61</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 592000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-39-51\n","  done: false\n","  episode_len_mean: 232.21\n","  episode_media: {}\n","  episode_reward_max: 320.7497325929117\n","  episode_reward_mean: 264.92656326522484\n","  episode_reward_min: 0.6954499069663314\n","  episodes_this_iter: 12\n","  episodes_total: 2300\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5447871685028076\n","          entropy_coeff: 0.0\n","          kl: 0.007384161464869976\n","          model: {}\n","          policy_loss: -0.008687789551913738\n","          total_loss: 163.8455810546875\n","          vf_explained_var: 0.5139466524124146\n","          vf_loss: 163.8528594970703\n","    num_agent_steps_sampled: 592000\n","    num_agent_steps_trained: 592000\n","    num_steps_sampled: 592000\n","    num_steps_trained: 592000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 148\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.233333333333333\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07476955315798611\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5879911236347364\n","    mean_inference_ms: 0.7563524719907714\n","    mean_raw_obs_processing_ms: 0.11242588055503969\n","  time_since_restore: 1286.532279253006\n","  time_this_iter_s: 8.8925302028656\n","  time_total_s: 1286.532279253006\n","  timers:\n","    learn_throughput: 1601.937\n","    learn_time_ms: 2496.977\n","    load_throughput: 9004033.704\n","    load_time_ms: 0.444\n","    sample_throughput: 483.451\n","    sample_time_ms: 8273.843\n","    update_time_ms: 2.901\n","  timestamp: 1649864391\n","  timesteps_since_restore: 592000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 592000\n","  training_iteration: 148\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:39:54 (running for 00:22:04.34)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   173</td><td style=\"text-align: right;\">         1288.86</td><td style=\"text-align: right;\">692000</td><td style=\"text-align: right;\">-454.491 </td><td style=\"text-align: right;\">            -244.058</td><td style=\"text-align: right;\">          -835.868  </td><td style=\"text-align: right;\">            135.29</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   118</td><td style=\"text-align: right;\">         1290.79</td><td style=\"text-align: right;\">472000</td><td style=\"text-align: right;\">  61.3509</td><td style=\"text-align: right;\">             278.446</td><td style=\"text-align: right;\">          -361.002  </td><td style=\"text-align: right;\">            466.28</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   148</td><td style=\"text-align: right;\">         1286.53</td><td style=\"text-align: right;\">592000</td><td style=\"text-align: right;\"> 264.927 </td><td style=\"text-align: right;\">             320.75 </td><td style=\"text-align: right;\">             0.69545</td><td style=\"text-align: right;\">            232.21</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 696000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-39-54\n","  done: false\n","  episode_len_mean: 139.15\n","  episode_media: {}\n","  episode_reward_max: -249.10795490882768\n","  episode_reward_mean: -465.6401451580585\n","  episode_reward_min: -908.4537183761612\n","  episodes_this_iter: 30\n","  episodes_total: 5802\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.78432921663701e+17\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.11023493856191635\n","          entropy_coeff: 0.0\n","          kl: 0.16744181513786316\n","          model: {}\n","          policy_loss: 0.019318237900733948\n","          total_loss: 2.9877128245805056e+16\n","          vf_explained_var: 0.5191271901130676\n","          vf_loss: 1715.926025390625\n","    num_agent_steps_sampled: 696000\n","    num_agent_steps_trained: 696000\n","    num_steps_sampled: 696000\n","    num_steps_trained: 696000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 174\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.409090909090908\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07041210209894172\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.30008606128897874\n","    mean_inference_ms: 0.7269253319666545\n","    mean_raw_obs_processing_ms: 0.11245136760252276\n","  time_since_restore: 1296.388480424881\n","  time_this_iter_s: 7.5327308177948\n","  time_total_s: 1296.388480424881\n","  timers:\n","    learn_throughput: 1575.811\n","    learn_time_ms: 2538.376\n","    load_throughput: 8696913.587\n","    load_time_ms: 0.46\n","    sample_throughput: 515.473\n","    sample_time_ms: 7759.86\n","    update_time_ms: 2.866\n","  timestamp: 1649864394\n","  timesteps_since_restore: 696000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 696000\n","  training_iteration: 174\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 596000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-39-58\n","  done: false\n","  episode_len_mean: 226.69\n","  episode_media: {}\n","  episode_reward_max: 320.7497325929117\n","  episode_reward_mean: 266.09010575332024\n","  episode_reward_min: 7.12763580961969\n","  episodes_this_iter: 23\n","  episodes_total: 2323\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5615512728691101\n","          entropy_coeff: 0.0\n","          kl: 0.006127819884568453\n","          model: {}\n","          policy_loss: -0.009935394860804081\n","          total_loss: 323.67547607421875\n","          vf_explained_var: 0.8475030064582825\n","          vf_loss: 323.6842346191406\n","    num_agent_steps_sampled: 596000\n","    num_agent_steps_trained: 596000\n","    num_steps_sampled: 596000\n","    num_steps_trained: 596000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 149\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.758333333333333\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07476315965630999\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5872655801852693\n","    mean_inference_ms: 0.7562456813215523\n","    mean_raw_obs_processing_ms: 0.11242047025554854\n","  time_since_restore: 1294.3435473442078\n","  time_this_iter_s: 7.811268091201782\n","  time_total_s: 1294.3435473442078\n","  timers:\n","    learn_throughput: 1596.621\n","    learn_time_ms: 2505.29\n","    load_throughput: 9241099.422\n","    load_time_ms: 0.433\n","    sample_throughput: 484.825\n","    sample_time_ms: 8250.405\n","    update_time_ms: 2.872\n","  timestamp: 1649864398\n","  timesteps_since_restore: 596000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 596000\n","  training_iteration: 149\n","  trial_id: e18ba_00002\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 476000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-39-59\n","  done: false\n","  episode_len_mean: 502.36\n","  episode_media: {}\n","  episode_reward_max: 278.44570431138135\n","  episode_reward_mean: 68.76326873883518\n","  episode_reward_min: -361.0023318393476\n","  episodes_this_iter: 6\n","  episodes_total: 1270\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.5187499523162842\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.7702551484107971\n","          entropy_coeff: 0.0\n","          kl: 0.008435281924903393\n","          model: {}\n","          policy_loss: -0.024687286466360092\n","          total_loss: 87.11827850341797\n","          vf_explained_var: 0.6405874490737915\n","          vf_loss: 87.13015747070312\n","    num_agent_steps_sampled: 476000\n","    num_agent_steps_trained: 476000\n","    num_steps_sampled: 476000\n","    num_steps_trained: 476000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 119\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.470588235294118\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07404950795472126\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1343452702214285\n","    mean_inference_ms: 0.7696729076770784\n","    mean_raw_obs_processing_ms: 0.11235836373734584\n","  time_since_restore: 1302.4469065666199\n","  time_this_iter_s: 11.656510829925537\n","  time_total_s: 1302.4469065666199\n","  timers:\n","    learn_throughput: 1610.976\n","    learn_time_ms: 2482.967\n","    load_throughput: 8681163.2\n","    load_time_ms: 0.461\n","    sample_throughput: 366.49\n","    sample_time_ms: 10914.349\n","    update_time_ms: 2.763\n","  timestamp: 1649864399\n","  timesteps_since_restore: 476000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 476000\n","  training_iteration: 119\n","  trial_id: e18ba_00001\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:39:59 (running for 00:22:09.36)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   174</td><td style=\"text-align: right;\">         1296.39</td><td style=\"text-align: right;\">696000</td><td style=\"text-align: right;\">-465.64  </td><td style=\"text-align: right;\">            -249.108</td><td style=\"text-align: right;\">          -908.454  </td><td style=\"text-align: right;\">            139.15</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         1302.45</td><td style=\"text-align: right;\">476000</td><td style=\"text-align: right;\">  68.7633</td><td style=\"text-align: right;\">             278.446</td><td style=\"text-align: right;\">          -361.002  </td><td style=\"text-align: right;\">            502.36</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   149</td><td style=\"text-align: right;\">         1294.34</td><td style=\"text-align: right;\">596000</td><td style=\"text-align: right;\"> 266.09  </td><td style=\"text-align: right;\">             320.75 </td><td style=\"text-align: right;\">             7.12764</td><td style=\"text-align: right;\">            226.69</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 700000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-40-02\n","  done: false\n","  episode_len_mean: 137.3\n","  episode_media: {}\n","  episode_reward_max: -250.0691471642349\n","  episode_reward_mean: -461.2232795855475\n","  episode_reward_min: -908.4537183761612\n","  episodes_this_iter: 30\n","  episodes_total: 5832\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 2.6764939108548608e+17\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.14120174944400787\n","          entropy_coeff: 0.0\n","          kl: 0.16336748003959656\n","          model: {}\n","          policy_loss: 0.01408499013632536\n","          total_loss: 4.372520661470413e+16\n","          vf_explained_var: 0.7000799179077148\n","          vf_loss: 1086.8890380859375\n","    num_agent_steps_sampled: 700000\n","    num_agent_steps_trained: 700000\n","    num_steps_sampled: 700000\n","    num_steps_trained: 700000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 175\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.090909090909093\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07041525761732513\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.30039130879114523\n","    mean_inference_ms: 0.726982327810031\n","    mean_raw_obs_processing_ms: 0.11245303834916592\n","  time_since_restore: 1304.1468291282654\n","  time_this_iter_s: 7.758348703384399\n","  time_total_s: 1304.1468291282654\n","  timers:\n","    learn_throughput: 1574.875\n","    learn_time_ms: 2539.884\n","    load_throughput: 8812951.621\n","    load_time_ms: 0.454\n","    sample_throughput: 516.54\n","    sample_time_ms: 7743.83\n","    update_time_ms: 2.867\n","  timestamp: 1649864402\n","  timesteps_since_restore: 700000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 700000\n","  training_iteration: 175\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:40:04 (running for 00:22:14.90)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   175</td><td style=\"text-align: right;\">         1304.15</td><td style=\"text-align: right;\">700000</td><td style=\"text-align: right;\">-461.223 </td><td style=\"text-align: right;\">            -250.069</td><td style=\"text-align: right;\">          -908.454  </td><td style=\"text-align: right;\">            137.3 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         1302.45</td><td style=\"text-align: right;\">476000</td><td style=\"text-align: right;\">  68.7633</td><td style=\"text-align: right;\">             278.446</td><td style=\"text-align: right;\">          -361.002  </td><td style=\"text-align: right;\">            502.36</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   149</td><td style=\"text-align: right;\">         1294.34</td><td style=\"text-align: right;\">596000</td><td style=\"text-align: right;\"> 266.09  </td><td style=\"text-align: right;\">             320.75 </td><td style=\"text-align: right;\">             7.12764</td><td style=\"text-align: right;\">            226.69</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 600000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-40-06\n","  done: false\n","  episode_len_mean: 227.69\n","  episode_media: {}\n","  episode_reward_max: 320.7497325929117\n","  episode_reward_mean: 266.46597990851984\n","  episode_reward_min: 37.64518265811651\n","  episodes_this_iter: 21\n","  episodes_total: 2344\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5538709163665771\n","          entropy_coeff: 0.0\n","          kl: 0.005058100912719965\n","          model: {}\n","          policy_loss: -0.013486037030816078\n","          total_loss: 281.78192138671875\n","          vf_explained_var: 0.8539168834686279\n","          vf_loss: 281.7944641113281\n","    num_agent_steps_sampled: 600000\n","    num_agent_steps_trained: 600000\n","    num_steps_sampled: 600000\n","    num_steps_trained: 600000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 150\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.290909090909093\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.0747613055384917\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5865332859724315\n","    mean_inference_ms: 0.7562076078022408\n","    mean_raw_obs_processing_ms: 0.11242102992269523\n","  time_since_restore: 1302.2060842514038\n","  time_this_iter_s: 7.862536907196045\n","  time_total_s: 1302.2060842514038\n","  timers:\n","    learn_throughput: 1597.403\n","    learn_time_ms: 2504.065\n","    load_throughput: 9209142.606\n","    load_time_ms: 0.434\n","    sample_throughput: 482.829\n","    sample_time_ms: 8284.501\n","    update_time_ms: 2.86\n","  timestamp: 1649864406\n","  timesteps_since_restore: 600000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 600000\n","  training_iteration: 150\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:40:09 (running for 00:22:20.08)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   175</td><td style=\"text-align: right;\">         1304.15</td><td style=\"text-align: right;\">700000</td><td style=\"text-align: right;\">-461.223 </td><td style=\"text-align: right;\">            -250.069</td><td style=\"text-align: right;\">           -908.454 </td><td style=\"text-align: right;\">            137.3 </td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         1302.45</td><td style=\"text-align: right;\">476000</td><td style=\"text-align: right;\">  68.7633</td><td style=\"text-align: right;\">             278.446</td><td style=\"text-align: right;\">           -361.002 </td><td style=\"text-align: right;\">            502.36</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   150</td><td style=\"text-align: right;\">         1302.21</td><td style=\"text-align: right;\">600000</td><td style=\"text-align: right;\"> 266.466 </td><td style=\"text-align: right;\">             320.75 </td><td style=\"text-align: right;\">             37.6452</td><td style=\"text-align: right;\">            227.69</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 704000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-40-10\n","  done: false\n","  episode_len_mean: 133.02\n","  episode_media: {}\n","  episode_reward_max: -270.2641328163826\n","  episode_reward_mean: -451.88342139476305\n","  episode_reward_min: -908.4537183761612\n","  episodes_this_iter: 30\n","  episodes_total: 5862\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 4.014740952181637e+17\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.145751491189003\n","          entropy_coeff: 0.0\n","          kl: 0.15860773622989655\n","          model: {}\n","          policy_loss: 0.029765067622065544\n","          total_loss: 6.367689307271987e+16\n","          vf_explained_var: 0.6742236018180847\n","          vf_loss: 1084.706298828125\n","    num_agent_steps_sampled: 704000\n","    num_agent_steps_trained: 704000\n","    num_steps_sampled: 704000\n","    num_steps_trained: 704000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 176\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.29090909090909\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07042926344194603\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.3006114810878748\n","    mean_inference_ms: 0.7271527181442281\n","    mean_raw_obs_processing_ms: 0.11247777948498534\n","  time_since_restore: 1312.180188179016\n","  time_this_iter_s: 8.033359050750732\n","  time_total_s: 1312.180188179016\n","  timers:\n","    learn_throughput: 1572.022\n","    learn_time_ms: 2544.494\n","    load_throughput: 8889533.196\n","    load_time_ms: 0.45\n","    sample_throughput: 518.244\n","    sample_time_ms: 7718.379\n","    update_time_ms: 2.904\n","  timestamp: 1649864410\n","  timesteps_since_restore: 704000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 704000\n","  training_iteration: 176\n","  trial_id: e18ba_00000\n","  \n","Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 480000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-40-11\n","  done: false\n","  episode_len_mean: 520.27\n","  episode_media: {}\n","  episode_reward_max: 278.44570431138135\n","  episode_reward_mean: 75.91554375263665\n","  episode_reward_min: -297.0554797265481\n","  episodes_this_iter: 7\n","  episodes_total: 1277\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.5187499523162842\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.802371621131897\n","          entropy_coeff: 0.0\n","          kl: 0.009519580751657486\n","          model: {}\n","          policy_loss: -0.04094293341040611\n","          total_loss: 116.76417541503906\n","          vf_explained_var: 0.7059898376464844\n","          vf_loss: 116.79066467285156\n","    num_agent_steps_sampled: 480000\n","    num_agent_steps_trained: 480000\n","    num_steps_sampled: 480000\n","    num_steps_trained: 480000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 120\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.435294117647059\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07404903255207071\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1343192483174658\n","    mean_inference_ms: 0.769672673077837\n","    mean_raw_obs_processing_ms: 0.11235568554549595\n","  time_since_restore: 1314.3377754688263\n","  time_this_iter_s: 11.890868902206421\n","  time_total_s: 1314.3377754688263\n","  timers:\n","    learn_throughput: 1608.027\n","    learn_time_ms: 2487.521\n","    load_throughput: 8686107.171\n","    load_time_ms: 0.461\n","    sample_throughput: 362.409\n","    sample_time_ms: 11037.239\n","    update_time_ms: 2.754\n","  timestamp: 1649864411\n","  timesteps_since_restore: 480000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 480000\n","  training_iteration: 120\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 604000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-40-14\n","  done: false\n","  episode_len_mean: 211.7\n","  episode_media: {}\n","  episode_reward_max: 320.7497325929117\n","  episode_reward_mean: 263.9632542391501\n","  episode_reward_min: 37.64518265811651\n","  episodes_this_iter: 20\n","  episodes_total: 2364\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5402805805206299\n","          entropy_coeff: 0.0\n","          kl: 0.005854194518178701\n","          model: {}\n","          policy_loss: -0.008037015795707703\n","          total_loss: 255.95558166503906\n","          vf_explained_var: 0.7664316892623901\n","          vf_loss: 255.96249389648438\n","    num_agent_steps_sampled: 604000\n","    num_agent_steps_trained: 604000\n","    num_steps_sampled: 604000\n","    num_steps_trained: 604000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 151\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.891666666666667\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07476733113633906\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5856486563988955\n","    mean_inference_ms: 0.7562192644897059\n","    mean_raw_obs_processing_ms: 0.11243283454005593\n","  time_since_restore: 1310.3043804168701\n","  time_this_iter_s: 8.098296165466309\n","  time_total_s: 1310.3043804168701\n","  timers:\n","    learn_throughput: 1611.336\n","    learn_time_ms: 2482.413\n","    load_throughput: 9311364.191\n","    load_time_ms: 0.43\n","    sample_throughput: 486.053\n","    sample_time_ms: 8229.556\n","    update_time_ms: 2.826\n","  timestamp: 1649864414\n","  timesteps_since_restore: 604000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 604000\n","  training_iteration: 151\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:40:15 (running for 00:22:25.22)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   176</td><td style=\"text-align: right;\">         1312.18</td><td style=\"text-align: right;\">704000</td><td style=\"text-align: right;\">-451.883 </td><td style=\"text-align: right;\">            -270.264</td><td style=\"text-align: right;\">           -908.454 </td><td style=\"text-align: right;\">            133.02</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   120</td><td style=\"text-align: right;\">         1314.34</td><td style=\"text-align: right;\">480000</td><td style=\"text-align: right;\">  75.9155</td><td style=\"text-align: right;\">             278.446</td><td style=\"text-align: right;\">           -297.055 </td><td style=\"text-align: right;\">            520.27</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   151</td><td style=\"text-align: right;\">         1310.3 </td><td style=\"text-align: right;\">604000</td><td style=\"text-align: right;\"> 263.963 </td><td style=\"text-align: right;\">             320.75 </td><td style=\"text-align: right;\">             37.6452</td><td style=\"text-align: right;\">            211.7 </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00000:\n","  agent_timesteps_total: 708000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-40-18\n","  done: false\n","  episode_len_mean: 129.38\n","  episode_media: {}\n","  episode_reward_max: -270.2641328163826\n","  episode_reward_mean: -443.36072464993964\n","  episode_reward_min: -925.0004846222253\n","  episodes_this_iter: 30\n","  episodes_total: 5892\n","  experiment_id: 532053c9a6a04052b52c110d1abf8844\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 6.022111084675072e+17\n","          cur_lr: 0.009999999776482582\n","          entropy: 0.13369335234165192\n","          entropy_coeff: 0.0\n","          kl: 0.1434919834136963\n","          model: {}\n","          policy_loss: 0.015821531414985657\n","          total_loss: 8.641245707291853e+16\n","          vf_explained_var: 0.7962785363197327\n","          vf_loss: 1821.8272705078125\n","    num_agent_steps_sampled: 708000\n","    num_agent_steps_trained: 708000\n","    num_steps_sampled: 708000\n","    num_steps_trained: 708000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 177\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 12.80909090909091\n","    ram_util_percent: 15.699999999999996\n","  pid: 608\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07044192591487848\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.300886741523557\n","    mean_inference_ms: 0.7273257818527454\n","    mean_raw_obs_processing_ms: 0.11250164810442584\n","  time_since_restore: 1319.8320372104645\n","  time_this_iter_s: 7.651849031448364\n","  time_total_s: 1319.8320372104645\n","  timers:\n","    learn_throughput: 1582.008\n","    learn_time_ms: 2528.433\n","    load_throughput: 8907468.012\n","    load_time_ms: 0.449\n","    sample_throughput: 515.692\n","    sample_time_ms: 7756.565\n","    update_time_ms: 2.917\n","  timestamp: 1649864418\n","  timesteps_since_restore: 708000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 708000\n","  training_iteration: 177\n","  trial_id: e18ba_00000\n","  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:40:20 (running for 00:22:30.66)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   177</td><td style=\"text-align: right;\">         1319.83</td><td style=\"text-align: right;\">708000</td><td style=\"text-align: right;\">-443.361 </td><td style=\"text-align: right;\">            -270.264</td><td style=\"text-align: right;\">           -925     </td><td style=\"text-align: right;\">            129.38</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   120</td><td style=\"text-align: right;\">         1314.34</td><td style=\"text-align: right;\">480000</td><td style=\"text-align: right;\">  75.9155</td><td style=\"text-align: right;\">             278.446</td><td style=\"text-align: right;\">           -297.055 </td><td style=\"text-align: right;\">            520.27</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   151</td><td style=\"text-align: right;\">         1310.3 </td><td style=\"text-align: right;\">604000</td><td style=\"text-align: right;\"> 263.963 </td><td style=\"text-align: right;\">             320.75 </td><td style=\"text-align: right;\">             37.6452</td><td style=\"text-align: right;\">            211.7 </td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Result for PPO_LunarLander-v2_e18ba_00001:\n","  agent_timesteps_total: 484000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-40-22\n","  done: false\n","  episode_len_mean: 535.14\n","  episode_media: {}\n","  episode_reward_max: 278.44570431138135\n","  episode_reward_mean: 80.44125447802725\n","  episode_reward_min: -189.6989556851844\n","  episodes_this_iter: 7\n","  episodes_total: 1284\n","  experiment_id: e406fef714334efb807e1b1a03fc7cac\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 1.5187499523162842\n","          cur_lr: 0.0010000000474974513\n","          entropy: 0.7484246492385864\n","          entropy_coeff: 0.0\n","          kl: 0.00816374458372593\n","          model: {}\n","          policy_loss: -0.042593203485012054\n","          total_loss: 341.70550537109375\n","          vf_explained_var: 0.6308419108390808\n","          vf_loss: 341.7357482910156\n","    num_agent_steps_sampled: 484000\n","    num_agent_steps_trained: 484000\n","    num_steps_sampled: 484000\n","    num_steps_trained: 484000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 121\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 13.541176470588237\n","    ram_util_percent: 15.7\n","  pid: 604\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07405083375746291\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 1.1343922749556994\n","    mean_inference_ms: 0.769697565833377\n","    mean_raw_obs_processing_ms: 0.11235716180096732\n","  time_since_restore: 1325.85630941391\n","  time_this_iter_s: 11.518533945083618\n","  time_total_s: 1325.85630941391\n","  timers:\n","    learn_throughput: 1604.459\n","    learn_time_ms: 2493.052\n","    load_throughput: 8635585.753\n","    load_time_ms: 0.463\n","    sample_throughput: 357.671\n","    sample_time_ms: 11183.448\n","    update_time_ms: 2.785\n","  timestamp: 1649864422\n","  timesteps_since_restore: 484000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 484000\n","  training_iteration: 121\n","  trial_id: e18ba_00001\n","  \n","Result for PPO_LunarLander-v2_e18ba_00002:\n","  agent_timesteps_total: 608000\n","  custom_metrics: {}\n","  date: 2022-04-13_15-40-22\n","  done: false\n","  episode_len_mean: 203.38\n","  episode_media: {}\n","  episode_reward_max: 320.7497325929117\n","  episode_reward_mean: 270.52191464207067\n","  episode_reward_min: 39.462876607168226\n","  episodes_this_iter: 22\n","  episodes_total: 2386\n","  experiment_id: 703ac753a4e54907ba32748844c964e6\n","  hostname: 2783ca1d819b\n","  info:\n","    learner:\n","      default_policy:\n","        custom_metrics: {}\n","        learner_stats:\n","          cur_kl_coeff: 0.18984374403953552\n","          cur_lr: 9.999999747378752e-05\n","          entropy: 0.5320643186569214\n","          entropy_coeff: 0.0\n","          kl: 0.0074140047654509544\n","          model: {}\n","          policy_loss: -0.017219113186001778\n","          total_loss: 88.81883239746094\n","          vf_explained_var: 0.8717724084854126\n","          vf_loss: 88.83465576171875\n","    num_agent_steps_sampled: 608000\n","    num_agent_steps_trained: 608000\n","    num_steps_sampled: 608000\n","    num_steps_trained: 608000\n","    num_steps_trained_this_iter: 4000\n","  iterations_since_restore: 152\n","  node_ip: 172.28.0.2\n","  num_healthy_workers: 1\n","  off_policy_estimator: {}\n","  perf:\n","    cpu_util_percent: 14.20909090909091\n","    ram_util_percent: 15.699999999999996\n","  pid: 601\n","  policy_reward_max: {}\n","  policy_reward_mean: {}\n","  policy_reward_min: {}\n","  sampler_perf:\n","    mean_action_processing_ms: 0.07477045216843207\n","    mean_env_render_ms: 0.0\n","    mean_env_wait_ms: 0.5845546993542833\n","    mean_inference_ms: 0.7561757571197174\n","    mean_raw_obs_processing_ms: 0.1124419657325648\n","  time_since_restore: 1317.9735143184662\n","  time_this_iter_s: 7.669133901596069\n","  time_total_s: 1317.9735143184662\n","  timers:\n","    learn_throughput: 1612.204\n","    learn_time_ms: 2481.076\n","    load_throughput: 9029232.011\n","    load_time_ms: 0.443\n","    sample_throughput: 487.824\n","    sample_time_ms: 8199.671\n","    update_time_ms: 2.783\n","  timestamp: 1649864422\n","  timesteps_since_restore: 608000\n","  timesteps_this_iter: 4000\n","  timesteps_total: 608000\n","  training_iteration: 152\n","  trial_id: e18ba_00002\n","  \n"]},{"output_type":"stream","name":"stderr","text":["2022-04-13 15:40:23,729\tWARNING tune.py:596 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["== Status ==<br>Current time: 2022-04-13 15:40:23 (running for 00:22:34.01)<br>Memory usage on this node: 5.5/35.2 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/40 CPUs, 0/0 GPUs, 0.0/20.28 GiB heap, 0.0/10.14 GiB objects<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n","<thead>\n","<tr><th>Trial name                    </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>PPO_LunarLander-v2_e18ba_00000</td><td>RUNNING </td><td>172.28.0.2:608</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   177</td><td style=\"text-align: right;\">         1319.83</td><td style=\"text-align: right;\">708000</td><td style=\"text-align: right;\">-443.361 </td><td style=\"text-align: right;\">            -270.264</td><td style=\"text-align: right;\">           -925     </td><td style=\"text-align: right;\">            129.38</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00001</td><td>RUNNING </td><td>172.28.0.2:604</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">   121</td><td style=\"text-align: right;\">         1325.86</td><td style=\"text-align: right;\">484000</td><td style=\"text-align: right;\">  80.4413</td><td style=\"text-align: right;\">             278.446</td><td style=\"text-align: right;\">           -189.699 </td><td style=\"text-align: right;\">            535.14</td></tr>\n","<tr><td>PPO_LunarLander-v2_e18ba_00002</td><td>RUNNING </td><td>172.28.0.2:601</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">   152</td><td style=\"text-align: right;\">         1317.97</td><td style=\"text-align: right;\">608000</td><td style=\"text-align: right;\"> 270.522 </td><td style=\"text-align: right;\">             320.75 </td><td style=\"text-align: right;\">             39.4629</td><td style=\"text-align: right;\">            203.38</td></tr>\n","</tbody>\n","</table><br><br>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2022-04-13 15:40:24,035\tERROR tune.py:635 -- Trials did not complete: [PPO_LunarLander-v2_e18ba_00000, PPO_LunarLander-v2_e18ba_00001, PPO_LunarLander-v2_e18ba_00002]\n","2022-04-13 15:40:24,036\tINFO tune.py:639 -- Total run time: 1354.23 seconds (1353.92 seconds for the tuning loop).\n","2022-04-13 15:40:24,037\tWARNING tune.py:644 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"]},{"output_type":"execute_result","data":{"text/plain":["<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7f464bffb710>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["print(\"Best hyperparameters found were: \", analysis.best_config)"],"metadata":{"id":"LJ8pqXHfdicB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# list of lists: one list per checkpoint; each checkpoint list contains\n","# 1st the path, 2nd the metric value\n","checkpoints = analysis.get_trial_checkpoints_paths(\n","    trial=analysis.get_best_trial(\"episode_reward_mean\"),\n","    metric=\"episode_reward_mean\")\n","\n","# or simply get the last checkpoint (with highest \"training_iteration\")\n","last_checkpoint = analysis.get_last_checkpoint()\n","# if there are multiple trials, select a specific trial or automatically\n","# choose the best one according to a given metric\n","last_checkpoint = analysis.get_last_checkpoint(\n","    metric=\"episode_reward_mean\", mode=\"max\"\n",")"],"metadata":{"id":"29uU1dxodFpL"},"execution_count":null,"outputs":[]}]}