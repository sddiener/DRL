{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# plotting\n",
    "%matplotlib inline\n",
    "import time\n",
    "import pylab as pl\n",
    "from IPython import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\DRL\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] Cannot change thread mode after it is set\n",
      "  warnings.warn(str(err))\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"LunarLander-v2\")\n",
    "env.reset()\n",
    "for _ in range(1000):\n",
    "    new_observation, reward, done, info = env.step(env.action_space.sample())\n",
    "    arr = env.render(mode=\"rgb_array\")\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(4)\n",
      "Box([-inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf], (8,), float32)\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space) #[Output: ] Discrete(2)\n",
    "print(env.observation_space) # [Output: ] Box(4,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 - Replay Buffer for Experience replay\n",
    "\n",
    "The first step of this lab is to create a Replay Buffer that will allow us to use Experience Replay and mini-batch learning.\n",
    "- First, we create a class Transition using named tuple, which holds state transition in a dedicated data structure.\n",
    "- Then, create a Replay Memory class that collects transition in a First In First Out fashion (fixed memory size). This Replay memory should convert the states, action, rewards into tensors.\n",
    "\n",
    "The models presented in the Pytorch tutorial are quite generic and can be used as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory:\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, state, action, next_state, reward):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        \n",
    "        state_tensor = T.from_numpy(state)\n",
    "        \n",
    "        if next_state is None:\n",
    "            state_tensor_next = None            \n",
    "        else:\n",
    "            state_tensor_next = T.from_numpy(next_state)\n",
    "        \n",
    "        action_tensor = torch.tensor([action], device=device).unsqueeze(0)\n",
    "\n",
    "        reward = torch.tensor([reward], device=device).unsqueeze(0)/10. # reward scaling\n",
    "\n",
    "        self.memory[self.position] = Transition(state_tensor, action_tensor, state_tensor_next, reward)  # save the transition\n",
    "        self.position = (self.position + 1) % self.capacity  # loop around memory\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Q-network\n",
    "\n",
    "A Q-network is a neural network that maps states to Q-values for each actions.\n",
    "\n",
    "Implement a first version of Q-networks.\n",
    "Keep it simple (e.g. 3 hidden layers, with Relu activations).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, size_hidden, output_size):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, size_hidden)\n",
    "        #self.bn1 = nn.BatchNorm1d(size_hidden)\n",
    "        \n",
    "        self.fc2 = nn.Linear(size_hidden, size_hidden)   \n",
    "        #self.bn2 = nn.BatchNorm1d(size_hidden)\n",
    "\n",
    "        self.fc3 = nn.Linear(size_hidden, size_hidden)  \n",
    "        #self.bn3 = nn.BatchNorm1d(size_hidden)\n",
    "\n",
    "        self.fc4 = nn.Linear(size_hidden, output_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        h1 = F.relu(self.fc1(x.float()))  # self.bn1()\n",
    "        h2 = F.relu(self.fc2(h1))  # self.bn2()\n",
    "        h3 = F.relu(self.fc3(h2))  # self.bn3()\n",
    "        output = self.fc4(h3) # .view(h3.size(0), -1)\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 - Set up the Q-networks\n",
    "\n",
    "In DQN, the weights of the target network are copied from the weights of policy network every few iterations.\n",
    "\n",
    "We set the frequency of update using TARGET_UPDATE = 10.\n",
    "\n",
    "Instead of RMSprop we will use SGD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBS_SIZE = 8\n",
    "HIDDEN_SIZE = 64\n",
    "ACTION_SIZE = 4\n",
    "\n",
    "Q_network = DQN(OBS_SIZE, HIDDEN_SIZE, ACTION_SIZE).to(device)\n",
    "Q_target = DQN(OBS_SIZE, HIDDEN_SIZE, ACTION_SIZE).to(device)\n",
    "Q_target.load_state_dict(Q_network.state_dict())\n",
    "Q_target.eval()\n",
    "\n",
    "TARGET_UPDATE = 20\n",
    "\n",
    "optimizer = optim.Adam(Q_network.parameters(), lr=0.001)\n",
    "memory = ReplayMemory(100000)\n",
    "\n",
    "#for p in Q_network.parameters():\n",
    "#    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4 - Epsilon-greedy policy\n",
    "\n",
    "You can take inspiration from pytorch tutorial and implement the select_action function.\n",
    "Or, alternatively, you can implement a E-greedy policy class that will select epsilon greedy actions..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class E_Greedy_Policy():\n",
    "    \n",
    "    def __init__(self, epsilon, decay, min_epsilon):\n",
    "        \n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_start = epsilon\n",
    "        self.decay = decay\n",
    "        self.epsilon_min = min_epsilon\n",
    "                \n",
    "    def __call__(self, state):\n",
    "                \n",
    "        is_greedy = random.random() > self.epsilon\n",
    "        if is_greedy :\n",
    "            # we select greedy action\n",
    "            with torch.no_grad():\n",
    "                Q_network.eval()\n",
    "                index_action = Q_network(state).argmax().detach().cpu().numpy().item()  # state is on cpu instead of GPU!\n",
    "                Q_network.train()\n",
    "\n",
    "        else:\n",
    "            # we sample a random action\n",
    "            index_action = env.action_space.sample() # select random action (4 possible values)\n",
    "        \n",
    "        return index_action\n",
    "                \n",
    "    def update_epsilon(self):\n",
    "        \n",
    "        self.epsilon = self.epsilon*self.decay\n",
    "        if self.epsilon < self.epsilon_min:\n",
    "            self.epsilon = self.epsilon_min\n",
    "        \n",
    "    def reset(self):\n",
    "        self.epsilon = self.epsilon_start\n",
    "        \n",
    "        \n",
    "policy = E_Greedy_Policy(epsilon=0.5, decay=0.997, min_epsilon=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5 - Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "GAMMA = 0.99\n",
    "\n",
    "def optimize_model():\n",
    "    \n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "    non_final_next_states = torch.reshape(non_final_next_states, (non_final_mask.sum(), -1)).float().to(device)  # Reshape to (nr. non final, 8)\n",
    "\n",
    "    state_batch = torch.cat(batch.state).float().to(device)  # .float().to(device) to move to GPU\n",
    "    state_batch = torch.reshape(state_batch, (BATCH_SIZE, -1))  # Reshape to (batch_size, 8)\n",
    "    action_batch = torch.cat(batch.action).to(device)\n",
    "    reward_batch = torch.cat(batch.reward).float().to(device)\n",
    "    \n",
    "    # Compute Q values using policy net\n",
    "    Q_values = Q_network(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute next Q values using Q_targets\n",
    "    next_Q_values = torch.zeros( BATCH_SIZE, device=device).to(device)\n",
    "    next_Q_values[non_final_mask] = Q_target(non_final_next_states).max(1)[0].detach()\n",
    "    next_Q_values = next_Q_values.unsqueeze(1)\n",
    "    \n",
    "    # Compute targets\n",
    "    target_Q_values = (next_Q_values * GAMMA) + reward_batch\n",
    "    \n",
    "    # Compute MSE Loss\n",
    "    loss = F.mse_loss(Q_values, target_Q_values)\n",
    "    \n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Trick: gradient clipping\n",
    "    for param in Q_network.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "        \n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warmup phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Viewer.__del__ at 0x0000028A853BC820>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DRL\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 185, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DRL\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 101, in close\n",
      "    self.window.close()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DRL\\lib\\site-packages\\pyglet\\window\\win32\\__init__.py\", line 319, in close\n",
      "    super(Win32Window, self).close()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DRL\\lib\\site-packages\\pyglet\\window\\__init__.py\", line 838, in close\n",
      "    app.windows.remove(self)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\DRL\\lib\\_weakrefset.py\", line 114, in remove\n",
      "    self.data.remove(ref(item))\n",
      "KeyError: <weakref at 0x0000028A853699A0; to 'Win32Window' at 0x0000028A84F7BA30>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with the warmup\n",
      "Episode 0 - reward: -123.670, eps: 0.498 loss: 0.709 avg. loss: -12.367\n",
      "Episode 10 - reward: -119.218, eps: 0.484 loss: 0.926 avg. loss: -171.985\n",
      "Episode 20 - reward: -230.425, eps: 0.469 loss: 0.842 avg. loss: -145.030\n",
      "Episode 30 - reward: -262.286, eps: 0.456 loss: 0.038 avg. loss: -145.577\n",
      "Episode 40 - reward: -74.872, eps: 0.442 loss: 0.115 avg. loss: -90.683\n",
      "Episode 50 - reward: -62.563, eps: 0.429 loss: 0.258 avg. loss: -90.298\n",
      "Episode 60 - reward: -58.674, eps: 0.416 loss: 0.104 avg. loss: -94.932\n",
      "Episode 70 - reward: 1.846, eps: 0.404 loss: 0.082 avg. loss: -28.565\n",
      "Episode 80 - reward: -57.531, eps: 0.392 loss: 0.178 avg. loss: -98.836\n",
      "Episode 90 - reward: 22.395, eps: 0.380 loss: 0.380 avg. loss: -89.916\n",
      "Episode 100 - reward: -209.239, eps: 0.369 loss: 0.078 avg. loss: -69.865\n",
      "Episode 110 - reward: -32.054, eps: 0.358 loss: 0.079 avg. loss: -64.228\n",
      "Episode 120 - reward: -49.352, eps: 0.348 loss: 0.177 avg. loss: -64.953\n",
      "Episode 130 - reward: 10.692, eps: 0.337 loss: 0.116 avg. loss: -36.824\n",
      "Episode 140 - reward: -44.100, eps: 0.327 loss: 0.061 avg. loss: -37.063\n",
      "Episode 150 - reward: 83.189, eps: 0.318 loss: 0.304 avg. loss: -11.939\n",
      "Episode 160 - reward: -42.270, eps: 0.308 loss: 0.165 avg. loss: -67.850\n",
      "Episode 170 - reward: 30.038, eps: 0.299 loss: 0.083 avg. loss: -50.211\n",
      "Episode 180 - reward: 13.415, eps: 0.290 loss: 0.090 avg. loss: -94.966\n",
      "Episode 190 - reward: 36.416, eps: 0.282 loss: 0.060 avg. loss: -35.591\n",
      "Episode 200 - reward: -27.933, eps: 0.273 loss: 0.183 avg. loss: -34.845\n",
      "Episode 210 - reward: 66.516, eps: 0.265 loss: 0.049 avg. loss: -27.282\n",
      "Episode 220 - reward: -15.129, eps: 0.257 loss: 0.104 avg. loss: 6.035\n",
      "Episode 230 - reward: -53.648, eps: 0.250 loss: 0.030 avg. loss: 13.208\n",
      "Episode 240 - reward: -81.573, eps: 0.242 loss: 0.083 avg. loss: -15.812\n",
      "Episode 250 - reward: -81.472, eps: 0.235 loss: 0.019 avg. loss: -16.645\n",
      "Episode 260 - reward: 11.739, eps: 0.228 loss: 0.057 avg. loss: -31.403\n",
      "Episode 270 - reward: -50.820, eps: 0.221 loss: 0.027 avg. loss: -49.369\n",
      "Episode 280 - reward: -59.399, eps: 0.215 loss: 0.038 avg. loss: -48.453\n",
      "Episode 290 - reward: -45.389, eps: 0.209 loss: 0.014 avg. loss: -11.987\n",
      "Episode 300 - reward: 26.867, eps: 0.202 loss: 0.010 avg. loss: -17.697\n",
      "Episode 310 - reward: 21.184, eps: 0.196 loss: 0.017 avg. loss: 44.184\n",
      "Episode 320 - reward: -38.852, eps: 0.191 loss: 0.016 avg. loss: 1.109\n",
      "Episode 330 - reward: -17.786, eps: 0.185 loss: 0.010 avg. loss: -24.709\n",
      "Episode 340 - reward: 11.020, eps: 0.179 loss: 0.008 avg. loss: -1.670\n",
      "Episode 350 - reward: -135.763, eps: 0.174 loss: 0.009 avg. loss: 13.895\n",
      "Episode 360 - reward: 4.166, eps: 0.169 loss: 0.008 avg. loss: 18.784\n",
      "Episode 370 - reward: 82.498, eps: 0.164 loss: 0.012 avg. loss: 31.142\n",
      "Episode 380 - reward: 28.721, eps: 0.159 loss: 0.009 avg. loss: 16.275\n",
      "Episode 390 - reward: -41.697, eps: 0.154 loss: 0.400 avg. loss: 123.653\n",
      "Episode 400 - reward: 189.868, eps: 0.150 loss: 0.008 avg. loss: 145.910\n",
      "Episode 410 - reward: 240.350, eps: 0.145 loss: 0.010 avg. loss: 99.734\n",
      "Episode 420 - reward: 202.557, eps: 0.141 loss: 0.010 avg. loss: 129.489\n",
      "Episode 430 - reward: 141.208, eps: 0.137 loss: 0.008 avg. loss: 92.986\n",
      "Episode 440 - reward: 248.779, eps: 0.133 loss: 0.006 avg. loss: 189.205\n",
      "Episode 450 - reward: 138.844, eps: 0.129 loss: 0.016 avg. loss: 104.365\n",
      "Episode 460 - reward: -26.143, eps: 0.125 loss: 0.009 avg. loss: 20.004\n",
      "Episode 470 - reward: 214.057, eps: 0.121 loss: 0.397 avg. loss: 108.609\n",
      "Episode 480 - reward: 266.857, eps: 0.118 loss: 0.008 avg. loss: 127.171\n",
      "Episode 490 - reward: -131.419, eps: 0.114 loss: 0.014 avg. loss: 62.492\n",
      "Episode 500 - reward: -103.748, eps: 0.111 loss: 0.020 avg. loss: 12.962\n",
      "Episode 510 - reward: 259.811, eps: 0.108 loss: 0.016 avg. loss: 59.092\n",
      "Episode 520 - reward: -99.601, eps: 0.105 loss: 0.008 avg. loss: 84.735\n",
      "Episode 530 - reward: 186.782, eps: 0.101 loss: 0.008 avg. loss: 45.640\n",
      "Episode 540 - reward: -119.676, eps: 0.098 loss: 0.216 avg. loss: -3.084\n",
      "Episode 550 - reward: -72.797, eps: 0.095 loss: 0.016 avg. loss: 64.988\n",
      "Episode 560 - reward: -52.058, eps: 0.093 loss: 0.013 avg. loss: -43.933\n",
      "Episode 570 - reward: 162.160, eps: 0.090 loss: 0.362 avg. loss: 66.449\n",
      "Episode 580 - reward: 127.236, eps: 0.087 loss: 0.058 avg. loss: 22.765\n",
      "Episode 590 - reward: -173.000, eps: 0.085 loss: 0.025 avg. loss: 61.820\n",
      "Episode 600 - reward: 13.661, eps: 0.082 loss: 0.018 avg. loss: 102.081\n",
      "Episode 610 - reward: -135.353, eps: 0.080 loss: 0.018 avg. loss: 45.794\n",
      "Episode 620 - reward: 195.922, eps: 0.077 loss: 0.020 avg. loss: -15.007\n",
      "Episode 630 - reward: -63.473, eps: 0.075 loss: 0.025 avg. loss: -54.473\n",
      "Episode 640 - reward: 224.441, eps: 0.073 loss: 0.037 avg. loss: 10.543\n",
      "Episode 650 - reward: 19.190, eps: 0.071 loss: 0.017 avg. loss: -9.877\n",
      "Episode 660 - reward: -46.736, eps: 0.069 loss: 0.024 avg. loss: 38.792\n",
      "Episode 670 - reward: 1.384, eps: 0.067 loss: 0.030 avg. loss: -10.860\n",
      "Episode 680 - reward: 182.394, eps: 0.065 loss: 0.033 avg. loss: 23.006\n",
      "Episode 690 - reward: 180.233, eps: 0.063 loss: 0.394 avg. loss: 71.249\n",
      "Episode 700 - reward: 201.715, eps: 0.061 loss: 0.043 avg. loss: 40.951\n",
      "Episode 710 - reward: -2.299, eps: 0.059 loss: 0.623 avg. loss: 33.996\n",
      "Episode 720 - reward: -22.237, eps: 0.057 loss: 0.369 avg. loss: 74.383\n",
      "Episode 730 - reward: -65.242, eps: 0.056 loss: 0.020 avg. loss: -2.552\n",
      "Episode 740 - reward: 160.735, eps: 0.054 loss: 0.182 avg. loss: 3.967\n",
      "Episode 750 - reward: -32.000, eps: 0.052 loss: 0.052 avg. loss: 55.233\n",
      "Episode 760 - reward: -35.392, eps: 0.051 loss: 0.032 avg. loss: 52.332\n",
      "Episode 770 - reward: 217.122, eps: 0.049 loss: 0.238 avg. loss: 57.295\n",
      "Episode 780 - reward: 170.370, eps: 0.048 loss: 0.045 avg. loss: 67.360\n",
      "Episode 790 - reward: -55.615, eps: 0.046 loss: 0.033 avg. loss: 111.905\n",
      "Episode 800 - reward: 138.425, eps: 0.045 loss: 0.087 avg. loss: 51.792\n",
      "Episode 810 - reward: 182.677, eps: 0.044 loss: 0.039 avg. loss: 158.888\n",
      "Episode 820 - reward: 262.419, eps: 0.042 loss: 0.306 avg. loss: 100.653\n",
      "Episode 830 - reward: -20.746, eps: 0.041 loss: 0.101 avg. loss: 83.395\n",
      "Episode 840 - reward: 282.497, eps: 0.040 loss: 0.101 avg. loss: 48.095\n",
      "Episode 850 - reward: 210.951, eps: 0.039 loss: 0.087 avg. loss: 82.311\n",
      "Episode 860 - reward: -255.999, eps: 0.038 loss: 0.039 avg. loss: -37.840\n",
      "Episode 870 - reward: -224.290, eps: 0.037 loss: 0.773 avg. loss: -52.420\n",
      "Episode 880 - reward: -287.193, eps: 0.035 loss: 0.047 avg. loss: -224.537\n",
      "Episode 890 - reward: -80.504, eps: 0.034 loss: 0.262 avg. loss: -177.331\n",
      "Episode 900 - reward: -65.224, eps: 0.033 loss: 0.439 avg. loss: -102.840\n",
      "Episode 910 - reward: -256.728, eps: 0.032 loss: 0.090 avg. loss: -23.294\n",
      "Episode 920 - reward: -360.833, eps: 0.031 loss: 0.123 avg. loss: -120.456\n",
      "Episode 930 - reward: 229.813, eps: 0.030 loss: 0.071 avg. loss: -119.741\n",
      "Episode 940 - reward: -118.818, eps: 0.030 loss: 0.711 avg. loss: -174.897\n",
      "Episode 950 - reward: -141.825, eps: 0.029 loss: 0.111 avg. loss: -263.731\n",
      "Episode 960 - reward: -370.246, eps: 0.028 loss: 0.281 avg. loss: -226.873\n",
      "Episode 970 - reward: -20.211, eps: 0.027 loss: 0.531 avg. loss: -194.660\n",
      "Episode 980 - reward: -359.033, eps: 0.026 loss: 0.292 avg. loss: -200.912\n",
      "Episode 990 - reward: 220.105, eps: 0.025 loss: 0.356 avg. loss: -145.088\n",
      "Episode 1000 - reward: 252.936, eps: 0.025 loss: 0.172 avg. loss: -234.413\n",
      "Episode 1010 - reward: -58.457, eps: 0.024 loss: 0.237 avg. loss: -41.916\n",
      "Episode 1020 - reward: 234.562, eps: 0.023 loss: 0.440 avg. loss: 73.905\n",
      "Episode 1030 - reward: -24.623, eps: 0.023 loss: 0.064 avg. loss: -97.293\n",
      "Episode 1040 - reward: 217.419, eps: 0.022 loss: 0.143 avg. loss: 75.967\n",
      "Episode 1050 - reward: -51.286, eps: 0.021 loss: 0.349 avg. loss: -5.128\n",
      "Episode 1060 - reward: 243.437, eps: 0.021 loss: 0.507 avg. loss: 3.674\n",
      "Episode 1070 - reward: 233.183, eps: 0.020 loss: 0.109 avg. loss: 129.123\n",
      "Episode 1080 - reward: 267.557, eps: 0.019 loss: 0.249 avg. loss: 94.664\n",
      "Episode 1090 - reward: 13.553, eps: 0.019 loss: 0.548 avg. loss: 64.743\n",
      "Episode 1100 - reward: -137.990, eps: 0.018 loss: 0.125 avg. loss: 12.316\n",
      "Episode 1110 - reward: 31.776, eps: 0.018 loss: 0.479 avg. loss: 135.766\n",
      "Episode 1120 - reward: -47.658, eps: 0.017 loss: 0.092 avg. loss: -43.302\n",
      "Episode 1130 - reward: 210.903, eps: 0.017 loss: 0.390 avg. loss: -38.950\n",
      "Episode 1140 - reward: -1.824, eps: 0.016 loss: 0.096 avg. loss: 90.757\n",
      "Episode 1150 - reward: 66.197, eps: 0.016 loss: 0.352 avg. loss: 53.486\n",
      "Episode 1160 - reward: 259.554, eps: 0.015 loss: 0.248 avg. loss: 102.814\n",
      "Episode 1170 - reward: -38.191, eps: 0.015 loss: 0.188 avg. loss: -67.141\n",
      "Episode 1180 - reward: 224.233, eps: 0.014 loss: 0.289 avg. loss: 84.259\n",
      "Episode 1190 - reward: -5.529, eps: 0.014 loss: 0.156 avg. loss: 123.676\n",
      "Episode 1200 - reward: 15.563, eps: 0.014 loss: 0.148 avg. loss: 18.337\n",
      "Episode 1210 - reward: 290.695, eps: 0.013 loss: 0.188 avg. loss: 105.724\n",
      "Episode 1220 - reward: -66.528, eps: 0.013 loss: 0.126 avg. loss: 71.517\n",
      "Episode 1230 - reward: -171.874, eps: 0.012 loss: 0.305 avg. loss: 82.186\n",
      "Episode 1240 - reward: -81.210, eps: 0.012 loss: 0.134 avg. loss: 21.989\n",
      "Episode 1250 - reward: -85.821, eps: 0.012 loss: 0.392 avg. loss: 65.036\n",
      "Episode 1260 - reward: -185.605, eps: 0.011 loss: 0.226 avg. loss: 103.355\n",
      "Episode 1270 - reward: -156.773, eps: 0.011 loss: 0.238 avg. loss: -8.755\n",
      "Episode 1280 - reward: 224.884, eps: 0.011 loss: 0.423 avg. loss: 87.925\n",
      "Episode 1290 - reward: 31.144, eps: 0.010 loss: 0.311 avg. loss: 61.339\n",
      "Episode 1300 - reward: -232.024, eps: 0.010 loss: 0.164 avg. loss: 22.024\n",
      "Episode 1310 - reward: 17.671, eps: 0.010 loss: 1.060 avg. loss: 42.008\n",
      "Episode 1320 - reward: 198.909, eps: 0.009 loss: 0.387 avg. loss: 68.325\n",
      "Episode 1330 - reward: -100.486, eps: 0.009 loss: 0.788 avg. loss: -52.705\n",
      "Episode 1340 - reward: -98.150, eps: 0.009 loss: 1.029 avg. loss: -37.149\n",
      "Episode 1350 - reward: 51.696, eps: 0.009 loss: 0.832 avg. loss: -75.043\n",
      "Episode 1360 - reward: -139.084, eps: 0.008 loss: 0.712 avg. loss: -13.159\n",
      "Episode 1370 - reward: -12.934, eps: 0.008 loss: 0.353 avg. loss: -24.772\n",
      "Episode 1380 - reward: -84.823, eps: 0.008 loss: 0.196 avg. loss: -75.821\n",
      "Episode 1390 - reward: -208.462, eps: 0.008 loss: 0.639 avg. loss: -81.621\n",
      "Episode 1400 - reward: -94.240, eps: 0.007 loss: 0.523 avg. loss: -64.701\n",
      "Episode 1410 - reward: -137.958, eps: 0.007 loss: 0.332 avg. loss: -139.883\n",
      "Episode 1420 - reward: -82.033, eps: 0.007 loss: 0.563 avg. loss: -117.958\n",
      "Episode 1430 - reward: 144.148, eps: 0.007 loss: 0.671 avg. loss: -40.302\n",
      "Episode 1440 - reward: -109.479, eps: 0.007 loss: 0.182 avg. loss: -43.840\n",
      "Episode 1450 - reward: 260.168, eps: 0.006 loss: 0.627 avg. loss: -34.511\n",
      "Episode 1460 - reward: -93.006, eps: 0.006 loss: 0.318 avg. loss: -101.067\n",
      "Episode 1470 - reward: -57.717, eps: 0.006 loss: 0.302 avg. loss: -46.928\n",
      "Episode 1480 - reward: -105.795, eps: 0.006 loss: 0.686 avg. loss: -69.854\n",
      "Episode 1490 - reward: 275.245, eps: 0.006 loss: 1.191 avg. loss: 48.749\n",
      "Episode 1500 - reward: -74.139, eps: 0.006 loss: 0.426 avg. loss: 40.655\n",
      "Episode 1510 - reward: -157.948, eps: 0.005 loss: 0.430 avg. loss: -38.868\n",
      "Episode 1520 - reward: -57.764, eps: 0.005 loss: 0.481 avg. loss: -94.265\n",
      "Episode 1530 - reward: -78.163, eps: 0.005 loss: 0.243 avg. loss: 35.428\n",
      "Episode 1540 - reward: -35.268, eps: 0.005 loss: 0.288 avg. loss: -14.896\n",
      "Episode 1550 - reward: -105.067, eps: 0.005 loss: 0.374 avg. loss: 73.009\n",
      "Episode 1560 - reward: 60.396, eps: 0.005 loss: 0.838 avg. loss: 37.968\n",
      "Episode 1570 - reward: 32.348, eps: 0.004 loss: 0.655 avg. loss: 92.668\n",
      "Episode 1580 - reward: 279.474, eps: 0.004 loss: 0.598 avg. loss: 109.344\n",
      "Episode 1590 - reward: 146.210, eps: 0.004 loss: 0.255 avg. loss: 137.392\n",
      "Episode 1600 - reward: 171.900, eps: 0.004 loss: 0.610 avg. loss: 66.447\n",
      "Episode 1610 - reward: 208.595, eps: 0.004 loss: 0.370 avg. loss: 100.571\n",
      "Episode 1620 - reward: 282.991, eps: 0.004 loss: 0.404 avg. loss: 42.332\n",
      "Episode 1630 - reward: -39.910, eps: 0.004 loss: 1.399 avg. loss: 73.602\n",
      "Episode 1640 - reward: 145.814, eps: 0.004 loss: 0.571 avg. loss: -7.543\n",
      "Episode 1650 - reward: 203.564, eps: 0.004 loss: 1.420 avg. loss: 172.285\n",
      "Episode 1660 - reward: -15.950, eps: 0.003 loss: 0.429 avg. loss: 132.459\n",
      "Episode 1670 - reward: 237.399, eps: 0.003 loss: 0.341 avg. loss: 139.526\n",
      "Episode 1680 - reward: 299.069, eps: 0.003 loss: 0.409 avg. loss: 165.884\n",
      "Episode 1690 - reward: -52.174, eps: 0.003 loss: 1.175 avg. loss: 146.756\n",
      "Episode 1700 - reward: -161.051, eps: 0.003 loss: 0.307 avg. loss: -7.507\n",
      "Episode 1710 - reward: 239.719, eps: 0.003 loss: 0.541 avg. loss: 116.451\n",
      "Episode 1720 - reward: 203.684, eps: 0.003 loss: 0.547 avg. loss: 97.167\n",
      "Episode 1730 - reward: 217.413, eps: 0.003 loss: 0.555 avg. loss: 175.720\n",
      "Episode 1740 - reward: 237.618, eps: 0.003 loss: 1.615 avg. loss: 136.600\n",
      "Episode 1750 - reward: 271.951, eps: 0.003 loss: 0.711 avg. loss: 165.007\n",
      "Episode 1760 - reward: 240.152, eps: 0.003 loss: 0.830 avg. loss: 166.661\n",
      "Episode 1770 - reward: 280.877, eps: 0.002 loss: 0.639 avg. loss: 107.452\n",
      "Episode 1780 - reward: 8.811, eps: 0.002 loss: 0.254 avg. loss: 176.650\n",
      "Episode 1790 - reward: 0.639, eps: 0.002 loss: 0.358 avg. loss: 84.959\n",
      "Episode 1800 - reward: 223.896, eps: 0.002 loss: 0.397 avg. loss: 106.415\n",
      "Episode 1810 - reward: 206.261, eps: 0.002 loss: 0.636 avg. loss: 116.649\n",
      "Episode 1820 - reward: 216.250, eps: 0.002 loss: 0.401 avg. loss: 219.059\n",
      "Episode 1830 - reward: 214.648, eps: 0.002 loss: 0.200 avg. loss: 90.998\n",
      "Episode 1840 - reward: 250.804, eps: 0.002 loss: 1.130 avg. loss: 146.785\n",
      "Episode 1850 - reward: 272.404, eps: 0.002 loss: 0.461 avg. loss: 246.702\n",
      "Episode 1860 - reward: 271.209, eps: 0.002 loss: 0.461 avg. loss: 230.106\n",
      "Episode 1870 - reward: 263.047, eps: 0.002 loss: 0.311 avg. loss: 167.800\n",
      "Episode 1880 - reward: 276.286, eps: 0.002 loss: 0.312 avg. loss: 203.869\n",
      "Episode 1890 - reward: 264.603, eps: 0.002 loss: 0.205 avg. loss: 240.839\n",
      "Episode 1900 - reward: 30.412, eps: 0.002 loss: 0.332 avg. loss: 191.233\n",
      "Episode 1910 - reward: 277.170, eps: 0.002 loss: 0.285 avg. loss: 185.129\n",
      "Episode 1920 - reward: 280.667, eps: 0.002 loss: 1.013 avg. loss: 180.004\n",
      "Episode 1930 - reward: 268.563, eps: 0.002 loss: 0.376 avg. loss: 187.360\n",
      "Episode 1940 - reward: 286.348, eps: 0.001 loss: 0.248 avg. loss: 104.386\n",
      "Episode 1950 - reward: -317.145, eps: 0.001 loss: 0.366 avg. loss: 91.212\n",
      "Episode 1960 - reward: 283.162, eps: 0.001 loss: 0.130 avg. loss: 153.549\n",
      "Episode 1970 - reward: 230.999, eps: 0.001 loss: 0.148 avg. loss: 151.128\n",
      "Episode 1980 - reward: 257.716, eps: 0.001 loss: 0.302 avg. loss: 235.273\n",
      "Episode 1990 - reward: 281.006, eps: 0.001 loss: 0.346 avg. loss: 200.683\n",
      "Episode 2000 - reward: 182.711, eps: 0.001 loss: 0.251 avg. loss: 199.128\n",
      "Episode 2010 - reward: 285.125, eps: 0.001 loss: 0.255 avg. loss: 100.917\n",
      "Episode 2020 - reward: 257.925, eps: 0.001 loss: 0.148 avg. loss: 167.602\n",
      "Episode 2030 - reward: 266.992, eps: 0.001 loss: 0.134 avg. loss: 182.624\n",
      "Episode 2040 - reward: 258.007, eps: 0.001 loss: 0.509 avg. loss: 189.299\n",
      "Episode 2050 - reward: 273.001, eps: 0.001 loss: 0.108 avg. loss: 197.270\n",
      "Episode 2060 - reward: 264.514, eps: 0.001 loss: 0.153 avg. loss: 10.358\n",
      "Episode 2070 - reward: 295.390, eps: 0.001 loss: 0.242 avg. loss: 155.025\n",
      "Episode 2080 - reward: 254.672, eps: 0.001 loss: 0.171 avg. loss: 208.353\n",
      "Episode 2090 - reward: 274.699, eps: 0.001 loss: 0.113 avg. loss: 126.779\n",
      "Episode 2100 - reward: 276.019, eps: 0.001 loss: 0.126 avg. loss: 196.879\n",
      "Episode 2110 - reward: 206.571, eps: 0.001 loss: 0.233 avg. loss: 106.278\n",
      "Episode 2120 - reward: -225.814, eps: 0.001 loss: 0.129 avg. loss: 160.038\n",
      "Episode 2130 - reward: 250.057, eps: 0.001 loss: 0.178 avg. loss: 140.508\n",
      "Episode 2140 - reward: 146.760, eps: 0.001 loss: 0.221 avg. loss: 81.327\n",
      "Episode 2150 - reward: 239.746, eps: 0.001 loss: 0.226 avg. loss: 171.959\n",
      "Episode 2160 - reward: 271.411, eps: 0.001 loss: 0.173 avg. loss: 198.738\n",
      "Episode 2170 - reward: 212.233, eps: 0.001 loss: 0.115 avg. loss: 32.682\n",
      "Episode 2180 - reward: 223.867, eps: 0.001 loss: 0.224 avg. loss: 137.041\n",
      "Episode 2190 - reward: 248.308, eps: 0.001 loss: 0.203 avg. loss: 107.610\n",
      "Episode 2200 - reward: 251.644, eps: 0.001 loss: 0.215 avg. loss: 240.266\n",
      "Episode 2210 - reward: 223.763, eps: 0.001 loss: 0.279 avg. loss: 212.047\n",
      "Episode 2220 - reward: 265.405, eps: 0.001 loss: 0.189 avg. loss: 249.846\n",
      "Episode 2230 - reward: 231.726, eps: 0.001 loss: 0.153 avg. loss: 205.378\n",
      "Episode 2240 - reward: 262.525, eps: 0.001 loss: 0.078 avg. loss: 255.840\n",
      "Episode 2250 - reward: 275.978, eps: 0.001 loss: 0.220 avg. loss: 140.484\n",
      "Episode 2260 - reward: 281.998, eps: 0.001 loss: 0.153 avg. loss: 168.773\n",
      "Episode 2270 - reward: 275.745, eps: 0.001 loss: 0.093 avg. loss: 124.691\n",
      "Episode 2280 - reward: 242.686, eps: 0.001 loss: 0.245 avg. loss: 147.570\n",
      "Episode 2290 - reward: 277.889, eps: 0.001 loss: 0.192 avg. loss: 172.918\n",
      "Episode 2300 - reward: 37.651, eps: 0.001 loss: 0.274 avg. loss: 110.800\n",
      "Episode 2310 - reward: 42.368, eps: 0.001 loss: 0.180 avg. loss: 184.858\n",
      "Episode 2320 - reward: 287.706, eps: 0.001 loss: 0.278 avg. loss: 224.372\n",
      "Episode 2330 - reward: 237.623, eps: 0.001 loss: 0.147 avg. loss: 253.656\n",
      "Episode 2340 - reward: 258.535, eps: 0.001 loss: 0.423 avg. loss: 199.954\n",
      "Episode 2350 - reward: 254.565, eps: 0.001 loss: 0.093 avg. loss: 215.351\n",
      "Episode 2360 - reward: 256.510, eps: 0.001 loss: 0.171 avg. loss: 255.885\n",
      "Episode 2370 - reward: 64.884, eps: 0.001 loss: 0.218 avg. loss: 223.519\n",
      "Episode 2380 - reward: 18.914, eps: 0.001 loss: 0.448 avg. loss: 129.478\n",
      "Episode 2390 - reward: 59.898, eps: 0.001 loss: 0.279 avg. loss: 184.468\n",
      "Episode 2400 - reward: 234.716, eps: 0.001 loss: 0.133 avg. loss: 163.580\n",
      "Episode 2410 - reward: 229.916, eps: 0.001 loss: 0.101 avg. loss: 193.941\n",
      "Episode 2420 - reward: -47.063, eps: 0.001 loss: 0.167 avg. loss: 202.197\n",
      "Episode 2430 - reward: 234.051, eps: 0.001 loss: 0.143 avg. loss: 212.065\n",
      "Episode 2440 - reward: 57.700, eps: 0.001 loss: 0.078 avg. loss: 172.572\n",
      "Episode 2450 - reward: 285.416, eps: 0.001 loss: 0.248 avg. loss: 166.192\n",
      "Episode 2460 - reward: 259.198, eps: 0.001 loss: 0.061 avg. loss: 183.006\n",
      "Episode 2470 - reward: 252.213, eps: 0.001 loss: 0.175 avg. loss: 197.739\n",
      "Episode 2480 - reward: 279.540, eps: 0.001 loss: 0.160 avg. loss: 169.566\n",
      "Episode 2490 - reward: 292.472, eps: 0.001 loss: 0.144 avg. loss: 208.171\n",
      "Episode 2500 - reward: 277.804, eps: 0.001 loss: 0.273 avg. loss: 196.339\n",
      "Episode 2510 - reward: 268.430, eps: 0.001 loss: 0.279 avg. loss: 258.018\n",
      "Episode 2520 - reward: -248.490, eps: 0.001 loss: 0.089 avg. loss: 122.851\n",
      "Episode 2530 - reward: 247.523, eps: 0.001 loss: 0.106 avg. loss: 191.341\n",
      "Episode 2540 - reward: 253.916, eps: 0.001 loss: 0.082 avg. loss: 149.595\n",
      "Episode 2550 - reward: 274.652, eps: 0.001 loss: 0.117 avg. loss: 95.385\n",
      "Episode 2560 - reward: 214.135, eps: 0.001 loss: 0.116 avg. loss: 109.871\n",
      "Episode 2570 - reward: 275.548, eps: 0.001 loss: 0.285 avg. loss: 89.717\n",
      "Episode 2580 - reward: 72.697, eps: 0.001 loss: 0.074 avg. loss: 121.164\n",
      "Episode 2590 - reward: 265.332, eps: 0.001 loss: 0.213 avg. loss: 196.542\n",
      "Episode 2600 - reward: 142.352, eps: 0.001 loss: 1.335 avg. loss: 166.774\n",
      "Episode 2610 - reward: 234.163, eps: 0.001 loss: 0.123 avg. loss: 251.793\n",
      "Episode 2620 - reward: 208.757, eps: 0.001 loss: 0.149 avg. loss: 208.592\n",
      "Episode 2630 - reward: 219.393, eps: 0.001 loss: 0.100 avg. loss: 152.976\n",
      "Episode 2640 - reward: 270.435, eps: 0.001 loss: 0.134 avg. loss: 179.916\n",
      "Episode 2650 - reward: -271.695, eps: 0.001 loss: 0.134 avg. loss: 97.555\n",
      "Episode 2660 - reward: 232.029, eps: 0.001 loss: 0.090 avg. loss: 160.376\n",
      "Episode 2670 - reward: 84.959, eps: 0.001 loss: 0.099 avg. loss: 199.752\n",
      "Episode 2680 - reward: 234.907, eps: 0.001 loss: 0.083 avg. loss: 175.206\n",
      "Episode 2690 - reward: 298.524, eps: 0.001 loss: 0.171 avg. loss: 122.123\n",
      "Episode 2700 - reward: 276.604, eps: 0.001 loss: 0.180 avg. loss: 243.627\n",
      "Episode 2710 - reward: -240.480, eps: 0.001 loss: 0.231 avg. loss: 171.901\n",
      "Episode 2720 - reward: 263.718, eps: 0.001 loss: 0.105 avg. loss: 199.689\n",
      "Episode 2730 - reward: -291.986, eps: 0.001 loss: 0.061 avg. loss: 74.132\n",
      "Episode 2740 - reward: 190.390, eps: 0.001 loss: 0.071 avg. loss: 39.927\n",
      "Episode 2750 - reward: -204.886, eps: 0.001 loss: 0.062 avg. loss: 90.550\n",
      "Episode 2760 - reward: -219.553, eps: 0.001 loss: 0.125 avg. loss: 36.979\n",
      "Episode 2770 - reward: -213.627, eps: 0.001 loss: 0.090 avg. loss: -109.244\n",
      "Episode 2780 - reward: -87.458, eps: 0.001 loss: 0.335 avg. loss: -93.151\n",
      "Episode 2790 - reward: -113.504, eps: 0.001 loss: 0.041 avg. loss: -37.297\n",
      "Episode 2800 - reward: -107.264, eps: 0.001 loss: 0.383 avg. loss: 31.854\n",
      "Episode 2810 - reward: 237.121, eps: 0.001 loss: 0.089 avg. loss: -33.152\n",
      "Episode 2820 - reward: -189.431, eps: 0.001 loss: 0.061 avg. loss: -108.906\n",
      "Episode 2830 - reward: -159.600, eps: 0.001 loss: 0.086 avg. loss: -9.479\n",
      "Episode 2840 - reward: -171.173, eps: 0.001 loss: 0.221 avg. loss: -143.503\n",
      "Episode 2850 - reward: -131.367, eps: 0.001 loss: 0.088 avg. loss: -132.664\n",
      "Episode 2860 - reward: -239.026, eps: 0.001 loss: 0.110 avg. loss: -147.019\n",
      "Episode 2870 - reward: -207.326, eps: 0.001 loss: 0.087 avg. loss: -207.703\n",
      "Episode 2880 - reward: -266.244, eps: 0.001 loss: 0.128 avg. loss: -230.752\n",
      "Episode 2890 - reward: 61.509, eps: 0.001 loss: 0.236 avg. loss: -158.310\n",
      "Episode 2900 - reward: -240.297, eps: 0.001 loss: 0.186 avg. loss: -349.546\n",
      "Episode 2910 - reward: -243.634, eps: 0.001 loss: 0.110 avg. loss: -189.423\n",
      "Episode 2920 - reward: -360.581, eps: 0.001 loss: 0.128 avg. loss: -258.227\n",
      "Episode 2930 - reward: -172.860, eps: 0.001 loss: 0.064 avg. loss: -200.101\n",
      "Episode 2940 - reward: -173.182, eps: 0.001 loss: 0.062 avg. loss: -236.555\n",
      "Episode 2950 - reward: -189.867, eps: 0.001 loss: 0.131 avg. loss: -196.148\n",
      "Episode 2960 - reward: -235.661, eps: 0.001 loss: 0.118 avg. loss: -190.950\n",
      "Episode 2970 - reward: -182.819, eps: 0.001 loss: 0.098 avg. loss: -175.922\n",
      "Episode 2980 - reward: -240.887, eps: 0.001 loss: 0.086 avg. loss: -196.434\n",
      "Episode 2990 - reward: -261.437, eps: 0.001 loss: 0.120 avg. loss: -222.429\n",
      "Episode 3000 - reward: -239.724, eps: 0.001 loss: 0.128 avg. loss: -220.507\n",
      "Episode 3010 - reward: -291.269, eps: 0.001 loss: 0.072 avg. loss: -242.321\n",
      "Episode 3020 - reward: -317.901, eps: 0.001 loss: 0.096 avg. loss: -247.757\n",
      "Episode 3030 - reward: -237.452, eps: 0.001 loss: 0.149 avg. loss: -294.603\n",
      "Episode 3040 - reward: -132.086, eps: 0.001 loss: 0.162 avg. loss: -241.278\n",
      "Episode 3050 - reward: -70.085, eps: 0.001 loss: 0.096 avg. loss: -240.706\n",
      "Episode 3060 - reward: -201.088, eps: 0.001 loss: 0.078 avg. loss: -239.030\n",
      "Episode 3070 - reward: -266.206, eps: 0.001 loss: 0.074 avg. loss: -297.843\n",
      "Episode 3080 - reward: -232.649, eps: 0.001 loss: 0.149 avg. loss: -234.761\n",
      "Episode 3090 - reward: -246.812, eps: 0.001 loss: 0.113 avg. loss: -288.160\n",
      "Episode 3100 - reward: -336.141, eps: 0.001 loss: 0.128 avg. loss: -272.468\n",
      "Episode 3110 - reward: -343.391, eps: 0.001 loss: 0.160 avg. loss: -264.557\n",
      "Episode 3120 - reward: -276.494, eps: 0.001 loss: 0.110 avg. loss: -267.345\n",
      "Episode 3130 - reward: -285.873, eps: 0.001 loss: 0.145 avg. loss: -367.638\n",
      "Episode 3140 - reward: -265.464, eps: 0.001 loss: 0.522 avg. loss: -348.860\n",
      "Episode 3150 - reward: -432.786, eps: 0.001 loss: 0.062 avg. loss: -286.945\n",
      "Episode 3160 - reward: -369.049, eps: 0.001 loss: 0.553 avg. loss: -266.473\n",
      "Episode 3170 - reward: -441.260, eps: 0.001 loss: 0.278 avg. loss: -332.733\n",
      "Episode 3180 - reward: -292.720, eps: 0.001 loss: 0.086 avg. loss: -322.002\n",
      "Episode 3190 - reward: -375.631, eps: 0.001 loss: 0.110 avg. loss: -254.359\n",
      "Episode 3200 - reward: -184.493, eps: 0.001 loss: 0.409 avg. loss: -204.157\n",
      "Episode 3210 - reward: -121.138, eps: 0.001 loss: 0.082 avg. loss: -157.358\n",
      "Episode 3220 - reward: -75.885, eps: 0.001 loss: 0.189 avg. loss: -209.784\n",
      "Episode 3230 - reward: -113.545, eps: 0.001 loss: 0.072 avg. loss: -222.809\n",
      "Episode 3240 - reward: -16.587, eps: 0.001 loss: 2.751 avg. loss: -216.026\n",
      "Episode 3250 - reward: -176.567, eps: 0.001 loss: 0.102 avg. loss: -173.364\n",
      "Episode 3260 - reward: -369.103, eps: 0.001 loss: 0.123 avg. loss: -211.771\n",
      "Episode 3270 - reward: -179.624, eps: 0.001 loss: 0.162 avg. loss: -206.125\n",
      "Episode 3280 - reward: -95.412, eps: 0.001 loss: 0.180 avg. loss: -133.052\n",
      "Episode 3290 - reward: -334.424, eps: 0.001 loss: 0.144 avg. loss: -281.340\n",
      "Episode 3300 - reward: -40.051, eps: 0.001 loss: 0.115 avg. loss: -198.866\n",
      "Episode 3310 - reward: -271.034, eps: 0.001 loss: 0.098 avg. loss: -292.754\n",
      "Episode 3320 - reward: -330.459, eps: 0.001 loss: 0.167 avg. loss: -160.564\n",
      "Episode 3330 - reward: -192.382, eps: 0.001 loss: 0.081 avg. loss: -214.344\n",
      "Episode 3340 - reward: -69.197, eps: 0.001 loss: 0.264 avg. loss: -231.203\n",
      "Episode 3350 - reward: -136.345, eps: 0.001 loss: 0.108 avg. loss: -161.487\n",
      "Episode 3360 - reward: -76.134, eps: 0.001 loss: 0.156 avg. loss: -158.947\n",
      "Episode 3370 - reward: -213.499, eps: 0.001 loss: 0.145 avg. loss: -276.070\n",
      "Episode 3380 - reward: -19.344, eps: 0.001 loss: 0.087 avg. loss: -194.095\n",
      "Episode 3390 - reward: -164.648, eps: 0.001 loss: 0.146 avg. loss: -306.609\n",
      "Episode 3400 - reward: -748.092, eps: 0.001 loss: 0.801 avg. loss: -280.930\n",
      "Episode 3410 - reward: -324.654, eps: 0.001 loss: 0.236 avg. loss: -277.968\n",
      "Episode 3420 - reward: -326.130, eps: 0.001 loss: 0.160 avg. loss: -255.572\n",
      "Episode 3430 - reward: -415.494, eps: 0.001 loss: 0.147 avg. loss: -251.803\n",
      "Episode 3440 - reward: -329.976, eps: 0.001 loss: 0.581 avg. loss: -246.730\n",
      "Episode 3450 - reward: -200.276, eps: 0.001 loss: 0.419 avg. loss: -352.595\n",
      "Episode 3460 - reward: -110.344, eps: 0.001 loss: 0.218 avg. loss: -287.041\n",
      "Episode 3470 - reward: -68.671, eps: 0.001 loss: 0.195 avg. loss: -244.553\n",
      "Episode 3480 - reward: -136.502, eps: 0.001 loss: 0.270 avg. loss: -223.592\n",
      "Episode 3490 - reward: -359.228, eps: 0.001 loss: 0.322 avg. loss: -201.950\n",
      "Episode 3500 - reward: -348.896, eps: 0.001 loss: 0.419 avg. loss: -310.500\n",
      "Episode 3510 - reward: -314.499, eps: 0.001 loss: 0.278 avg. loss: -262.151\n",
      "Episode 3520 - reward: -133.213, eps: 0.001 loss: 0.378 avg. loss: -170.458\n",
      "Episode 3530 - reward: -453.691, eps: 0.001 loss: 0.402 avg. loss: -232.917\n",
      "Episode 3540 - reward: -262.438, eps: 0.001 loss: 0.591 avg. loss: -211.045\n",
      "Episode 3550 - reward: -72.187, eps: 0.001 loss: 0.450 avg. loss: -240.537\n",
      "Episode 3560 - reward: -53.805, eps: 0.001 loss: 0.506 avg. loss: -258.295\n",
      "Episode 3570 - reward: -287.926, eps: 0.001 loss: 0.521 avg. loss: -258.799\n",
      "Episode 3580 - reward: -44.599, eps: 0.001 loss: 0.504 avg. loss: -287.060\n",
      "Episode 3590 - reward: -406.802, eps: 0.001 loss: 0.622 avg. loss: -242.438\n",
      "Episode 3600 - reward: -53.963, eps: 0.001 loss: 0.382 avg. loss: -223.060\n",
      "Episode 3610 - reward: -217.578, eps: 0.001 loss: 0.526 avg. loss: -248.311\n",
      "Episode 3620 - reward: -319.855, eps: 0.001 loss: 0.441 avg. loss: -224.250\n",
      "Episode 3630 - reward: -94.848, eps: 0.001 loss: 0.742 avg. loss: -191.465\n",
      "Episode 3640 - reward: -77.790, eps: 0.001 loss: 0.467 avg. loss: -235.260\n",
      "Episode 3650 - reward: -253.527, eps: 0.001 loss: 0.419 avg. loss: -278.954\n",
      "Episode 3660 - reward: -154.890, eps: 0.001 loss: 0.593 avg. loss: -303.744\n",
      "Episode 3670 - reward: -300.557, eps: 0.001 loss: 0.565 avg. loss: -279.959\n",
      "Episode 3680 - reward: -393.957, eps: 0.001 loss: 0.747 avg. loss: -353.957\n",
      "Episode 3690 - reward: -267.885, eps: 0.001 loss: 1.038 avg. loss: -296.739\n",
      "Episode 3700 - reward: -237.495, eps: 0.001 loss: 0.442 avg. loss: -329.874\n",
      "Episode 3710 - reward: -148.653, eps: 0.001 loss: 0.549 avg. loss: -198.750\n",
      "Episode 3720 - reward: -183.231, eps: 0.001 loss: 1.449 avg. loss: -241.129\n",
      "Episode 3730 - reward: -383.974, eps: 0.001 loss: 0.787 avg. loss: -276.886\n",
      "Episode 3740 - reward: -277.999, eps: 0.001 loss: 7.718 avg. loss: -273.446\n",
      "Episode 3750 - reward: -259.851, eps: 0.001 loss: 0.716 avg. loss: -270.283\n",
      "Episode 3760 - reward: -178.928, eps: 0.001 loss: 0.704 avg. loss: -264.625\n",
      "Episode 3770 - reward: -303.068, eps: 0.001 loss: 1.176 avg. loss: -293.007\n",
      "Episode 3780 - reward: -351.403, eps: 0.001 loss: 0.732 avg. loss: -307.066\n",
      "Episode 3790 - reward: -510.474, eps: 0.001 loss: 0.824 avg. loss: -306.993\n",
      "Episode 3800 - reward: -301.733, eps: 0.001 loss: 0.623 avg. loss: -233.969\n",
      "Episode 3810 - reward: -338.418, eps: 0.001 loss: 1.697 avg. loss: -276.197\n",
      "Episode 3820 - reward: -306.200, eps: 0.001 loss: 0.840 avg. loss: -267.963\n",
      "Episode 3830 - reward: -303.227, eps: 0.001 loss: 0.992 avg. loss: -267.535\n",
      "Episode 3840 - reward: -218.296, eps: 0.001 loss: 0.882 avg. loss: -223.545\n",
      "Episode 3850 - reward: -207.817, eps: 0.001 loss: 0.898 avg. loss: -265.421\n",
      "Episode 3860 - reward: -300.228, eps: 0.001 loss: 0.909 avg. loss: -245.461\n",
      "Episode 3870 - reward: -502.941, eps: 0.001 loss: 0.879 avg. loss: -300.752\n",
      "Episode 3880 - reward: -259.051, eps: 0.001 loss: 0.546 avg. loss: -191.523\n",
      "Episode 3890 - reward: -342.253, eps: 0.001 loss: 1.111 avg. loss: -272.984\n",
      "Episode 3900 - reward: -330.191, eps: 0.001 loss: 0.751 avg. loss: -286.968\n",
      "Episode 3910 - reward: -506.697, eps: 0.001 loss: 0.776 avg. loss: -314.307\n",
      "Episode 3920 - reward: -310.969, eps: 0.001 loss: 1.720 avg. loss: -270.058\n",
      "Episode 3930 - reward: -193.753, eps: 0.001 loss: 0.964 avg. loss: -243.314\n",
      "Episode 3940 - reward: -167.359, eps: 0.001 loss: 1.577 avg. loss: -220.080\n",
      "Episode 3950 - reward: -239.160, eps: 0.001 loss: 1.364 avg. loss: -232.320\n",
      "Episode 3960 - reward: -320.731, eps: 0.001 loss: 1.777 avg. loss: -252.912\n",
      "Episode 3970 - reward: -203.667, eps: 0.001 loss: 1.271 avg. loss: -223.984\n",
      "Episode 3980 - reward: -274.443, eps: 0.001 loss: 2.150 avg. loss: -211.321\n",
      "Episode 3990 - reward: -239.564, eps: 0.001 loss: 1.532 avg. loss: -228.256\n",
      "Episode 4000 - reward: -226.529, eps: 0.001 loss: 0.982 avg. loss: -280.074\n",
      "Episode 4010 - reward: -190.643, eps: 0.001 loss: 1.111 avg. loss: -222.385\n",
      "Episode 4020 - reward: -271.848, eps: 0.001 loss: 1.157 avg. loss: -263.807\n",
      "Episode 4030 - reward: -211.660, eps: 0.001 loss: 0.701 avg. loss: -201.712\n",
      "Episode 4040 - reward: -128.556, eps: 0.001 loss: 0.664 avg. loss: -227.122\n",
      "Episode 4050 - reward: -675.246, eps: 0.001 loss: 1.171 avg. loss: -400.844\n",
      "Episode 4060 - reward: -160.312, eps: 0.001 loss: 1.536 avg. loss: -225.008\n",
      "Episode 4070 - reward: -339.391, eps: 0.001 loss: 1.183 avg. loss: -263.719\n",
      "Episode 4080 - reward: -276.851, eps: 0.001 loss: 1.144 avg. loss: -270.213\n",
      "Episode 4090 - reward: -262.369, eps: 0.001 loss: 0.917 avg. loss: -238.908\n",
      "Episode 4100 - reward: -482.846, eps: 0.001 loss: 0.881 avg. loss: -253.377\n",
      "Episode 4110 - reward: -175.737, eps: 0.001 loss: 1.359 avg. loss: -296.127\n",
      "Episode 4120 - reward: -389.060, eps: 0.001 loss: 3.756 avg. loss: -212.519\n",
      "Episode 4130 - reward: -204.084, eps: 0.001 loss: 0.775 avg. loss: -295.712\n",
      "Episode 4140 - reward: -382.517, eps: 0.001 loss: 1.237 avg. loss: -260.799\n",
      "Episode 4150 - reward: -101.321, eps: 0.001 loss: 1.704 avg. loss: -236.308\n",
      "Episode 4160 - reward: -202.290, eps: 0.001 loss: 1.628 avg. loss: -249.017\n",
      "Episode 4170 - reward: -160.397, eps: 0.001 loss: 0.704 avg. loss: -278.267\n",
      "Episode 4180 - reward: -196.306, eps: 0.001 loss: 1.226 avg. loss: -221.927\n",
      "Episode 4190 - reward: -221.798, eps: 0.001 loss: 1.547 avg. loss: -233.095\n",
      "Episode 4200 - reward: -269.975, eps: 0.001 loss: 2.240 avg. loss: -205.193\n",
      "Episode 4210 - reward: -253.873, eps: 0.001 loss: 1.146 avg. loss: -236.949\n",
      "Episode 4220 - reward: -229.573, eps: 0.001 loss: 0.973 avg. loss: -232.105\n",
      "Episode 4230 - reward: -190.399, eps: 0.001 loss: 2.230 avg. loss: -229.385\n",
      "Episode 4240 - reward: -269.793, eps: 0.001 loss: 0.931 avg. loss: -264.917\n",
      "Episode 4250 - reward: -258.931, eps: 0.001 loss: 2.186 avg. loss: -240.924\n",
      "Episode 4260 - reward: -221.939, eps: 0.001 loss: 1.240 avg. loss: -232.909\n",
      "Episode 4270 - reward: -240.155, eps: 0.001 loss: 3.739 avg. loss: -225.795\n",
      "Episode 4280 - reward: -351.839, eps: 0.001 loss: 1.312 avg. loss: -287.739\n",
      "Episode 4290 - reward: -197.117, eps: 0.001 loss: 1.485 avg. loss: -283.856\n",
      "Episode 4300 - reward: -316.045, eps: 0.001 loss: 1.382 avg. loss: -267.904\n",
      "Episode 4310 - reward: -183.190, eps: 0.001 loss: 2.711 avg. loss: -227.046\n",
      "Episode 4320 - reward: -192.235, eps: 0.001 loss: 2.210 avg. loss: -197.454\n",
      "Episode 4330 - reward: -239.547, eps: 0.001 loss: 1.732 avg. loss: -313.109\n",
      "Episode 4340 - reward: -263.395, eps: 0.001 loss: 1.888 avg. loss: -326.019\n",
      "Episode 4350 - reward: -429.966, eps: 0.001 loss: 1.229 avg. loss: -268.391\n",
      "Episode 4360 - reward: -149.072, eps: 0.001 loss: 1.918 avg. loss: -328.500\n",
      "Episode 4370 - reward: -237.390, eps: 0.001 loss: 1.141 avg. loss: -225.827\n",
      "Episode 4380 - reward: -162.212, eps: 0.001 loss: 1.972 avg. loss: -239.922\n",
      "Episode 4390 - reward: -162.660, eps: 0.001 loss: 1.611 avg. loss: -271.461\n",
      "Episode 4400 - reward: -462.223, eps: 0.001 loss: 1.713 avg. loss: -302.077\n",
      "Episode 4410 - reward: -115.851, eps: 0.001 loss: 2.521 avg. loss: -322.521\n",
      "Episode 4420 - reward: -371.440, eps: 0.001 loss: 4.245 avg. loss: -292.783\n",
      "Episode 4430 - reward: -248.949, eps: 0.001 loss: 1.222 avg. loss: -254.368\n",
      "Episode 4440 - reward: -158.713, eps: 0.001 loss: 2.241 avg. loss: -198.729\n",
      "Episode 4450 - reward: -154.911, eps: 0.001 loss: 1.702 avg. loss: -215.342\n",
      "Episode 4460 - reward: -297.008, eps: 0.001 loss: 1.969 avg. loss: -304.870\n",
      "Episode 4470 - reward: -291.072, eps: 0.001 loss: 2.736 avg. loss: -259.670\n",
      "Episode 4480 - reward: -314.478, eps: 0.001 loss: 1.909 avg. loss: -288.402\n",
      "Episode 4490 - reward: -299.463, eps: 0.001 loss: 1.852 avg. loss: -291.562\n",
      "Episode 4500 - reward: -184.062, eps: 0.001 loss: 3.713 avg. loss: -225.512\n",
      "Episode 4510 - reward: -469.779, eps: 0.001 loss: 3.638 avg. loss: -247.780\n",
      "Episode 4520 - reward: -502.073, eps: 0.001 loss: 3.449 avg. loss: -294.993\n",
      "Episode 4530 - reward: -263.374, eps: 0.001 loss: 2.074 avg. loss: -323.099\n",
      "Episode 4540 - reward: -261.138, eps: 0.001 loss: 4.242 avg. loss: -230.317\n",
      "Episode 4550 - reward: -121.527, eps: 0.001 loss: 2.962 avg. loss: -222.087\n",
      "Episode 4560 - reward: -123.595, eps: 0.001 loss: 2.128 avg. loss: -278.248\n",
      "Episode 4570 - reward: -258.914, eps: 0.001 loss: 2.072 avg. loss: -196.248\n",
      "Episode 4580 - reward: -348.284, eps: 0.001 loss: 2.645 avg. loss: -222.500\n",
      "Episode 4590 - reward: -299.729, eps: 0.001 loss: 3.283 avg. loss: -252.051\n",
      "Episode 4600 - reward: -24.988, eps: 0.001 loss: 2.489 avg. loss: -255.978\n",
      "Episode 4610 - reward: -538.605, eps: 0.001 loss: 2.019 avg. loss: -252.006\n",
      "Episode 4620 - reward: -371.134, eps: 0.001 loss: 2.597 avg. loss: -378.941\n",
      "Episode 4630 - reward: -177.402, eps: 0.001 loss: 1.969 avg. loss: -250.589\n",
      "Episode 4640 - reward: -191.554, eps: 0.001 loss: 1.894 avg. loss: -279.253\n",
      "Episode 4650 - reward: -256.426, eps: 0.001 loss: 3.384 avg. loss: -225.428\n",
      "Episode 4660 - reward: -369.980, eps: 0.001 loss: 2.378 avg. loss: -365.292\n",
      "Episode 4670 - reward: -380.439, eps: 0.001 loss: 2.607 avg. loss: -315.542\n",
      "Episode 4680 - reward: -282.262, eps: 0.001 loss: 3.173 avg. loss: -324.544\n",
      "Episode 4690 - reward: -271.651, eps: 0.001 loss: 3.420 avg. loss: -271.541\n",
      "Episode 4700 - reward: -226.012, eps: 0.001 loss: 2.806 avg. loss: -344.094\n",
      "Episode 4710 - reward: -296.656, eps: 0.001 loss: 1.782 avg. loss: -296.504\n",
      "Episode 4720 - reward: -305.746, eps: 0.001 loss: 3.573 avg. loss: -315.038\n",
      "Episode 4730 - reward: -487.214, eps: 0.001 loss: 4.577 avg. loss: -358.860\n",
      "Episode 4740 - reward: -257.734, eps: 0.001 loss: 1.732 avg. loss: -306.386\n",
      "Episode 4750 - reward: -386.349, eps: 0.001 loss: 3.687 avg. loss: -371.475\n",
      "Episode 4760 - reward: -270.956, eps: 0.001 loss: 1.508 avg. loss: -333.405\n",
      "Episode 4770 - reward: -476.083, eps: 0.001 loss: 2.403 avg. loss: -435.772\n",
      "Episode 4780 - reward: -278.906, eps: 0.001 loss: 1.740 avg. loss: -313.305\n",
      "Episode 4790 - reward: -287.741, eps: 0.001 loss: 2.125 avg. loss: -340.047\n",
      "Episode 4800 - reward: -533.749, eps: 0.001 loss: 2.280 avg. loss: -365.569\n",
      "Episode 4810 - reward: -219.434, eps: 0.001 loss: 62.879 avg. loss: -332.428\n",
      "Episode 4820 - reward: -122.368, eps: 0.001 loss: 3.866 avg. loss: -310.771\n",
      "Episode 4830 - reward: -402.843, eps: 0.001 loss: 5.501 avg. loss: -349.119\n",
      "Episode 4840 - reward: -358.317, eps: 0.001 loss: 2.742 avg. loss: -374.376\n",
      "Episode 4850 - reward: -237.905, eps: 0.001 loss: 1.807 avg. loss: -341.768\n",
      "Episode 4860 - reward: -337.746, eps: 0.001 loss: 2.733 avg. loss: -393.221\n",
      "Episode 4870 - reward: -376.729, eps: 0.001 loss: 2.024 avg. loss: -442.651\n",
      "Episode 4880 - reward: -386.708, eps: 0.001 loss: 1.490 avg. loss: -263.889\n",
      "Episode 4890 - reward: -275.436, eps: 0.001 loss: 3.002 avg. loss: -373.400\n",
      "Episode 4900 - reward: -333.739, eps: 0.001 loss: 2.441 avg. loss: -357.709\n",
      "Episode 4910 - reward: -265.831, eps: 0.001 loss: 2.211 avg. loss: -309.337\n",
      "Episode 4920 - reward: -350.515, eps: 0.001 loss: 2.157 avg. loss: -317.362\n",
      "Episode 4930 - reward: -235.887, eps: 0.001 loss: 1.855 avg. loss: -203.993\n",
      "Episode 4940 - reward: -184.329, eps: 0.001 loss: 1.878 avg. loss: -289.058\n",
      "Episode 4950 - reward: -366.296, eps: 0.001 loss: 2.872 avg. loss: -258.708\n",
      "Episode 4960 - reward: -347.762, eps: 0.001 loss: 2.176 avg. loss: -226.082\n",
      "Episode 4970 - reward: -103.416, eps: 0.001 loss: 1.814 avg. loss: -177.959\n",
      "Episode 4980 - reward: -186.738, eps: 0.001 loss: 1.932 avg. loss: -198.106\n",
      "Episode 4990 - reward: -357.099, eps: 0.001 loss: 1.941 avg. loss: -251.327\n",
      "Episode 5000 - reward: -156.937, eps: 0.001 loss: 3.323 avg. loss: -278.184\n",
      "Episode 5010 - reward: -13.579, eps: 0.001 loss: 2.784 avg. loss: -193.978\n",
      "Episode 5020 - reward: -60.683, eps: 0.001 loss: 2.090 avg. loss: -143.531\n",
      "Episode 5030 - reward: -353.541, eps: 0.001 loss: 18.165 avg. loss: -282.813\n",
      "Episode 5040 - reward: -236.061, eps: 0.001 loss: 1.646 avg. loss: -207.903\n",
      "Episode 5050 - reward: -178.780, eps: 0.001 loss: 1.482 avg. loss: -369.121\n",
      "Episode 5060 - reward: 11.168, eps: 0.001 loss: 1.814 avg. loss: -233.254\n",
      "Episode 5070 - reward: -47.663, eps: 0.001 loss: 1.704 avg. loss: -419.490\n",
      "Episode 5080 - reward: -476.182, eps: 0.001 loss: 2.567 avg. loss: -317.453\n",
      "Episode 5090 - reward: -502.694, eps: 0.001 loss: 2.196 avg. loss: -301.389\n",
      "Episode 5100 - reward: -546.538, eps: 0.001 loss: 4.269 avg. loss: -376.275\n",
      "Episode 5110 - reward: -491.634, eps: 0.001 loss: 2.693 avg. loss: -505.149\n",
      "Episode 5120 - reward: -367.683, eps: 0.001 loss: 2.407 avg. loss: -606.548\n",
      "Episode 5130 - reward: -459.108, eps: 0.001 loss: 27.223 avg. loss: -400.781\n",
      "Episode 5140 - reward: -270.452, eps: 0.001 loss: 19.366 avg. loss: -373.738\n",
      "Episode 5150 - reward: -237.762, eps: 0.001 loss: 11.613 avg. loss: -354.361\n",
      "Episode 5160 - reward: -399.966, eps: 0.001 loss: 4.373 avg. loss: -393.716\n",
      "Episode 5170 - reward: -388.922, eps: 0.001 loss: 2.732 avg. loss: -304.425\n",
      "Episode 5180 - reward: -338.567, eps: 0.001 loss: 4.338 avg. loss: -418.949\n",
      "Episode 5190 - reward: -332.678, eps: 0.001 loss: 2.217 avg. loss: -379.745\n",
      "Episode 5200 - reward: -286.368, eps: 0.001 loss: 4.817 avg. loss: -347.148\n",
      "Episode 5210 - reward: -277.128, eps: 0.001 loss: 44.267 avg. loss: -339.387\n",
      "Episode 5220 - reward: -505.921, eps: 0.001 loss: 6.531 avg. loss: -346.374\n",
      "Episode 5230 - reward: -348.347, eps: 0.001 loss: 4.324 avg. loss: -349.281\n",
      "Episode 5240 - reward: -253.557, eps: 0.001 loss: 5.905 avg. loss: -335.997\n",
      "Episode 5250 - reward: -292.617, eps: 0.001 loss: 4.299 avg. loss: -353.485\n",
      "Episode 5260 - reward: -474.643, eps: 0.001 loss: 6.161 avg. loss: -440.434\n",
      "Episode 5270 - reward: -410.451, eps: 0.001 loss: 6.058 avg. loss: -382.844\n",
      "Episode 5280 - reward: -368.810, eps: 0.001 loss: 8.621 avg. loss: -334.823\n",
      "Episode 5290 - reward: -407.272, eps: 0.001 loss: 98.157 avg. loss: -378.279\n",
      "Episode 5300 - reward: -378.536, eps: 0.001 loss: 17.749 avg. loss: -416.015\n",
      "Episode 5310 - reward: -338.937, eps: 0.001 loss: 124.987 avg. loss: -385.284\n",
      "Episode 5320 - reward: -382.611, eps: 0.001 loss: 5.475 avg. loss: -358.788\n",
      "Episode 5330 - reward: -207.125, eps: 0.001 loss: 7.956 avg. loss: -385.484\n",
      "Episode 5340 - reward: -432.084, eps: 0.001 loss: 21.108 avg. loss: -433.086\n",
      "Episode 5350 - reward: -405.350, eps: 0.001 loss: 5.533 avg. loss: -371.481\n",
      "Episode 5360 - reward: -317.005, eps: 0.001 loss: 30.457 avg. loss: -458.054\n",
      "Episode 5370 - reward: -399.790, eps: 0.001 loss: 8.044 avg. loss: -354.436\n",
      "Episode 5380 - reward: -446.473, eps: 0.001 loss: 71.421 avg. loss: -389.822\n",
      "Episode 5390 - reward: -415.458, eps: 0.001 loss: 94.004 avg. loss: -442.111\n",
      "Episode 5400 - reward: -511.671, eps: 0.001 loss: 12.702 avg. loss: -383.167\n",
      "Episode 5410 - reward: -372.752, eps: 0.001 loss: 9.633 avg. loss: -432.671\n",
      "Episode 5420 - reward: -540.399, eps: 0.001 loss: 8.547 avg. loss: -432.577\n",
      "Episode 5430 - reward: -472.384, eps: 0.001 loss: 68.799 avg. loss: -422.379\n",
      "Episode 5440 - reward: -476.758, eps: 0.001 loss: 39.866 avg. loss: -399.501\n",
      "Episode 5450 - reward: -448.702, eps: 0.001 loss: 28.648 avg. loss: -437.193\n",
      "Episode 5460 - reward: -380.802, eps: 0.001 loss: 18.180 avg. loss: -408.738\n",
      "Episode 5470 - reward: -394.480, eps: 0.001 loss: 9.888 avg. loss: -381.704\n",
      "Episode 5480 - reward: -419.648, eps: 0.001 loss: 25.143 avg. loss: -393.599\n",
      "Episode 5490 - reward: -459.758, eps: 0.001 loss: 19.852 avg. loss: -415.574\n",
      "Episode 5500 - reward: -449.018, eps: 0.001 loss: 14.996 avg. loss: -403.032\n",
      "Episode 5510 - reward: -334.947, eps: 0.001 loss: 32.496 avg. loss: -353.493\n",
      "Episode 5520 - reward: -444.189, eps: 0.001 loss: 15.748 avg. loss: -387.359\n",
      "Episode 5530 - reward: -413.632, eps: 0.001 loss: 27.190 avg. loss: -357.454\n",
      "Episode 5540 - reward: -377.219, eps: 0.001 loss: 21.286 avg. loss: -353.271\n",
      "Episode 5550 - reward: -380.901, eps: 0.001 loss: 25.119 avg. loss: -371.418\n",
      "Episode 5560 - reward: -363.295, eps: 0.001 loss: 64.537 avg. loss: -370.885\n",
      "Episode 5570 - reward: -386.067, eps: 0.001 loss: 29.285 avg. loss: -366.391\n",
      "Episode 5580 - reward: -373.051, eps: 0.001 loss: 45.340 avg. loss: -399.430\n",
      "Episode 5590 - reward: -345.744, eps: 0.001 loss: 16.003 avg. loss: -379.016\n",
      "Episode 5600 - reward: -433.186, eps: 0.001 loss: 9.685 avg. loss: -451.826\n",
      "Episode 5610 - reward: -415.210, eps: 0.001 loss: 12.942 avg. loss: -409.014\n",
      "Episode 5620 - reward: -386.815, eps: 0.001 loss: 24.605 avg. loss: -394.204\n",
      "Episode 5630 - reward: -35.008, eps: 0.001 loss: 54.124 avg. loss: -445.043\n",
      "Episode 5640 - reward: -466.935, eps: 0.001 loss: 61.334 avg. loss: -419.251\n",
      "Episode 5650 - reward: -242.144, eps: 0.001 loss: 40.747 avg. loss: -381.438\n",
      "Episode 5660 - reward: -376.253, eps: 0.001 loss: 66.351 avg. loss: -394.512\n",
      "Episode 5670 - reward: -242.763, eps: 0.001 loss: 14.163 avg. loss: -481.457\n",
      "Episode 5680 - reward: -593.271, eps: 0.001 loss: 15.369 avg. loss: -594.524\n",
      "Episode 5690 - reward: -320.876, eps: 0.001 loss: 15.211 avg. loss: -790.306\n",
      "Episode 5700 - reward: -305.662, eps: 0.001 loss: 36.358 avg. loss: -901.472\n",
      "Episode 5710 - reward: -365.282, eps: 0.001 loss: 11.334 avg. loss: -448.285\n",
      "Episode 5720 - reward: -1165.635, eps: 0.001 loss: 9.884 avg. loss: -574.229\n",
      "Episode 5730 - reward: -1111.790, eps: 0.001 loss: 21.619 avg. loss: -1603.135\n",
      "Episode 5740 - reward: -417.412, eps: 0.001 loss: 18.920 avg. loss: -515.681\n",
      "Episode 5750 - reward: -945.985, eps: 0.001 loss: 21.502 avg. loss: -475.183\n",
      "Episode 5760 - reward: -907.688, eps: 0.001 loss: 16.717 avg. loss: -571.173\n",
      "Episode 5770 - reward: -572.251, eps: 0.001 loss: 9.043 avg. loss: -486.887\n",
      "Episode 5780 - reward: -353.021, eps: 0.001 loss: 12.603 avg. loss: -535.262\n",
      "Episode 5790 - reward: -339.935, eps: 0.001 loss: 11.889 avg. loss: -473.527\n",
      "Episode 5800 - reward: -335.044, eps: 0.001 loss: 23.855 avg. loss: -547.815\n",
      "Episode 5810 - reward: -417.351, eps: 0.001 loss: 19.477 avg. loss: -529.680\n",
      "Episode 5820 - reward: -362.741, eps: 0.001 loss: 13.021 avg. loss: -524.779\n",
      "Episode 5830 - reward: -393.813, eps: 0.001 loss: 18.715 avg. loss: -398.131\n",
      "Episode 5840 - reward: -560.108, eps: 0.001 loss: 15.557 avg. loss: -512.012\n",
      "Episode 5850 - reward: -408.849, eps: 0.001 loss: 12.537 avg. loss: -547.078\n",
      "Episode 5860 - reward: -674.916, eps: 0.001 loss: 15.190 avg. loss: -523.182\n",
      "Episode 5870 - reward: -2950.404, eps: 0.001 loss: 7.698 avg. loss: -960.926\n",
      "Episode 5880 - reward: -474.056, eps: 0.001 loss: 352.779 avg. loss: -569.986\n",
      "Episode 5890 - reward: -284.536, eps: 0.001 loss: 8.718 avg. loss: -671.202\n",
      "Episode 5900 - reward: -641.550, eps: 0.001 loss: 372.131 avg. loss: -554.378\n",
      "Episode 5910 - reward: -572.201, eps: 0.001 loss: 17.423 avg. loss: -421.319\n",
      "Episode 5920 - reward: -325.807, eps: 0.001 loss: 372.653 avg. loss: -440.814\n",
      "Episode 5930 - reward: -496.466, eps: 0.001 loss: 96.802 avg. loss: -466.861\n",
      "Episode 5940 - reward: -307.863, eps: 0.001 loss: 15.487 avg. loss: -722.197\n",
      "Episode 5950 - reward: -536.523, eps: 0.001 loss: 13.816 avg. loss: -561.263\n",
      "Episode 5960 - reward: -367.154, eps: 0.001 loss: 14.704 avg. loss: -377.808\n",
      "Episode 5970 - reward: -375.209, eps: 0.001 loss: 18.660 avg. loss: -410.542\n",
      "Episode 5980 - reward: -990.538, eps: 0.001 loss: 8.918 avg. loss: -413.183\n",
      "Episode 5990 - reward: -345.627, eps: 0.001 loss: 9.923 avg. loss: -519.926\n",
      "Episode 6000 - reward: -238.214, eps: 0.001 loss: 8.572 avg. loss: -508.869\n",
      "Episode 6010 - reward: -223.733, eps: 0.001 loss: 13.191 avg. loss: -400.449\n",
      "Episode 6020 - reward: -336.591, eps: 0.001 loss: 9.688 avg. loss: -307.816\n",
      "Episode 6030 - reward: -306.487, eps: 0.001 loss: 151.283 avg. loss: -440.124\n",
      "Episode 6040 - reward: -300.778, eps: 0.001 loss: 9.490 avg. loss: -350.472\n",
      "Episode 6050 - reward: -250.672, eps: 0.001 loss: 13.726 avg. loss: -330.875\n",
      "Episode 6060 - reward: -420.168, eps: 0.001 loss: 9.427 avg. loss: -348.828\n",
      "Episode 6070 - reward: -406.704, eps: 0.001 loss: 336.332 avg. loss: -450.206\n",
      "Episode 6080 - reward: -123.448, eps: 0.001 loss: 139.244 avg. loss: -277.997\n",
      "Episode 6090 - reward: -515.294, eps: 0.001 loss: 482.791 avg. loss: -392.003\n",
      "Episode 6100 - reward: -388.556, eps: 0.001 loss: 109.185 avg. loss: -338.164\n",
      "Episode 6110 - reward: -393.818, eps: 0.001 loss: 15.636 avg. loss: -463.160\n",
      "Episode 6120 - reward: -395.717, eps: 0.001 loss: 17.506 avg. loss: -373.384\n",
      "Episode 6130 - reward: -330.769, eps: 0.001 loss: 78.242 avg. loss: -368.839\n",
      "Episode 6140 - reward: -323.266, eps: 0.001 loss: 83.076 avg. loss: -548.565\n",
      "Episode 6150 - reward: -231.571, eps: 0.001 loss: 31.556 avg. loss: -359.079\n",
      "Episode 6160 - reward: -397.007, eps: 0.001 loss: 15.569 avg. loss: -373.620\n",
      "Episode 6170 - reward: -282.547, eps: 0.001 loss: 712.746 avg. loss: -473.512\n",
      "Episode 6180 - reward: -189.343, eps: 0.001 loss: 25.686 avg. loss: -503.240\n",
      "Episode 6190 - reward: -366.845, eps: 0.001 loss: 811.091 avg. loss: -547.103\n",
      "Episode 6200 - reward: -350.415, eps: 0.001 loss: 619.063 avg. loss: -475.133\n",
      "Episode 6210 - reward: -2911.891, eps: 0.001 loss: 42.108 avg. loss: -906.087\n",
      "Episode 6220 - reward: -354.224, eps: 0.001 loss: 61.521 avg. loss: -621.496\n",
      "Episode 6230 - reward: -443.580, eps: 0.001 loss: 130.429 avg. loss: -441.593\n",
      "Episode 6240 - reward: -377.352, eps: 0.001 loss: 74.565 avg. loss: -799.808\n",
      "Episode 6250 - reward: -190.043, eps: 0.001 loss: 176.698 avg. loss: -285.218\n",
      "Episode 6260 - reward: -258.231, eps: 0.001 loss: 224.625 avg. loss: -378.139\n",
      "Episode 6270 - reward: -317.795, eps: 0.001 loss: 30.477 avg. loss: -392.125\n",
      "Episode 6280 - reward: -264.724, eps: 0.001 loss: 147.303 avg. loss: -363.934\n",
      "Episode 6290 - reward: -263.170, eps: 0.001 loss: 136.127 avg. loss: -333.059\n",
      "Episode 6300 - reward: -181.263, eps: 0.001 loss: 168.498 avg. loss: -249.951\n",
      "Episode 6310 - reward: -189.766, eps: 0.001 loss: 273.394 avg. loss: -376.654\n",
      "Episode 6320 - reward: -481.379, eps: 0.001 loss: 90.971 avg. loss: -414.738\n",
      "Episode 6330 - reward: -261.932, eps: 0.001 loss: 1264.668 avg. loss: -293.614\n",
      "Episode 6340 - reward: -423.959, eps: 0.001 loss: 184.327 avg. loss: -299.663\n",
      "Episode 6350 - reward: -306.628, eps: 0.001 loss: 16837.287 avg. loss: -292.359\n",
      "Episode 6360 - reward: -176.265, eps: 0.001 loss: 198.273 avg. loss: -463.267\n",
      "Episode 6370 - reward: -264.677, eps: 0.001 loss: 361.429 avg. loss: -294.805\n",
      "Episode 6380 - reward: -314.089, eps: 0.001 loss: 235.330 avg. loss: -352.226\n",
      "Episode 6390 - reward: -379.078, eps: 0.001 loss: 660.139 avg. loss: -566.539\n",
      "Episode 6400 - reward: -298.148, eps: 0.001 loss: 5096.312 avg. loss: -301.895\n",
      "Episode 6410 - reward: -468.809, eps: 0.001 loss: 536.944 avg. loss: -289.494\n",
      "Episode 6420 - reward: -484.374, eps: 0.001 loss: 534.338 avg. loss: -278.315\n",
      "Episode 6430 - reward: -377.530, eps: 0.001 loss: 315.488 avg. loss: -313.696\n",
      "Episode 6440 - reward: -223.582, eps: 0.001 loss: 121.645 avg. loss: -244.231\n",
      "Episode 6450 - reward: -637.269, eps: 0.001 loss: 293.127 avg. loss: -340.111\n",
      "Episode 6460 - reward: -270.903, eps: 0.001 loss: 352.950 avg. loss: -279.651\n",
      "Episode 6470 - reward: -249.081, eps: 0.001 loss: 6653.612 avg. loss: -309.076\n",
      "Episode 6480 - reward: -214.112, eps: 0.001 loss: 316.786 avg. loss: -312.303\n",
      "Episode 6490 - reward: -184.657, eps: 0.001 loss: 351.499 avg. loss: -200.135\n",
      "Episode 6500 - reward: -344.937, eps: 0.001 loss: 716.248 avg. loss: -316.574\n",
      "Episode 6510 - reward: -319.911, eps: 0.001 loss: 233.490 avg. loss: -321.568\n",
      "Episode 6520 - reward: -409.826, eps: 0.001 loss: 228.467 avg. loss: -320.374\n",
      "Episode 6530 - reward: -536.952, eps: 0.001 loss: 1051.847 avg. loss: -386.562\n",
      "Episode 6540 - reward: -318.728, eps: 0.001 loss: 1083.455 avg. loss: -454.810\n",
      "Episode 6550 - reward: -310.303, eps: 0.001 loss: 162.075 avg. loss: -604.534\n",
      "Episode 6560 - reward: -291.977, eps: 0.001 loss: 298.030 avg. loss: -397.654\n",
      "Episode 6570 - reward: -298.163, eps: 0.001 loss: 181.235 avg. loss: -389.350\n",
      "Episode 6580 - reward: -504.211, eps: 0.001 loss: 578.705 avg. loss: -422.986\n",
      "Episode 6590 - reward: -327.305, eps: 0.001 loss: 1039.939 avg. loss: -618.723\n",
      "Episode 6600 - reward: -303.121, eps: 0.001 loss: 540.648 avg. loss: -325.857\n",
      "Episode 6610 - reward: -1055.580, eps: 0.001 loss: 503.689 avg. loss: -656.141\n",
      "Episode 6620 - reward: -407.450, eps: 0.001 loss: 254.240 avg. loss: -472.063\n",
      "Episode 6630 - reward: -395.389, eps: 0.001 loss: 337.746 avg. loss: -553.504\n",
      "Episode 6640 - reward: -603.835, eps: 0.001 loss: 1087.572 avg. loss: -759.863\n",
      "Episode 6650 - reward: -409.927, eps: 0.001 loss: 479.540 avg. loss: -447.656\n",
      "Episode 6660 - reward: -343.471, eps: 0.001 loss: 324.791 avg. loss: -425.787\n",
      "Episode 6670 - reward: -513.575, eps: 0.001 loss: 1272.448 avg. loss: -501.444\n",
      "Episode 6680 - reward: -456.342, eps: 0.001 loss: 532.096 avg. loss: -476.098\n",
      "Episode 6690 - reward: -479.430, eps: 0.001 loss: 7871.881 avg. loss: -548.828\n",
      "Episode 6700 - reward: -479.922, eps: 0.001 loss: 1192.944 avg. loss: -660.720\n",
      "Episode 6710 - reward: -381.739, eps: 0.001 loss: 2116.883 avg. loss: -470.838\n",
      "Episode 6720 - reward: -515.225, eps: 0.001 loss: 803.201 avg. loss: -478.785\n",
      "Episode 6730 - reward: -440.408, eps: 0.001 loss: 713.789 avg. loss: -458.456\n",
      "Episode 6740 - reward: -401.221, eps: 0.001 loss: 747.036 avg. loss: -474.780\n",
      "Episode 6750 - reward: -473.341, eps: 0.001 loss: 1025.516 avg. loss: -389.569\n",
      "Episode 6760 - reward: -464.315, eps: 0.001 loss: 1319.279 avg. loss: -499.111\n",
      "Episode 6770 - reward: -430.483, eps: 0.001 loss: 703.431 avg. loss: -405.622\n",
      "Episode 6780 - reward: -370.130, eps: 0.001 loss: 726.254 avg. loss: -409.841\n",
      "Episode 6790 - reward: -278.232, eps: 0.001 loss: 856.449 avg. loss: -416.933\n",
      "Episode 6800 - reward: -500.660, eps: 0.001 loss: 1247.003 avg. loss: -442.496\n",
      "Episode 6810 - reward: -421.174, eps: 0.001 loss: 1337.564 avg. loss: -420.784\n",
      "Episode 6820 - reward: -703.560, eps: 0.001 loss: 3980.776 avg. loss: -488.864\n",
      "Episode 6830 - reward: -527.242, eps: 0.001 loss: 402.440 avg. loss: -510.711\n",
      "Episode 6840 - reward: -464.627, eps: 0.001 loss: 889.508 avg. loss: -458.401\n",
      "Episode 6850 - reward: -504.749, eps: 0.001 loss: 820.274 avg. loss: -417.768\n",
      "Episode 6860 - reward: -564.151, eps: 0.001 loss: 398.401 avg. loss: -510.058\n",
      "Episode 6870 - reward: -393.447, eps: 0.001 loss: 1140.370 avg. loss: -413.576\n",
      "Episode 6880 - reward: -384.700, eps: 0.001 loss: 49329.227 avg. loss: -396.893\n",
      "Episode 6890 - reward: -419.895, eps: 0.001 loss: 691.661 avg. loss: -445.624\n",
      "Episode 6900 - reward: -583.531, eps: 0.001 loss: 1392.166 avg. loss: -419.101\n",
      "Episode 6910 - reward: -255.761, eps: 0.001 loss: 790.853 avg. loss: -406.406\n",
      "Episode 6920 - reward: -291.175, eps: 0.001 loss: 749.478 avg. loss: -453.919\n",
      "Episode 6930 - reward: -313.039, eps: 0.001 loss: 854.912 avg. loss: -362.829\n",
      "Episode 6940 - reward: -262.782, eps: 0.001 loss: 757.301 avg. loss: -349.819\n",
      "Episode 6950 - reward: -560.742, eps: 0.001 loss: 2087.048 avg. loss: -435.716\n",
      "Episode 6960 - reward: -354.949, eps: 0.001 loss: 612.367 avg. loss: -356.738\n",
      "Episode 6970 - reward: -321.671, eps: 0.001 loss: 349.316 avg. loss: -339.679\n",
      "Episode 6980 - reward: -535.225, eps: 0.001 loss: 434.561 avg. loss: -396.006\n",
      "Episode 6990 - reward: -379.509, eps: 0.001 loss: 860.133 avg. loss: -392.146\n",
      "Episode 7000 - reward: -435.259, eps: 0.001 loss: 1374.108 avg. loss: -381.866\n",
      "Episode 7010 - reward: -531.297, eps: 0.001 loss: 20107.910 avg. loss: -509.406\n",
      "Episode 7020 - reward: -375.344, eps: 0.001 loss: 293.965 avg. loss: -343.886\n",
      "Episode 7030 - reward: -119.079, eps: 0.001 loss: 1154.818 avg. loss: -343.580\n",
      "Episode 7040 - reward: -155.120, eps: 0.001 loss: 30098.623 avg. loss: -408.916\n",
      "Episode 7050 - reward: -488.024, eps: 0.001 loss: 1078.699 avg. loss: -366.271\n",
      "Episode 7060 - reward: -278.580, eps: 0.001 loss: 904.806 avg. loss: -389.651\n",
      "Episode 7070 - reward: -599.562, eps: 0.001 loss: 573.550 avg. loss: -392.583\n",
      "Episode 7080 - reward: -546.166, eps: 0.001 loss: 569.063 avg. loss: -422.366\n",
      "Episode 7090 - reward: -326.233, eps: 0.001 loss: 522.871 avg. loss: -375.558\n",
      "Episode 7100 - reward: -595.591, eps: 0.001 loss: 523.450 avg. loss: -403.077\n",
      "Episode 7110 - reward: -640.829, eps: 0.001 loss: 1193.313 avg. loss: -437.249\n",
      "Episode 7120 - reward: -353.483, eps: 0.001 loss: 545.569 avg. loss: -464.817\n",
      "Episode 7130 - reward: -681.287, eps: 0.001 loss: 12079.469 avg. loss: -372.439\n",
      "Episode 7140 - reward: -107.868, eps: 0.001 loss: 1035.129 avg. loss: -394.303\n",
      "Episode 7150 - reward: -396.310, eps: 0.001 loss: 619.736 avg. loss: -415.611\n",
      "Episode 7160 - reward: -348.873, eps: 0.001 loss: 578.011 avg. loss: -451.507\n",
      "Episode 7170 - reward: -688.323, eps: 0.001 loss: 243.670 avg. loss: -492.501\n",
      "Episode 7180 - reward: -580.063, eps: 0.001 loss: 3822.692 avg. loss: -369.407\n",
      "Episode 7190 - reward: -324.550, eps: 0.001 loss: 790.863 avg. loss: -481.064\n",
      "Episode 7200 - reward: -438.291, eps: 0.001 loss: 1422.418 avg. loss: -404.112\n",
      "Episode 7210 - reward: -516.153, eps: 0.001 loss: 1561.550 avg. loss: -476.983\n",
      "Episode 7220 - reward: -487.779, eps: 0.001 loss: 1038.581 avg. loss: -503.695\n",
      "Episode 7230 - reward: -509.358, eps: 0.001 loss: 1554.886 avg. loss: -508.764\n",
      "Episode 7240 - reward: -370.727, eps: 0.001 loss: 4440.841 avg. loss: -490.480\n",
      "Episode 7250 - reward: -325.714, eps: 0.001 loss: 2982.578 avg. loss: -467.436\n",
      "Episode 7260 - reward: -419.431, eps: 0.001 loss: 89870.242 avg. loss: -451.855\n",
      "Episode 7270 - reward: -492.777, eps: 0.001 loss: 4702.707 avg. loss: -499.440\n",
      "Episode 7280 - reward: -487.784, eps: 0.001 loss: 2147.262 avg. loss: -502.378\n",
      "Episode 7290 - reward: -625.166, eps: 0.001 loss: 1062.537 avg. loss: -520.143\n",
      "Episode 7300 - reward: -558.981, eps: 0.001 loss: 3278.726 avg. loss: -511.920\n",
      "Episode 7310 - reward: -378.216, eps: 0.001 loss: 2705.763 avg. loss: -522.933\n",
      "Episode 7320 - reward: -120.452, eps: 0.001 loss: 1727.488 avg. loss: -504.448\n",
      "Episode 7330 - reward: -643.657, eps: 0.001 loss: 11059.218 avg. loss: -582.716\n",
      "Episode 7340 - reward: -487.189, eps: 0.001 loss: 2647.471 avg. loss: -513.375\n",
      "Episode 7350 - reward: -612.897, eps: 0.001 loss: 10958.592 avg. loss: -532.452\n",
      "Episode 7360 - reward: -676.065, eps: 0.001 loss: 1753.567 avg. loss: -585.140\n",
      "Episode 7370 - reward: -352.651, eps: 0.001 loss: 3059.397 avg. loss: -485.121\n",
      "Episode 7380 - reward: -635.409, eps: 0.001 loss: 45887.012 avg. loss: -515.280\n",
      "Episode 7390 - reward: -619.378, eps: 0.001 loss: 2749.382 avg. loss: -582.214\n",
      "Episode 7400 - reward: -646.482, eps: 0.001 loss: 3003.298 avg. loss: -529.719\n",
      "Episode 7410 - reward: -633.817, eps: 0.001 loss: 2774.139 avg. loss: -514.444\n",
      "Episode 7420 - reward: -241.334, eps: 0.001 loss: 4581.928 avg. loss: -342.103\n",
      "Episode 7430 - reward: -438.483, eps: 0.001 loss: 162206.906 avg. loss: -549.141\n",
      "Episode 7440 - reward: -613.196, eps: 0.001 loss: 4467.147 avg. loss: -462.354\n",
      "Episode 7450 - reward: -523.910, eps: 0.001 loss: 1694.572 avg. loss: -494.953\n",
      "Episode 7460 - reward: -562.568, eps: 0.001 loss: 1956.254 avg. loss: -568.765\n",
      "Episode 7470 - reward: -784.779, eps: 0.001 loss: 4461.745 avg. loss: -600.109\n",
      "Episode 7480 - reward: -700.656, eps: 0.001 loss: 82638.969 avg. loss: -422.722\n",
      "Episode 7490 - reward: -661.904, eps: 0.001 loss: 3359.150 avg. loss: -544.184\n",
      "Episode 7500 - reward: -696.312, eps: 0.001 loss: 2883.831 avg. loss: -479.452\n",
      "Episode 7510 - reward: -509.387, eps: 0.001 loss: 76697.195 avg. loss: -494.163\n",
      "Episode 7520 - reward: -574.581, eps: 0.001 loss: 5060.044 avg. loss: -479.475\n",
      "Episode 7530 - reward: -880.244, eps: 0.001 loss: 27823.561 avg. loss: -498.646\n",
      "Episode 7540 - reward: -865.957, eps: 0.001 loss: 2659.454 avg. loss: -552.292\n",
      "Episode 7550 - reward: -30.516, eps: 0.001 loss: 5145.590 avg. loss: -646.947\n",
      "Episode 7560 - reward: -706.044, eps: 0.001 loss: 4705.350 avg. loss: -533.808\n",
      "Episode 7570 - reward: -583.799, eps: 0.001 loss: 88308.359 avg. loss: -640.881\n",
      "Episode 7580 - reward: -596.122, eps: 0.001 loss: 8839.838 avg. loss: -522.654\n",
      "Episode 7590 - reward: -785.343, eps: 0.001 loss: 4987.680 avg. loss: -537.735\n",
      "Episode 7600 - reward: -331.490, eps: 0.001 loss: 124318.297 avg. loss: -582.018\n",
      "Episode 7610 - reward: -649.940, eps: 0.001 loss: 7134.431 avg. loss: -515.588\n",
      "Episode 7620 - reward: -349.906, eps: 0.001 loss: 14740.290 avg. loss: -425.990\n",
      "Episode 7630 - reward: -570.908, eps: 0.001 loss: 5374.603 avg. loss: -469.838\n",
      "Episode 7640 - reward: -134.793, eps: 0.001 loss: 377580.531 avg. loss: -499.778\n",
      "Episode 7650 - reward: -376.491, eps: 0.001 loss: 122476.938 avg. loss: -522.449\n",
      "Episode 7660 - reward: -479.239, eps: 0.001 loss: 42901.316 avg. loss: -599.548\n",
      "Episode 7670 - reward: -771.179, eps: 0.001 loss: 4888.786 avg. loss: -708.108\n",
      "Episode 7680 - reward: -489.628, eps: 0.001 loss: 4877.800 avg. loss: -537.986\n",
      "Episode 7690 - reward: -845.847, eps: 0.001 loss: 6437.525 avg. loss: -531.596\n",
      "Episode 7700 - reward: -692.022, eps: 0.001 loss: 70840.797 avg. loss: -604.596\n",
      "Episode 7710 - reward: -735.520, eps: 0.001 loss: 34319.102 avg. loss: -663.561\n",
      "Episode 7720 - reward: -128.453, eps: 0.001 loss: 5075.283 avg. loss: -511.262\n",
      "Episode 7730 - reward: -144.954, eps: 0.001 loss: 5902.804 avg. loss: -633.819\n",
      "Episode 7740 - reward: -685.369, eps: 0.001 loss: 7723.611 avg. loss: -649.344\n",
      "Episode 7750 - reward: -579.300, eps: 0.001 loss: 8095.013 avg. loss: -495.068\n",
      "Episode 7760 - reward: -556.371, eps: 0.001 loss: 26668.766 avg. loss: -572.232\n",
      "Episode 7770 - reward: -563.589, eps: 0.001 loss: 8543.222 avg. loss: -423.694\n",
      "Episode 7780 - reward: -112.153, eps: 0.001 loss: 104641.352 avg. loss: -471.576\n",
      "Episode 7790 - reward: -497.231, eps: 0.001 loss: 279316.750 avg. loss: -570.684\n",
      "Episode 7800 - reward: -350.901, eps: 0.001 loss: 7713.887 avg. loss: -582.914\n",
      "Episode 7810 - reward: -115.945, eps: 0.001 loss: 23253.258 avg. loss: -414.893\n",
      "Episode 7820 - reward: -645.473, eps: 0.001 loss: 109770.562 avg. loss: -403.685\n",
      "Episode 7830 - reward: -721.904, eps: 0.001 loss: 147278.406 avg. loss: -555.377\n",
      "Episode 7840 - reward: -720.013, eps: 0.001 loss: 13120.258 avg. loss: -566.486\n",
      "Episode 7850 - reward: -354.279, eps: 0.001 loss: 7340.794 avg. loss: -468.208\n",
      "Episode 7860 - reward: -659.387, eps: 0.001 loss: 75437.273 avg. loss: -604.448\n",
      "Episode 7870 - reward: -157.844, eps: 0.001 loss: 8954.691 avg. loss: -607.157\n",
      "Episode 7880 - reward: -538.590, eps: 0.001 loss: 11321.838 avg. loss: -486.742\n",
      "Episode 7890 - reward: -700.088, eps: 0.001 loss: 179784.125 avg. loss: -649.122\n",
      "Episode 7900 - reward: -780.622, eps: 0.001 loss: 252606.078 avg. loss: -647.493\n",
      "Episode 7910 - reward: -468.077, eps: 0.001 loss: 417524.094 avg. loss: -611.067\n",
      "Episode 7920 - reward: -777.717, eps: 0.001 loss: 379081.125 avg. loss: -589.710\n",
      "Episode 7930 - reward: -709.772, eps: 0.001 loss: 8838.076 avg. loss: -595.249\n",
      "Episode 7940 - reward: -829.201, eps: 0.001 loss: 62651.363 avg. loss: -973.804\n",
      "Episode 7950 - reward: -410.426, eps: 0.001 loss: 145030.875 avg. loss: -695.067\n",
      "Episode 7960 - reward: -1203.398, eps: 0.001 loss: 17173.660 avg. loss: -1058.726\n",
      "Episode 7970 - reward: -523.568, eps: 0.001 loss: 15546.182 avg. loss: -742.393\n",
      "Episode 7980 - reward: -827.077, eps: 0.001 loss: 20104.775 avg. loss: -830.997\n",
      "Episode 7990 - reward: -700.783, eps: 0.001 loss: 510480.750 avg. loss: -858.554\n",
      "Episode 8000 - reward: -95.723, eps: 0.001 loss: 335640.625 avg. loss: -485.601\n",
      "Episode 8010 - reward: -744.897, eps: 0.001 loss: 22527.066 avg. loss: -951.711\n",
      "Episode 8020 - reward: -87.984, eps: 0.001 loss: 204949.766 avg. loss: -914.322\n",
      "Episode 8030 - reward: -119.073, eps: 0.001 loss: 43059.402 avg. loss: -886.950\n",
      "Episode 8040 - reward: -1975.655, eps: 0.001 loss: 814164.875 avg. loss: -784.295\n",
      "Episode 8050 - reward: -118.382, eps: 0.001 loss: 46342.211 avg. loss: -797.242\n",
      "Episode 8060 - reward: -109.670, eps: 0.001 loss: 338211.375 avg. loss: -551.693\n",
      "Episode 8070 - reward: -132.757, eps: 0.001 loss: 228416.531 avg. loss: -893.068\n",
      "Episode 8080 - reward: -2263.349, eps: 0.001 loss: 50806.242 avg. loss: -1347.071\n",
      "Episode 8090 - reward: -556.610, eps: 0.001 loss: 43456.895 avg. loss: -1096.060\n",
      "Episode 8100 - reward: -444.865, eps: 0.001 loss: 432587.938 avg. loss: -494.608\n",
      "Episode 8110 - reward: -853.523, eps: 0.001 loss: 107597.281 avg. loss: -709.368\n",
      "Episode 8120 - reward: -527.075, eps: 0.001 loss: 239132.156 avg. loss: -640.661\n",
      "Episode 8130 - reward: -671.955, eps: 0.001 loss: 25144.203 avg. loss: -601.918\n",
      "Episode 8140 - reward: -610.708, eps: 0.001 loss: 54420.777 avg. loss: -653.439\n",
      "Episode 8150 - reward: -757.359, eps: 0.001 loss: 97132.680 avg. loss: -550.719\n",
      "Episode 8160 - reward: -869.574, eps: 0.001 loss: 78195.133 avg. loss: -690.785\n",
      "Episode 8170 - reward: -1255.526, eps: 0.001 loss: 46810.500 avg. loss: -782.171\n",
      "Episode 8180 - reward: -129.315, eps: 0.001 loss: 371286.281 avg. loss: -571.186\n",
      "Episode 8190 - reward: -144.736, eps: 0.001 loss: 41584.078 avg. loss: -467.419\n",
      "Episode 8200 - reward: -148.512, eps: 0.001 loss: 82587.992 avg. loss: -669.970\n",
      "Episode 8210 - reward: -14.239, eps: 0.001 loss: 74470.547 avg. loss: -634.472\n",
      "Episode 8220 - reward: -887.927, eps: 0.001 loss: 5610920.500 avg. loss: -687.256\n",
      "Episode 8230 - reward: -552.025, eps: 0.001 loss: 697257.812 avg. loss: -487.214\n",
      "Episode 8240 - reward: -1829.365, eps: 0.001 loss: 94748.586 avg. loss: -791.692\n",
      "Episode 8250 - reward: -139.187, eps: 0.001 loss: 6952906.000 avg. loss: -525.778\n",
      "Episode 8260 - reward: -136.423, eps: 0.001 loss: 231048.203 avg. loss: -599.230\n",
      "Episode 8270 - reward: -118.603, eps: 0.001 loss: 91865.367 avg. loss: -570.105\n",
      "Episode 8280 - reward: -918.940, eps: 0.001 loss: 319323.531 avg. loss: -737.726\n",
      "Episode 8290 - reward: -131.998, eps: 0.001 loss: 6516452.500 avg. loss: -871.229\n",
      "Episode 8300 - reward: -816.278, eps: 0.001 loss: 478111.500 avg. loss: -922.604\n",
      "Episode 8310 - reward: -1297.079, eps: 0.001 loss: 188937.922 avg. loss: -778.438\n",
      "Episode 8320 - reward: -1333.144, eps: 0.001 loss: 558817.938 avg. loss: -711.873\n",
      "Episode 8330 - reward: -87.871, eps: 0.001 loss: 93957.289 avg. loss: -502.329\n",
      "Episode 8340 - reward: -1389.391, eps: 0.001 loss: 158608.203 avg. loss: -916.084\n",
      "Episode 8350 - reward: -783.861, eps: 0.001 loss: 236778.500 avg. loss: -742.830\n",
      "Episode 8360 - reward: -535.545, eps: 0.001 loss: 219661.531 avg. loss: -519.199\n",
      "Episode 8370 - reward: -317.342, eps: 0.001 loss: 423833.344 avg. loss: -1822.681\n",
      "Episode 8380 - reward: -89.224, eps: 0.001 loss: 5963299.000 avg. loss: -474.122\n",
      "Episode 8390 - reward: -252.429, eps: 0.001 loss: 4016878.250 avg. loss: -1372.869\n",
      "Episode 8400 - reward: -117.352, eps: 0.001 loss: 973831.875 avg. loss: -348.403\n",
      "Episode 8410 - reward: -362.541, eps: 0.001 loss: 16369799.000 avg. loss: -732.261\n",
      "Episode 8420 - reward: -159.842, eps: 0.001 loss: 441990.688 avg. loss: -661.470\n",
      "Episode 8430 - reward: -1031.232, eps: 0.001 loss: 213246432.000 avg. loss: -453.703\n",
      "Episode 8440 - reward: -180.835, eps: 0.001 loss: 354256.562 avg. loss: -243.661\n",
      "Episode 8450 - reward: -13.075, eps: 0.001 loss: 2132137.750 avg. loss: -476.939\n",
      "Episode 8460 - reward: -830.141, eps: 0.001 loss: 1344331.250 avg. loss: -540.902\n",
      "Episode 8470 - reward: -155.511, eps: 0.001 loss: 163312.641 avg. loss: -597.820\n",
      "Episode 8480 - reward: -1075.048, eps: 0.001 loss: 280839200.000 avg. loss: -762.065\n",
      "Episode 8490 - reward: -230.180, eps: 0.001 loss: 11220803.000 avg. loss: -766.589\n",
      "Episode 8500 - reward: -262.036, eps: 0.001 loss: 1726038.750 avg. loss: -406.036\n",
      "Episode 8510 - reward: -251.944, eps: 0.001 loss: 727606.000 avg. loss: -698.430\n",
      "Episode 8520 - reward: -710.212, eps: 0.001 loss: 8726282.000 avg. loss: -1083.794\n",
      "Episode 8530 - reward: -654.787, eps: 0.001 loss: 877590.375 avg. loss: -483.301\n",
      "Episode 8540 - reward: -137.160, eps: 0.001 loss: 1511701.250 avg. loss: -581.899\n",
      "Episode 8550 - reward: -386.991, eps: 0.001 loss: 3029965.000 avg. loss: -507.473\n",
      "Episode 8560 - reward: -2642.200, eps: 0.001 loss: 1918054.125 avg. loss: -793.913\n",
      "Episode 8570 - reward: -130.308, eps: 0.001 loss: 67874224.000 avg. loss: -901.166\n",
      "Episode 8580 - reward: -138.238, eps: 0.001 loss: 15272116.000 avg. loss: -680.348\n",
      "Episode 8590 - reward: -1893.448, eps: 0.001 loss: 1190289.500 avg. loss: -815.905\n",
      "Episode 8600 - reward: -139.334, eps: 0.001 loss: 107358072.000 avg. loss: -958.222\n",
      "Episode 8610 - reward: -1537.366, eps: 0.001 loss: 1113625.750 avg. loss: -1235.415\n",
      "Episode 8620 - reward: -2805.972, eps: 0.001 loss: 436021.469 avg. loss: -965.641\n",
      "Episode 8630 - reward: -753.775, eps: 0.001 loss: 641512.625 avg. loss: -807.392\n",
      "Episode 8640 - reward: -183.047, eps: 0.001 loss: 1738884.625 avg. loss: -729.892\n",
      "Episode 8650 - reward: -1875.496, eps: 0.001 loss: 3959709.500 avg. loss: -1344.875\n",
      "Episode 8660 - reward: -1880.670, eps: 0.001 loss: 7811400.000 avg. loss: -684.046\n",
      "Episode 8670 - reward: -520.189, eps: 0.001 loss: 8841442.000 avg. loss: -801.812\n",
      "Episode 8680 - reward: -845.878, eps: 0.001 loss: 4941541.000 avg. loss: -574.412\n",
      "Episode 8690 - reward: -166.412, eps: 0.001 loss: 1325680.750 avg. loss: -878.891\n",
      "Episode 8700 - reward: -803.663, eps: 0.001 loss: 19242556.000 avg. loss: -752.510\n",
      "Episode 8710 - reward: -175.434, eps: 0.001 loss: 46412276.000 avg. loss: -956.923\n",
      "Episode 8720 - reward: -583.867, eps: 0.001 loss: 11325533.000 avg. loss: -490.442\n",
      "Episode 8730 - reward: -939.063, eps: 0.001 loss: 5513077248.000 avg. loss: -632.237\n",
      "Episode 8740 - reward: -154.206, eps: 0.001 loss: 9928577.000 avg. loss: -739.993\n",
      "Episode 8750 - reward: -1188.092, eps: 0.001 loss: 4702562.500 avg. loss: -578.438\n",
      "Episode 8760 - reward: -308.420, eps: 0.001 loss: 3405618.000 avg. loss: -617.341\n",
      "Episode 8770 - reward: -718.071, eps: 0.001 loss: 6492805.500 avg. loss: -1014.059\n",
      "Episode 8780 - reward: -786.563, eps: 0.001 loss: 9578372.000 avg. loss: -836.176\n",
      "Episode 8790 - reward: -885.873, eps: 0.001 loss: 24254724.000 avg. loss: -541.251\n",
      "Episode 8800 - reward: -502.866, eps: 0.001 loss: 2973784.000 avg. loss: -398.212\n",
      "Episode 8810 - reward: -996.936, eps: 0.001 loss: 4512710.000 avg. loss: -501.191\n",
      "Episode 8820 - reward: -158.981, eps: 0.001 loss: 12576082.000 avg. loss: -318.293\n",
      "Episode 8830 - reward: -231.129, eps: 0.001 loss: 20682076.000 avg. loss: -454.294\n",
      "Episode 8840 - reward: -1182.671, eps: 0.001 loss: 3956037.000 avg. loss: -506.711\n",
      "Episode 8850 - reward: -1211.185, eps: 0.001 loss: 12453615.000 avg. loss: -456.090\n",
      "Episode 8860 - reward: -155.836, eps: 0.001 loss: 113153192.000 avg. loss: -167.914\n",
      "Episode 8870 - reward: -147.367, eps: 0.001 loss: 15419029.000 avg. loss: -198.256\n",
      "Episode 8880 - reward: -169.745, eps: 0.001 loss: 1801043.000 avg. loss: -274.847\n",
      "Episode 8890 - reward: -142.342, eps: 0.001 loss: 8757560.000 avg. loss: -319.914\n",
      "Episode 8900 - reward: -164.631, eps: 0.001 loss: 26219242.000 avg. loss: -224.573\n",
      "Episode 8910 - reward: -229.867, eps: 0.001 loss: 6229130.000 avg. loss: -242.100\n",
      "Episode 8920 - reward: -19.025, eps: 0.001 loss: 6858537.500 avg. loss: -134.783\n",
      "Episode 8930 - reward: -427.457, eps: 0.001 loss: 28839502.000 avg. loss: -309.765\n",
      "Episode 8940 - reward: -136.355, eps: 0.001 loss: 2164664.500 avg. loss: -148.886\n",
      "Episode 8950 - reward: -1499.831, eps: 0.001 loss: 161171296.000 avg. loss: -599.271\n",
      "Episode 8960 - reward: -142.147, eps: 0.001 loss: 530262528.000 avg. loss: -294.480\n",
      "Episode 8970 - reward: -154.478, eps: 0.001 loss: 6837199360.000 avg. loss: -522.801\n",
      "Episode 8980 - reward: -706.446, eps: 0.001 loss: 3492936.000 avg. loss: -405.679\n",
      "Episode 8990 - reward: -147.142, eps: 0.001 loss: 4815791.000 avg. loss: -400.700\n",
      "Episode 9000 - reward: -160.553, eps: 0.001 loss: 42988316.000 avg. loss: -351.909\n",
      "Episode 9010 - reward: -432.100, eps: 0.001 loss: 3116389.500 avg. loss: -581.159\n",
      "Episode 9020 - reward: -684.330, eps: 0.001 loss: 26665824.000 avg. loss: -414.906\n",
      "Episode 9030 - reward: -967.322, eps: 0.001 loss: 5787281.000 avg. loss: -462.623\n",
      "Episode 9040 - reward: -168.985, eps: 0.001 loss: 249488640.000 avg. loss: -512.100\n",
      "Episode 9050 - reward: -664.472, eps: 0.001 loss: 274734336.000 avg. loss: -809.633\n",
      "Episode 9060 - reward: -1505.605, eps: 0.001 loss: 26301864.000 avg. loss: -431.407\n",
      "Episode 9070 - reward: -584.192, eps: 0.001 loss: 17733556.000 avg. loss: -227.404\n",
      "Episode 9080 - reward: -836.313, eps: 0.001 loss: 35383488.000 avg. loss: -489.901\n",
      "Episode 9090 - reward: -221.412, eps: 0.001 loss: 51022444.000 avg. loss: -436.006\n",
      "Episode 9100 - reward: -442.127, eps: 0.001 loss: 5096942.500 avg. loss: -338.505\n",
      "Episode 9110 - reward: -45.484, eps: 0.001 loss: 9466672.000 avg. loss: -155.651\n",
      "Episode 9120 - reward: -28.112, eps: 0.001 loss: 66076696.000 avg. loss: -305.810\n",
      "Episode 9130 - reward: -123.686, eps: 0.001 loss: 5776520.500 avg. loss: -340.103\n",
      "Episode 9140 - reward: -600.306, eps: 0.001 loss: 9297508.000 avg. loss: -447.199\n",
      "Episode 9150 - reward: -184.015, eps: 0.001 loss: 50396404.000 avg. loss: -321.798\n",
      "Episode 9160 - reward: -278.135, eps: 0.001 loss: 102191480.000 avg. loss: -250.713\n",
      "Episode 9170 - reward: -679.895, eps: 0.001 loss: 24162864.000 avg. loss: -491.729\n",
      "Episode 9180 - reward: -319.780, eps: 0.001 loss: 3400322.500 avg. loss: -280.938\n",
      "Episode 9190 - reward: -789.392, eps: 0.001 loss: 9379307.000 avg. loss: -296.009\n",
      "Episode 9200 - reward: -281.802, eps: 0.001 loss: 5230160.500 avg. loss: -423.851\n",
      "Episode 9210 - reward: -928.738, eps: 0.001 loss: 2275970.250 avg. loss: -600.772\n",
      "Episode 9220 - reward: -480.771, eps: 0.001 loss: 19248920.000 avg. loss: -480.106\n",
      "Episode 9230 - reward: -299.317, eps: 0.001 loss: 2149497.000 avg. loss: -629.399\n",
      "Episode 9240 - reward: -214.400, eps: 0.001 loss: 18328350.000 avg. loss: -531.562\n",
      "Episode 9250 - reward: -565.503, eps: 0.001 loss: 5495581.000 avg. loss: -622.154\n",
      "Episode 9260 - reward: -103.922, eps: 0.001 loss: 11468096.000 avg. loss: -556.082\n",
      "Episode 9270 - reward: -462.405, eps: 0.001 loss: 85022728.000 avg. loss: -570.702\n",
      "Episode 9280 - reward: -602.237, eps: 0.001 loss: 2448258.000 avg. loss: -616.741\n",
      "Episode 9290 - reward: -147.662, eps: 0.001 loss: 6984418.000 avg. loss: -427.861\n",
      "Episode 9300 - reward: -338.267, eps: 0.001 loss: 68727440.000 avg. loss: -453.072\n",
      "Episode 9310 - reward: -336.098, eps: 0.001 loss: 3282025.000 avg. loss: -602.488\n",
      "Episode 9320 - reward: -500.920, eps: 0.001 loss: 108924792.000 avg. loss: -592.149\n",
      "Episode 9330 - reward: -166.298, eps: 0.001 loss: 21116684.000 avg. loss: -352.811\n",
      "Episode 9340 - reward: -595.236, eps: 0.001 loss: 10445275.000 avg. loss: -542.933\n",
      "Episode 9350 - reward: -672.116, eps: 0.001 loss: 1273544832.000 avg. loss: -489.780\n",
      "Episode 9360 - reward: -205.914, eps: 0.001 loss: 13250651.000 avg. loss: -470.269\n",
      "Episode 9370 - reward: -759.975, eps: 0.001 loss: 608625984.000 avg. loss: -571.711\n",
      "Episode 9380 - reward: -641.886, eps: 0.001 loss: 42374860.000 avg. loss: -525.987\n",
      "Episode 9390 - reward: -248.992, eps: 0.001 loss: 3213300.500 avg. loss: -616.617\n",
      "Episode 9400 - reward: -392.769, eps: 0.001 loss: 6321961.500 avg. loss: -610.218\n",
      "Episode 9410 - reward: -601.084, eps: 0.001 loss: 122096640.000 avg. loss: -579.828\n",
      "Episode 9420 - reward: -1279.080, eps: 0.001 loss: 12109756.000 avg. loss: -684.646\n",
      "Episode 9430 - reward: -613.166, eps: 0.001 loss: 1361138176.000 avg. loss: -699.699\n",
      "Episode 9440 - reward: -683.540, eps: 0.001 loss: 2556728.000 avg. loss: -551.595\n",
      "Episode 9450 - reward: -639.177, eps: 0.001 loss: 29559434.000 avg. loss: -659.535\n",
      "Episode 9460 - reward: -624.154, eps: 0.001 loss: 1985135744.000 avg. loss: -595.152\n",
      "Episode 9470 - reward: -594.753, eps: 0.001 loss: 2370921472.000 avg. loss: -608.980\n",
      "Episode 9480 - reward: -666.292, eps: 0.001 loss: 248025760.000 avg. loss: -603.560\n",
      "Episode 9490 - reward: -1192.649, eps: 0.001 loss: 1600152576.000 avg. loss: -659.383\n",
      "Episode 9500 - reward: -435.761, eps: 0.001 loss: 39527136.000 avg. loss: -744.354\n",
      "Episode 9510 - reward: -584.268, eps: 0.001 loss: 80510088.000 avg. loss: -521.882\n",
      "Episode 9520 - reward: -906.630, eps: 0.001 loss: 55207396.000 avg. loss: -753.440\n",
      "Episode 9530 - reward: -792.096, eps: 0.001 loss: 7913469.500 avg. loss: -744.000\n",
      "Episode 9540 - reward: -1243.685, eps: 0.001 loss: 15462432.000 avg. loss: -650.589\n",
      "Episode 9550 - reward: -530.665, eps: 0.001 loss: 116104896.000 avg. loss: -803.656\n",
      "Episode 9560 - reward: -732.530, eps: 0.001 loss: 10688691.000 avg. loss: -659.187\n",
      "Episode 9570 - reward: -800.177, eps: 0.001 loss: 44307408.000 avg. loss: -809.092\n",
      "Episode 9580 - reward: -715.734, eps: 0.001 loss: 72711368.000 avg. loss: -676.469\n",
      "Episode 9590 - reward: -473.711, eps: 0.001 loss: 23750800.000 avg. loss: -718.252\n",
      "Episode 9600 - reward: -512.990, eps: 0.001 loss: 566622336.000 avg. loss: -650.523\n",
      "Episode 9610 - reward: -672.264, eps: 0.001 loss: 82792704.000 avg. loss: -803.269\n",
      "Episode 9620 - reward: -817.773, eps: 0.001 loss: 3177615.000 avg. loss: -728.214\n",
      "Episode 9630 - reward: -1628.725, eps: 0.001 loss: 264484512.000 avg. loss: -687.108\n",
      "Episode 9640 - reward: -966.697, eps: 0.001 loss: 44313996.000 avg. loss: -710.555\n",
      "Episode 9650 - reward: -457.599, eps: 0.001 loss: 4854058.000 avg. loss: -698.836\n",
      "Episode 9660 - reward: -1137.136, eps: 0.001 loss: 258468384.000 avg. loss: -682.066\n",
      "Episode 9670 - reward: -578.714, eps: 0.001 loss: 38605236.000 avg. loss: -606.666\n",
      "Episode 9680 - reward: -546.489, eps: 0.001 loss: 22410130.000 avg. loss: -659.386\n",
      "Episode 9690 - reward: -1096.982, eps: 0.001 loss: 6741415.000 avg. loss: -691.740\n",
      "Episode 9700 - reward: -691.692, eps: 0.001 loss: 39618808.000 avg. loss: -703.765\n",
      "Episode 9710 - reward: -683.533, eps: 0.001 loss: 66207488.000 avg. loss: -636.134\n",
      "Episode 9720 - reward: -627.823, eps: 0.001 loss: 96133520.000 avg. loss: -623.533\n",
      "Episode 9730 - reward: -639.526, eps: 0.001 loss: 10084053.000 avg. loss: -655.214\n",
      "Episode 9740 - reward: -573.952, eps: 0.001 loss: 38506560.000 avg. loss: -637.140\n",
      "Episode 9750 - reward: -564.220, eps: 0.001 loss: 70028896.000 avg. loss: -720.226\n",
      "Episode 9760 - reward: -857.043, eps: 0.001 loss: 5398186.000 avg. loss: -650.352\n",
      "Episode 9770 - reward: -660.332, eps: 0.001 loss: 1162716032.000 avg. loss: -642.178\n",
      "Episode 9780 - reward: -649.335, eps: 0.001 loss: 10958718.000 avg. loss: -628.543\n",
      "Episode 9790 - reward: -658.730, eps: 0.001 loss: 5909189.000 avg. loss: -734.948\n",
      "Episode 9800 - reward: -374.329, eps: 0.001 loss: 100761504.000 avg. loss: -566.003\n",
      "Episode 9810 - reward: -619.467, eps: 0.001 loss: 131558240.000 avg. loss: -581.110\n",
      "Episode 9820 - reward: -713.742, eps: 0.001 loss: 19777944.000 avg. loss: -604.895\n",
      "Episode 9830 - reward: -351.785, eps: 0.001 loss: 12590566.000 avg. loss: -624.294\n",
      "Episode 9840 - reward: -606.041, eps: 0.001 loss: 9377564.000 avg. loss: -623.690\n",
      "Episode 9850 - reward: -552.463, eps: 0.001 loss: 20245708.000 avg. loss: -599.521\n",
      "Episode 9860 - reward: -491.050, eps: 0.001 loss: 16622623.000 avg. loss: -979.151\n",
      "Episode 9870 - reward: -579.366, eps: 0.001 loss: 60609316.000 avg. loss: -639.433\n",
      "Episode 9880 - reward: -700.012, eps: 0.001 loss: 273698368.000 avg. loss: -632.390\n",
      "Episode 9890 - reward: -539.678, eps: 0.001 loss: 40385788.000 avg. loss: -552.810\n",
      "Episode 9900 - reward: -545.495, eps: 0.001 loss: 8364575.000 avg. loss: -580.919\n",
      "Episode 9910 - reward: -491.319, eps: 0.001 loss: 99962288.000 avg. loss: -641.593\n",
      "Episode 9920 - reward: -656.267, eps: 0.001 loss: 100708224.000 avg. loss: -625.522\n",
      "Episode 9930 - reward: -334.046, eps: 0.001 loss: 102010400.000 avg. loss: -576.072\n",
      "Episode 9940 - reward: -872.731, eps: 0.001 loss: 9603062.000 avg. loss: -780.693\n",
      "Episode 9950 - reward: -539.813, eps: 0.001 loss: 11272557.000 avg. loss: -961.235\n",
      "Episode 9960 - reward: -1182.365, eps: 0.001 loss: 12855592.000 avg. loss: -954.652\n",
      "Episode 9970 - reward: -585.373, eps: 0.001 loss: 12296308.000 avg. loss: -969.469\n",
      "Episode 9980 - reward: -608.979, eps: 0.001 loss: 486662016.000 avg. loss: -622.537\n",
      "Episode 9990 - reward: -644.728, eps: 0.001 loss: 27127568.000 avg. loss: -658.853\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"LunarLander-v2\")  # create environment\n",
    "\n",
    "num_episodes = 10000\n",
    "policy.reset()\n",
    "rewards_history = []\n",
    "\n",
    "# Warmup phase!\n",
    "memory_filled = False\n",
    "print(\"Warmup phase...\")\n",
    "while not memory_filled:\n",
    "    \n",
    "    state = env.reset()  # 8 states: coordinates of the lander (x,y), linear velocities (x,y), angle, angular velocity, 2 bools if each leg is touches ground.\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:  # for each episode\n",
    "        # Get action and act in the world\n",
    "        state_tensor = T.from_numpy(state).float().to(device)\n",
    "        action = policy(state_tensor)  # <<--- choose greedy (choose index of highest q-value predicted by network) or exploration\n",
    "        next_state, reward, done, __ = env.step(action)\n",
    "        total_reward += float(reward)\n",
    "        \n",
    "        # Observe new state\n",
    "        if done:\n",
    "            next_state = None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, float(reward))\n",
    "        state = next_state\n",
    "\n",
    "    memory_filled = memory.capacity == len(memory)\n",
    "\n",
    "print('Done with the warmup')\n",
    "    \n",
    "    \n",
    "for i_episode in range(num_episodes):\n",
    "    # New dungeon at every run\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    \n",
    "    while not done:  # iterate through states\n",
    "        \n",
    "        # Get action and act in the world\n",
    "        state_tensor = T.from_numpy(state).float().to(device)  # <<--- convert state to tensor and move to GPU\n",
    "        \n",
    "        action = policy(state_tensor)   # choose greedy (index of q-value predictions) or exploration\n",
    "        next_state, reward, done, __ = env.step(action)\n",
    "        total_reward += float(reward)\n",
    "        \n",
    "        # Observe new state\n",
    "        if done:\n",
    "            next_state = None\n",
    "        memory.push(state, action, next_state, float(reward))  # Store the transition in memory\n",
    "        state = next_state  # Move to the next state\n",
    "\n",
    "        # Perform one step of the optimization\n",
    "        #started_training = True\n",
    "        loss = optimize_model()\n",
    "\n",
    "    policy.update_epsilon()\n",
    "    rewards_history.append( float(total_reward) )\n",
    "\n",
    "    \n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "\n",
    "        Q_target.load_state_dict(Q_network.state_dict())\n",
    "    \n",
    "    # if i_episode % 10 == 0: \n",
    "    #     env.render()\n",
    "    if i_episode % 10 == 0:\n",
    "        print('Episode {} - reward: {:.3f}, eps: {:.3f} loss: {:.3f} avg. loss: {:.3f}'.format(\n",
    "            i_episode, total_reward, policy.epsilon, loss, sum(rewards_history[-10:])/10))   \n",
    "\n",
    "print('Complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28b14d80d30>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rewards_history, 'b.', alpha=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ef810184dd1ed1e7e90889c2154f0f529619798a6f354d5d90c8edd2323b55a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('NC')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
